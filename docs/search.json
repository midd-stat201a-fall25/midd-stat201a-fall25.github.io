[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "",
    "text": "Welcome to the website for Middlebury College’s Spring 2025 STAT 201. On this website you will find the course syllabus, schedule, and assignments. The website is frequently updated throughout the semester, so please make a habit of refreshing the page. The icons at the top right will link to the supplemental textbook and Canvas."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "Course details",
    "text": "Course details\nInstructor: Prof. Becky Tang (she/her)\n\nOffice: WNS 214\nEmail: btang@middlebury.edu\n\nMeeting times and location:\n\nMW 11:15am-12:30pm in Warner 011\nR 11:15am-12:30pm in Warner 101\n\nOffice hours: Monday 2-3pm, Friday 10am-12pm\nTA hours in Quantitative Center (MBH 202):\n\nSunday, Monday, Thursdays 7-9pm\n\nThe syllabus (most recent update: 2/7/25) outlines our course policies and a rough schedule. Once classes begin, you should follow the schedule and due dates found on this website.\n\nNote the textbooks are optional in this class. However, several practice and homework problems are pulled from the OpenIntro textbook."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Jump to:\nTo print PDF of the slides with multiple slides on a page:"
  },
  {
    "objectID": "slides/slides-01-study-design.html#population-and-samples",
    "href": "slides/slides-01-study-design.html#population-and-samples",
    "title": "Study design",
    "section": "Population and samples",
    "text": "Population and samples\n\nData do not come from thin air! Data have to be collected in some way.\nThis usually takes the form of sampling a subset of individuals from a target group of interest\n\nThe target group of interest is called the population\nThe subset of individuals from whom we actually collect data is the sample\n\nA case is a fancy term for saying one observational unit\n\nWhat are the target populations in the following research questions? What would an individual case/unit be?\n\nWhat is the average height of trees on Middlebury College campus?\nWhat proportion of current Middlebury professors attended a liberal arts college?\nOver the last five years, what is the average time to complete a degree for Middlebury College students?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#example",
    "href": "slides/slides-01-study-design.html#example",
    "title": "Study design",
    "section": "Example",
    "text": "Example\nThe U.S. Census Bureau is responsible for producing data about the American people and economy.\n\nDecennial census\nAmerican community survey"
  },
  {
    "objectID": "slides/slides-01-study-design.html#parameters-and-statistics",
    "href": "slides/slides-01-study-design.html#parameters-and-statistics",
    "title": "Study design",
    "section": "Parameters and statistics",
    "text": "Parameters and statistics\n\nOften times, answering the research question simplifies to understanding a numerical summary.\n\nA numerical summary calculated from (or considered for calculation from) the entire population is called a (population) parameter\nIn contrast, a numerical summary calculated from the sample is called a (sample) statistic\n\nWhy do we differentiate? It’s always good to remember that we are trying to answer questions about the population!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#population-and-samples-cont.",
    "href": "slides/slides-01-study-design.html#population-and-samples-cont.",
    "title": "Study design",
    "section": "Population and samples (cont.)",
    "text": "Population and samples (cont.)\n\nTypically, the size of the sample is way smaller than the population. Why?\n\nIn the lucky event that we are able to collect data for every individual in the population, the sample is referred to as a census\n\nExample: the U.S. Census Bureau is responsible for producing data about the American people and economy. They collect data with different schemes and frequency:\n\nDecennial census\nAmerican community survey"
  },
  {
    "objectID": "slides/slides-01-study-design.html#a-good-sample",
    "href": "slides/slides-01-study-design.html#a-good-sample",
    "title": "Study design",
    "section": "A “good” sample",
    "text": "A “good” sample\n\nAsk class: do you like statistics? Expect: response, non-response, and selection bias due to convenience sampling\n\n\nThe way we sample data from a population can directly influence the quality of that sample.\n\nWhat are desirable characteristics of a sample?\n\n\nRepresentative: the sample roughly “looks like” the population\n\ni.e. the characteristics of participants in the sample are similar to those of the population\n\nGeneralizable: any results based on the sample can generalize to the population\n\ni.e. we can use results from a sample to draw conclusions about a specific population"
  },
  {
    "objectID": "slides/slides-01-study-design.html#bias-in-a-sample",
    "href": "slides/slides-01-study-design.html#bias-in-a-sample",
    "title": "Study design",
    "section": "Bias in a sample",
    "text": "Bias in a sample\n\nBiased samples occur when the methods used to obtain data result in inaccurate/skewed depictions of the population. This is bad!!\n\nCan occur if a sample is not representative\n\nBias in a sample can arise due to many causes. Here are just a few:\n\nSelection bias: systematic tendency in procedure that causes some members of population to be more likely to be included than others\nNon-response bias: the values of the response variable of non-respondents differ systematically from those that do respond\nResponse bias: systematic favoring of certain response variable values that occurs when people don’t answer truthfully (e.g. lying)\n\nAny type of bias could lead to our sample being non representative or not generalizable"
  },
  {
    "objectID": "slides/slides-01-study-design.html#simple-random-sampling",
    "href": "slides/slides-01-study-design.html#simple-random-sampling",
    "title": "Study design",
    "section": "Simple random sampling",
    "text": "Simple random sampling\n\nThe most intuitive and basic form of random sampling!\nEach individual is chosen entirely by chance from the population, each member of the population has an equal chance of being sampled.\n\nKnowing that an individual was sampled does not provide useful information about which other cases are included\nAny given fixed-size subset of the population is equally likely to be chosen.\n\n\nConsider again the research question: What proportion of current Middlebury professors attended a liberal arts college?\nHow might I obtain a sample random sample of 25 professors?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#stratified-sampling",
    "href": "slides/slides-01-study-design.html#stratified-sampling",
    "title": "Study design",
    "section": "2. Stratified sampling",
    "text": "2. Stratified sampling\n\nAssume that the population is/can be broken up into several different, distinct sub-populations or strata\n\nCases grouped into a strata should be similar to each other\n\nThen take a (simple) random sample from each stratum (“divide and conquer”)\n\nHow many from each stratum? Typically use a sampling fraction that is proportional to entire population!\nE.g. if population of trees on Middlebury campus are 80% deciduous and 20% coniferous and we want to sample \\(n = 10\\) trees total, we should randomly sample ___ deciduous and ___ coniferous trees\n\nWhat are some pros/cons?\n\n\n\nDepending on the population, we might need to use different random sampling methods to ensure the sample is representative\nMay be useful to ensure we have samples from rare groups, and helps to improve precision of the sample\nMost useful when stratifying variables are simple to work with, easy to observe, closely related to topic of survey\nCan be expensive to travel –> motivates the next type\nAnalyzing data from stratified sampling usually requires a more complex approach (beyond our scope here)"
  },
  {
    "objectID": "slides/slides-01-study-design.html#cluster-sampling",
    "href": "slides/slides-01-study-design.html#cluster-sampling",
    "title": "Study design",
    "section": "3. Cluster sampling",
    "text": "3. Cluster sampling\n\nDivide total population into \\(M\\) distinct groups or clusters of roughly equal size\nPerform a (simple) random sample on the \\(M\\) clusters, than sample all individuals within each of the randomly selected clusters\n\nDiscuss the following:\n\nWould you prefer the individuals within a cluster to be homogeneous (similar) or heterogeneous (varied)? Why?\nWould you prefer that cluster A and cluster B be relatively similar or different in terms of their sub-populations?\nWhat is the difference between stratified and cluster sampling?\n\n\n\n\n\nCreates pockets of sampled units –> reducing costs. Also useful when we cannot obtain a list of ALL units in the population, but can easily obtain a list of all units within a cluster\nLess efficient that SRS –> better to survey large number of small clusters than vice versa\n\nNeighboring units tend to be more similar –> sampling one being cluster would not represent a whole spectrum of variation present in the entire population\n\nDifficult to control final sample size. If you want a particular size n (e.g. 100), the other two methods are easier"
  },
  {
    "objectID": "slides/slides-01-study-design.html#multistage-sampling",
    "href": "slides/slides-01-study-design.html#multistage-sampling",
    "title": "Study design",
    "section": "Multistage sampling",
    "text": "Multistage sampling\n\nBuilds on the cluster sampling method, but rather than sampling all individuals within the selected clusters, only collect a random sample within each selected cluster\nThough seemingly more complicated, why might we prefer multistage sampling over cluster sampling?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#experimental-design",
    "href": "slides/slides-01-study-design.html#experimental-design",
    "title": "Study design",
    "section": "Experimental design",
    "text": "Experimental design\n\nExperiments are studies where the researcher assigns treatments to cases\n\nNote: experiments are often conducted in medical settings, hence the word “treatment”\n\nAre treatments considered explanatory or response variables?\n\n\nWhen the researcher randomly assigns the treatments, we have a randomized experiment\n\nRandomized experiments are critical when trying to assess the causal effect of the explanatory variable on the response variable\nNote: random assignment \\(\\ne\\) random sampling\n\n\n\nRunning example: quizzes and final exam. Want to know if having quizzes throughout semester boosts performance on final exam. Randomly assign half of class to do quizzes, and the other half to not. Then compare their final exam scores."
  },
  {
    "objectID": "slides/slides-01-study-design.html#confounding-variables",
    "href": "slides/slides-01-study-design.html#confounding-variables",
    "title": "Study design",
    "section": "Confounding variables",
    "text": "Confounding variables\n\nUnderstanding a causal relationship is made difficult by confounding variables: variables that are associated with both the explanatory and response variable of interest\n\n\nConfounders are bad!! Why?\n\n\nExample: consider a study that seeks to examine the effect of coffee consumption on heart disease.\n\nFrom each person, we only collect information on the average amount of coffee they consume per day and whether or not they have heart disease.\nWe find a positive association: more coffee \\(\\rightarrow\\) higher risk of heart disease\nPossible confounder: smoker status. Smokers tend to drink more coffee and tend to have higher rates of heart disease than non-smokers.\nSo the increase in heart disease may be due to smoker status rather than caffeine intake\n\n\n\nConfounders prevent us from attributing the cause to the (desired) explanatory variable!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#principles-of-experimental-design",
    "href": "slides/slides-01-study-design.html#principles-of-experimental-design",
    "title": "Study design",
    "section": "Principles of experimental design",
    "text": "Principles of experimental design\n\nRandomization: randomly assign patients to treatments\n\nHelps account possible confounding variables\n\nControlling for differences in the treatment: ensure that everyone follows the same protocol exactly\nReplication: the more cases we observe, the more confidence we have in the effect of the explanatory on the response\n\nAchieved by collecting a sufficiently large sample in a single study, or repeating the entire study more than once"
  },
  {
    "objectID": "slides/slides-01-study-design.html#principles-of-experimental-design-cont.",
    "href": "slides/slides-01-study-design.html#principles-of-experimental-design-cont.",
    "title": "Study design",
    "section": "Principles of experimental design (cont.)",
    "text": "Principles of experimental design (cont.)\n\nBlocking: suppose we know ahead of time that there is/are variable(s) that could influence the response besides just the explanatory. We assign patients to their respective blocks, and than randomly assign treatments within blocks.\n\nHelps to decrease unexplained variability by accounting for nuisance variables: variables that affect the response variable but are not of interest for answering the scientific question\nCan lead to greater interpretation of results"
  },
  {
    "objectID": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments",
    "href": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments",
    "title": "Study design",
    "section": "Reducing bias in human experiments",
    "text": "Reducing bias in human experiments\n\nBiases can still unintentionally arise in experiments, even if we follow these three principles.\nWe should make the experiment a blind experiment by not allowing participants to know which group they’ve been assigned to\n\nGive a fake treatment known as a placebo to those in the control group (e.g. a sugar pill that looks exactly like the actual treatment pill)\nPlacebo effect: a placebo results in a slight but real improvement in control patients\n\nDoctors and researchers involved in the study should also be blinded so they do not give preferential treatment or care to patients in certain groups.\n\nDouble-blind experiments: both the patients and the doctors/researchers who interact with patients are unaware of who is receive which treatment"
  },
  {
    "objectID": "slides/slides-01-study-design.html#treatment-vs.-control",
    "href": "slides/slides-01-study-design.html#treatment-vs.-control",
    "title": "Study design",
    "section": "Treatment vs. control",
    "text": "Treatment vs. control\n\nRandomized experiments are the gold standard for data collection, but biases can still occur!\nWhen we want to learn if the explanatory variable causes some effect in the response variable.\n\nWe have a control group which establishes a baseline, and typically receives “zero amount” of the explanatory variable.\nWe also have a treatment group which receives some “non-zero amount” of the explanatory variable\n\nExample: suppose we want to test the effect of a drug that is developed to help people fall asleep.\n\nTreatment group: receives 50mg of the drug in pill form\nControl group: does not receive the drug at all\n\nWhat is a potential issue?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#observational-studies-1",
    "href": "slides/slides-01-study-design.html#observational-studies-1",
    "title": "Study design",
    "section": "Observational studies",
    "text": "Observational studies\n\nStudies where no treatment is explictly applied\nNothing is manipulated; researchers simply record/observe without intervening\nTypically cannot obtain causal conclusions using data from observational studies\n\nThere are too many confounding variables at play in observational studies\n\nBut we can use these studies to identify associations or form hypotheses for future experiments!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#observational-studies",
    "href": "slides/slides-01-study-design.html#observational-studies",
    "title": "Study design",
    "section": "Observational studies",
    "text": "Observational studies\n\nCausal conclusions cannot be obtained using data from observational studies\n\nThere are too many confounding variables at play!\n\nBut they are much cheaper, and can be used to identify associations or form hypotheses for future experiments!"
  },
  {
    "objectID": "practice/practice-01-study-design.html",
    "href": "practice/practice-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "Please work on the practice problems in your group. At least one of the following problems will be assigned to the weekly problem set. Unless otherwise stated, problems come from the IMS textbook.\n\nTime to implement the sampling methods we learned! Keep track of your work on this problem; we will return to it in the next few classes.\nWe have a farmer who grows sunflowers for making sunflower oil. Her field is arranged in a grid pattern, with 12 rows and 12 columns as shown below. Water is important for crops, so irrigation ditches have been installed along the top and bottom of the field. It is expected that plants closer to a water source will perform better than those further away from water.\nThe farmer would like to estimate the number of healthy plants in the field, along with a few other characteristics about the sunflowers. It would be unfeasible to conduct a census, so we should choose to sample a subset of the grid cells. Suppose we’d like to sample \\(n = 12\\) grid cells total.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using simple random sampling. I should be able to read your work and know what to do without any questions! Think about how you will perform the random sampling.\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are rows. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are columns. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using cluster sampling where we have 24 clusters total. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using multistage sampling. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\n\nWe discussed several methods of sampling today. Now consider a new sampling scheme that is commonly used in the social sciences when sampling from a “hidden” population. A scenario might be that we want to conduct a poll among homeless people, but the research team may only have contact details for a few homeless people.\nDenote the initial contacts as Group 1. The sampling proceeds in the following stages:\n\nStage 1: ask the people in Group 1 to take the survey, and then provide contact details for other people from the population who might want to participate. Denote these new contacts as Group 2.\nStage 2: ask the people in Group 2 to take the survey, and then provide contact details for other people from the population who might want to participate. Denote these new contacts as Group 3.\nProceed in a similar manner until the researchers have sufficient data.\n\n\n\nWhat are some advantages to this method of sampling?\nWhat are some disadvantages? Think about statistically and also ethically.\n\n(2.5.20) To assess the effectiveness of taking large doses of vitamin C in reducing the duration of the common cold, researchers recruited 400 healthy volunteers from staff and students at a university. A quarter of the patients were assigned a placebo, and the rest were evenly divided between 1g Vitamin C, 3g Vitamin C, or 3g Vitamin C plus additives to be taken at onset of a cold for the following two days. All tablets had identical appearance and packaging. The nurses who handed the prescribed pills to the patients knew which patient received which treatment, but the researchers assessing the patients when they were sick did not. No statistically discernible differences were observed in any measure of cold duration or severity between the four groups, and the placebo group had the shortest duration of symptoms.\n\nWas this an experiment or an observational study? Why?\nWhat are the explanatory and response variables in this study?\nWere the patients blinded to their treatment?\nWas this study double-blind?\nParticipants are ultimately able to choose whether to use the pills prescribed to them. We might expect that not all of them will adhere and take their pills. Does this introduce a confounding variable to the study? Explain your reasoning."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#data",
    "href": "slides/slides-03-numerical-vis.html#data",
    "title": "Numerical data",
    "section": "Data",
    "text": "Data\nWhich of the following variables are numerical?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#scatterplots",
    "href": "slides/slides-03-numerical-vis.html#scatterplots",
    "title": "Numerical data",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are bivariate visualizations that prove a case-by-case view of the data for two numerical variables\n\nEach point represents the observed pair of values of variables 1 and 2 for each case in the dataset"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#scatterplots-cont.",
    "href": "slides/slides-03-numerical-vis.html#scatterplots-cont.",
    "title": "Numerical data",
    "section": "Scatterplots (cont.)",
    "text": "Scatterplots (cont.)\n\nHow do we determine which variable to put on each axis?\nWhat do scatterplots reveal about the data, and how are they useful?\nHow might we improve on this visualization?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#dot-plots",
    "href": "slides/slides-03-numerical-vis.html#dot-plots",
    "title": "Numerical data",
    "section": "Dot plots",
    "text": "Dot plots\n\nDot plots are a basic visualization that show the distribution of a single variable. They are univariate (one-variable) scatterplots.\nIn the following, we have a dot plot of BMI rounded to the nearest integer."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#binning",
    "href": "slides/slides-03-numerical-vis.html#binning",
    "title": "Numerical data",
    "section": "Binning",
    "text": "Binning\n\nDot plot display the exact value for each observation. Become hard to read when the variable of interest has a wide set of values\nWe will sacrifice a bit of precision for convenience by binning: we will consider segmenting the variable into equal-sized bins and visualize the value of each observation using its corresponding bin\nFor example, the bmi variable has observed values of \\(15.96\\) through \\(49.6\\). Consider the following bins of size 5:\n\n[14, 18), [18, 22), [22, 26), …, [48, 52)\n\nWe tabulate/count up the number of observations that fall into each bin.\n\n\n\n\n# A tibble: 8 × 2\n  bmi_bin  count\n  <chr>    <int>\n1 [15, 19)     5\n2 [19, 23)    12\n3 [23, 27)    35\n4 [27, 31)    58\n5 [31, 35)    41\n6 [35, 39)    35\n7 [39, 43)    13\n8 [49, 52)     1"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms",
    "href": "slides/slides-03-numerical-vis.html#histograms",
    "title": "Numerical data",
    "section": "Histograms",
    "text": "Histograms\nHistograms are visualizations that display the binned counts as bars for each bin."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms-cont.",
    "href": "slides/slides-03-numerical-vis.html#histograms-cont.",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHistograms provide a view of the density of the data; the values the data take on as well as how often\nVery helpful for understanding the shape of the data distribution\n\nDistributions are either symmetric or skewed in a one direction\nDistributions with long tails to the left are called left-skewed, whereas distributions with long tails to the right are right-skewed\n\nAlso helpful for identifying modes which are prominent peaks in the distribution\n\nDistribution may be unimodal (one peak), bimodal (two peaks), or multimodal (more than two peaks)\nPeaks need not be same height in histogram"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms-cont.-1",
    "href": "slides/slides-03-numerical-vis.html#histograms-cont.-1",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape and modality in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#mean",
    "href": "slides/slides-03-numerical-vis.html#mean",
    "title": "Numerical data",
    "section": "Mean",
    "text": "Mean\n\nBy far the most common way to measure the center of the distribution of numerical data is using the mean, also called the average\nWe use the term sample mean when referring to the mean of observed/sampled data, which is typically denoted as \\(\\bar{x}\\)\n\n\\(x\\) is a placeholder for the variable of interest (e.g. BMI, charges)\nThe bar communicates that we are looking at the average\n\nThe (sample) mean is the sum over all the values of the variable, divided by total number of observations \\(n\\):\n\n\n\\[\\bar{x} = \\frac{x_{1} + x_{2} + \\ldots x_{n}}{n} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\]"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#mean-cont.",
    "href": "slides/slides-03-numerical-vis.html#mean-cont.",
    "title": "Numerical data",
    "section": "Mean (cont.)",
    "text": "Mean (cont.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample mean \\(\\bar{x}\\) is an example of a sample statistic\nThe mean over the entire population is an example of a population parameter. The population mean is often denoted \\(\\mu\\) (Greek letter mu)\nThe sample mean \\(\\bar{x}\\) is often used as an estimate for \\(\\mu\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#live-code",
    "href": "slides/slides-03-numerical-vis.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\n\nBase R\nggplot"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#example",
    "href": "slides/slides-03-numerical-vis.html#example",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nSuppose we have obtained the following data on diastolic blood pressure from patients at Porter Hospital:\n\\[\n\\boldsymbol{x} =76, 64, 62, 81, 70, 72, 81, 63, 67, 77\n\\]\n\nWrite out how you would calculate \\(\\bar{x}\\)\nThen we will use R to calculate the sample mean diastolic blood pressure!"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#means-depend-on-proportions",
    "href": "slides/slides-03-numerical-vis.html#means-depend-on-proportions",
    "title": "Numerical data",
    "section": "Means depend on proportions",
    "text": "Means depend on proportions\n\n\nWhat is the average of the following values: \\(1, 4, 4\\)?\n\n\n\\(\\bar{x} = \\frac{1+4+4}{3} = 1\\left(\\frac{1}{3} \\right) + 4\\left( \\frac{2}{3}\\right) = \\frac{9}{3} = 3\\)\n\n\nIf instead there were 10 1’s and 20 4’s, would the average be the same?\n\n\nYes! \\(\\bar{x} = 1\\left(\\frac{10}{30}\\right) + 4 \\left(\\frac{20}{30} \\right) = \\frac{90}{30} = 3\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variability",
    "href": "slides/slides-03-numerical-vis.html#variability",
    "title": "Numerical data",
    "section": "Variability",
    "text": "Variability\n\nWe learned that the mean is a way to describe the center or “average value” of a numerical variable\nHowever, at the heart of statistics is also the variability or spread of the distribution of the variable\nWe will work with variance and standard deviation, which describe how spread out data are from their mean"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#deviation",
    "href": "slides/slides-03-numerical-vis.html#deviation",
    "title": "Numerical data",
    "section": "Deviation",
    "text": "Deviation\nWe return to the blood pressure data:\n\\[\n\\boldsymbol{x} = 76, 64, 62, 81, 70, 72, 81, 63, 67, 77 \\qquad \\qquad \\qquad \\bar{x} = 71.3\n\\]\n\nWe start with deviation, which is the distance of or difference between an observation from the (sample) mean\n\nHow might we write this using statistical notation?\n\n\n\n\n\n    x deviation\n1  76       4.7\n2  64      -7.3\n3  62      -9.3\n4  81       9.7\n5  70      -1.3\n6  72       0.7\n7  81       9.7\n8  63      -8.3\n9  67      -4.3\n10 77       5.7"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation",
    "href": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation",
    "title": "Numerical data",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\nThe sample variance \\(s^2\\) squares the deviations and takes an average:\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^2}{n-1}\n\\]\n\nLet’s talk about this notation and intuition behind this formula. In particular, there are at least two things to note\n\nThe sample standard deviation \\(s\\) is simply the square root of the sample variance (\\(s = \\sqrt{s^2}\\))\nCalculate the sample variance and standard deviation for the blood pressure data\n\nBy hand\nUsing R"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation-cont.",
    "href": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation-cont.",
    "title": "Numerical data",
    "section": "Variance and standard deviation (cont.)",
    "text": "Variance and standard deviation (cont.)\n\nLike the mean, the population values for variance and standard deviation are denoted with Greek letters:\n\n\\(\\sigma\\) for population standard deviation (sigma)\n\\(\\sigma^2\\) for population variance\n\n\nIf the calculation of standard deviation is a more complicated quantity than the variance, why do we bother with standard deviation?"
  },
  {
    "objectID": "practice_probs/practice-03-numerical-data-pt1.html",
    "href": "practice_probs/practice-03-numerical-data-pt1.html",
    "title": "Numerical data (part 1)",
    "section": "",
    "text": "Please work on the practice problems in your group. Problems with an asterisk \\(^*\\) will be assigned to the weekly problem set.\n\nIndicate which of the plots show a positive association, negative association, or no association. Also determine if the positive and negative associations are linear or nonlinear.\n\nA list has 10 entries, and each entry is either a 1, 2, or 3. What must the list be if the average is 3? Give examples of values that the average cannot be.\nSuppose someone tells you that they have some data where the standard deviation is 10,000. What does this tell you about your data, if anything?\n\\(^*\\) Consider the following two sets of data: \\[\\mathbf{x} =  (1, \\ 3,\\ 4, \\ 5,\\  7) \\qquad \\qquad \\qquad  \\mathbf{y} =  (6,\\ 8,\\ 9,\\ 10,\\ 12)\\]\n\nFor each set, find the average and the standard deviation. Show your work by writing out the calculations explicitly. Please use the proper symbols/notation!\nHow is the set of data \\(\\mathbf{y}\\) related to \\(\\mathbf{x}\\)? How does this relationship carry over/affect the average and the standard deviation of \\(\\mathbf{y}\\) in comparison to those of \\(\\mathbf{x}\\)?\n\n\\(^*\\) Calculate the sample mean in each of the following scenarios:\n\nSuppose that we have some data where 20% of the data are 1’s, 50% are 2’s, and 30% are 3’s. What is the sample mean?\nA school has two classes, one with 10 students and one with 100 students. What is the average class size?\nA school has two classes, one with 10 students and one with 100 students. What is the average size of the class that a student is enrolled in?"
  },
  {
    "objectID": "practice_probs/practice-01-study-design.html",
    "href": "practice_probs/practice-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "In Spring 2024, Prof. Tang asked her STAT 311 students to fill out a mid-semester survey. She was particularly interested in the the amount of hours her STAT 311 students were spending per week on the course. Of the 90% of students who responded, the average time spent on the course was found to be 10.2 hours per week.\nBased on this information, identify which of the following correspond to a: case, variable, parameter, and statistic.\n\n10.2 hours\nThe average number of hours spent on the course of all STAT 311 students from Spring 2024\nA STAT 311 student\nThe number of hours spent on STAT 311\n\nSuppose we want to estimate household size, where a “household” is defined as people living together in the same dwelling, and sharing living accommodations. If we select students at random at an elementary school and ask them what their family size is, will this be a good measure of household size? Or will our average be biased? If so, will it overestimate or underestimate the true value?\nChia seeds have gained reputation as a diet supplement. In one 2009 study, 38 men and 38 women were recruited (i.e. specifically chosen) and then divided randomly into two groups: treatment or control. One group was given 25 grams of chia seeds twice a day to consume, and the other was given a placebo. The seeds and placebo were designed to look the same. The subjects volunteered to be a part of the study. After 12 weeks, the scientists found no statistically discernible difference between the groups in appetite or weight loss.\n\nWhat are the treatments in this study?\nIs there any blinding?\nComment on whether we can make a causal statement, and indicate whether we can generalize the conclusions from this study to the population at large.\n\n\n\n\n    a.  What are some advantages to this method of sampling?\n    b.  What are some disadvantages? Think about statistically and also ethically.\n-->"
  },
  {
    "objectID": "coding_practice/coding-practice-03-numerical-pt1.html",
    "href": "coding_practice/coding-practice-03-numerical-pt1.html",
    "title": "Numerical data coding practice",
    "section": "",
    "text": "Change your name in the YAML. Be sure to keep the quotation marks!\nIn the following code chunk, load in the openintro package. Then run the code in the code chunk. We will once again work with the cherry data set.\n\n\n\n\n\nIn the code chunk below, write code to find the mean and median of the diameter of trees in the cherry data frame.\n\n\n\n\n\nMake a box plot of the height of cherry trees. Can you make an informative axis label for your plot? Try changing the color of your boxplot by specifying col = \"color name\" in the function. Note that the name of the color must be in quotes! If you’re confused, look at the examples in the bottom of the Help file of the appropriate function,\n\n\n\n\n\nMake a scatter plot of the diameter and volume of cherry trees. Put volume on the y-axis.\n\n\n\n\nOnce you’re finished, be sure to knit and submit the output file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#recap",
    "href": "slides/slides-04-numerical-pt2.html#recap",
    "title": "Numerical data",
    "section": "Recap",
    "text": "Recap\nWe learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#boxplot",
    "href": "slides/slides-04-numerical-pt2.html#boxplot",
    "title": "Numerical data",
    "section": "Boxplot",
    "text": "Boxplot\nAnother commonly used visualization to display the distribution of a numerical variable is the boxplot. Boxplots are created using five statistics and identify unusual observations.\n\n\nDoes the orientation (vertical or horizontal) matter?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#median",
    "href": "slides/slides-04-numerical-pt2.html#median",
    "title": "Numerical data",
    "section": "Median",
    "text": "Median\n\nThe (sample) median \\(m\\) is another common measure of center of a distribution. It is the value of the data distribution where 50% of the data are less than \\(m\\) and 50% of the data are greater than \\(m\\).\n\nIf we order the data from smallest to largest, the median is the value in the middle.\nIf the number of observations \\(n\\) is even, then there will be two values in the middle, and the median is taken as their average\n\n\nConsider the following data: \\(\\boldsymbol{x} =108,112,113, 114, 115, 116, 118, 119, 121, 129\\). What is the median?\n\nThe median is also known the 50th percentile because 50% of the data fall below \\(m\\)\nCode in R: median(x) where \\(x\\) is a vector"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#mean-vs.-median",
    "href": "slides/slides-04-numerical-pt2.html#mean-vs.-median",
    "title": "Numerical data",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\n\nWhich is better measure of center? The mean or the median?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#interquartile-range",
    "href": "slides/slides-04-numerical-pt2.html#interquartile-range",
    "title": "Numerical data",
    "section": "Interquartile range",
    "text": "Interquartile range\nThe interquartile range (IQR) is another measure of variability/spread in the data.\n\\[\nIQR = Q_{3} - Q_{1}\n\\]\n\nIf the data are more spread out data, should the IQR increase or decrease?\nWhat is the IQR of the data \\(\\boldsymbol{x}\\)?\n\n\nIQR are not the values themselves, but rather, the spread of the middle 50% of the data. Interpretation once again depends on the scale of the data.\nQ3 = 119 and Q1 = 113 -> IQR = 6"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#creating-the-boxplot",
    "href": "slides/slides-04-numerical-pt2.html#creating-the-boxplot",
    "title": "Numerical data",
    "section": "Creating the boxplot",
    "text": "Creating the boxplot\n\nThe “box” part of the boxplot is created using \\(Q_{1}\\), \\(m\\), and \\(Q_{3}\\)\nDraw whiskers from the box that attempt to capture data outside the IQR\n\nHow long should the whiskers be? There isn’t a fixed rule, but \\(1.5 \\times IQR\\) below \\(Q_1\\) and above \\(Q_{3}\\) is common\nWe “cut off” the whiskers at one of the observed values\n\ne.g. we draw out the right whisker to greatest data point that is less than or equal to \\(Q_{3} + 1.5\\times IQR\\)\n\n\nLastly, we add dots for any cases that lie beyond the whiskers\n\nThese points are unusually high/low compared to the rest of the data and are worth identifying as potential outliers\nAn outlier is an observation that appears extreme relative to the rest of the data\n\nLet’s draw a boxplot for the data \\(\\boldsymbol{x}\\)!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#a-note-on-outliers",
    "href": "slides/slides-04-numerical-pt2.html#a-note-on-outliers",
    "title": "Numerical data",
    "section": "A note on outliers",
    "text": "A note on outliers\n\n\nWhy are we interested in identifying outliers?\n\n\nIdentifying strong skew\nIdentifying possible data collection/data entry errors\nProviding insight into interesting properties of the data\n\nAre outliers necessarily indicative of a problem in the data?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#histograms-vs-boxplots",
    "href": "slides/slides-04-numerical-pt2.html#histograms-vs-boxplots",
    "title": "Numerical data",
    "section": "Histograms vs boxplots",
    "text": "Histograms vs boxplots\n\nWhat characteristics of the distribution are apparent in the histogram and not in the box plot? What characteristics are apparent in the box plot but not in the histogram?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#robust-statistics",
    "href": "slides/slides-04-numerical-pt2.html#robust-statistics",
    "title": "Numerical data",
    "section": "Robust statistics",
    "text": "Robust statistics\n\n\n\n\nIn the data \\(\\boldsymbol{x} = 108,112,113, 114, 115, 116, 118, 119, 121, 129\\) that we have been working with, we have the following sample statistics:\n\n\n\\(\\qquad \\bar{x} =\\) 116.5, \\(s =\\) 5.8, \\(m =\\) 115.5 , \\(IQR =\\) 6\n\n\n\nSuppose we actually observed an additional data point with a value of \\(170\\). What are the sample statistics with this additional data point? How do they compare to the values above?\n\\(\\bar{x}' =\\) 121.4, \\(s' =\\) 17.03, \\(m' =\\) _____, \\(IQR' =\\) _____\n\nRobust statistics are statistics that are minimally affected by extreme values\n\nWhich of the statistics above would be considered robust?\n\n\nWhen should the mean be similar to the median (and the standard deviation similar to the IQR)?\n\n\n\nm’ = 116\nQ1’ = 113, Q3’ = 121, IQR’ = 8"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#mean-vs.-median-1",
    "href": "slides/slides-04-numerical-pt2.html#mean-vs.-median-1",
    "title": "Numerical data",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\nLet’s return to the insurance data. In the plot below, the orange line denotes the sample mean charges, and the blue line denotes the sample median:\n\nWhich is better? The mean or the median?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#boxplots-vs-histograms",
    "href": "slides/slides-04-numerical-pt2.html#boxplots-vs-histograms",
    "title": "Numerical data",
    "section": "Boxplots vs histograms",
    "text": "Boxplots vs histograms\nWhich plot do you prefer?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#transforming-data",
    "href": "slides/slides-04-numerical-pt2.html#transforming-data",
    "title": "Numerical data",
    "section": "Transforming data",
    "text": "Transforming data\n\nWhen data are strongly skewed or take on an “inconvenient” range of values, we might transform them so they are easier to work with\nA transformation rescales the data using a function\n\ne.g. \\(f(x) = e^x\\), \\(f(x) = \\log_{10}(x)\\), \\(f(x) = \\ln(x)\\), \\(f(x) = \\sqrt{x}\\)\nThe exact transformation you choose depends heavily on the data!!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#exploratory-data-analysis",
    "href": "slides/slides-05-data-vis.html#exploratory-data-analysis",
    "title": "Visualizations with ggplot",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nExploratory data analysis (EDA) is an approach to analyzing data sets to summarize the main characteristics.\n\nOften visual through plots\n\nBecause of its name “exploratory”, we typically perform EDA at the beginning of a project\nCan also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#tidy-data",
    "href": "slides/slides-05-data-vis.html#tidy-data",
    "title": "Visualizations with ggplot",
    "section": "Tidy data",
    "text": "Tidy data\n\nThe first step of any data/statistical analysis is to understand the data you are working with. This often involves getting the data into R\nThen, it is a good idea to take a macro-level look at the data to ensure it is in tidy format, which means:\n\nEach row in the data set represent an observation/case\nEach columns represents a variable\n\nAnscombe data: four datasets with two variables each\n\n\n\n\nNon-tidy version:\n\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\n\nTidy version:\n\n\n   set  x     y\n1    I 10  8.04\n2    I  8  6.95\n3    I 13  7.58\n4    I  9  8.81\n5    I 11  8.33\n6    I 14  9.96\n7    I  6  7.24\n8    I  4  4.26\n9    I 12 10.84\n10   I  7  4.82\n11   I  5  5.68\n12  II 10  9.14\n13  II  8  8.14\n14  II 13  8.74\n15  II  9  8.77"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-datahttpswww.kaggle.comfootprintnetworkecological-footprint",
    "href": "slides/slides-05-data-vis.html#country-footprint-datahttpswww.kaggle.comfootprintnetworkecological-footprint",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data^[https://www.kaggle.com/footprintnetwork/ecological-footprint]",
    "text": "Country footprint data^[https://www.kaggle.com/footprintnetwork/ecological-footprint]\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 188 × 14\n   Country   Region Population   HDI    GDP Cropland Grazing Forest Carbon  Fish\n   <chr>     <chr>       <dbl> <dbl>  <dbl>    <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n 1 Afghanis… Middl…      29.8   0.46   615.     0.3     0.2    0.08   0.18  0   \n 2 Albania   North…       3.16  0.73  4534.     0.78    0.22   0.25   0.87  0.02\n 3 Algeria   Africa      38.5   0.73  5431.     0.6     0.16   0.17   1.14  0.01\n 4 Angola    Africa      20.8   0.52  4666.     0.33    0.15   0.12   0.2   0.09\n 5 Antigua … Latin…       0.09  0.78 13205.    NA      NA     NA     NA    NA   \n 6 Argentina Latin…      41.1   0.83 13540      0.78    0.79   0.29   1.08  0.1 \n 7 Armenia   Middl…       2.97  0.73  3426.     0.74    0.18   0.34   0.89  0.01\n 8 Aruba     Latin…       0.1  NA       NA     NA      NA     NA     NA    NA   \n 9 Australia Asia-…      23.0   0.93 66604.     2.68    0.63   0.89   4.85  0.11\n10 Austria   Europ…       8.46  0.88 51274.     0.82    0.27   0.63   4.14  0.06\n# ℹ 178 more rows\n# ℹ 4 more variables: Total <dbl>, EarthsRequired <dbl>,\n#   CountriesRequired <dbl>, DataQuality <chr>"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-data-httpswww.kaggle.comfootprintnetworkecological-footprint",
    "href": "slides/slides-05-data-vis.html#country-footprint-data-httpswww.kaggle.comfootprintnetworkecological-footprint",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data ^[https://www.kaggle.com/footprintnetwork/ecological-footprint]",
    "text": "Country footprint data ^[https://www.kaggle.com/footprintnetwork/ecological-footprint]\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 188 × 14\n   Country   Region Population   HDI    GDP Cropland Grazing Forest Carbon  Fish\n   <chr>     <chr>       <dbl> <dbl>  <dbl>    <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n 1 Afghanis… Middl…      29.8   0.46   615.     0.3     0.2    0.08   0.18  0   \n 2 Albania   North…       3.16  0.73  4534.     0.78    0.22   0.25   0.87  0.02\n 3 Algeria   Africa      38.5   0.73  5431.     0.6     0.16   0.17   1.14  0.01\n 4 Angola    Africa      20.8   0.52  4666.     0.33    0.15   0.12   0.2   0.09\n 5 Antigua … Latin…       0.09  0.78 13205.    NA      NA     NA     NA    NA   \n 6 Argentina Latin…      41.1   0.83 13540      0.78    0.79   0.29   1.08  0.1 \n 7 Armenia   Middl…       2.97  0.73  3426.     0.74    0.18   0.34   0.89  0.01\n 8 Aruba     Latin…       0.1  NA       NA     NA      NA     NA     NA    NA   \n 9 Australia Asia-…      23.0   0.93 66604.     2.68    0.63   0.89   4.85  0.11\n10 Austria   Europ…       8.46  0.88 51274.     0.82    0.27   0.63   4.14  0.06\n# ℹ 178 more rows\n# ℹ 4 more variables: Total <dbl>, EarthsRequired <dbl>,\n#   CountriesRequired <dbl>, DataQuality <chr>"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-data",
    "href": "slides/slides-05-data-vis.html#country-footprint-data",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data",
    "text": "Country footprint data\nData on the ecological footprint by country in 2023\n\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 182 × 15\n   Country       Region  SDGi Life_Exectancy   HDI   GDP Income_Group Population\n   <chr>         <chr>  <dbl>          <dbl> <dbl> <dbl> <chr>             <dbl>\n 1 Afghanistan   Middl…  52.5             62  0.48    NA LI                 40.8\n 2 Albania       Other…  71.6             76  0.8  14889 UM                  2.9\n 3 Algeria       Africa  71.5             76  0.75 11137 UM                 45.4\n 4 Angola        Africa  50.9             62  0.59  6304 LM                 35  \n 5 Antigua and … Centr…  NA               78  0.79 18749 HI                  0.1\n 6 Argentina     South…  72.8             75  0.84 22117 UM                 46  \n 7 Armenia       Middl…  71.1             72  0.76 13548 LM                  3  \n 8 Australia     Asia-…  75.6             83  0.95 53053 HI                 26.1\n 9 Austria       EU-27   82.3             81  0.92 55460 HI                  9.1\n10 Azerbaijan    Middl…  73.5             69  0.75 14692 UM                 10.3\n# ℹ 172 more rows\n# ℹ 7 more variables: Cropland <dbl>, Grazing <dbl>, Forest_Product <dbl>,\n#   Carbon <dbl>, Fish <dbl>, Built_up_land <dbl>, Total <dbl>\n\n\n\nData obtained from https://www.kaggle.com/datasets/jainaru/global-ecological-footprint-2023"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#why-do-we-visualize",
    "href": "slides/slides-05-data-vis.html#why-do-we-visualize",
    "title": "Visualizations with ggplot",
    "section": "Why do we visualize?",
    "text": "Why do we visualize?\n\nSummary statistics from each of the four datasets in Anscombe:\n\n\n\n\n# A tibble: 4 × 5\n  set   mean_x mean_y  sd_x  sd_y\n  <fct>  <dbl>  <dbl> <dbl> <dbl>\n1 I          9   7.50  3.32  2.03\n2 II         9   7.50  3.32  2.03\n3 III        9   7.5   3.32  2.03\n4 IV         9   7.50  3.32  2.03\n\n\n\n\nLet’s visualize the four data sets. What would be an appropriate type of plot to examine the relationship between the two variables?"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#common-plots-numerical",
    "href": "slides/slides-05-data-vis.html#common-plots-numerical",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical)",
    "text": "Common plots (numerical)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#aesthetics",
    "href": "slides/slides-05-data-vis.html#aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics",
    "text": "Aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, alpha = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#faceting",
    "href": "slides/slides-05-data-vis.html#faceting",
    "title": "Visualizations with ggplot",
    "section": "Faceting",
    "text": "Faceting"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#modifications",
    "href": "slides/slides-05-data-vis.html#modifications",
    "title": "Visualizations with ggplot",
    "section": "Modifications",
    "text": "Modifications\n\nAdding title\nChanging axis title"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#common-plots-numerical-in-ggplot",
    "href": "slides/slides-05-data-vis.html#common-plots-numerical-in-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical) in ggplot",
    "text": "Common plots (numerical) in ggplot\n\nWe have learned about histograms, density plots, boxplots, and scatterplots\nNow learn how to create these plots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\nThis is what the code will generally look like. Values in < > denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, \n       mapping = aes(x = <x-var>, y = <y-var>)) +\n  geom_xxx() +\n  <other options>\n\n\n\n\nNew lines and spacing don’t impact the execution of code, but are important for good coding style!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#additional-variables",
    "href": "slides/slides-05-data-vis.html#additional-variables",
    "title": "Visualizations with ggplot",
    "section": "Additional variables",
    "text": "Additional variables\n\nDepending on the plot and data, we can map additional variables by using aesthetics (color, size, shape, alpha (transparency) or faceting"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#live-code",
    "href": "slides/slides-05-data-vis.html#live-code",
    "title": "Visualizations with ggplot",
    "section": "Live code",
    "text": "Live code\nNote: most of the code I will show will be presented at the end of these slides. However, we will most likely go off-script based on questions from the class!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_histogram",
    "href": "slides/slides-05-data-vis.html#geom_histogram",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram()\n\n\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram(binwidth = 5000)\n\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_density",
    "href": "slides/slides-05-data-vis.html#geom_density",
    "title": "Visualizations with ggplot",
    "section": "geom_density()",
    "text": "geom_density()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_density()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_boxplot",
    "href": "slides/slides-05-data-vis.html#geom_boxplot",
    "title": "Visualizations with ggplot",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#side-by-side-boxplots",
    "href": "slides/slides-05-data-vis.html#side-by-side-boxplots",
    "title": "Visualizations with ggplot",
    "section": "Side-by-side boxplots",
    "text": "Side-by-side boxplots\n\nggplot(data = insurance, mapping = aes(x = sex, y = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_point",
    "href": "slides/slides-05-data-vis.html#geom_point",
    "title": "Visualizations with ggplot",
    "section": "geom_point()",
    "text": "geom_point()\n\nggplot(data = insurance, mapping = aes(x = age, y = charges)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#when-to-map-to-variable",
    "href": "slides/slides-05-data-vis.html#when-to-map-to-variable",
    "title": "Visualizations with ggplot",
    "section": "When to map to variable",
    "text": "When to map to variable\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point(col = \"purple\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = \"purple\")) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#facet_wrap",
    "href": "slides/slides-05-data-vis.html#facet_wrap",
    "title": "Visualizations with ggplot",
    "section": "facet_wrap()",
    "text": "facet_wrap()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker)\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#facet_grid",
    "href": "slides/slides-05-data-vis.html#facet_grid",
    "title": "Visualizations with ggplot",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#adding-titles",
    "href": "slides/slides-05-data-vis.html#adding-titles",
    "title": "Visualizations with ggplot",
    "section": "Adding titles",
    "text": "Adding titles\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#looking-at-your-data",
    "href": "slides/slides-06-categorical-data.html#looking-at-your-data",
    "title": "Categorical data",
    "section": "Looking at your data",
    "text": "Looking at your data\nIs your data tidy, or do you have a table of counts (i.e. a frequency table)?\n\n\n\n\n\n\n\n# A tibble: 5 × 1\n  fruit \n  <chr> \n1 apple \n2 apple \n3 orange\n4 apple \n5 orange\n\n\n\n\n\n# A tibble: 2 × 2\n  fruit  number\n  <chr>   <dbl>\n1 apple       3\n2 orange      2"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate-visualizations",
    "href": "slides/slides-06-categorical-data.html#univariate-visualizations",
    "title": "Categorical data",
    "section": "Univariate visualizations",
    "text": "Univariate visualizations\nIf we are interested in visualizing the distribution of a single categorical variable, it is common to use a barplot, where the different levels are displayed on ones axis and the counts of each level are portrayed on the the other axis.\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#contingency-tables",
    "href": "slides/slides-06-categorical-data.html#contingency-tables",
    "title": "Categorical data",
    "section": "Contingency tables",
    "text": "Contingency tables\n\nPerhaps we are interested in examining the distribution of two categorical variables at the same time\nWe can summarize the distribution using a two-way table of counts known as a contingency table, where each value in the table count the number of times a particular combination of variable 1 and variable 2 outcomes/levels occurred\n\n\n\n\nContingency table\n\n\nsmoker\nfemale\nmale\n\n\n\n\nno\n87\n68\n\n\nyes\n17\n28\n\n\n\n\n\n\n\nNote: can easily obtain the distribution of just one of the variables by looking row-wise or column-wise\n\nWe essentially convert the contingency table to a visualization to visualize the distribution of two categorical variables"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#dodged-bar-plot",
    "href": "slides/slides-06-categorical-data.html#dodged-bar-plot",
    "title": "Categorical data",
    "section": "Dodged bar plot",
    "text": "Dodged bar plot\nThe dodged bar plot directly converts the contingency table to a visualization.\n\n\n\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#stacked-bar-plot",
    "href": "slides/slides-06-categorical-data.html#stacked-bar-plot",
    "title": "Categorical data",
    "section": "Stacked bar plot",
    "text": "Stacked bar plot\n\n\nThe stacked bar plot looks at the counts either row-wise or column-wise.\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#proportions",
    "href": "slides/slides-06-categorical-data.html#proportions",
    "title": "Categorical data",
    "section": "Proportions",
    "text": "Proportions\nCan convert the contingency table to proportions row-wise or column-wise to obtain the fractional breakdown of one variable in another.\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\n\n\n\nRow-wise proportions\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    0.561 \n    0.439 \n  \n  \n    yes \n    0.378 \n    0.622 \n  \n\n\n\n\n\n\n\n\n\n\n\nWhat does the quantity 0.378 represent?\nIf we take the proportions row-wise, does each row need to sum to 1?\nIf we take the proportions row-wise, does each column need to sum to 1?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#proportions-cont.",
    "href": "slides/slides-06-categorical-data.html#proportions-cont.",
    "title": "Categorical data",
    "section": "Proportions (cont.)",
    "text": "Proportions (cont.)\n\nSet up how to find the column-wise proportions using our contingency table\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#standardized-bar-plot",
    "href": "slides/slides-06-categorical-data.html#standardized-bar-plot",
    "title": "Categorical data",
    "section": "Standardized bar plot",
    "text": "Standardized bar plot\nThe standardized bar plot visualizes these row-wise or column-wise proportions."
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#choosing-a-bar-plot",
    "href": "slides/slides-06-categorical-data.html#choosing-a-bar-plot",
    "title": "Categorical data",
    "section": "Choosing a bar plot",
    "text": "Choosing a bar plot\n\n\n\nUsing any of the plots, do you believe the smoker status and sex are associated?\nWhen might you prefer to use the stacked, dodged, or standardized bar plot?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#live-code",
    "href": "slides/slides-06-categorical-data.html#live-code",
    "title": "Categorical data",
    "section": "Live code",
    "text": "Live code\n\nBar plots\nAesthetics: fill, shape\nFaceting\nPlot background"
  },
  {
    "objectID": "live_code/dplyr.html",
    "href": "live_code/dplyr.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "library(tidyverse)\n\n## modify this line accordingly!\ndatascience <- read_csv(\"data/datascience_survey_subset.csv\")\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/dplyr.html#selecting-a-single-column",
    "href": "live_code/dplyr.html#selecting-a-single-column",
    "title": "Untitled",
    "section": "Selecting a single column",
    "text": "Selecting a single column\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,618 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    21\n 7    22\n 8    29\n 9    35\n10    37\n# ℹ 2,608 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,618 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    21\n 7    22\n 8    29\n 9    35\n10    37\n# ℹ 2,608 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe the data frame using |> the select() function and specify that we want the variable Age\nThe result is a data frame with 2618 rows and 1 column\n\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "practice_probs/practice-04-numerical-data-pt2.html",
    "href": "practice_probs/practice-04-numerical-data-pt2.html",
    "title": "Numerical data (part 2)",
    "section": "",
    "text": "Please work on the practice problems in your group. Problems with an asterisk \\(^*\\) will be assigned to the weekly problem set.\n\nThe infant mortality rate is defined as the number of infant deaths per 1,000 live births. This rate is often used as an indicator of the level of health in a country. The histogram below shows the distribution of estimated infant death rates for 224 countries for which such data were available in 2014. In particular, this is a relative frequency histogram, which shows proportions instead of raw counts on the y-axis:\n\nEstimate \\(Q_{1}\\), the median \\(m\\), and \\(Q_{3}\\) from the histogram.\nSuppose that an exam has a total of 100 possible points, and the average score was an 85 with standard deviation of 15. Is the distribution of the scores on this exam symmetric? If not, what shape would you expect this distribution to have? Explain your reasoning.\nFor registered students at universities in the United States, do you expect the average age or the median age to be larger? Why?\n(\\(^*\\)) The statistic \\(\\frac{\\bar{x}}{m}\\) can be used as a measure of skewness. Suppose we have a distribution where all observations are greater than 0 (i.e. \\(x_{i} > 0\\) for all observations \\(i = 1,\\ldots, n\\)). What is the expected shape of the distribution under the following conditions? Explain your reasoning.\n\\[\\text{(a)} \\ \\ \\frac{\\bar{x}}{m} = 1 \\qquad \\qquad \\text{(b)} \\ \\ \\frac{\\bar{x}}{m} > 1 \\qquad \\qquad \\text{(c)} \\ \\ \\frac{\\bar{x}}{m} < 1\\]"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#data",
    "href": "slides/slides-03-numerical-pt1.html#data",
    "title": "Numerical data",
    "section": "Data",
    "text": "Data\nWhich of the following variables are numerical?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#scatterplots",
    "href": "slides/slides-03-numerical-pt1.html#scatterplots",
    "title": "Numerical data",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are bivariate (two-variable) visualizations that provide a case-by-case view of the data for two numerical variables\n\nEach point represents the observed pair of values of variables 1 and 2 for a case in the dataset"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#live-code",
    "href": "slides/slides-03-numerical-pt1.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\nFunctions to calculate sample mean, variance, and standard deviation in R. Each expects a vector of numerical values as input:\n\n\nmean()\nvar()\nsd()"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#scatterplots-cont.",
    "href": "slides/slides-03-numerical-pt1.html#scatterplots-cont.",
    "title": "Numerical data",
    "section": "Scatterplots (cont.)",
    "text": "Scatterplots (cont.)\n\nHow do we determine which variable to put on each axis?\nWhat do scatterplots reveal about the data, and how are they useful?\n\n\nAssociations/patterns (linear, exponential, etc) between two variables. They might not tell the complete story, however!\nPositive vs negative associations"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#dot-plots",
    "href": "slides/slides-03-numerical-pt1.html#dot-plots",
    "title": "Numerical data",
    "section": "Dot plots",
    "text": "Dot plots\n\nDot plots are a basic visualization that show the distribution of a single variable (univariate)\nIn the following, we have a dot plot of BMI rounded to the nearest integer.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypically, one dot for each case in our data. What is a disadvantage of dot plots?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#binning",
    "href": "slides/slides-03-numerical-pt1.html#binning",
    "title": "Numerical data",
    "section": "Binning",
    "text": "Binning\n\nWe will sacrifice precision for convenience by binning:\n\nSegment the variable into equal-sized bins\nVisualize the value of each observation using its corresponding bin\n\nFor example, the bmi variable has observed values of \\(15.96\\) through \\(49.6\\). Consider the following bins of size 5: [15, 19), [19, 23), [23, 27), …, [49, 53)\n\nConvention of left or right inclusive?\n\nWe tabulate/count up the number of observations that fall into each bin."
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms",
    "href": "slides/slides-03-numerical-pt1.html#histograms",
    "title": "Numerical data",
    "section": "Histograms",
    "text": "Histograms\nHistograms are visualizations that display the binned counts as bars for each bin.\n\nHistograms provide a view of the density of the data (the values the data take on as well as how often)\n\n\n\n\n\n\n\n\n\nbmi_bin\ncount\n\n\n\n\n[15, 19)\n5\n\n\n[19, 23)\n12\n\n\n[23, 27)\n35\n\n\n[27, 31)\n58\n\n\n[31, 35)\n41\n\n\n[35, 39)\n35\n\n\n[39, 43)\n13\n\n\n[49, 52)\n1"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms-cont.",
    "href": "slides/slides-03-numerical-pt1.html#histograms-cont.",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape (i.e. skewness and modality) of the distributions in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms-cont.-1",
    "href": "slides/slides-03-numerical-pt1.html#histograms-cont.-1",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape and modality in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#mean",
    "href": "slides/slides-03-numerical-pt1.html#mean",
    "title": "Numerical data",
    "section": "Mean",
    "text": "Mean\n\nMost common way to measure the center of the distribution of a numerical variable is using the mean (also called the average)\nSample mean: a mean calculated using sampled data. The sample mean is typically denoted as \\(\\bar{x}\\)\n\n\\(x\\) is a placeholder for the variable of interest (e.g. BMI, charges)\nThe bar communicates that we are looking at the average\n\nThe sample mean is the sum over all the observed values of the variable, divided by total number of observations \\(n\\):\n\n\n\\[\\bar{x} = \\frac{x_{1} + x_{2} + \\ldots x_{n}}{n} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\]"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#mean-cont.",
    "href": "slides/slides-03-numerical-pt1.html#mean-cont.",
    "title": "Numerical data",
    "section": "Mean (cont.)",
    "text": "Mean (cont.)\n\nThe sample mean \\(\\bar{x}\\) is an example of a sample statistic\nThe mean over the entire population is an example of a population parameter. The population mean is denoted \\(\\mu\\) (Greek letter mu)\n\nThe sample mean \\(\\bar{x}\\) is often used as an estimate for \\(\\mu\\) (more on this in a few weeks!)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#example",
    "href": "slides/slides-03-numerical-pt1.html#example",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nWe will be looking at some medical insurance data throughout these slides.\n\nWhich of the following variables are numerical? Which are discrete vs. continuous?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#means-depend-on-proportions",
    "href": "slides/slides-03-numerical-pt1.html#means-depend-on-proportions",
    "title": "Numerical data",
    "section": "Means depend on proportions",
    "text": "Means depend on proportions\n\n\n\nWhat is the average of the following values? \\(\\qquad 1, 4, 4\\)\nIf instead there were ten 1’s and twenty 4’s, would the average be the same?\n\n\n\n\n\\(\\bar{x} = \\frac{1+4+4}{3} = 1\\left(\\frac{1}{3} \\right) + 4\\left( \\frac{2}{3}\\right) = \\frac{9}{3} = 3\\)\n\\(\\bar{x} = 1\\left(\\frac{10}{30}\\right) + 4 \\left(\\frac{20}{30} \\right) = \\frac{90}{30} = 3\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variability",
    "href": "slides/slides-03-numerical-pt1.html#variability",
    "title": "Numerical data",
    "section": "Variability",
    "text": "Variability\n\nAt the heart of statistics is also the variability or spread of the distribution of the variable\nWe will work with variance and standard deviation, which are ways to describe how spread out data are from their mean"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#deviation",
    "href": "slides/slides-03-numerical-pt1.html#deviation",
    "title": "Numerical data",
    "section": "Deviation",
    "text": "Deviation\nWe begin with deviation, which is the distance or difference between an observation from the (sample) mean\n\nHow might we write this using statistical notation?\nLet’s write out the deviations of your five sampled weights"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation",
    "href": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation",
    "title": "Numerical data",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\nThe sample variance \\(s^2\\) squares the deviations and takes an average:\n\\[\ns^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\n\\]\n\nLet’s talk about this notation and intuition behind this formula. In particular, there are at least two things to note\n\n\nSet-up the calculation of the sample variance of your sample\n\n\nI will calculate this in R\n\nThe sample standard deviation \\(s\\) is the simply the square root of the sample variance (\\(s = \\sqrt{s^2}\\))"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation-cont.",
    "href": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation-cont.",
    "title": "Numerical data",
    "section": "Variance and standard deviation (cont.)",
    "text": "Variance and standard deviation (cont.)\n\nLike the mean, the population values for variance and standard deviation are denoted with Greek letters:\n\n\\(\\sigma\\) for population standard deviation (Greek letter “sigma”)\n\\(\\sigma^2\\) for population variance\n\n\nIf the calculation of standard deviation is a more complicated quantity than the variance, why do we bother with standard deviation?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#comparing-numerical-data-across-groups",
    "href": "slides/slides-04-numerical-pt2.html#comparing-numerical-data-across-groups",
    "title": "Numerical data",
    "section": "Comparing numerical data across groups",
    "text": "Comparing numerical data across groups\n\nWhile we haven’t yet discussed categorical data, it is common to want to visualize the distribution of a numerical variable across different groups/levels of a categorical variable"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#live-code",
    "href": "slides/slides-04-numerical-pt2.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\n\nmedian()\nBoxplots in base R"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html",
    "href": "slides/slides-06-categorical-data.html",
    "title": "Categorical data",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nProblem set 2 due tomorrow! Please be sure to submit both written and rendered parts by combining into a single PDF\nOffice hours canceled today, moved to tomorrow 2-3pm\nProblem set 1 graded\n\n\n\n\nRecall that a variable is either numerical or categorical\nCategorical variables are variables that can take one of a limited (usually fixed) number of possible values, known as levels\n\nRepresent data that can be divided into groups\n\nTwo types:\n\nOrdinal: the levels have a special ordering\nNominal: the levels don’t have an ordering\n\nWe will almost exclusively treat our categorical variables as nominal in this class\n\n\nExamples and non-examples?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we are interested in understanding the distribution of a single categorical variable, it is common to:\n\n\n\nDisplay a frequency table, which is a table of counts of each level\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45\n\n\n\n\n\nCreate a bar plot, where different levels are displayed on one axis and the counts are portrayed on the other\n\n\n\n\n\n\n\n\n\nHow do bar plots differ from histograms?\n\n\n\n\n\nPerhaps we are interested in examining the distribution of two categorical variables at the same time\nSummarize the distribution using a two-way table known as a contingency table:\n\nEach value in the table counts the number of times a particular combination of variable 1 and variable 2 levels occurred in data\n\n\n\n`summarise()` has grouped output by 'smoker'. You can override using the\n`.groups` argument.\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\nHow can we use contingency table to obtain the distribution of just one of the variables?\n\n\n\n\n\nThe dodged bar plot directly converts the contingency table to a visualization.\n\n\n\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe stacked bar plot looks at the counts either row-wise or column-wise.\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan convert the contingency table to proportions row-wise or column-wise to obtain the fractional breakdown of one variable in another.\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\n\n`summarise()` has grouped output by 'smoker'. You can override using the\n`.groups` argument.\n\n\n\n\nRow-wise proportions\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    0.561 \n    0.439 \n  \n  \n    yes \n    0.378 \n    0.622 \n  \n\n\n\n\n\n\n\n\n\n\n\nWhat does the quantity 0.378 represent?\nIf we take the proportions row-wise, does each row need to sum to 1?\nIf we take the proportions row-wise, does each column need to sum to 1?\n\n\n\n\n\n\n\nSet up how to find the column-wise proportions using our contingency table\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\nThe standardized bar plot visualizes these row-wise or column-wise proportions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing any of the plots, do you believe the smoker status and sex are associated?\nWhen might you prefer to use the stacked, dodged, or standardized bar plot?\n\n\n\n\n\n\nBar plots\nAesthetics: fill, shape\nFaceting\nPlot background\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = smoker)) +\n  geom_bar()\n\n\n\n\n\nNote: if your data are already in the form of frequency table, we should use geom_col() instead!\n\n\n\n\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"dodge\")  \n\n\n\n\n\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"stack\") # this is default\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\nHow might we make the bars horizontal instead of vertical?\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point() \n\n\n\n\n\n\n\nWhat do you notice about the legend for color?\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, shape = smoker)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nFaceting is used when we want to split a particular visualization by the values of another (categorical) variable\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker) \n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker, scales = \"free_y\")\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_grid(sex ~ smoker)\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = smoker, y = bmi)) +\n  geom_boxplot()\n\n\n\n\n\n\nLike faceting, but only for box plots.\n\n\n\n\nCan change the background of plots by adding on any one of the following to your plot:\n\ntheme_bw(), theme_minimal(), theme_gray(), theme_void() and a few more (see all options by checking the help file for any one of these)\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = smoker, y = bmi)) +\n  geom_boxplot() +\n  theme_minimal()"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#factoring",
    "href": "slides/slides-06-categorical-data.html#factoring",
    "title": "Categorical data",
    "section": "Factoring",
    "text": "Factoring"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html",
    "href": "slides/slides-05-numerical-data-viz.html",
    "title": "Visualizations with ggplot",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 1338 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#exploratory-data-analysis",
    "href": "slides/slides-05-numerical-data-viz.html#exploratory-data-analysis",
    "title": "Visualizations with ggplot",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\nExploratory data analysis (EDA) is an approach to analyzing data sets to summarize the main characteristics.\n\nOften visual through plots\n\nBecause of its name “exploratory”, we typically perform EDA at the beginning of a project\nCan also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#tidy-data",
    "href": "slides/slides-05-numerical-data-viz.html#tidy-data",
    "title": "Visualizations with ggplot",
    "section": "Tidy data",
    "text": "Tidy data\n\nWhen working with data in R, always look at the data to ensure it is in tidy format:\n\nEach row represents an observation, each column represents a variable describing the observations\n\nanscombe data frame: four datasets each with 11 observations each and the same two variables\n\n\n\n\nNon-tidy version:\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\n\nTidy version (first 15 rows):\n\n\n   set  x     y\n1    I 10  8.04\n2    I  8  6.95\n3    I 13  7.58\n4    I  9  8.81\n5    I 11  8.33\n6    I 14  9.96\n7    I  6  7.24\n8    I  4  4.26\n9    I 12 10.84\n10   I  7  4.82\n11   I  5  5.68\n12  II 10  9.14\n13  II  8  8.14\n14  II 13  8.74\n15  II  9  8.77"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#why-do-we-visualize",
    "href": "slides/slides-05-numerical-data-viz.html#why-do-we-visualize",
    "title": "Visualizations with ggplot",
    "section": "Why do we visualize?",
    "text": "Why do we visualize?\n\nSummary statistics from each of the four datasets in anscombe:\n\n\n\n\n# A tibble: 4 × 5\n  set   mean_x mean_y  sd_x  sd_y\n  <fct>  <dbl>  <dbl> <dbl> <dbl>\n1 I          9   7.50  3.32  2.03\n2 II         9   7.50  3.32  2.03\n3 III        9   7.5   3.32  2.03\n4 IV         9   7.50  3.32  2.03\n\n\n\n\nLet’s visualize the four data sets. What would be an appropriate type of plot to examine the relationship between the two variables x and y?"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#common-plots-numerical-in-ggplot",
    "href": "slides/slides-05-numerical-data-viz.html#common-plots-numerical-in-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical) in ggplot",
    "text": "Common plots (numerical) in ggplot\n\nWe have learned about histograms, density plots, boxplots, and scatterplots, and how to code them in base R\nNow learn how to create these plots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from what we’ve seen in the past?\n\nThis is what the code will generally look like. Values in < > denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, \n       mapping = aes(x = <x-var>, y = <y-var>)) +\n  geom_xxx() +\n  <other options>\n\n\n\n\nNew lines and spacing don’t impact the execution of code, but are important for good coding style!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#country-footprint-data",
    "href": "slides/slides-05-numerical-data-viz.html#country-footprint-data",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data",
    "text": "Country footprint data\nData on the ecological footprint by country in 2023\n\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 182 × 15\n   Country       Region  SDGi Life_Exectancy   HDI   GDP Income_Group Population\n   <chr>         <chr>  <dbl>          <dbl> <dbl> <dbl> <chr>             <dbl>\n 1 Afghanistan   Middl…  52.5             62  0.48    NA LI                 40.8\n 2 Albania       Other…  71.6             76  0.8  14889 UM                  2.9\n 3 Algeria       Africa  71.5             76  0.75 11137 UM                 45.4\n 4 Angola        Africa  50.9             62  0.59  6304 LM                 35  \n 5 Antigua and … Centr…  NA               78  0.79 18749 HI                  0.1\n 6 Argentina     South…  72.8             75  0.84 22117 UM                 46  \n 7 Armenia       Middl…  71.1             72  0.76 13548 LM                  3  \n 8 Australia     Asia-…  75.6             83  0.95 53053 HI                 26.1\n 9 Austria       EU-27   82.3             81  0.92 55460 HI                  9.1\n10 Azerbaijan    Middl…  73.5             69  0.75 14692 UM                 10.3\n# ℹ 172 more rows\n# ℹ 7 more variables: Cropland <dbl>, Grazing <dbl>, Forest_Product <dbl>,\n#   Carbon <dbl>, Fish <dbl>, Built_up_land <dbl>, Total <dbl>\n\n\n\nData obtained from https://www.kaggle.com/datasets/jainaru/global-ecological-footprint-2023"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#additional-variables",
    "href": "slides/slides-05-numerical-data-viz.html#additional-variables",
    "title": "Visualizations with ggplot",
    "section": "Additional variables",
    "text": "Additional variables\n\nDepending on the plot and data, we can map additional variables by using aesthetics (color, size, shape, alpha (transparency) or faceting"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#modifications",
    "href": "slides/slides-05-numerical-data-viz.html#modifications",
    "title": "Visualizations with ggplot",
    "section": "Modifications",
    "text": "Modifications\n\nAdding title\nChanging axis title"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#live-code",
    "href": "slides/slides-05-numerical-data-viz.html#live-code",
    "title": "Visualizations with ggplot",
    "section": "Live code",
    "text": "Live code\nNote: most of the code I will show is included in the remaining slides. However, we will most likely go off-script based on questions from the class!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_histogram",
    "href": "slides/slides-05-numerical-data-viz.html#geom_histogram",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\nggplot(data = insurance,  mapping = aes(x = charges)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\nNote the message provided when you execute this code!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_density",
    "href": "slides/slides-05-numerical-data-viz.html#geom_density",
    "title": "Visualizations with ggplot",
    "section": "geom_density()",
    "text": "geom_density()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_density()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_boxplot",
    "href": "slides/slides-05-numerical-data-viz.html#geom_boxplot",
    "title": "Visualizations with ggplot",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(y = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#side-by-side-boxplots",
    "href": "slides/slides-05-numerical-data-viz.html#side-by-side-boxplots",
    "title": "Visualizations with ggplot",
    "section": "Side-by-side boxplots",
    "text": "Side-by-side boxplots\n\nggplot(data = insurance, mapping = aes(x = sex, y = charges)) +\n  geom_boxplot()\n\n\n\n\n\n\nBivariate plot for a numerical and a categorical variable."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_point",
    "href": "slides/slides-05-numerical-data-viz.html#geom_point",
    "title": "Visualizations with ggplot",
    "section": "geom_point()",
    "text": "geom_point()\n\nggplot(data = insurance, mapping = aes(x = age, y = charges)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics",
    "text": "Aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       col = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, alpha = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#when-to-map-to-variable",
    "href": "slides/slides-05-numerical-data-viz.html#when-to-map-to-variable",
    "title": "Visualizations with ggplot",
    "section": "When to map to variable",
    "text": "When to map to variable\nWhat’s going on here?\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(col = \"purple\")\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(aes(col = \"purple\"))\n\n\n\n\n\n\n\n\n\n\nKey takeaway: aesthetics should correspond/map to a variable in the data frame\n\n\n“Fixed” visual cues are set outside of aes()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#facet_wrap",
    "href": "slides/slides-05-numerical-data-viz.html#facet_wrap",
    "title": "Visualizations with ggplot",
    "section": "facet_wrap()",
    "text": "facet_wrap()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker)\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#facet_grid",
    "href": "slides/slides-05-numerical-data-viz.html#facet_grid",
    "title": "Visualizations with ggplot",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#adding-titles",
    "href": "slides/slides-05-numerical-data-viz.html#adding-titles",
    "title": "Visualizations with ggplot",
    "section": "Adding titles",
    "text": "Adding titles\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "live_code/dplyr.html#selecting-columns",
    "href": "live_code/dplyr.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/dplyr.html#arranging-rows",
    "href": "live_code/dplyr.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/dplyr.html#slicing-for-certain-row-numbers",
    "href": "live_code/dplyr.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row in index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/dplyr.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/dplyr.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we only retain the observations where the person’s Major was Computer Science:\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”:\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/dplyr.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/dplyr.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/dplyr.html#mutate-to-add-a-new-variable",
    "href": "live_code/dplyr.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify the name of the new variable and how to calculate the value of that variable for each observation:\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/dplyr.html#counting-to-create-frequency-tables",
    "href": "live_code/dplyr.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/dplyr.html#practice",
    "href": "live_code/dplyr.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/dplyr.html#summarising-for-summary-statistics",
    "href": "live_code/dplyr.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a single/multiple summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead?"
  },
  {
    "objectID": "live_code/dplyr.html#grouping-by-grouped-operations",
    "href": "live_code/dplyr.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\n\ndatascience |>\n  group_by(EmploymentStatus) |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 3 × 2\n  EmploymentStatus                                     mean_age\n  <chr>                                                   <dbl>\n1 Employed full-time                                       34.3\n2 Employed part-time                                       29.5\n3 Independent contractor, freelancer, or self-employed     39.0"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#working-dataset",
    "href": "slides/slides-07-wrangling.html#working-dataset",
    "title": "Data wrangling with dplyr",
    "section": "Working dataset",
    "text": "Working dataset\nData from Kaggle: In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\n\nLet’s go ahead and pull to get the data locally\nThen open a new .Rmd to work in\nLet’s load in the data together and take a quick look at it before diving into data wrangling"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#grammar-of-data-wrangling",
    "href": "slides/slides-07-wrangling.html#grammar-of-data-wrangling",
    "title": "Data wrangling with dplyr",
    "section": "Grammar of data wrangling",
    "text": "Grammar of data wrangling\n\n\n\n\nRecall: data frames are objects in R that store tabular data in tidy form\nThe dplyr package (included in tidyverse package) uses the concept of functions as verbs that manipulate data frames.\n\nselect(): pick columns by name\nslice(): pick rows using indices\nfilter(): pick rows matching criteria\ndistinct(): filter for unique rows\nmutate(): add new variables as columns\nsummarise(): reduce variables to quantitative values\ngroup_by(): for grouped operations based on a variable\nand many more!!!"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#rules-of-dplyr-functions",
    "href": "slides/slides-07-wrangling.html#rules-of-dplyr-functions",
    "title": "Data wrangling with dplyr",
    "section": "Rules of dplyr functions",
    "text": "Rules of dplyr functions\n\nThe first argument is always a data frame\nSubsequent argument(s) say what to do with that data frame\n\nWe connect lines to code using a pipe operator (see next slide)\n\nAlways return a data frame, unless specifically told otherwise"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#pipes",
    "href": "slides/slides-07-wrangling.html#pipes",
    "title": "Data wrangling with dplyr",
    "section": "Pipes",
    "text": "Pipes\n\nIn programming, a pipe is a technique for passing information from one process to another\nIn dplyr, the pipes are coded as |> (i.e. vertical bar and greater than sign)\n\nNot to be confused with +\n\nWe can think about pipes as following a sequence of actions which provide a more natural and easier to read structure\nFor example: suppose that in order to get to work, I need to find my car keys, start my car, drive to work, and then park my car\n\n\n\n\nExpressed as a set of nested R pseudocode, this may look like:\n\n\n\npark(drive(start_car(find(\"car_keys\")), \n           to = \"work\"))\n\n\n\n\nExpressed using pipes, this may look like:\n\n\n\nfind(\"car_keys\") |>\n  start_car() |>\n  drive(to = \"work\") |>\n  park()"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#logical-operators-in-r",
    "href": "slides/slides-07-wrangling.html#logical-operators-in-r",
    "title": "Data wrangling with dplyr",
    "section": "Logical operators in R",
    "text": "Logical operators in R\nIt is common to compare two quantities using logical operators. All of these operators will return a logical TRUE or FALSE. List of some common operators:\n\n<: less than\n<=: less than or equal to\n>: greater than\n>=: greater than or equal to\n==: (exactly) equal to\n!=: not equal to\n\n\n\n1 < 4\n\n[1] TRUE\n\n\n\n\n\n2==3\n\n[1] FALSE\n\n\n\n\n\n2!=3\n\n[1] TRUE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#logical-operators-cont.",
    "href": "slides/slides-07-wrangling.html#logical-operators-cont.",
    "title": "Data wrangling with dplyr",
    "section": "Logical operators (cont.)",
    "text": "Logical operators (cont.)\nWe might also want to know if a certain quantity “behaves” a certain way. The following also return logical outputs:\n\nis.na(x): test if x is NA\nx %in% y: test if x is in y\n!x: not x\n\n\n\nis.na(NA)\n\n[1] TRUE\n\n\n\n\n\nis.na(\"apple\")\n\n[1] FALSE\n\n\n\n\n\n3 %in% 1:10\n\n[1] TRUE\n\n\n\n\n\n!TRUE\n\n[1] FALSE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#commenting-code",
    "href": "slides/slides-07-wrangling.html#commenting-code",
    "title": "Data wrangling with dplyr",
    "section": "Commenting code",
    "text": "Commenting code\nRecall that in R, we can comment out lines of code using the # symbol. The line of code will still be displayed, but it will not execute:\n\n1 + 1\n\n[1] 2\n\n# 2 * 1\n3 %in% 1:10\n\n[1] TRUE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#live-code",
    "href": "slides/slides-07-wrangling.html#live-code",
    "title": "Data wrangling with dplyr",
    "section": "Live code",
    "text": "Live code\nData from Kaggle: In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nCopy and paste the following code into a code chunk in your live code! We will load in the data together and take a quick look at it before diving into data wrangling\n\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/datascience_survey_subset.csv\""
  },
  {
    "objectID": "slides/slides-07-wrangling.html#piping-to-ggplot",
    "href": "slides/slides-07-wrangling.html#piping-to-ggplot",
    "title": "Data wrangling with dplyr",
    "section": "Piping to ggplot",
    "text": "Piping to ggplot\n\nRemember that when creating plots, the ggplot() function expect a data frame as its first argument\nWe may sometimes need to wrangle data prior to visualizing it. We have two options (both have pros and cons)\n\nWrangle the data, store the resulting data frame with a new variable name, and then refer to that data frame with ggplot(), or\n\n\ndf_new <- df |>\n  mutate(age_months = age*12)\nggplot(df_new, aes(x = age_months)) +\n  geom_histogram()\n\n\nWrangle the data, and then directly pipe the result into ggplot()\n\n\ndf |>\n  mutate(age_months = age*12) |>\n  ggplot(aes(x = age_months)) +\n  geom_histogram()\n\n\n\n\nWhen do we use |> and when do we use + to connect lines of code?"
  },
  {
    "objectID": "slides/slides-08-probability.html#key-terms",
    "href": "slides/slides-08-probability.html#key-terms",
    "title": "Probability basics",
    "section": "Key terms",
    "text": "Key terms\n\nRandom process: a situation in which a particular result, called an outcome, is random/not known ahead of time\n\nExamples: flipping a coin, rolling six-sided die, sports game, if a treatment is effective\n\nA sample space \\(S\\) is the set of all possible outcomes of the random process\n\n\nWhat are possible sample spaces for the above examples?\n\n\nAn event is a set of outcomes from a random process"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability",
    "href": "slides/slides-08-probability.html#probability",
    "title": "Probability basics",
    "section": "Probability",
    "text": "Probability\n\nFor us, the probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times\n\nProbability is used to express the likelihood that some outcome or event will or will not occur\nThink of as a proportion\n\nLet \\(A\\) denote some outcome or event. We denote the probability of \\(A\\) occurring as \\(\\text{P}(A)\\) or \\(\\text{Pr}(A)\\).\nWhen the sample space \\(S\\) is discrete with a finite size, then \\(\\text{Pr}(A) = \\frac{\\text{ number of outcomes favorable to } A}{\\text{ number of total outcomes possible} }\\)"
  },
  {
    "objectID": "slides/slides-08-probability.html#example",
    "href": "slides/slides-08-probability.html#example",
    "title": "Probability basics",
    "section": "Example",
    "text": "Example\nLet the random process rolling a fair, six-sided die. Let \\(X\\) a random variable representing the value of the die.\n\nFor each of the following, determine the outcome(s) and event under consideration, along with the value of the probability itself:\n\n\\(\\text{Pr}(X = 1)\\)\n\\(\\text{Pr}(X = 1 \\text{ and } 2)\\)\n\\(\\text{Pr}(X \\text{ is even})\\)\n\n\n\nConvince ourselves that \\(X\\) is a RV. Recall: sample space is 1,..,6.\nPossible outcome is 1, and an event would be \\(X=1\\); the RV being 1.\nPossible event is 1 or 2."
  },
  {
    "objectID": "slides/slides-08-probability.html#operations-with-events",
    "href": "slides/slides-08-probability.html#operations-with-events",
    "title": "Probability basics",
    "section": "Operations with events",
    "text": "Operations with events\nLet \\(A\\) and \\(B\\) be two possible events.\n\nThe intersection of \\(A\\) and \\(B\\) is denoted as \\(A \\cap B\\), and is the set of outcomes that belong to both events \\(A\\) and \\(B\\)\nThe union of \\(A\\) and \\(B\\) is denoted as \\(A \\cup B\\), and is the set of outcomes that belong to \\(A\\) and/or \\(B\\)\n\n\nWhen we have only two or three events, Venn diagrams can be very useful for visualizing probabilities!"
  },
  {
    "objectID": "slides/slides-08-probability.html#addition-rule",
    "href": "slides/slides-08-probability.html#addition-rule",
    "title": "Probability basics",
    "section": "Addition rule",
    "text": "Addition rule\nLet \\(A\\) and \\(B\\) be two possible events. Then the addition rule states that the probability that at least one will occur is:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\nVenn diagram\nExample: in a standard deck of 52 cards, we have four suits (diamond, heart, club, spade) with 13 cards within each suit (1-10, Jack, Queen, King).\n\nSuppose we randomly draw one card from the shuffled deck.\nLet \\(A\\) be the event that the card is a spade.\nLet \\(B\\) be the event that the card is a face card (Jack, Queen or King).\nFind \\(P(A \\cup B)\\)."
  },
  {
    "objectID": "slides/slides-08-probability.html#disjoint-events",
    "href": "slides/slides-08-probability.html#disjoint-events",
    "title": "Probability basics",
    "section": "Disjoint events",
    "text": "Disjoint events\nTwo events are disjoint or mutually exclusive if they cannot simultaneously happen.\n\nThat is, if \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cap B) = ?\\)\n\nIf our random process is rolling a six-sided die one time, what are some examples of disjoint events?"
  },
  {
    "objectID": "slides/slides-08-probability.html#rules-of-probability",
    "href": "slides/slides-08-probability.html#rules-of-probability",
    "title": "Probability basics",
    "section": "Rules of probability",
    "text": "Rules of probability\nKolmogorov axioms\n\nThe probability of any event is non-negative real number\nThe probability of the entire sample space 1\nIf \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cup B) = \\text{Pr}(A) + \\text{Pr}(B)\\)\n\n\nThese axioms imply that all probabilities are between 0 and 1 inclusive, and lead to some important rules!"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability-distributions",
    "href": "slides/slides-08-probability.html#probability-distributions",
    "title": "Probability basics",
    "section": "Probability distributions",
    "text": "Probability distributions\nWhen a random variable is discrete, it can be useful to discuss its probability distribution, which is a table of all (disjoint) outcomes and their associated probabilities.\n\n\nLet \\(X\\) be the sum of two fair, six-sided dice. What is the sample space \\(S\\)?\nFill out the table below to display the probability distribution of \\(X\\):\n\n\n\n\n\n\n\\(X\\)\n2\n3\n4\n5\n6\n7\n\n\nProbability\n\n\n\n\n\n\n\n\n\\(X\\)\n8\n9\n10\n11\n12\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nWhy not include 1 or 13?"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability-distributions-cont.",
    "href": "slides/slides-08-probability.html#probability-distributions-cont.",
    "title": "Probability basics",
    "section": "Probability distributions (cont.)",
    "text": "Probability distributions (cont.)\nThe probability distribution of a discrete random variable must satisfy the following three rules:\n\nThe outcomes listed must be disjoint\nEach probability must be between 0 and 1 (inclusive)\nThe probabilities must sum to 1\n\n\nLet’s confirm that the distribution we found on the previous slide satisfies these rules!"
  },
  {
    "objectID": "slides/slides-08-probability.html#complement",
    "href": "slides/slides-08-probability.html#complement",
    "title": "Probability basics",
    "section": "Complement",
    "text": "Complement\n\nThe complement of an event \\(A\\) is the set of all outcomes in \\(S\\) that are not in \\(A\\)\n\nDenoted as \\(A^c\\)\n\nContinuing the dice example, if \\(A\\) is the event that a 1 or 2 is rolled, what is \\(A^c\\)?\nComplement rule: \\(\\text{Pr}(A^c) = 1 - \\text{Pr}(A)\\)\n\nLet our random process be the sum of two dice. What is the probability that…\n\nthe sum of the dice is \\(not\\) 6?\nthe sum is at least 4?"
  },
  {
    "objectID": "slides/slides-08-probability.html#demorgans-laws",
    "href": "slides/slides-08-probability.html#demorgans-laws",
    "title": "Probability basics",
    "section": "DeMorgan’s Laws",
    "text": "DeMorgan’s Laws\nLet’s use Venn diagrams to try and determine formulas for the following:\n\nComplement of union: \\((A \\cup B)^c = \\ ?\\)\nComplement of intersection: \\((A \\cap B)^c = \\ ?\\)"
  },
  {
    "objectID": "slides/slides-08-probability.html#independence",
    "href": "slides/slides-08-probability.html#independence",
    "title": "Probability basics",
    "section": "Independence",
    "text": "Independence\n\nQualitatively, two processes are independent if knowing the outcome of one does not provide any information about the outcome of the other process\n\nExamples and non-examples? How to formalize this?\n\nIf \\(A\\) and \\(B\\) are independent events from two different and independent processes, then \\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\)\nMore generally, if \\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\) and \\(A\\) and \\(B\\) are events from the same process, then \\(A\\) and \\(B\\) are independent.\n\nThis is known as the multiplication rule for independent events"
  },
  {
    "objectID": "slides/slides-08-probability.html#practice",
    "href": "slides/slides-08-probability.html#practice",
    "title": "Probability basics",
    "section": "Practice",
    "text": "Practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-08-probability.html#more-practice",
    "href": "slides/slides-08-probability.html#more-practice",
    "title": "Probability basics",
    "section": "More practice",
    "text": "More practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political afilliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#probabilities-with-contingency-tables",
    "href": "slides/slides-09-conditional-probability.html#probabilities-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Probabilities with contingency tables",
    "text": "Probabilities with contingency tables\n\nAs we saw in the previous class, sometimes the probabilities of events are quite clear to calculate (e.g. dice rolls or drawing cards)\nBut oftentimes we have to use data to try and estimate probabilities\n\nWhy? Some probabilities are not known, and we use proportions from data as a proxy\n\nWhen we have two (or more) variables, we often want to understand the relationships between them (e.g. \\(A \\cap B\\))"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#practice",
    "href": "slides/slides-09-conditional-probability.html#practice",
    "title": "Conditional probability",
    "section": "Practice",
    "text": "Practice\n\nSource: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\n\nDefine events \\(A\\) = died and \\(B\\) = non-coffee drinker. Calculate/set-up the calculations for the following for a randomly selected person in the cohort:\n\n\\(\\text{P}(A)\\)\n\\(\\text{P}(A \\cap B)\\)\n\\(\\text{P}(A \\cup B^c)\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#marginal-and-joint-probabilities",
    "href": "slides/slides-09-conditional-probability.html#marginal-and-joint-probabilities",
    "title": "Conditional probability",
    "section": "Marginal and joint probabilities",
    "text": "Marginal and joint probabilities\n\n\\(\\text{P}(A)\\) is an example of a marginal probability, which is a probability involving a single event\n\nFrom the contingency table, we use row totals or column totals and the overall total to obtain marginal probabilities\n\n\\(\\text{P}(A \\cap B)\\) and \\(\\text{P}(A \\cup B^c)\\) are examples of a joint probability, which is a probability involving two or more events that have yet to occur\n\nFrom the contingency table, we use specific cells and the overall total to obtain joint probabilities"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#marginal-from-joint",
    "href": "slides/slides-09-conditional-probability.html#marginal-from-joint",
    "title": "Conditional probability",
    "section": "Marginal from joint",
    "text": "Marginal from joint\nUsing LoTP, we can obtain the marginal probabilities from joint probabilities (which some of you intuitively did)!\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\\[\\begin{align*}\n\\text{P}(B) &=\\text{P}(\\text{no coffee}) \\\\\n&\\overset{\\text{LoTP}}{=} \\text{P}(\\text{no coffee} \\ \\cap \\text{ did not die}) + \\text{P}(\\text{no coffee} \\ \\cap \\text{ died})  \\\\\n&= \\text{P}(B \\cap A) + \\text{P}(B \\cap A^c) \\\\\n&= \\frac{5438}{69164 } + \\frac{1039}{69164} \\\\\n&= 0.0936\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability",
    "title": "Conditional probability",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nConditional probability: a probability that an event will occur given that another event has already occurred\n\nE.g. Given that it rained yesterday, what is the probability that it will rain today?\nIt is called “conditional” because we calculate a probability under a specific condition\n\n\n\n\\(\\text{Pr}(A | B)\\) : probability of \\(A\\) given \\(B\\)\n\nNot to be confused with the coding | which is “or”\nAppears to involve two events, but we assume that the event that is conditioned on (in this case \\(B\\)) has already happened\n\nWe can easily obtain conditional probabilities from contingency tables!"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability-with-contingency-tables",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Conditional probability with contingency tables",
    "text": "Conditional probability with contingency tables\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nFrom contingency table, we use specific cells and row or column totals to obtain conditional probabilities\n\n\n\nRecall events \\(A\\) = died and \\(B\\) = non-coffee drinker. Write \\(\\text{P}()\\) notation for the conditional probability of dying given that someone does not drink coffee, and then obtain this probability."
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability-formula",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability-formula",
    "title": "Conditional probability",
    "section": "Conditional probability formula",
    "text": "Conditional probability formula\nWe can re-arrange the general multiplication formula to obtain the following general formula for conditional probability. For any events \\(A\\) and \\(B\\):\n\n\\[\n\\text{P}(A| B) = \\frac{\\text{P}(A \\cap B)}{\\text{P}(B)}\n\\]\n\n\n\nCome up with a similar formula for \\(\\text{P}(B|A)\\)\n\n\nNote: complement rule holds for conditional probabilities if we condition on the same information: \\(\\text{P}(A|B) = 1 - \\text{P}(A^c | B)\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#independence-and-conditional-probabilities",
    "href": "slides/slides-09-conditional-probability.html#independence-and-conditional-probabilities",
    "title": "Conditional probability",
    "section": "Independence and conditional probabilities",
    "text": "Independence and conditional probabilities\n\nRecall, events \\(A\\) and \\(B\\) are independent when what is true about their joint probability?\nUsing the general multiplication rule, what is another way to determine if events \\(A\\) and \\(B\\) are independent?\n\nWhy does this make sense “intuitively”?\n\n\nUsing this new test of independence, are dying and abstaining from coffee independent events?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#bayes-rule-1",
    "href": "slides/slides-09-conditional-probability.html#bayes-rule-1",
    "title": "Conditional probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\nAs we saw before, the two conditional probabilities \\(P(A|B)\\) and \\(P(B|A)\\) are not the same. But are they related in some way?\nBayes’ rule:\n\n\n\\[\n\\text{P}(A|B) =\n\\]\n\n\nWhy is this seemingly more complicated formula useful?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#bayes-theorem-more-general",
    "href": "slides/slides-09-conditional-probability.html#bayes-theorem-more-general",
    "title": "Conditional probability",
    "section": "Bayes’ Theorem (more general)",
    "text": "Bayes’ Theorem (more general)\n\nSuppose we have a random process and have a defined event \\(A\\)\nFurther suppose we can break up the sample space into \\(k\\) disjoint/mutually exclusive outcomes or events \\(B_{1}, B_{2}, \\ldots, B_{k}\\)\nWithout loss of generality, suppose we want \\(\\text{P}(B_{1} | A)\\)\nBayes’ Theorem states:\n\\[\\begin{align*}\n\\text{P}(B_{1} |  A ) &= \\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A)}\\qquad \\qquad\\qquad \\qquad \\text{(Bayes' Rule)} \\\\\n&= \\frac{\\text{P}(A|B_{1})\\text{P}(B_{1})}{\\text{P}(A\\cap B_{1}) + \\text{P}(A \\cap B_{2}) + \\ldots + \\text{P}(A \\cap B_{k})} \\qquad \\qquad \\text{(LoTP)} \\\\\n&=\\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A|B_{1}) \\text{P}(B_{1}) + \\text{P}(A | B_{2}) \\text{P}(B_{2}) + \\ldots + \\text{P}(A | B_{k} ) \\text{P}(B_{k})}\n\\end{align*}\\]\n\n\nHow would this change if we wanted \\(P(A_{2} | B)\\) instead?\nWhy is this important? We want P(B_i | A), but sometimes we only have probabilities in the other order of conditioning!"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#diagnostic-testing-example",
    "href": "slides/slides-09-conditional-probability.html#diagnostic-testing-example",
    "title": "Conditional probability",
    "section": "Diagnostic testing example",
    "text": "Diagnostic testing example\nSuppose we are interested in the performance of a medical diagnostic test. Let \\(D\\) be the event that a patient has the disease, and let \\(T\\) be the event that the test is positive for the disease.\n\nSome definitions (don’t worry about memorizing):\n\nPrevalence: \\(P(D)\\)\nSensitivity of test: \\(P(T|D)\\)\nSpecificity of test: \\(P(T^c | D^c)\\)\nPositive predictive value: \\(P(D | T)\\)\nNegative predictive value: \\(P(D^c | T^c)\\)\n\n\nWhat do these probabilities mean in plain English? Which ones do we hope are low? Which ones do we hope are high?\nWhich probability would you be most interested in knowing?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#example",
    "href": "slides/slides-09-conditional-probability.html#example",
    "title": "Conditional probability",
    "section": "Example",
    "text": "Example\n\nIn Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but this test is not perfect.\nIn about 11% of patients with breast cancer, the test gives a false negative: it indicates a woman does not have breast cancer when she does have breast cancer.\nIn about 7% of patients who do not have breast cancer, the test gives a false positive: it indicates these patients have breast cancer when they actually do not.\nIf we tested a random Canadian woman over 40 for breast cancer using a mammogram and the test came back positive, what is the probability that the patient actually has breast cancer?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#study-design",
    "href": "slides/slides-10-simpsons.html#study-design",
    "title": "Simpson’s paradox",
    "section": "Study design",
    "text": "Study design\n\nWhat are the differences between observational studies and experimental studies?\nWhat is a confounding variable?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#probability",
    "href": "slides/slides-10-simpsons.html#probability",
    "title": "Simpson’s paradox",
    "section": "Probability",
    "text": "Probability\nObservational study on sex bias based on Fall 1973 admissions data to the graduate program at the University of California, Berkeley\n\nRows: applicant gender. Columns: application results.\n\n\n\nAdmit\nDeny\nTotal\n\n\n\n\nMen\n3738\n4704\n8442\n\n\nWomen\n1494\n2827\n4321\n\n\nTotal\n5232\n7531\n12763\n\n\n\n\n\nWhat is the probability of admission for a randomly selected applicant?\nWhat is the probability of admission among men? Among women?\nAre the probabilities you found marginal, joint, or conditional probabilities?\n\n\n\n\nSuppose we want to understand the relationship between gender and admission decision. What sort of visualization might be appropriate for representing this data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#dive-into-data",
    "href": "slides/slides-10-simpsons.html#dive-into-data",
    "title": "Simpson’s paradox",
    "section": "Dive into data",
    "text": "Dive into data\nWe have more nuanced data about the graduate admissions: we know the department that each person was applied to.\nWe will consider the six largest departments: A, B, C, D, E, F\n\nThe first six observations in the data frame are as follows:\n\n\n\nhead(admissions)\n\n# A tibble: 6 × 3\n  Decision Gender Dept \n  <chr>    <chr>  <chr>\n1 Admit    Male   B    \n2 Reject   Female C    \n3 Admit    Male   C    \n4 Reject   Female C    \n5 Admit    Male   A    \n6 Reject   Male   F    \n\n\n\n\n\nWhat sort of EDA would be interesting/appropriate for these data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#live-code",
    "href": "slides/slides-10-simpsons.html#live-code",
    "title": "Simpson’s paradox",
    "section": "Live code",
    "text": "Live code\n\n\nFemale applicants:\n\n\n\n\n\nDept\nDecision\nn\n\n\n\n\nA\nAdmit\n89\n\n\nA\nReject\n19\n\n\nB\nAdmit\n17\n\n\nB\nReject\n8\n\n\nC\nAdmit\n202\n\n\nC\nReject\n391\n\n\nD\nAdmit\n131\n\n\nD\nReject\n244\n\n\nE\nAdmit\n94\n\n\nE\nReject\n299\n\n\nF\nAdmit\n24\n\n\nF\nReject\n317\n\n\n\n\n\n\nMale applicants:\n\n\n\n\n\nDept\nDecision\nn\n\n\n\n\nA\nAdmit\n512\n\n\nA\nReject\n313\n\n\nB\nAdmit\n353\n\n\nB\nReject\n207\n\n\nC\nAdmit\n120\n\n\nC\nReject\n205\n\n\nD\nAdmit\n138\n\n\nD\nReject\n279\n\n\nE\nAdmit\n53\n\n\nE\nReject\n138\n\n\nF\nAdmit\n22\n\n\nF\nReject\n351"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#visualize",
    "href": "slides/slides-10-simpsons.html#visualize",
    "title": "Simpson’s paradox",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#closer-look",
    "href": "slides/slides-10-simpsons.html#closer-look",
    "title": "Simpson’s paradox",
    "section": "Closer look",
    "text": "Closer look\nProbability of admission conditioning on gender and department:\n\n\n\n\n\n\n \n  \n    Dept \n    Gender \n    cond_prob_admit \n  \n \n\n  \n    A \n    Female \n    0.82 \n  \n  \n    A \n    Male \n    0.62 \n  \n  \n    B \n    Female \n    0.68 \n  \n  \n    B \n    Male \n    0.63 \n  \n  \n    C \n    Female \n    0.34 \n  \n  \n    C \n    Male \n    0.37 \n  \n  \n    D \n    Female \n    0.35 \n  \n  \n    D \n    Male \n    0.33 \n  \n  \n    E \n    Female \n    0.24 \n  \n  \n    E \n    Male \n    0.28 \n  \n  \n    F \n    Female \n    0.07 \n  \n  \n    F \n    Male \n    0.06 \n  \n\n\n\n\n\n\n\n\nAre all departments uniform in admission rates?\nDo admissions still seem biased against female applicants?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#whats-going-on",
    "href": "slides/slides-10-simpsons.html#whats-going-on",
    "title": "Simpson’s paradox",
    "section": "What’s going on?",
    "text": "What’s going on?\n\n\n\nBut wait… didn’t we start by noting that men were way more likely to be admitted than women?\nThe first two departments (A and B) are easy to get into\nThe following table shows for each gender, the proportion of applicants each department received.\n\n\n\n\n\n\n\n \n  \n    Gender \n    Dept \n    cond_prop \n  \n \n\n  \n    Female \n    A \n    0.059 \n  \n  \n    Female \n    B \n    0.014 \n  \n  \n    Female \n    C \n    0.323 \n  \n  \n    Female \n    D \n    0.204 \n  \n  \n    Female \n    E \n    0.214 \n  \n  \n    Female \n    F \n    0.186 \n  \n  \n    Male \n    A \n    0.307 \n  \n  \n    Male \n    B \n    0.208 \n  \n  \n    Male \n    C \n    0.121 \n  \n  \n    Male \n    D \n    0.155 \n  \n  \n    Male \n    E \n    0.071 \n  \n  \n    Male \n    F \n    0.139 \n  \n\n\n\n\n\n\n\n\nWhat do you notice?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#simpsons-paradox",
    "href": "slides/slides-10-simpsons.html#simpsons-paradox",
    "title": "Simpson’s paradox",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\nThe UC Berkeley admissions observational study is an example of Simpson’s paradox: when omitting one explanatory variable causes the measure/degree of association between another explanatory variable and a response variable to reverse or disappear\n\nIn other words, the inclusion/exclusion of a third variable in the analysis can change the apparent relationship between the other two variables\nWhat was the confounding variable in UC Berkeley study?"
  },
  {
    "objectID": "practice_probs/practice-08-probability.html",
    "href": "practice_probs/practice-08-probability.html",
    "title": "Probability",
    "section": "",
    "text": "If events \\(A\\) and \\(B\\) are disjoint, what is a simple formula for \\(P(A \\cup B)\\)?\n(\\(^*\\)) The American Community Survey (ACS) is an ongoing survey that provides data every year to give communities the current information they need to plan investments and services. The 2010 ACS estimated that 14.6% of Americans live below the poverty line, 20.7% speak a language other than English (i.e. a foreign language) at home, and 4.2% fall into both categories.\n\nAre living below the poverty line and speaking a foreign language at home disjoint?\nDraw a Venn diagram summarizing the probabilities and their associated probabilities. Be sure to complete the diagram by including a ``bounding box”.\nWhat percent of Americans live below the poverty line and only speak English at home?\nWhat percent of Americans live below the poverty line or speak a foreign language at home?\nWhat percent of Americans live below the poverty line and only speak English at home?\nIs the event that someone lives below the poverty line independent of the event that the person speaks a foreign language at home?\n\nIn a multiple choice exam, there are 5 questions and 4 choices for each question. Nancy has not studied for the exam at all and decides to randomly guess the answers. What is the probability that:\n\nthe first question Nancy gets correct is the 5th question? State any assumptions that you make.\nNancy gets all of the questions right?\nNancy gets at least one question right?"
  },
  {
    "objectID": "practice_probs/practice-09-conditional-probability.html",
    "href": "practice_probs/practice-09-conditional-probability.html",
    "title": "Conditional probability",
    "section": "",
    "text": "Suppose we have an event \\(A\\) from one random process and an event \\(B\\) from a second random process such that \\(P(A) = 0.3\\), \\(P(B) = 0.7\\), and \\(P(A \\cap B) = 0.1\\).\n\nAre the random processes independent?\nWhat is \\(P(A|B)\\)?\n\nAssortative mating is a nonrandom mating pattern where individuals with similar genotypes and/or phenotypes mate with one another more frequently than what would be expected under a random mating pattern. Researchers studying this topic collected the following data on eye colors of 204 Scandinavian men and their female partners. For simplicity, we only include heterosexual relationships in this exercise.\n\n\nFind the probability that a randomly chosen male respondent or his partner has blue eyes.\nWhat is the probability that a randomly chosen male respondent with blue eyes has a partner with blue eyes?\nWhat is the probability that a randomly chosen male respondent with brown eyes has a partner with blue eyes? What about the probability of a randomly chosen male respondent with green eyes having a partner with blue eyes?\nDoes it appear that the eye colors of male respondents and their partners are independent? Explain your reasoning.\n\n\\(^*\\) To get to Middlebury College, a professor uses their car 30% of the time, walks 20% of the time, and bikes 50% of the time. They are late 5% when walking, 10% of the time when driving (because this is Vermont and people stop for all pedestrians), and 2% of the time when biking.\n\nWhat is the probability the professor drove to work if they were late?\nWhat is the probability the professor walked to work if they were on time?"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html",
    "href": "live_code/data_wrangling_viz.html",
    "title": "Group data wrangling",
    "section": "",
    "text": "We will now work a larger subset of the Kaggle data science survey data!"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#warm-up-exercises",
    "href": "live_code/data_wrangling_viz.html#warm-up-exercises",
    "title": "More data wrangling",
    "section": "Warm-up exercises",
    "text": "Warm-up exercises\nHow many different programming languages were recommended in the survey?\n\n\n\nHow many of the respondents who work in academia in the United States are at most 25 years old at the time taking the survey?"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#group-analysis",
    "href": "live_code/data_wrangling_viz.html#group-analysis",
    "title": "Group data wrangling",
    "section": "Group analysis",
    "text": "Group analysis\nI want your group to generate your own investigation. Using your data-wrangling and plotting skills to do some EDA. After about a half hour, your group will share your process and results with the rest of the class!\nYour final results must include:\n\nA meaningful use of group_by()\nSummary statistics or frequency table\nVisualization with meaningful labels/titles\n\nYou can create more than one visualization and/or more than one table. Whatever speaks to you! The individual components (i.e. table/summary stats vs plot) do not need to use the same set of variables. Feel free to create as many code chunks as you’d like! There is a data dictionary at the bottom of this page that defines all the variables in the data set for you."
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#data-dictionary",
    "href": "live_code/data_wrangling_viz.html#data-dictionary",
    "title": "Group data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the data dictionary for the subset of the Kaggle data data.\n\nCountry: home country of employee (character)\nGender: specified gender (character)\nAge: age at time of survey (numeric)\nEmploymentStatus: reported employed status (character)\nEmploymerIndustry: employer’s industry (character)\nMajor: college major (character)\nCompensationAmount: annual compensation (numeric)\nCompensationCurrency: three-letter currency code (character)\nCurrentJobTitle: job title (character)\nTitleFit: assessment of how well the job title fits (“Fine”, “Perfectly”, “Poorly”)\nLanguageRecommendation: recommended programming language (character)\nWorkDataVisualizations: proportion of job dedicated to creating data visualizations, broken into pre-determined categories (character)\nJobSatisfaction: rating of job satisfaction on scale of 1-10, where 1 is not satisfied and 10 is highly satisfied (character)\nJobSatisfaction2: numeric version of JobSatisfaction (numeric)\nConversionUSD: conversion factor from CompensationCurrency to USD (numeric)"
  },
  {
    "objectID": "live_code/data_wrangling.html",
    "href": "live_code/data_wrangling.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "Recall that we are looking at data provided by Kaggle. In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/data_wrangling.html#selecting-columns",
    "href": "live_code/data_wrangling.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/data_wrangling.html#arranging-rows",
    "href": "live_code/data_wrangling.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/data_wrangling.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#practice",
    "href": "live_code/data_wrangling.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/data_wrangling.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling.html#grouping-by-grouped-operations",
    "href": "live_code/data_wrangling.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\n\ndatascience |>\n  group_by(EmploymentStatus) |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 3 × 2\n  EmploymentStatus                                     mean_age\n  <chr>                                                   <dbl>\n1 Employed full-time                                       34.3\n2 Employed part-time                                       29.5\n3 Independent contractor, freelancer, or self-employed     39.0"
  },
  {
    "objectID": "coding_practice/coding-practice-07-wrangling.html",
    "href": "coding_practice/coding-practice-07-wrangling.html",
    "title": "Data wrangling coding practice",
    "section": "",
    "text": "Load in the tidyverse and openintro packages in the code chunk below. We will once again work with the starbucks data from the openintro package.\n\n\n# load packages here\n\n\nWrangle the starbucks data to show a data frame that contains the number of each type of Starbucks item. Display the resulting data frame in descending order.\n\n\n\n\n\nWrangle the data to display the five Starbucks items with the highest amount of calories. Only display the name of the items and their calorie content.\n\n\n\n\n\nThree macronutrients serve as sources of calories (i.e. energy) in food: carbohydrates, proteins, and fat. Carbohydrates contain 4 calories per gram, proteins contain 4 calories per gram, and fats contain 9 calories per gram.\n\nWrangle the data to add a new variable called theoretical_cals which represents the number of calories each item in the starbucks data theoretically should have based on its levels of carbohydrates, protein, and fat. Store the resulting data frame as a new data frame called starbucks_new.\n\n\n\n\nUsing your starbucks_new data frame from the previous step, display a summary table/data frame that shows the standard deviation of the differences between the reported calories and theoretical calories. Make sure to specify an informative/nicer name in your summary table.\n\n\n\n\nOnce you’re finished, be sure to render and submit the PDF file to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "slides/slides-00-welcome.html#syllabus-and-website",
    "href": "slides/slides-00-welcome.html#syllabus-and-website",
    "title": "Welcome!",
    "section": "Syllabus and website",
    "text": "Syllabus and website\n\nCourse website: https://midd-stat201-fall2024.github.io/\n\nPlease bookmark this page and visit frequently!\nNote that both sections will use the same website"
  },
  {
    "objectID": "slides/slides-00-welcome.html#what-is-this-course-about",
    "href": "slides/slides-00-welcome.html#what-is-this-course-about",
    "title": "Welcome!",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nWhat is statistics? What is data science?\nBy the end of this course, you will:\n\nProduce and interpret graphical displays and numerical summaries of data\nHave developed confidence and some proficiency in coding in R (and in particular, the tidyverse syntax)\nBetter understand the central role of randomness in designing studies and making conclusions\nHopefully want to pursue another Statistics or Mathematics course!\nAnd much more…"
  },
  {
    "objectID": "slides/slides-00-welcome.html#necessary-background",
    "href": "slides/slides-00-welcome.html#necessary-background",
    "title": "Welcome!",
    "section": "Necessary background",
    "text": "Necessary background\n\nWe assume zero background in statistics and data science\nThere is a large computing component, though not as much as in STAT 118\n\nComfort in typing on keyboard, navigating your file system\n\nMATH 121 (Calculus 1) pre-req"
  },
  {
    "objectID": "slides/slides-00-welcome.html#recommendations",
    "href": "slides/slides-00-welcome.html#recommendations",
    "title": "Welcome!",
    "section": "Recommendations",
    "text": "Recommendations\n\nTakes notes! Each day’s slides will be made available on the course website by 10pm the night before. I recommend either:\n\nPrinting out the PDF version of slides to write notes on during class\n\nI recommend 4 or 6 slides per page (demo)\n\nDownloading PDF of slides to iPad/tablet/laptop and write notes on then using device\nTaking supplemental notes on paper/device\n\nRe–visit notes within 24 hours of class"
  },
  {
    "objectID": "slides/slides-00-welcome.html#recommendations-cont.",
    "href": "slides/slides-00-welcome.html#recommendations-cont.",
    "title": "Welcome!",
    "section": "Recommendations (cont.)",
    "text": "Recommendations (cont.)\n\nWe will frequently make use of our laptops. Please bring one with enough charge to last the entire class each day we meet!\n\nPlease let me know as soon as possible if you do not have access to a laptop\n\nTry to resist the temptation to do other tasks (e.g. check email, online shop, watch shows) when your laptop is open\n\nThis can be distracting to those around you\n\nKeep an open mind and don’t be afraid to ask for assistance or tell me to slow down!\nResist the temptation of using ChatGPT or other generative AI tools"
  },
  {
    "objectID": "slides/slides-00-welcome.html#github-username",
    "href": "slides/slides-00-welcome.html#github-username",
    "title": "Welcome!",
    "section": "GitHub username",
    "text": "GitHub username\n\nIf you don’t already have a GitHub account, please make one by visiting https://github.com/ and creating an account.\n\nTips for creating a username: incorporate your actual name, shorter is better than longer, make it timeless\n\nOnce you have an account, please go to this GoogleForm and enter in your GitHub username."
  },
  {
    "objectID": "slides/slides-00-welcome.html#beyoncés-albums",
    "href": "slides/slides-00-welcome.html#beyoncés-albums",
    "title": "Welcome!",
    "section": "Beyoncé’s albums",
    "text": "Beyoncé’s albums\n\nBeyoncé is one of the most famous singers of the 21st century\nBy 2023, Beyoncé had produced eight solo studio albums:\n\nDangerously in Love (2003), B’Day (2006), I Am… Sasha Fierce (2008), 4 (2011), Beyoncé (2013), Lemonade (2016), Renaissance (2022)\nPopular opinion (i.e. Reddit) is that Lemonade is her best album\n\nIs there any difference between the first four albums and Lemonade?\nLet’s consider the average length of words in these albums\n\nWe will discuss “average” in more detail next week, but for today, we will treat “average” as a number that is calculated by summing a bunch of quantities together and dividing by the total number of quantities"
  },
  {
    "objectID": "slides/slides-00-welcome.html#average-word-length",
    "href": "slides/slides-00-welcome.html#average-word-length",
    "title": "Welcome!",
    "section": "Average word length",
    "text": "Average word length\n\n\n\nThe average length of a word in Beyoncé’s first four alums is 3.62. What is the average length of a word in Lemonade?\n\n\nHow might we go about answering this question?\n\nLet’s collect some data!"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#reproducibility",
    "href": "slides/slides-02-toolkit-installation.html#reproducibility",
    "title": "Toolkit",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nAllows your code execution or an experiment to be repeated by another person\nGoals:\n\nAre the tables and figures generated directly from the code?\nDoes the code actually do what you think it does?\nCan your code be used for other data/analyses?"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#toolkit",
    "href": "slides/slides-02-toolkit-installation.html#toolkit",
    "title": "Toolkit",
    "section": "Toolkit",
    "text": "Toolkit\n\n\nWe will use the programming language R to write code\nHow will interact with the R code? In the integrated development environment called RStudio. Helps us be more productive with R\n\nR is like a car engine, and RStudio is like a car’s dashboard\n\nWe will liberate our programming by keeping code, narrative, and output all in the same interface using Quarto Markdown documents"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#r-markdown",
    "href": "slides/slides-02-toolkit-installation.html#r-markdown",
    "title": "Toolkit",
    "section": "R Markdown",
    "text": "R Markdown\n\nAllows us to create fully reproducible reports\nCan code in code chunks and type regular text/narrative outside of these chunks\nHow will we use R Markdown?\n\nYou coding practice problems and some weekly lab assignments will be assigned as an R Markdown document (.Rmd)\nYou will almost always be provided with a template .Rmd to start with (the exception being the end of the semester when you’ve mastered this material!)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#version-control",
    "href": "slides/slides-02-toolkit-installation.html#version-control",
    "title": "Installation Day",
    "section": "Version control",
    "text": "Version control"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#git-and-github",
    "href": "slides/slides-02-toolkit-installation.html#git-and-github",
    "title": "Installation Day",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\nGit is a version control system (like “Track Changes” in Microsoft Word)\nGitHub is the home for your Git-based projects (like DropBox)\nWe will work with GitHub Desktop to make working on code on your personal machine and sending it to the cloud for “safe keeping” seamless\n\nAlso makes for great collaboration, because multiple people can be on the same GitHub project and will see all the change you make (kind of like a shared GoogleDoc)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#installing-r",
    "href": "slides/slides-02-toolkit-installation.html#installing-r",
    "title": "Installation Day",
    "section": "Installing R",
    "text": "Installing R\nPlease be patient! This process may be time-consuming and stressful, but it is necessary for the rest of the course!\n\nWINDOWS/MAC: Go to the CRAN website and click on the appropriate link under “Download and Install R”. Then:\n\nIf you are Windows: click on the blue text that says “install R for the first time”.\nIf you are macOS: check your Mac OS system and if you have a chip (Apple icon -> About this Mac -> Overview)\n\nThen on the website, click the newest release that supports your current OS version. This will most likely be R-4.4.1-arm64.pkg or R-4.4.1-x86_64.pkg.\n\n\n\nLINUX: follow the instructions on for Steps 1 and 2 on this website."
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#install-r-cont.",
    "href": "slides/slides-02-toolkit-installation.html#install-r-cont.",
    "title": "Installation Day",
    "section": "Install R (cont.)",
    "text": "Install R (cont.)\n\nA file will download, most likely to your Downloads folder. Run the file by clicking on it. Allow the app to make changes to your device if prompted.\n\nFollow the installation instructions, until you click on “Finish” to exit the installation setup. At this point, R should be successfully installed!"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#installing-rstudio",
    "href": "slides/slides-02-toolkit-installation.html#installing-rstudio",
    "title": "Installation Day",
    "section": "Installing RStudio",
    "text": "Installing RStudio\n\nLINUX: go to step 3 of the same website\nWINDOWS/MACS: Go to the Posit website and scroll down a little until you see two steps. We already did Step 1!\n\nUnder Step 2, click the blue Download RStudio Desktop button recommended for your computer\n\nmacOS users: double check you have an OS that is recent enough! Otherwise, raise your hand!\n\nRun the downloaded RStudio Executable file until you hit the “Finish” button. It may be the case that you don’t have to click anything at all.\nAfter RStudio finishes downloading, a window like this might pop up. If so, go ahead and drag the RStudio icon into the Applications folder."
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#opening-rstudio",
    "href": "slides/slides-02-toolkit-installation.html#opening-rstudio",
    "title": "Installation Day",
    "section": "Opening RStudio",
    "text": "Opening RStudio\n\nIn the previous step, we put an RStudio shortcut into your Applications folder.\nYou may find it easier to put a shortcut somewhere else for easier access (e.g. your dock or home screen)\nTo open RStudio, simply double click on the RStudio icon (you do not need to click on the R icon)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#make-a-folder",
    "href": "slides/slides-02-toolkit-installation.html#make-a-folder",
    "title": "Toolkit",
    "section": "Make a folder",
    "text": "Make a folder\nCreate a new folder on your Desktop that is named STAT 201.\n\n\nAll of your files for this course should go into this folder!!!!"
  },
  {
    "objectID": "slides/slides-00-welcome.html",
    "href": "slides/slides-00-welcome.html",
    "title": "Welcome!",
    "section": "",
    "text": "Professor Becky Tang\n\nOffice: Warner 214\nEmail: btang@middlebury.edu\nOffice hours: Mondays 2-3pm, Fridays 10-11am\n\nCourse website: https://midd-stat201-spring2025.github.io/\n\nPlease bookmark this page and visit frequently!\nNote that both sections will use the same website\n\n\n\n\n\n\nWhat is statistics? What is data science?\nBy the end of this course, you will:\n\nProduce and interpret graphical displays and numerical summaries of data\nHave developed confidence and some proficiency in coding in R (and in particular, the tidyverse syntax)\nBetter understand the central role of randomness in designing studies and making conclusions\nHopefully want to pursue another Statistics or Mathematics course!\nAnd much more…\n\n\n\n\n\n\nWe assume zero background in statistics and data science\nThere is a large computing component, though not as much as in STAT 118\n\nComfort in typing on keyboard, navigating your file system\n\nMATH 121 (Calculus 1) pre-req\n\n\n\n\n\nTakes notes! Each day’s slides will be made available on the course website by 10pm the night before. I recommend either:\n\nPrinting out the PDF version of slides to write notes on during class\n\nI recommend 4 or 6 slides per page (demo)\n\nDownloading PDF of slides to iPad/tablet/laptop and write notes on then using device\nTaking supplemental notes on paper/device\n\nRe–visit notes within 24 hours of class\n\n\n\n\n\nWe will frequently make use of our laptops. Please bring one with enough charge to last the entire class each day we meet!\n\nPlease let me know as soon as possible if you do not have access to a laptop\n\nTry to resist the temptation to do other tasks (e.g. check email, online shop, watch shows) when your laptop is open\n\nThis can be distracting to those around you\n\nKeep an open mind and don’t be afraid to ask for assistance or tell me to slow down!\nResist the temptation of using ChatGPT or other generative AI tools\n\n\n\n\n\nProblem Set 0: answers to a brief questionnaire are due before next class. See the course Schedule page for details!\nAll coding practice and homework assignments will be submitted to Gradescope via Canvas. You should all be able to access your Gradescope account using your Middlebury College credentials.\n\nOn Canvas, assignments can be found in both the Assignment tab and the Gradescope tab\nSubmissions can be resubmitted as many times as you like up until the due date\nWe will walk through how to submit an assignment together, but instructions + video can also be found here\n\n\n\n\n\nCounties of the U.S. within the bottom 10% of death rates for kidney cancer for white males, 1980-1989.\n\n\n\n\n\n\nWhat do you notice? What might be the explanation?\n\n\n\n\nCounties of the U.S. within the top 10% of death rates for kidney cancer for white males, 1980-1989.\n\n\n\n\n\n\n\n\nWhat’s going on? Let’s do some digging…\n\nDeath rate for kidney cancer: https://seer.cancer.gov/statfacts/html/kidrp.html\nCounty sizes: https://en.wikipedia.org/wiki/County_statistics_of_the_United_States"
  },
  {
    "objectID": "live_code/intro_R.html",
    "href": "live_code/intro_R.html",
    "title": "Intro to R and Quarto Markdown",
    "section": "",
    "text": "In the Console, type the following code: 1 + 1. What happens?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNothing!\n\n\n\nTo execute/run code in the Console, we simply press Enter. Try it! What happens?\n\n\nNote that spacing doesn’t matter in R code.\nWe can add (+), subtract (-), multiply (*), divide (/), and perform more complicated calculations using R."
  },
  {
    "objectID": "live_code/intro_R.html#introduction-to-r-markdown",
    "href": "live_code/intro_R.html#introduction-to-r-markdown",
    "title": "Untitled",
    "section": "Introduction to R Markdown",
    "text": "Introduction to R Markdown\nThis document that we are working in is called an R markdown document. It allows us to seamlessly move between R code and regular text. How do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right.\nThis defines ______. All of our R code should go into one.\n\n\n\n\n\n\n\nWhat happens if we delete a back tick?\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n1.\n2."
  },
  {
    "objectID": "live_code/intro_R.html#saving-progress",
    "href": "live_code/intro_R.html#saving-progress",
    "title": "Intro to R and Quarto Markdown",
    "section": "Saving progress",
    "text": "Saving progress\nAt this point it is a good idea to save our progress. Like most document editors, we need to explicitly save our work. You know your work is not saved when _____.\nTo save our work in Quarto Markdown document, we can do one of the following:\n\nClick on the floppy disk at the top of the panel\nGo to File -> Save\nHit Cmd+S\n____ the document"
  },
  {
    "objectID": "live_code/intro_R.html#r-markdown-basics",
    "href": "live_code/intro_R.html#r-markdown-basics",
    "title": "Intro to R and R Markdown",
    "section": "R Markdown basics",
    "text": "R Markdown basics\nHow do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right. These backs ticks must be aligned on the same tabulation.\nThis defines ______. All of our R code should go into one.\n\n\n\n\n\n\n\nWhat happens if we delete a back tick?\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n1.\n2.\n\nsqrt(4)\n\n[1] 2"
  },
  {
    "objectID": "live_code/intro_R.html#coding-in-r",
    "href": "live_code/intro_R.html#coding-in-r",
    "title": "Intro to R and Quarto Markdown",
    "section": "Coding in R",
    "text": "Coding in R\nR is more than just a calculator! It provides lots of functionality for performing tasks related specifically to statistics.\n\nObject types\nEverything in R is an object. Here, we provide a non-exhaustive list of common objects (i.e. structures) you will encounter.\n\nA ____ object contains only a single number\n\n\n\n\n\nA ____ or ____ object is a set of characters within one pair of quotation marks\n\n\n\n\n\nA ____ object is an ordered collection of numbers or strings. We can create vectors using the command c():\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhat happened here?\n\nc(1, \"no\")\n\n[1] \"1\"  \"no\"\n\n\n\n\n\n\nA ____ object is either TRUE or FALSE. It is also referred to as a boolean.\nData frames are representations of datasets in R where the rows correspond to observations and columns correspond to variables that describe the observations (more on this later).\n\n\n\nFunctions\nWhen we calculated \\(\\sqrt{4}\\), we used the code sqrt(). This is an example of a function. Functions allow us to automate common tasks in a general way. Functions (just like in math) take in one or more inputs. These inputs are known as _____ or _____. They will almost always return an output. We know a command in R is a function because it has _____.\nIt is possible for us to create our own customized functions (you definitely will if you take STAT 218). However, in STAT 201, we will work with pre-provided functions. All pre-provided functions in R are accompanied by a Help file. To access the Help file, simply type ? followed by the name of the function in the Console. Try opening the Help file for the sqrt() function.\nIf I want to obtain the square root of the values 1, 4, 9, and 16, what code can I type?\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsqrt(c(1,4,9, 16))\n\n[1] 1 2 3 4\n\n\n\n\n\n\n\nStoring objects as variables\nSuppose I want to save the result of a big calculation to use moving forward. We _____ or ______ the value of 1 + 2 + 3 + 4 + 5 into the ______ called x using the keys <-.\n\n\n\nAs you should note: when we assign an object a value, its value is not automatically shown as output. In order to display the output, you must _____."
  },
  {
    "objectID": "live_code/intro_R.html#errors-warnings-and-messages",
    "href": "live_code/intro_R.html#errors-warnings-and-messages",
    "title": "Intro to R and Quarto Markdown",
    "section": "Errors, warnings, and messages",
    "text": "Errors, warnings, and messages\nThese are always shown in red text in the Console. Whenever you see them, don’t panic! With practice, you will be able to decipher the messages and de-bug your code with ease.\n\nErrors: prevent code from executing and documents from rendering It will be prefaced with “Error in…”. Trying typing in the following code in your Console: 1 + a. What happens?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n1+a\n\nError in eval(expr, envir, enclos): object 'a' not found\n\n\n\n\n\n\n\nA good reason to render often is to ensure your code is error-free!\n\nWarnings: your code will run with some caveats. It will be prefaced with “Warning:”. We will see examples of this later on.\nMessages: messages in red that do not begin with “Error” or “Warning” are simply friendly messages that might provide you more information about the execution of your code."
  },
  {
    "objectID": "live_code/intro_R.html#packages",
    "href": "live_code/intro_R.html#packages",
    "title": "Intro to R and Quarto Markdown",
    "section": "Packages",
    "text": "Packages\nPackages in R extend the functionality by providing additional functions and data. You can view them as analogous to apps you download from the App Store or Google Play on a cell phone. To use an app on a phone, you have to:\n\nDownload the app\nExplicitly open the app\n\nTo use a package, we need to:\n\n____ the package\n____ the package\n\nUnless you update R Studio, you will only need to install a package once. However, you will need to explicitly load in packages every time you work in a new Quarto Markdown document.\nThere are thousands of available packages to work with. Two of the most common packages we will use are the openintro package and the tidyverse package (though, the tidyverse package is actually a giant package that is comprised of several other packages).\n\nPackage installation\nThere are two ways to install a package:\n\nOption 1:\n\nClick on the “Packages” tab in the Files pane of RStudio\nClick on “Install”\nType the name of the package under “Packages (separate multiple with space or comma):”.\nClick “Install”\n\nOption 2:\n\nType install.packages(\"package name\") into the Console. Note that the quotation marks are necessary.\nPress Return/Enter\n\n\nWe will install the openintro package together.\nThen, try installing the tidyverse package on your own!\n\n\nPackage loading\nIf we want to use a package, we use the library() command:\n\nlibrary(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\n\n\n\nThis is an example of a function that does not return an output\n\n\n\n\n\n\nTip\n\n\n\nYou may have seen some red text in your Console when you loaded in the package above. That’s okay!"
  },
  {
    "objectID": "coding_practice/coding-practice-02-intro-r.html",
    "href": "coding_practice/coding-practice-02-intro-r.html",
    "title": "Intro to R coding practice",
    "section": "",
    "text": "Change your name in the YAML. Be sure to keep the quotation marks!\nExecute the following the code in the code chunk. In the space below the code chunk that reads Answer: describe in words (as specifically as possible) what the code is doing. What type of object is this?\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nAnswer:\n\nWe will learn how to use the important function sample(), which allows us to obtain a random sample in R. Look at the Help file by typing ?sample into your Console. After some experimenting, write code that randomly samples five numbers from the set of numbers/integers 5-10, without replacement. Note: it’s okay if you get something different from those around you! We are randomly sampling after all!\n\n\n\n\n\nIn following code chunk, write code that randomly samples five numbers from the set of numbers/integers 5-10, with replacement.\n\n\n\n\n\nIn the following code chunk, write code to load in the openintro package. Then run the code in the code chunk.\n\n\n\n\n\nIn the Console, type in ?cherry to open up the Help file for the cherry data frame. What are the units for each of the variables?\n\nAnswer:\n\nRemember that rows in data frames represent observations. How many observations are there in the cherry data frame? Answer this via code by using the nrow() function and passing in the name of data frame of interest.\n\n\n\n\nOnce you’re finished, be sure to Render one last time and submit the outputted PDF to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#explanatory-vs.-response",
    "href": "slides/slides-01-study-design.html#explanatory-vs.-response",
    "title": "Study design",
    "section": "Explanatory vs. Response",
    "text": "Explanatory vs. Response\n\nLots of scientific questions revolve around asking how \\(x\\) relates to \\(y\\)\nIf \\(y\\) is the primary variable of interest, i.e. the variable whose behavior we want to understand, it is called the response variable\nIf we try to understand how changing \\(x\\) affects \\(y\\), then \\(x\\) is called the explanatory variable\n\nExplanatory variables can often be manipulated/controlled/observed by the researcher ahead of time"
  },
  {
    "objectID": "slides/slides-00-welcome.html#important-course-information",
    "href": "slides/slides-00-welcome.html#important-course-information",
    "title": "Welcome!",
    "section": "Important course information",
    "text": "Important course information\n\nProfessor Becky Tang\n\nOffice: Warner 214\nEmail: btang@middlebury.edu\nOffice hours: Mondays 2-3pm, Fridays 10-11am\n\nCourse website: https://midd-stat201-spring2025.github.io/\n\nPlease bookmark this page and visit frequently!"
  },
  {
    "objectID": "slides/slides-00-welcome.html#example",
    "href": "slides/slides-00-welcome.html#example",
    "title": "Welcome!",
    "section": "Example",
    "text": "Example\nCounties of the U.S. within the bottom 10% of death rates for kidney cancer for white males, 1980-1989.\n\n\nWhat do you notice? What might be the explanation?"
  },
  {
    "objectID": "slides/slides-00-welcome.html#example-cont.",
    "href": "slides/slides-00-welcome.html#example-cont.",
    "title": "Welcome!",
    "section": "Example (cont.)",
    "text": "Example (cont.)\nCounties of the U.S. within the top 10% of death rates for kidney cancer for white males, 1980-1989."
  },
  {
    "objectID": "slides/slides-00-welcome.html#example-cont.-1",
    "href": "slides/slides-00-welcome.html#example-cont.-1",
    "title": "Welcome!",
    "section": "Example (cont.)",
    "text": "Example (cont.)\nWhat’s going on? Let’s do some digging…\n\nDeath rate for kidney cancer: https://seer.cancer.gov/statfacts/html/kidrp.html\nCounty sizes: https://en.wikipedia.org/wiki/County_statistics_of_the_United_States"
  },
  {
    "objectID": "slides/slides-01-study-design.html#example-literary-digest-poll",
    "href": "slides/slides-01-study-design.html#example-literary-digest-poll",
    "title": "Study design",
    "section": "Example: Literary Digest poll",
    "text": "Example: Literary Digest poll\n\n1936 was an election year in the United States. Franklin D. Roosevelt (a Democrat) was completing his first term in office as president.\nRepublican candidate Alfred Landon of Kansas was his competitor\nLiterary Digest magazine conducted a polling survey, which received 2.4 million respondents (largest number of people every replying to a poll at that time)\n\nPrediction: overwhelming victory for Landon (predicted FDR would only get 43% of popular vote)\n\nActual result: FDR won by a landslide! (62% to 38%)\nWhat happened? Selection and non-response bias\n\n\n\nSelection bias: Digest mailed questionnaires to 10 million people. Where did they get the address form? Telephone books and club membership lists –> screened out the poor (only about 25% of households had phones)\n\nThis wouldn’t necessarily be bias, EXCEPT for the fact that poor people overwhelmingly favored FDR and the rich favored Landon\n\nNon-response bias: lots of people didn’t respond to survey (~75%)\n\nOnce again, wouldn’t matter if there wasn’t a difference in the opinions of respondents vs non-respondents. But among the 25% who responded, over half favored Landon\nNon-respondents can be very different from respondents. When there is high non-response rate, look for non-response bias\n\nLesson: not all samples that were done poorly are necessarily biased, but we should always ask how the sample was conducted! Also, when a selection procedure is biased, a large sample does not help; this just replicates the mistake on a larger scale!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#simple-random-sampling-srs",
    "href": "slides/slides-01-study-design.html#simple-random-sampling-srs",
    "title": "Study design",
    "section": "1. Simple random sampling (SRS)",
    "text": "1. Simple random sampling (SRS)\n\nIn a simple random sample, each case is chosen entirely by chance from the population, and each member of the population has an equal chance of being sampled\n\nKnowing that an individual was sampled does not provide useful information about which other cases are included\n\nAny given fixed-size subset of the population is equally likely to be chosen\n\n\n\nConsider again the research question: What proportion of current Middlebury professors attended a liberal arts college?\nHow might I obtain a simple random sample of 25 professors?\n\n\n\nRequires us to list all of the units in the target/survey population –> May be unrealistic!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#multistage-cluster-sampling",
    "href": "slides/slides-01-study-design.html#multistage-cluster-sampling",
    "title": "Study design",
    "section": "Multistage cluster sampling",
    "text": "Multistage cluster sampling\n\nBuilds on the cluster sampling method, but rather than sampling all individuals within the selected clusters, only collect a simple random sample within each selected cluster\n\nCan make more stages/layers if appropriate!\n\nThough seemingly more complicated, why might we prefer multistage sampling over cluster sampling?\nHow might we devise a multistage cluster sample for Literary Digest?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#probability-sampling",
    "href": "slides/slides-01-study-design.html#probability-sampling",
    "title": "Study design",
    "section": "Probability sampling",
    "text": "Probability sampling\n\nIn general, sampling methods that include a bit of randomness can help reduce the chance of bias\nProbability/random sampling: any sampling method where the selection from the population is based on random selection/chance\n\nNo one has full discretion about who is included in the sample\n\nRandom sampling usually yields a representative and generalizable sample\nExamples include: simple random, stratified, cluster, systematic"
  },
  {
    "objectID": "live_code/intro_R.html#yaml",
    "href": "live_code/intro_R.html#yaml",
    "title": "Intro to R and Quarto Markdown",
    "section": "YAML",
    "text": "YAML\nAt the top of a markdown topic, you’ll see code between two sets of three dashed lines. This is known as a YAML header, and it contains the “informational” content of a document (e.g. title, author, date). Change these arguments accordingly for each assignment.\n\n\n\n\n\n\n\nNotice the quotation marks! These are extremely important!\nGo ahead and change your name in the author argument of the YAML."
  },
  {
    "objectID": "slides/slides-01-study-design.html",
    "href": "slides/slides-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "Please bring your laptops tomorrow! We will be working with R and RStudio!"
  },
  {
    "objectID": "live_code/template_intro_R.html",
    "href": "live_code/template_intro_R.html",
    "title": "Introduction to R and R Markdown",
    "section": "",
    "text": "This document that we are working in is called an R markdown document. It allows us to seamlessly move between R code and regular text. The name of the file is easily found at the top this panel. All R markdown files end in ____.\n\n\nAt the top of a markdown topic, you’ll see code between two sets of three dashed lines. This is known as a YAML header, and it contains the “informational” content of a document (e.g. title, author, date). Change these accordingly for each assignment!\nGo ahead and change your name in the author argument of the YAML.\n\n\n\nHow do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right. These backs ticks must be aligned on the same tabulation.\nThis defines ______. All of our R code should go into one.\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n\n\n\n\n\n\n\nAt this point it is a good idea to save our progress. Like most document editors, we need to explicitly save our work. You know your work is not saved when _____.\nTo save our work in R Markdown document, we can do one of the following:\n\nClick on the floppy disk at the top of the panel\nGo to File -> Save\nHit Cmd+S\n____ the document\n\n\n\nKnitting the document will render your R markdown into its final output form. To knit, simply click on the ball of yarn at the top of the panel. Knitting can take anywhere from a few seconds to a few minutes depending on the amount of code and narrative you have.\nNow, outside of R Studio, go to the Folder where this R Markdown document is located. What do you notice? ______\n\n\n\n\nR is more than just a calculator! It provides lots of functionality for performing tasks related specifically to statistics.\n\n\nEverything in R is an object. Here, we provide a non-exhaustive list of common objects (i.e. structures) you will encounter.\n\nA ____ object contains only a single number\n\n\n\n\n\nA ____ or ____ object is a set of characters within one pair of quotation marks\n\n\n\n\n\nA ____ object is an ordered collection of numbers or strings. We can create vectors using the command c():\n\n\n\n\n\nA ____ object is either TRUE or FALSE. It is also referred to as a boolean.\nData frames are representations of datasets in R where the rows correspond to observations and columns correspond to variables that describe the observations (more on this later).\n\n\n\n\nWhen we calculated \\(\\sqrt{4}\\), we used the code sqrt(). This is an example of a function. Functions allow us to automate common tasks in a general way. Functions (just like in math) take in one or more inputs. These inputs are known as _____ or _____. They will almost always return an output. We know a command in R is a function because it has _____.\nIt is possible for us to create our own customized functions (you definitely will if you take STAT 218). However, in STAT 201, we will work with pre-provided functions. All pre-provided functions in R are accompanied by a Help file. To access the Help file, simply type ? followed by the name of the function in the Console. Try opening the Help file for the sqrt() function.\n\n\n\nSuppose I want to calculate the volume of a cube, where each edge is of length 2. The volume is \\(\\text{edge length}^3\\) . We could calculate the area as follows:\n\n\n\nNow suppose someone tells you that the edge length was actually 2.1 instead of 2. So you modify as follows:\n\n\n\nThen you get told the edge length is actually 2.2. So frustrating! To save ourselves further troubles, we do the following to make our code reproducible:\n\n\n\nWhat did we do in the above code? We _____ or ______ the value 2.2 into the ______ called length using the keys <-.\nNow make a new R code chunk here. In this new code chunk, make a new object called volume and assign to it an appropriate value. Knit the document.\nOnce you knit, you should note: when we assign an object a value, its value is not automatically shown as output. In order to display the output, you must _____.\n\n\n\n\nThese are always shown in red text in the Console. Whenever you see them, don’t panic! With practice, you will be able to decipher the messages and de-bug your code with ease.\n\nErrors: prevent code from executing and documents from knitting. It will be prefaced with “Error in…”. Trying typing in the following code in your Console: 1 + a. What happens?\nWarnings: your code will run with some caveats. It will be prefaced with “Warning:”. We will see examples of this later on.\nMessages: messages in red that do not begin with “Error” or “Warning” are simply friendly messages that might provide you more information about the execution of your code.\n\n\n\n\nPackages in R extend the functionality by providing additional functions and data. You can view them as analogous to apps you download from the App Store or Google Play on a cell phone. To use an app on a phone, you have to:\n\nDownload the app\nExplicitly open the app\n\nTo use a package, we need to:\n\n____ the package\n____ the package\n\nUnless you update R Studio, you will only need to install a package once. However, you will need to explicitly load in packages every time you work in a new R Markdown document.\nThere are thousands of available packages to work with. Two of the most common packages we will use are the openintro package and the tidyverse package (though, the tidyverse package is actually a giant package that is comprised of several other packages).\n\n\nThere are two ways to install a package:\n\nOption 1:\n\nClick on the “Packages” tab in the Files pane of RStudio\nClick on “Install”\nType the name of the package under “Packages (separate multiple with space or comma):”.\nClick “Install”\n\nOption 2:\n\nType install.packages(\"package name\") into the Console. Note that the quotation marks are necessary.\nPress Return/Enter\n\n\nWe will install the openintro package together. Then try installing the tidyverse package on your own!\n\n\n\nTo use the package we have installed, we use the library() command:"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html",
    "href": "slides/slides-02-toolkit-installation.html",
    "title": "Toolkit",
    "section": "",
    "text": "More homework problems released today. All due to Canvas on Monday by 11:59pm! Feel free to hand-write and then scan your work, or work in a text editor directly.\nOffice hours reminder!"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variables-types",
    "href": "slides/slides-03-numerical-pt1.html#variables-types",
    "title": "Numerical data",
    "section": "Variables types",
    "text": "Variables types\n\nVariables can be broadly broken into two categories: numerical (quantitative) or categorical (qualitative)\nNumerical variables take a wide range of numerical values, and it is sensible to add/subtract/do mathematical operations with those values. Two types:\n\nDiscrete if it can only take on finitely many numerical values within a given interval\nContinuous if it can take on any infinitely many values within a given interval\n\nCategorical variables are essentially everything else (more on this next week!)\nExamples and non-examples?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#example-1",
    "href": "slides/slides-03-numerical-pt1.html#example-1",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nLet’s calculate the sample mean weight of a piece of candy in our bag. Let \\(x\\) be the weight of a candy.\n\n\nWrite out how you would calculate your \\(\\bar{x}\\)\n\nNote: we did not need individual values \\(x_{1}, x_{2},\\ldots\\) to calculate \\(\\bar{x}\\)!\nCan we obtain the population mean?\n\n\\(\\mu=\\)"
  },
  {
    "objectID": "live_code/stat201_live_code.html",
    "href": "live_code/stat201_live_code.html",
    "title": "STAT 201 Live code",
    "section": "",
    "text": "# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "live_code/numerical_pt1_live.html",
    "href": "live_code/numerical_pt1_live.html",
    "title": "9/16/2024 Live code",
    "section": "",
    "text": "# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# first argument is x-axis\nplot(insurance$bmi, insurance$charges)\n\n\n\n# make axis labels more informative and add title \nplot(insurance$bmi, insurance$charges, xlab = \"BMI\", ylab = \"Charges ($)\", \n     main = \"Scatterplot of insurance charges by BMI\")"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#creating-visualizations",
    "href": "slides/slides-03-numerical-pt1.html#creating-visualizations",
    "title": "Numerical data",
    "section": "Creating visualizations",
    "text": "Creating visualizations\nWorking in your groups:\n\n\nUsing a histogram, visualize the distribution of the sample mean weights from our activity\nConvince yourselves as a group: what is does a case represent in this data?\nDescribe the shape of your distribution (i.e. skewness and modality)\nObtain the sample mean and standard deviation of the sample means"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#live-code-1",
    "href": "slides/slides-03-numerical-pt1.html#live-code-1",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\nFunctions to calculate sample mean, variance, and standard deviation in R:\n\nmean()\nvar()\nsd()"
  },
  {
    "objectID": "live_code/numerical_pt1_live.html#plots-in-base-r",
    "href": "live_code/numerical_pt1_live.html#plots-in-base-r",
    "title": "9/16/2024 Live code",
    "section": "Plots in base R",
    "text": "Plots in base R\n\n# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# scatter plot: first argument is x-axis\nplot(insurance$bmi, insurance$charges)\n\n\n\n# make axis labels more informative, add title, add color for fun\nplot(insurance$bmi, insurance$charges, xlab = \"BMI\", ylab = \"Charges ($)\", \n     main = \"Scatterplot of insurance charges by BMI\",\n     col = \"blue\")\n\n\n\n# make histogram\nhist(insurance$bmi)\n\n\n\n# change numbers of bins. Check Help file!\nhist(insurance$bmi, xlab = \"BMI\", ylab = \"Histogram of BMI\", breaks = 15)"
  },
  {
    "objectID": "live_code/numerical_pt1_live.html#summary-statistics",
    "href": "live_code/numerical_pt1_live.html#summary-statistics",
    "title": "9/16/2024 Live code",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nmean(insurance$bmi)\n\n[1] 30.63417\n\nvar(insurance$bmi)\n\n[1] 31.98109\n\nsd(insurance$bmi)\n\n[1] 5.655182\n\n# confirm\nsqrt(var(insurance$bmi))\n\n[1] 5.655182"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#another-boxplot",
    "href": "slides/slides-04-numerical-pt2.html#another-boxplot",
    "title": "Numerical data",
    "section": "Another boxplot",
    "text": "Another boxplot\nNow a boxplot of the estimated weights from the previous class!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#quartiles",
    "href": "slides/slides-04-numerical-pt2.html#quartiles",
    "title": "Numerical data",
    "section": "Quartiles",
    "text": "Quartiles\n\nThe 25th percentile is the value of data with 25% of values below it. Special name: first quartile \\(Q_{1}\\)\nThe 75th percentile is the value of data with 75% of values below it. Special name: third quartile \\(Q_{3}\\)\n\nWhat percent of the data fall between \\(Q_{1}\\) and \\(Q_{3}\\)? What percent of the data fall between \\(Q_{1}\\) and the median?\n\nHow to calculate? Suppose we have \\(2q\\) (even) or \\(2q + 1\\) (odd) number of values\n\n\\(Q_{1}\\) is the median of the \\(q\\) smallest values\n\\(Q_{3}\\) is the median of the \\(q\\) largest values\n\n\nWhat are \\(Q_{1}\\) and \\(Q_{3}\\) of the data \\(\\boldsymbol{x} = 108,112,113, 114, 115, 116, 118, 119, 121, 129\\)?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#more-visualizations-and-statistics",
    "href": "slides/slides-04-numerical-pt2.html#more-visualizations-and-statistics",
    "title": "Numerical data",
    "section": "More visualizations and statistics",
    "text": "More visualizations and statistics\n\n\n\n\nWe know how to calculate some summary statistics and interpret them alongside the histogram. But wouldn’t it be great if we had a visualization that directly displays some summary statistics?"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot",
    "href": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Introduction to ggplot",
    "text": "Introduction to ggplot\n\nWe will learn how to create histograms, box plots, and scatterplots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from the previous coding practice?\n\nThis is what the code will generally look like. Values in < > and xxx denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, # specify data frame\n       mapping = aes(x = <x-var>)) + #  specify variables to be used in plot\n  geom_xxx() + # specify plot type\n  <other options>"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot-.incremental-t",
    "href": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot-.incremental-t",
    "title": "Visualizations with ggplot",
    "section": "Introduction to ggplot {.incremental = T}",
    "text": "Introduction to ggplot {.incremental = T}\n\nWe will learn how to create histograms, box plots, and scatterplots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from what we’ve seen in the past?\n\nThis is what the code will generally look like. Values in < > and xxx denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, # <1>\n       mapping = aes(x = <x-var>)) + # <2> \n  geom_xxx() + # <3>\n  <other options>\n\n\nSpecify data frame\nSpecify variables to be use in plot\nSpecify type of plot"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#test",
    "href": "slides/slides-05-numerical-data-viz.html#test",
    "title": "Visualizations with ggplot",
    "section": "Test",
    "text": "Test\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |>                                      # <1>\n  mutate(                                        # <2>\n    bill_ratio = bill_depth_mm / bill_length_mm, # <2>\n    bill_area  = bill_depth_mm * bill_length_mm  # <2>\n  )                                              # <2>\n\nTake penguins, and then,\nadd new columns for the bill ratio and bill area."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics-color",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics-color",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics: color",
    "text": "Aesthetics: color\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges, \n                     col = age)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(aes(col = age))"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics-transparency",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics-transparency",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics: transparency",
    "text": "Aesthetics: transparency\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       alpha = age)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetic-color",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetic-color",
    "title": "Visualizations with ggplot",
    "section": "Aesthetic: color",
    "text": "Aesthetic: color\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       col = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetic-shape",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetic-shape",
    "title": "Visualizations with ggplot",
    "section": "Aesthetic: shape",
    "text": "Aesthetic: shape\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#specifying-multiple-aesthetics",
    "href": "slides/slides-05-numerical-data-viz.html#specifying-multiple-aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Specifying multiple aesthetics",
    "text": "Specifying multiple aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age, alpha = age)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#adding-a-title",
    "href": "slides/slides-05-numerical-data-viz.html#adding-a-title",
    "title": "Visualizations with ggplot",
    "section": "Adding a title",
    "text": "Adding a title\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\",\n          subtitle = \"In USD\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#changing-axis-labels",
    "href": "slides/slides-05-numerical-data-viz.html#changing-axis-labels",
    "title": "Visualizations with ggplot",
    "section": "Changing axis labels",
    "text": "Changing axis labels\nBy default, axis titles are taken from variable name specified in aes(). To change:\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_histogram-cont.",
    "href": "slides/slides-05-numerical-data-viz.html#geom_histogram-cont.",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram() cont.",
    "text": "geom_histogram() cont.\nTo improve on histogram we change the bin width.\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram(binwidth = 5000)\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#additional-variables-modifications",
    "href": "slides/slides-05-numerical-data-viz.html#additional-variables-modifications",
    "title": "Visualizations with ggplot",
    "section": "Additional variables + modifications",
    "text": "Additional variables + modifications\n\nWe emphasize making informative and useful visualizations.\n\nInformative titles and labels\nPlot should tell a meaningful story\n\nDepending on the plot and data, we can map additional variables by:\n\nSpecifying visual cues via aesthetics: color, size, shape, alpha (transparency)\nFaceting (will see this next week)"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html",
    "href": "slides/slides-04-numerical-pt2.html",
    "title": "Numerical data",
    "section": "",
    "text": "We learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#aesthetic-color",
    "href": "slides/slides-06-categorical-data.html#aesthetic-color",
    "title": "Categorical data",
    "section": "Aesthetic: color",
    "text": "Aesthetic: color\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point() \n\n\n\nWhat do you notice about the legend for color?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#aesthetic-shape",
    "href": "slides/slides-06-categorical-data.html#aesthetic-shape",
    "title": "Categorical data",
    "section": "Aesthetic: shape",
    "text": "Aesthetic: shape\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#facet_wrap",
    "href": "slides/slides-06-categorical-data.html#facet_wrap",
    "title": "Categorical data",
    "section": "facet_wrap()",
    "text": "facet_wrap()\nFaceting is used when we want to split a particular visualization by the values of another (categorical) variable\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker) \n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#facet_grid",
    "href": "slides/slides-06-categorical-data.html#facet_grid",
    "title": "Categorical data",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#describing-distributions",
    "href": "slides/slides-03-numerical-pt1.html#describing-distributions",
    "title": "Numerical data",
    "section": "Describing distributions",
    "text": "Describing distributions\nA convenient way to describe a variable’s behavior is through the shape of its distribution. Using histograms, we should identify:\n\nSkewness (or lack thereof):\n\nDistributions with long tails to the left are called left-skewed\nDistributions with long tails to the right are right-skewed\nIf not skewed, then the distribution is symmetric\n\nModes: prominent peaks in the distribution\n\nDistribution may be unimodal (one peak), bimodal (two peaks), or multimodal (more than two peaks)\nPeaks need not be same height"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#interpreting-sd",
    "href": "slides/slides-04-numerical-pt2.html#interpreting-sd",
    "title": "Numerical data",
    "section": "Interpreting SD",
    "text": "Interpreting SD\nWe learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#visualizing-sd",
    "href": "slides/slides-04-numerical-pt2.html#visualizing-sd",
    "title": "Numerical data",
    "section": "Visualizing SD",
    "text": "Visualizing SD"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#visualizing-sd-cont.",
    "href": "slides/slides-04-numerical-pt2.html#visualizing-sd-cont.",
    "title": "Numerical data",
    "section": "Visualizing SD (cont.)",
    "text": "Visualizing SD (cont.)\n\n\nWe know how to calculate some summary statistics and interpret them alongside the histogram. But wouldn’t it be great if we had a visualization that directly displays some summary statistics?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#summary",
    "href": "slides/slides-04-numerical-pt2.html#summary",
    "title": "Numerical data",
    "section": "Summary",
    "text": "Summary\n\nBoxplots are another univariate visualization for numerical data\nMedian and IQR are robust to outliers, whereas mean and standard deviation are sensitive to outliers\nWhen should we prefer median over mean (or vice versa)?\n\n\nMedian is more stable; not affected by one single data point. But mean is easier to compute than median since you do not have sort observations. Also, mean has nice theoretical properties (STAT 311). If possible, always good to calculate both!!\nMedian = what is typical, mean = what you expect. The typical charge amount is around $9000. But if you’re looking at insurance charges, you shouldn’t expect to pay that low amount."
  },
  {
    "objectID": "live_code/numerical_pt2_live.html#boxplot-and-median",
    "href": "live_code/numerical_pt2_live.html#boxplot-and-median",
    "title": "9/18/2024 Live code",
    "section": "Boxplot and median",
    "text": "Boxplot and median\n\n# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# boxplot: first argument is x-axis\nboxplot(insurance$bmi)\n\n\n\n# median\nmedian(insurance$bmi)\n\n[1] 30.2075\n\n# making and sorting vectors\nmy_vec <- c(1, 9, 8, -2, 4)\nsort(my_vec)\n\n[1] -2  1  4  8  9"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#inheriting-arguments",
    "href": "slides/slides-05-numerical-data-viz.html#inheriting-arguments",
    "title": "Visualizations with ggplot",
    "section": "Inheriting arguments",
    "text": "Inheriting arguments\n\nMany functions related to plotting in ggplot take the form geom_xxx()\nThe Help file for these functions show that the first two arguments are mapping and data. These are automatically inherited from the mapping and data arguments in the first layer ggplot() function\n\ni.e. you don’t need to re-specify them, unless you are trying to add a new data frame’s data to your visualization"
  },
  {
    "objectID": "coding_practice/coding-practice-04-numerical-pt2.html",
    "href": "coding_practice/coding-practice-04-numerical-pt2.html",
    "title": "Numerical data coding practice",
    "section": "",
    "text": "Change your name in the YAML.\nIn the following code chunk, load in the openintro package. Then run this code chunk. We need this package to once again work with the cherry data frame.\n\n\n\n\n\nIf we have a data frame (like cherry), we can access a specific variable’s data in the data frame by typing the code like the following: data_frame_name$variable_name. Note that the spelling of the variable name must match how it appears in the data frame!\n\nIn the code chunk below, obtain the values of the observed diameters of these trees using code. Then answer: what type of object is output from the code?\n\n\n\nAnswer:\n\nIn the code chunk below, write code to find the mean and median of the height of trees in the cherry data frame. Based on what you find, answer the following: do you believe the distribution of the height of cherry trees is skewed or symmetric? Why?\n\n\n\n\nAnswer:\n\nLet’s confirm your answer above by creating a rather ugly (but easy to obtain) histogram. The hist() function requires one input: a vector of numerical values to visualize. Plot a histogram of the heights of these trees.\n\n\n\n\n\nOptional: modify the plot above by specifying some of all of following extra inputs to the hist() function.\n\n\nmain: plot title (must be a string object)\nxlab: x-axis label (must be a string object)\ncol: color to fill the bars in with (must be a valid color specified as a string object)\n\nThis looks like hist(data, main = \"Title\", xlab = \"x-axis title\", col = \"some color\").\nOnce you’re finished, be sure to render and submit the outputted PDF file to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "coding_practice/coding-practice-06-ggplot.html",
    "href": "coding_practice/coding-practice-06-ggplot.html",
    "title": "ggplot coding practice",
    "section": "",
    "text": "Load the tidyverse and openintro packages in the code chunk below. We will work with the mammals data from the openintro package. Load the data by typing data(mammals) right underneath where you loaded the packages. Then run the code chunk, and take a quick look at the data by clicking twice on the variable mammals in your Environment.\n\n\n# packages\n\n# data\n\n\nUsing ggplot, make a scatterplot of the gestation time and life span. (Gestation time is how long a baby is in the uterus.) You should notice that a Warning message appears. Describe in common language what the warning is trying to tell you.\n\n\n\n\nAnswer:\n\nNow, let’s make your plot from above more presentable. Using the labs() function, change the axes on your plots to have better titles that include the units. Also add a title. You may copy and paste your from above to get started. Start practicing good coding style by having line breaks between layers of the code!\n\n\n\n\n\nLet’s add color to your plot! Modify your code above to map the color of the points to the total amount of sleep each mammal gets. You might notice that some points are colored gray, instead of blue. Why do you think that is?\n\nAnswer:\nOnce you’re finished, be sure to knit and submit the outputted file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "homework/hw2_r.html",
    "href": "homework/hw2_r.html",
    "title": "STAT 201: Problem Set 2 (R)",
    "section": "",
    "text": "Change your name in the YAML. Then load in the tidyverse and openintro packages in the code chunk below. We will work with the starbucks data from the openintro package.\n\n\n# load packages here\n\nGet a feel for the data by looking at its Help file and View()-ing it.\n\nWrite code that creates two variables: one for the average number of calories in a Starbucks food item and another for the standard deviation.\n\n\n\n\n\nUsing ggplot, create a histogram of the calories in Starbucks food items. Change the binwidth or number of bins to make a more “pleasing” plot. Add an informative title.\n\n\n\n\n\nModify your code chunk above so your plot includes:\n\n\nA vertical line that displays the mean number of calories. Do this by adding a layer to your plot and using the geom_vline() (which stands for vertical line). You can look at the Help file to figure out exactly how to use this function. You should use one of the variables you created in number 1.\nMake your line a color of your choice by specifying the col argument within the geom_vline() function.\nA caption that provides a brief description of what the line represents.\n\n\nUsing the plots you created, along with some summary statistics, describe the distribution of calories in Starbucks food items. Make sure you discuss shape, center, spread, and potential outliers.\n\nAnswer:\n\nNow, create a scatterplot in ggplot with calories on the y-axis. For the x-axis variable, choose a variable that displays a strong association/pattern with calories. You may have to play around a bit! Add an informative title.\n\n\n\n\n\nIn the code chunk above, color the points by another variable in the data set. Then, add a layer of code using the function scale_color_viridis_c(). When you run this code, you’ll notice that this function changes the color palette to something called the Viridis color palette. Play around with different palettes by looking to the Help file for this function and looking at the option parameter. Choose one of the eight options!\n\n\n\nBriefly interpret this last plot you created. Your interpretation may include discussing associations/trends/patterns (or lack thereof)!\n\nAnswer:\nOnce you’re done, render this file one more time, and submit this file to Gradescope alongside the other homework problems."
  },
  {
    "objectID": "coding_practice/coding-practice-05-ggplot.html",
    "href": "coding_practice/coding-practice-05-ggplot.html",
    "title": "ggplot coding practice",
    "section": "",
    "text": "Load the tidyverse and openintro packages in the code chunk below, then be sure to run the code chunk. We will work with the mammals data from the openintro package.\n\n\n# packages\n\nIf you want to see the data frame, type View(mammals) in the Console. That will open up a new tab displaying the data frame in the Source pane.\n\nUsing ggplot, make a boxplot of the body weights of these mammals.\n\n\n\n\n\nThis plot doesn’t seem useful at all! Modify your code above to get rid of/hide the potential outliers. Check out the help file for the appropriate function to figure out how to do this!\nUsing ggplot, make a scatterplot of the gestation time and life span. (Gestation time is how long a baby is in the uterus.) You should notice that a Warning message appears. Describe in common language what the warning is trying to tell you.\n\n\n\n\nAnswer:\n\nNow, let’s make your plot from above more presentable. Using the labs() function, change the axes on your plots to have better titles that include the units. Also add a title. You may copy and paste your from above to get started. Start practicing good coding style by having line breaks between layers of the code!\n\n\n\n\n\nLet’s add color to your plot! Modify your code above to map the color of the points to the total amount of sleep each mammal gets. You might notice that some points are colored gray, instead of blue. Why do you think that is?\n\nAnswer:\nOnce you’re finished, be sure to render and submit the outputted PDF file to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#categorical-data",
    "href": "slides/slides-06-categorical-data.html#categorical-data",
    "title": "Categorical data",
    "section": "Categorical data",
    "text": "Categorical data\n\nRecall that a variable is either numerical or categorical\nCategorical variables are variables that can take one of a limited (usually fixed) number of possible values, known as levels\n\nRepresent data that can be divided into groups\n\nTwo types:\n\nOrdinal: the levels have a special ordering\nNominal: the levels don’t have an ordering\n\nWe will almost exclusively treat our categorical variables as nominal in this class\n\n\nExamples and non-examples?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#insurance-data",
    "href": "slides/slides-06-categorical-data.html#insurance-data",
    "title": "Categorical data",
    "section": "Insurance data",
    "text": "Insurance data"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate",
    "href": "slides/slides-06-categorical-data.html#univariate",
    "title": "Categorical data",
    "section": "Univariate",
    "text": "Univariate\nIf we are interested in understanding the distribution of a single categorical variable, it is common to:\n\n\n\n\nDisplay a frequency table, which is a table of counts of each level\n\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45\n\n\n\n\n\n\nVisualize the data through a bar plot, where different levels are displayed on one axis and the counts are portrayed on the other"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate-eda",
    "href": "slides/slides-06-categorical-data.html#univariate-eda",
    "title": "Categorical data",
    "section": "Univariate EDA",
    "text": "Univariate EDA\nIf we are interested in understanding the distribution of a single categorical variable, it is common to:\n\n\n\nDisplay a frequency table, which is a table of counts of each level\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45\n\n\n\n\n\nCreate a bar plot, where different levels are displayed on one axis and the counts are portrayed on the other\n\n\n\n\n\n\n\n\n\nHow do bar plots differ from histograms?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-eda",
    "href": "slides/slides-06-categorical-data.html#bivariate-eda",
    "title": "Categorical data",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\n\nPerhaps we are interested in examining the distribution of two categorical variables at the same time\nSummarize the distribution using a two-way table known as a contingency table:\n\nEach value in the table counts the number of times a particular combination of variable 1 and variable 2 levels occurred in data\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\nHow can we use contingency table to obtain the distribution of just one of the variables?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#visualizing-numerical-and-categorical",
    "href": "slides/slides-06-categorical-data.html#visualizing-numerical-and-categorical",
    "title": "Categorical data",
    "section": "Visualizing numerical and categorical",
    "text": "Visualizing numerical and categorical\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point() \n\n\n\nWhat do you notice about the legend for color?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bar-plot-univariate",
    "href": "slides/slides-06-categorical-data.html#bar-plot-univariate",
    "title": "Categorical data",
    "section": "Bar plot (univariate)",
    "text": "Bar plot (univariate)\n\nggplot(data = insurance, mapping = aes(x = smoker)) +\n  geom_bar()\n\n\n\nNote: if your data are already in the form of frequency table, we should use geom_col() instead!"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-bar-plots",
    "href": "slides/slides-06-categorical-data.html#bivariate-bar-plots",
    "title": "Categorical data",
    "section": "Bivariate bar plots",
    "text": "Bivariate bar plots\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"dodge\")  \n\n\n\n\n\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"stack\") # this is default"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-bar-plots-cont.",
    "href": "slides/slides-06-categorical-data.html#bivariate-bar-plots-cont.",
    "title": "Categorical data",
    "section": "Bivariate bar plots (cont.)",
    "text": "Bivariate bar plots (cont.)\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"fill\")\n\n\nHow might we make the bars horizontal instead of vertical?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#side-by-side-box-plots",
    "href": "slides/slides-06-categorical-data.html#side-by-side-box-plots",
    "title": "Categorical data",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\nggplot(data = insurance, \n       mapping = aes(x = smoker, y = bmi)) +\n  geom_boxplot()\n\n\nLike faceting, but only for box plots."
  },
  {
    "objectID": "coding_practice/coding-practice-06-categorical.html",
    "href": "coding_practice/coding-practice-06-categorical.html",
    "title": "Categorical data coding practice",
    "section": "",
    "text": "# load additional packages here\n\n\nIn the code chunk above, add a line of code to load in the package necessary for ggplot-ing. Also change your name in the YAML.\nWe will be using the diamonds dataset that is included in the package you loaded above. Please take a look at the Help file. Create vertical side-by-side boxplots that display the distribution of diamond prices for each color of diamond.\n\nThen answer the following question: which diamonds seem to be the most expensive? Is this result surprising to you given the description of the data? If so, what might be a possible explanation?\n\n\n\nAnswer:\n\nNow visualize the distribution of diamonds prices using histograms, where we have one histogram for each color. You should be able to do this in just three lines/layers of code!\n\nThen answer the following: which visualization (the boxplots or the histograms) do you think is more effective for answering the research question of “which diamonds seem to be the most expensive”? Briefly explain why.\n\n\n\nAnswer:\n\nUsing an appropriate type of bar plot, compare the distribution of how clear a diamond is across the distribution of the quality of th cut. Do the frequencies of occurrences of the levels of one variable depend on/change with the levels of the second variable? That is, do you think there is an association between the two variables?\n\n\n\n\nAnswer:\n\nWe will change the colors in our bar plot! Look at the Help file for the function scale_fill_brewer(). You should see many options of different palettes. Add this function to your code above (use good coding style!), and set the palette argument to one of the palette names. Play around until you’ve settled on one!\nYou used the function scale_fill_brewer() above, but there is a similar function called scale_color_brewer(). Why do you think we used the first function and not the second? (You can explore this by changing your code above to scale_color_brewer and seeing what happens. Be sure to revert back to scale_fill_brewer before submitting!)\n\nAnswer:\nOnce you’re finished, be sure to knit and submit the rendered PDF to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "homework/hw3_r.html",
    "href": "homework/hw3_r.html",
    "title": "STAT 201: Problem Set 3 (R)",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article titled “These Nobel Prize Winners Show Why Immigration Is So Important For American Science”. In the article they explore where many Nobel laureates in the sciences were born and where they lived when they won their prize.\nIn this homework we will work with the data about Nobel laureates to recreate/update some of their visualizations with new data as well as explore new questions.\n\nlibrary(readr)\n# add more packages here as necessary\n\n\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-spring2025/midd-stat201-spring2025.github.io/refs/heads/main/data/nobel_prize.csv\"\nnobel <- read_csv(url_file, name_repair = \"unique_quiet\")\n\n\nChange your name in the YAML and add the package(s) necessary for creating ggplots and wrangling data in the code chunk above. Then run the code chunk to load in the data.\n\nA description of the variables in the nobel data are as follows:\n\nid: unique identifier of laureate\nfirstname: first name (and possible middle initial) of laureate\nsurname: last name/surname\nyear: the year the prize was awarded\ncategory: category of prize (Chemistry, Economics, Literature, Peace, Physics, or Medicine)\nborn_year: year laureate was born\ndied_year: year laureate died\naffiliation: affiliation of laureate at time of winning\ncity: city of laureate in prize year\ncountry: country where laureate was based in prize year\ngender: gender or laureate (male, female, or org, where org represents an organization)\nshare: reciprocal of the portion of prize awarded to the laureate\nmotivation: motivation for recognition\n\n\nDisplay a summary table of the sample average and standard deviation of the ages of Nobel laureates at the time of receiving the prize. Do this in a single pipeline by:\n\n\nCreating a new variable that represents the age of the laureate when they one their prize, calculated as the year they received the award minus the year they were born\nFiltering to only retain observations for which your newly calculated age variable is available\nWriting code to actually create the summary statistics\n\nBe sure to explicitly set/define the column titles of your summary table. Then interpret these statistics (particularly the standard deviation) in context.\n\n\n\nAnswer:\n\nCreate a new data frame called nobel_living that only retains cases from the original data frame that meet the following criteria:\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations\nlaureates who are still alive\n\n\n\n\nUse code to confirm that you have 21 female and 222 male laureates in your new data frame:\n\n\n\n\nBuzzfeed’s Claim #1: “Most living Nobel laureates were based in the US when they won their prizes”. Let’s see if that’s true.\n\nModify (i.e. store/assign over) your nobel_living data frame by with a new version that as an additional variable called country_base. The variable should equal:\n\n“USA” if the laureate was based in the USA when they won\n“Other” if the laureate’s was based in the USA when they won\n\nYou will have to use the if_else() function. Take a look at its Help file (and in particular, its examples).\n\n\n\nNow would be a good time to render your work to save the progress and make sure everything is working!\n\nCreate a new data frame called nobel_living_science that only retains observations with laureates from the Physics, Chemistry, Medicine, and Economics categories from the nobel_living data frame.\n\n\n\n\n\nUsing the data frame nobel_living_science, create a faceted bar plot with horizontal bars that visualizes the relationship between 1) the category of prize and 2) whether the laureate was in the US when they won the Nobel prize. Note: Your visualization should be faceted by category. For each facet you should have two bars, one for winners based in the US and one for Other.\n\nInterpret your visualization, and say a few words about whether the Buzzfeed Claim #1 is supported by the data.\n\n\n\nAnswer:\nNow would be a good time to rebder your work to save the progress and make sure everything is working!\n\nBuzzfeed’s Claim #2: “But of those US-based Nobel laureates, many were born in other countries.” Let’s investigate this second claim!\n\nThe following code reads in another dataset that has information about the birthplaces of these Nobel laureates. We store the resulting data frame as born_info. Run the following code chunk (no need to do anything here). The variables in the data frame are:\n\nID: unique identifier of laureate\nborn_city: city where laureate was born\nborn_country: country where laureate was born\nborn_country_code: two-letter country code of born_country\n\n\nurl2 <- \"https://raw.githubusercontent.com/midd-stat201-spring2025/midd-stat201-spring2025.github.io/refs/heads/main/data/nobel_born_info.csv\"\nborn_info <- read_csv(url2)\n\nNow, add the information from born_info into the nobel_living_science data frame, retaining only observations from nobel_living_science. Store the resulting data frame as a new one called nobel_living_science2.\n\n\n\nThen create a new variable called born_country_us that has the value “USA” if the laureate is born in the US, and “Other” if not. Be sure to save the variable to the data frame by storing the output back into nobel_living_science2.\n\n\n\n\nLet’s improve on our previous visualization here. Visualize the relationship between where the laureate was based when they won the Nobel Prize and where they were born, split by category. Your final visualization should:\n\n\ncontain a facet for each category\nwithin each facet, bars for whether the laureate won the award in the US or not\nwithin each bar, display whether the laureate was born in the US or not\n\nBased on your visualization, do the data appear to support Buzzfeed’s Claim #2? Explain your reasoning in a few sentences.\n\n\n\nAnswer:\n\nWe will explore where the non-US laureates were born. In a single pipeline starting with nobel_living_science2, filter for laureates who were living in the US when they won their prize but where born outside of the US. Then create a frequency table for their birth country, only displaying the countries with at least three laureates. Display your order in descending order of number of laureates.\n\n\n\n\nOnce you’re finished, render once more."
  },
  {
    "objectID": "live_code/data_wrangling.html#remember-to-save-over-data-frames-for-future-use",
    "href": "live_code/data_wrangling.html#remember-to-save-over-data-frames-for-future-use",
    "title": "Data wrangling with dplyr",
    "section": "Remember to save over data frames for future use!",
    "text": "Remember to save over data frames for future use!\nOften, we wrangle a data frame because we want certain variables to exist for future analyses. When we have modify a data frame for several future analyses, we should save over/store back into the same data frame with our new operations. As an example, in the following code, I am creating a new variable called age_months that represents the age in months.\n\ndatascience |>\n  mutate(age_months = Age * 12)\n\nNow suppose I want to visualize this variable:\n\nggplot(data = datascience, mapping = aes(x = age_months))+\n  geom_histogram()\n\nError in `geom_histogram()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! object 'age_months' not found\n\n\nIt’s complaining because the data frame datascience does not have a variable called age_months! We need to store over the previous version to make sure we “save our work”:\n\ndatascience <- datascience |>\n  mutate(age_months = Age * 12)\nggplot(data = datascience, mapping = aes(x = age_months))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html",
    "href": "live_code/data_wrangling_pt1.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "Don’t forget to load the tidyverse package, which includes dplyr!\nRecall that we are looking at data provided by Kaggle. In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#selecting-columns",
    "href": "live_code/data_wrangling_pt1.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 102 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    36\n# ℹ 92 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 102 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    36\n# ℹ 92 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 102 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 102 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    36 Information technology, networking, or system administration\n# ℹ 92 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:Major)\n\n# A tibble: 102 × 3\n   Gender   Age Major                                                       \n   <chr>  <dbl> <chr>                                                       \n 1 Male      56 Mathematics or statistics                                   \n 2 Male      33 Other                                                       \n 3 Male      26 Computer Science                                            \n 4 Male      25 Physics                                                     \n 5 Male      33 Electrical Engineering                                      \n 6 Male      22 Information technology, networking, or system administration\n 7 Male      29 Computer Science                                            \n 8 Male      35 Physics                                                     \n 9 Male      37 Electrical Engineering                                      \n10 Male      36 Information technology, networking, or system administration\n# ℹ 92 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 102 × 7\n   Gender   Age Major    FormalEducation CompensationAmount CompensationCurrency\n   <chr>  <dbl> <chr>    <chr>                        <dbl> <chr>               \n 1 Male      56 Mathema… Master's degree             250000 USD                 \n 2 Male      33 Other    Bachelor's deg…            1200000 RUB                 \n 3 Male      26 Compute… Master's degree            1100000 TWD                 \n 4 Male      25 Physics  Bachelor's deg…              20000 USD                 \n 5 Male      33 Electri… Doctoral degree             100000 USD                 \n 6 Male      22 Informa… Bachelor's deg…             624000 RUB                 \n 7 Male      29 Compute… Master's degree             126000 PLN                 \n 8 Male      35 Physics  Doctoral degree             133000 USD                 \n 9 Male      37 Electri… Master's degree              80000 USD                 \n10 Male      36 Informa… Master's degree              80000 AUD                 \n# ℹ 92 more rows\n# ℹ 1 more variable: LanguageRecommendation <chr>"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#arranging-rows",
    "href": "live_code/data_wrangling_pt1.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 102 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    21 Computer Science                                            \n 2    21 Computer Science                                            \n 3    22 Information technology, networking, or system administration\n 4    22 Computer Science                                            \n 5    22 Computer Science                                            \n 6    22 Computer Science                                            \n 7    22 Computer Science                                            \n 8    22 Computer Science                                            \n 9    22 Computer Science                                            \n10    23 Biology                                                     \n# ℹ 92 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling_pt1.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 8\n  Country       Gender   Age Major            FormalEducation CompensationAmount\n  <chr>         <chr>  <dbl> <chr>            <chr>                        <dbl>\n1 United States Male      56 Mathematics or … Master's degree             250000\n2 Russia        Male      33 Other            Bachelor's deg…            1200000\n3 Taiwan        Male      26 Computer Science Master's degree            1100000\n4 United States Male      25 Physics          Bachelor's deg…              20000\n5 United States Male      33 Electrical Engi… Doctoral degree             100000\n# ℹ 2 more variables: CompensationCurrency <chr>, LanguageRecommendation <chr>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling_pt1.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 35 × 8\n   Country                 Gender   Age Major FormalEducation CompensationAmount\n   <chr>                   <chr>  <dbl> <chr> <chr>                        <dbl>\n 1 Taiwan                  Male      26 Comp… Master's degree            1100000\n 2 Poland                  Male      29 Comp… Master's degree             126000\n 3 India                   Male      34 Comp… Master's degree            2300000\n 4 Russia                  Male      22 Comp… Bachelor's deg…             528000\n 5 People 's Republic of … Male      28 Comp… Master's degree              70000\n 6 Russia                  Male      34 Comp… Some college/u…            1500000\n 7 Russia                  Male      22 Comp… Master's degree              70000\n 8 Italy                   Male      22 Comp… Bachelor's deg…              10000\n 9 India                   Male      23 Comp… Bachelor's deg…             400000\n10 Other                   Male      32 Comp… Master's degree            1200000\n# ℹ 25 more rows\n# ℹ 2 more variables: CompensationCurrency <chr>, LanguageRecommendation <chr>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 3 × 2\n  Major              Age\n  <chr>            <dbl>\n1 Computer Science    30\n2 Computer Science    30\n3 Computer Science    30\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    34\n 4 Computer Science    22\n 5 Computer Science    28\n 6 Computer Science    34\n 7 Computer Science    22\n 8 Computer Science    22\n 9 Computer Science    23\n10 Computer Science    32\n# ℹ 26 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 3 × 2\n  Major              Age\n  <chr>            <dbl>\n1 Computer Science    30\n2 Computer Science    30\n3 Computer Science    30"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling_pt1.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 4 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 29 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree Computer Science                                           \n 5 Bachelor's degree Biology                                                    \n 6 Bachelor's degree A humanities discipline                                    \n 7 Bachelor's degree Electrical Engineering                                     \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree Mathematics or statistics                                  \n10 Doctoral degree   Electrical Engineering                                     \n# ℹ 19 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling_pt1.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 102 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              80000              80\n# ℹ 92 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling_pt1.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(LanguageRecommendation)\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 C/C++/C#                   3\n2 Haskell                    1\n3 Matlab                     3\n4 Other                      1\n5 Python                    66\n6 R                         19\n7 SQL                        6\n8 Scala                      3\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(LanguageRecommendation, sort = T)\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 Python                    66\n2 R                         19\n3 SQL                        6\n4 C/C++/C#                   3\n5 Matlab                     3\n6 Scala                      3\n7 Haskell                    1\n8 Other                      1\n\n\n\ndatascience |>\n  count(LanguageRecommendation) |>\n  arrange(desc(n))\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 Python                    66\n2 R                         19\n3 SQL                        6\n4 C/C++/C#                   3\n5 Matlab                     3\n6 Scala                      3\n7 Haskell                    1\n8 Other                      1\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#practice",
    "href": "live_code/data_wrangling_pt1.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling_pt1.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     32.8\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html",
    "href": "live_code/data_wrangling_pt2.html",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "",
    "text": "Don’t forget to load the tidyverse package!\n2016 fisheries data about capture and aquaculture harvests (in tons) by country."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#selecting-columns",
    "href": "live_code/data_wrangling_pt2.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#arranging-rows",
    "href": "live_code/data_wrangling_pt2.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling_pt2.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling_pt2.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling_pt2.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling_pt2.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling_pt2.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#practice",
    "href": "live_code/data_wrangling_pt2.html#practice",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Practice",
    "text": "Practice\nWrite code to create a summary table reporting the average age of survey respondents for each category of formal education, in descending order.\n\n\nCode\ndatascience |>\n  group_by(FormalEducation) |>\n  summarise(avg_age = mean(Age)) |>\n  arrange(desc(avg_age))"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling_pt2.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#remember-to-save-over-data-frames-for-future-use",
    "href": "live_code/data_wrangling_pt2.html#remember-to-save-over-data-frames-for-future-use",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Remember to save over data frames for future use!",
    "text": "Remember to save over data frames for future use!\nOften, we wrangle a data frame because we want certain variables to exist for future analyses. When we have modify a data frame for several future analyses, we should save over/store back into the same data frame with our new operations. As an example, in the following code, I am creating a new variable called age_months that represents the age in months.\n\ndatascience |>\n  mutate(age_months = Age * 12)\n\nNow suppose I want to work with this variable:\n\ndatascience |>\n  summarise(mean_age_months = mean(age_months))\n\nError in `summarise()`:\nℹ In argument: `mean_age_months = mean(age_months)`.\nCaused by error:\n! object 'age_months' not found\n\n\nIt’s complaining because the data frame datascience does not have a variable called age_months! We need to store over the previous version to make sure we “save our work”:\n\ndatascience <- datascience |>\n  mutate(age_months = Age * 12)"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#grouping-by-grouped-operations",
    "href": "live_code/data_wrangling_pt2.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\nIn the following, we obtain the average total harvest (in millions of tons) per continent:\n\nfish_joined |>\n  group_by(continent) |>\n  summarise(mean_total_mil = mean(total_mil))\n\n# A tibble: 6 × 2\n  continent mean_total_mil\n  <chr>              <dbl>\n1 Africa            0.222 \n2 Americas          0.522 \n3 Asia              3.21  \n4 Europe            0.384 \n5 Oceania           0.0874\n6 <NA>              0.185 \n\n\nIt’s always important to ungroup() after using group_by() if you’re going to continue using the data frame in future analyses! Otherwise, the grouping will carry on and could lead to potential errors in your future wrangling!\nSee the following example:\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\n\n\n\ndata\n\n# A tibble: 6 × 4\n     ID Sex      Age Score\n  <int> <chr>  <dbl> <dbl>\n1     1 male      26 0.01 \n2     2 male      25 0.418\n3     3 male      39 0.014\n4     4 female    37 0.09 \n5     5 female    31 0.061\n6     6 female    20 0.328\n\ndata |> \n  group_by(Sex) |> \n  mutate(m = mean(Age)) |>   # calculates the average age of males and females\n  mutate(x = mean(Score)) # counts number of participants\n\n# A tibble: 6 × 6\n# Groups:   Sex [2]\n     ID Sex      Age Score     m     x\n  <int> <chr>  <dbl> <dbl> <dbl> <dbl>\n1     1 male      26 0.01   30   0.147\n2     2 male      25 0.418  30   0.147\n3     3 male      39 0.014  30   0.147\n4     4 female    37 0.09   29.3 0.160\n5     5 female    31 0.061  29.3 0.160\n6     6 female    20 0.328  29.3 0.160\n\ndata |> \n  group_by(Sex) |> \n  mutate(m = mean(Age)) |>  # calculates the average age of males and females\n  ungroup() |>              # nested ungroup()\n  mutate(x = mean(Score))    # counts number of participants\n\n# A tibble: 6 × 6\n     ID Sex      Age Score     m     x\n  <int> <chr>  <dbl> <dbl> <dbl> <dbl>\n1     1 male      26 0.01   30   0.154\n2     2 male      25 0.418  30   0.154\n3     3 male      39 0.014  30   0.154\n4     4 female    37 0.09   29.3 0.154\n5     5 female    31 0.061  29.3 0.154\n6     6 female    20 0.328  29.3 0.154\n\n\n\n\n\nNotice the differences in the outputs in the following examples. We also remove the NAs:\n\nfish_joined |>\n  group_by(continent) |>\n  summarise(mean_total_mil = mean(total_mil)) |>\n  ungroup() |>\n  na.omit() # this could go in many places\n\n# A tibble: 5 × 2\n  continent mean_total_mil\n  <chr>              <dbl>\n1 Africa            0.222 \n2 Americas          0.522 \n3 Asia              3.21  \n4 Europe            0.384 \n5 Oceania           0.0874"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#piping-to-ggplot",
    "href": "live_code/data_wrangling_pt2.html#piping-to-ggplot",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Piping to ggplot()",
    "text": "Piping to ggplot()\nRemember that when creating plots, ggplot() expects a data frame as its first argument.\nWe may sometimes need to wrangle data prior to visualizing it. We have two options (both have pros and cons):\n\nWrangle the original data, store the resulting data frame as a new object or overwrite the previous one, and then refer to that data frame with ggplot()\n\n\nfish_joined_no_na <- fish_joined |>\n  na.omit()\nfish_joined_no_na |> \n  ggplot(aes(x = continent, y = total)) +\n  geom_boxplot(outliers = F) +\n  labs(caption = \"Excluding outliers\") \n\n\n\n\n\nWrangle the original data, and then directly pipe the result into ggplot(), which knows to expect a data frame as its first argument:\n\n\n# Notice that we don't specify the data parameter in ggplot()!\nfish_joined |>\n  na.omit() |>\n  ggplot(aes(x = continent, y = total)) +\n  geom_boxplot(outliers = F) +\n  labs(caption = \"Excluding outliers\")"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#warm-uprecap",
    "href": "live_code/data_wrangling_pt2.html#warm-uprecap",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Warm-up/Recap:",
    "text": "Warm-up/Recap:\nWrite code to wrangle the data to include a variable called total_mil that represents the total harvest for each continent in millions of tons. Assign the output back into fish, so the data frame is updated to include this new variable. Only display the 10 countries with the highest total harvest, and only display the two variables of interest.\n\n\nCode\nfish <- fish |>\n  mutate(total = capture + aquaculture) |>\n  mutate(total_mil = total/1000000)\n\n\nThen wrangle the data to only display the 10 countries with the highest total harvest, and only display the two variables of interest.\n\n\nCode\nfish |>\n  arrange(-total_mil) |>\n  slice(1:10) |>\n  select(country, total_mil)"
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html",
    "href": "live_code/kaggle_survey_analysis.html",
    "title": "Kaggle survey: group data wrangling",
    "section": "",
    "text": "We will now work a larger subset of the Kaggle data science survey data!"
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html#group-analysis",
    "href": "live_code/kaggle_survey_analysis.html#group-analysis",
    "title": "Kaggle survey: group data wrangling",
    "section": "Group analysis",
    "text": "Group analysis\nI want your group to generate your own investigation. Using your data-wrangling and plotting skills to do some EDA. After about a half hour, your group will share your process and results with the rest of the class!\nYour final results must include:\n\nA meaningful use of group_by()\nSummary statistics or frequency table\nVisualization with meaningful labels/titles\n\nYou can create more than one visualization and/or more than one table. Whatever speaks to you! The individual components (i.e. table/summary stats vs plot) do not need to use the same set of variables. Feel free to create as many code chunks as you’d like! There is a data dictionary at the bottom of this page that defines all the variables in the data set for you."
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html#data-dictionary",
    "href": "live_code/kaggle_survey_analysis.html#data-dictionary",
    "title": "Kaggle survey: group data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the data dictionary for the subset of the Kaggle data data.\n\nCountry: home country of employee (character)\nGender: specified gender (character)\nAge: age at time of survey (numeric)\nEmploymentStatus: reported employed status (character)\nEmployerIndustry: employer’s industry (character)\nMajor: college major (character)\nCompensationAmount: annual compensation (numeric)\nCompensationCurrency: three-letter currency code (character)\nCurrentJobTitle: job title (character)\nTitleFit: assessment of how well the job title fits (“Fine”, “Perfectly”, “Poorly”)\nLanguageRecommendation: recommended programming language (character)\nDataScienceIdentity: does the respondent identify as a data scientist (character)\nWorkDataVisualizations: proportion of job dedicated to creating data visualizations, broken into pre-determined categories (character)\nJobSatisfaction: rating of job satisfaction on scale of 1-10, where 1 is not satisfied and 10 is highly satisfied (character)\nJobSatisfaction2: numeric version of JobSatisfaction (numeric)\nConversionUSD: conversion factor from CompensationCurrency to USD (numeric)"
  },
  {
    "objectID": "slides/slides-08-probability.html#random-variable",
    "href": "slides/slides-08-probability.html#random-variable",
    "title": "Probability basics",
    "section": "Random variable",
    "text": "Random variable\n\nA random variable is a variable whose value is unknown and depends on random events\n\nOften denoted with a capital letter like \\(X\\) or \\(Y\\)\n\nThere are two types: discrete and continuous (just like in numeric variables)\n\nDiscrete: represents random process where sample space is countable (i.e. finite, or distinct counts)\nContinuous: sample space is uncountable (i.e. can take on any value within a specified interval with infinite number of possible values)\n\nNOTE: we will focus on discrete random variables for now"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#misc.-live-code",
    "href": "slides/slides-10-simpsons.html#misc.-live-code",
    "title": "Simpson’s paradox",
    "section": "Misc. live code",
    "text": "Misc. live code\n\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\ninsurance <- read_csv(url_file)\n\nWe will return to insurance data to learn about:\n\nUsing wrangling to obtain probabilities\ncase_when() to create more complex categorical variables"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#wrangling-for-probabilities",
    "href": "slides/slides-10-simpsons.html#wrangling-for-probabilities",
    "title": "Simpson’s paradox",
    "section": "Wrangling for probabilities",
    "text": "Wrangling for probabilities\n\n\nWhat is probability that someone is a smoker?\n\ninsurance |>\n  count(smoker) |>\n  mutate(prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 2 × 2\n  smoker  prob\n  <chr>  <dbl>\n1 no     0.775\n2 yes    0.225\n\n\n\n\nWhat is the probability that someone is a smoker, conditioned on sex?\n\ninsurance |>\n  count(smoker, sex) |>\n  group_by(sex) |>\n  mutate(cond_prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 4 × 3\n# Groups:   sex [2]\n  smoker sex    cond_prob\n  <chr>  <chr>      <dbl>\n1 no     female     0.837\n2 no     male       0.708\n3 yes    female     0.163\n4 yes    male       0.292"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#case_when",
    "href": "slides/slides-10-simpsons.html#case_when",
    "title": "Simpson’s paradox",
    "section": "case_when()",
    "text": "case_when()\nWe will use the case_when() function which generalizes if_else(). We use the following notation: <logical condition> ~ <value of variable>. Different “ifs” are separated by commas, and the logical conditions are checked sequentially.\n\n\n\ninsurance |>\n  mutate(bmi_cat = case_when(\n    bmi < 18.5 ~ \"under\",\n    bmi >= 18.5 & bmi < 25 ~ \"healthy\",\n    bmi >= 25 & bmi < 30 ~ \"over\",\n    bmi >= 30 ~ \"obese\"\n  )) |>\n  select(bmi, bmi_cat) |>\n  slice(1:5)\n\n# A tibble: 5 × 2\n    bmi bmi_cat\n  <dbl> <chr>  \n1  27.9 over   \n2  33.8 obese  \n3  33   obese  \n4  22.7 healthy\n5  28.9 over   \n\n\n\n\n# The following is also acceptable, but \n# relies on sequential ordering:\ninsurance |>\n  mutate(bmi_cat = case_when(\n    bmi < 18.5 ~ \"under\",\n    bmi >= 18.5 & bmi < 25 ~ \"healthy\",\n    bmi >= 25 & bmi < 30 ~ \"over\",\n    T ~ \"obese\" \n  )) |>\n  select(bmi, bmi_cat) |>\n  slice(1:5)\n\n# A tibble: 5 × 2\n    bmi bmi_cat\n  <dbl> <chr>  \n1  27.9 over   \n2  33.8 obese  \n3  33   obese  \n4  22.7 healthy\n5  28.9 over"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#more-complex-categorical-variables",
    "href": "slides/slides-10-simpsons.html#more-complex-categorical-variables",
    "title": "Simpson’s paradox",
    "section": "More complex categorical variables",
    "text": "More complex categorical variables\nSuppose I want to create a new variable representing the categories of BMI, constructed as follows:\n\nunderweight if someone’s BMI is less than 18.5\nhealthy if BMI is 18.5 to less than 25\noverweight if BMI is 25 to less than 30\nobese if BMI is 30 or greater\n\n\n\n# option 1 (awful): nested if_else()\ninsurance |>\n  mutate(bmi_cat = if_else(bmi < 18.5, \"under\",\n                           if_else(bmi >= 18.5 & bmi < 25, \"healthy\",\n                                   if_else(...))))"
  },
  {
    "objectID": "coding-practice-10-simpsons.html",
    "href": "coding-practice-10-simpsons.html",
    "title": "Conditional probabilities coding practice",
    "section": "",
    "text": "Today’s data comes from a study of conducted in Whickham, England. In this study, the researchers recorded each participant’s age, smoking status at the start of the study, and their health outcome 20 years later.\nThe data is in the mosaicData package. You will have to install the package first! Then run the following code:\n\nlibrary(tidyverse)\nlibrary(mosaicData)\n\nWe will work with the Whickham data. You should open its Help file and take a view of the data before proceeding. Note that “factor” can be though of as a categorical variable. Make sure you understand the data before proceeding!\nDiscuss with your group: What would you expect the relationship between smoking status and health outcome to be?\n\nCreate an appropriate visualization depicting the relationship between smoking status and health outcome.\n\n\n\n\n\nUsing wrangling code, calculate the conditional probabilities of death of each smoking status. Please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, briefly describe the relationship and whether or not it is what you expected. You may want to discuss the visualization from the previous exercise as well.\n\nCreate a new variable for future use called age_cat that takes the values as follows:\n\n\n“18-44”: if someone is less than or equal to 44 years old\n“45-64”: if someone is between 45 and 64 years old, inclusive\n“65+”: if someone is older than 64\n\n\n\n\n\nRe-create your first visualization, this time faceting by age_cat. You are welcome to copy-paste code if that is helpful.\n\n\n\n\n\nExtend your table from above by breaking it down by age category. You are welcome to copy-paste code if that is helpful.\n\n\n\n\nWith your group, compare the two visualizations and the two summary tables. What changed, and what might explain the change?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#general-multiplication-rule",
    "href": "slides/slides-09-conditional-probability.html#general-multiplication-rule",
    "title": "Conditional probability",
    "section": "General multiplication rule",
    "text": "General multiplication rule\nConditional, joint, and marginal probabilities are related via the general multiplication rule:\n\n\\[\n\\text{P}(A \\cap B) =\n\\]\n\n\nLet’s see this in the coffee example!\nVery useful for finding probability that two events will happen in sequence.\n\nExample: A box has three tickets, colored red, orange, yellow. We will draw two tickets randomly one-at-a-time without replacement. What is the probability of drawing the red ticket first and then the orange ticket?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#tree-diagram",
    "href": "slides/slides-09-conditional-probability.html#tree-diagram",
    "title": "Conditional probability",
    "section": "Tree diagram",
    "text": "Tree diagram\nTool to organize outcomes and probabilities around the structure of the data. Useful when outcomes occur sequentially, and outcomes are conditioned on predecessors. Let’s do an example:\n\nA class has a midterm and a final exam. 13% of students earned an A on the midterm. Of those students who earned an A on the midterm, 47% received an A on the final. Of those student who earned below an A on the midterm, 11% received an A on the final. You randomly pick up a final exam and notice the student received an A. What is the probability that they earned an A on the midterm?\n\nUsing \\(\\text{P}()\\) notation, what probability are we interested in? What probabilities do we need to calculate along the way?\n\nLet’s construct our tree!\n\nIn the tree diagram, where are the three types of probabilities appearing?"
  },
  {
    "objectID": "midterms.html",
    "href": "midterms.html",
    "title": "Midterms",
    "section": "",
    "text": "All questions except for 1c, 1d, 1f, and 2d are eligible for points back\nRe-do all desired problems on a separate sheet of paper, clearly indicating each problem.\n\nFor the multiple choice questions: explain why your original selection was incorrect, and why your new selection is correct.\n\nYou should work alone and only use your notes to do your revisions. You cannot consult other people (besides Professor Tang), ChatGPT or other online tools. To acknowledge this, on your revision, write and sign the Honor Code Pledge “I have neither given nor received unauthorized aid on this assignment.” Revisions submitted without an honor code pledge will not be considered for points back.\nStaple revisions to original midterm, and submit them by Friday 5/9 3:00pm to Professor Tang’s office. There will be a box outside her door where you can drop off the revisions. No peeking!\n\n\n\n\n\nWhen and where: Thursday, 5/1/25 during class (75 minutes)\n\nNOTE: this is a change from the syllabus which originally stated an evening midterm.\n\nWhat: inference content (Weeks 6-10)\n\nNote: some concepts from Weeks 1-4 are important to understand concepts from Weeks 6-10, but you will not be explicitly assessed on the earlier content\nThis is a written exam. No dplyr or ggplot code will be assessed, but feel comfortable hand-writing code to obtain p-values and critical values!\nYou are allowed to bring a single, one-sided 8.5x11 inch piece of paper as your note sheet. Your note sheet cannot have any example problems. You will submit your note sheet alongside your midterm. No other outside resources will be allowed.\nA calculator will be provided for you.\nYou will be provided a table z, t, and \\(\\chi^2\\) table. We will familiarize ourselves with them in class prior to the midterm.\n\n\n\n\n\n\nCome to office hours!\n\n\n\nMy personal working strategy:\n\nFirst review your notes and homework\nMake a first draft of your note sheet, then do some practice problems using only your note sheet to see if what you wrote on it is actually useful for you\nMake a new note sheet\nRepeat as necessary\n\nExtra practice problems are available here.\nA previous midterm is shared here. Note, there are some concepts on the previous midterm that were not taught this semester (e.g. mean difference in paired data).\nYou should make sure you understand how to read the distribution tables. Prof. Tang will not be able to help you read them during the midterm."
  },
  {
    "objectID": "midterms.html#preparation",
    "href": "midterms.html#preparation",
    "title": "Midterms",
    "section": "Preparation",
    "text": "Preparation\n\nThe best preparation you can do for the midterm is to go through your homework and coding practices and be honest with yourself about what you do/don’t understand. This means going through the painful process of looking at feedback on Gradescope. For the concepts that you need to practice more, try more problems (see below)!\nJust because the midterm is open note, this does not mean you cannot study and prepare. You will not have time to try and re-learn what all the functions we learned do!\n\nI suggest going through each of the ggplot and dplyr functions that we’ve seen in the course and ensuring you know how they work and when to use them!\n\nFor extra practice, additional coding problems will soon be made available below. These questions are not necessarily representative of the typical scope and difficulty of individual exam questions. This review is not comprehensive, nor does it represent the expected amount of time for it will take for you to complete the midterm.\n\nPractice 1: rendered version\n\n.qmd template\n Midterm practice \n\nPractice 2: rendered version\n\n.qmd template\n Midterm practice"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "Announcements",
    "text": "Announcements\n\nFinal project work!\n\nSign up for 1:1 meetings outside of office hours here"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#recap",
    "href": "slides/slides-09-conditional-probability.html#recap",
    "title": "Conditional probability",
    "section": "Recap",
    "text": "Recap\n\nTwo events are disjoint/mutually exclusive if they do not have any overlapping outcomes\nAddition rule: \\(\\text{Pr}(A \\cup B) =\\)\nComplement rule: \\(\\text{Pr}(A^c) =\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#law-of-total-probability",
    "href": "slides/slides-09-conditional-probability.html#law-of-total-probability",
    "title": "Conditional probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nLet \\(A\\) be an event, then let \\(\\{B_{1},B_{2},\\ldots, B_{k}\\}\\) be a set of mutually exclusive events whose union comprises their entire sample space \\(S\\)\nThen Law of Total Probability (LoTP) says:\n\n\n\\[\n\\text{Pr}(A) = \\text{Pr}(A \\cap B_{1} ) + \\text{Pr}(A \\cap B_{2}) + \\ldots + \\text{Pr}(A \\cap B_{k})\n\\]\n\n\nBlob picture"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#uc-berkeley-admissions",
    "href": "slides/slides-10-simpsons.html#uc-berkeley-admissions",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions",
    "text": "UC Berkeley admissions\nObservational study on sex bias based on Fall 1973 admissions data to the graduate program at the University of California, Berkeley\n\n\n\n\nAdmit\nDeny\nTotal\n\n\n\n\nMen\n3738\n4704\n8442\n\n\nWomen\n1494\n2827\n4321\n\n\nTotal\n5232\n7531\n12763\n\n\n\n\n\nWhat is the probability of admission for a randomly selected applicant?\nWhat is the probability of admission among men? Among women?\nAre the probabilities you found marginal, joint, or conditional probabilities?\n\n\n\n\nSuppose we want to understand the relationship between gender and admission decision. What sort of visualization might be appropriate for representing this data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#section",
    "href": "slides/slides-10-simpsons.html#section",
    "title": "Simpson’s paradox",
    "section": "",
    "text": "Dept\nFemale: Admit\nMale: Admit\nFemale: Reject\nMale: Reject\n\n\n\n\nA\n89\n512\n19\n313\n\n\nB\n17\n353\n8\n207\n\n\nC\n202\n120\n391\n205\n\n\nD\n131\n138\n244\n279\n\n\nE\n94\n53\n299\n138\n\n\nF\n24\n22\n317\n351"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#frequency-tables",
    "href": "slides/slides-10-simpsons.html#frequency-tables",
    "title": "Simpson’s paradox",
    "section": "Frequency tables",
    "text": "Frequency tables\nNumber of applicants by department:\n\n\nFemale applicants:\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n108\n\n\nB\n25\n\n\nC\n593\n\n\nD\n375\n\n\nE\n393\n\n\nF\n341\n\n\n\n\n\n\nMale applicants:\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n825\n\n\nB\n560\n\n\nC\n325\n\n\nD\n417\n\n\nE\n191\n\n\nF\n373"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#more-detailed-frequency-tables",
    "href": "slides/slides-10-simpsons.html#more-detailed-frequency-tables",
    "title": "Simpson’s paradox",
    "section": "More-detailed frequency tables",
    "text": "More-detailed frequency tables\nNumber of applicants by department and admission status:\n\n\nFemale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    89 \n  \n  \n    A \n    Reject \n    19 \n  \n  \n    B \n    Admit \n    17 \n  \n  \n    B \n    Reject \n    8 \n  \n  \n    C \n    Admit \n    202 \n  \n  \n    C \n    Reject \n    391 \n  \n  \n    D \n    Admit \n    131 \n  \n  \n    D \n    Reject \n    244 \n  \n  \n    E \n    Admit \n    94 \n  \n  \n    E \n    Reject \n    299 \n  \n  \n    F \n    Admit \n    24 \n  \n  \n    F \n    Reject \n    317 \n  \n\n\n\n\n\n\nMale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    512 \n  \n  \n    A \n    Reject \n    313 \n  \n  \n    B \n    Admit \n    353 \n  \n  \n    B \n    Reject \n    207 \n  \n  \n    C \n    Admit \n    120 \n  \n  \n    C \n    Reject \n    205 \n  \n  \n    D \n    Admit \n    138 \n  \n  \n    D \n    Reject \n    279 \n  \n  \n    E \n    Admit \n    53 \n  \n  \n    E \n    Reject \n    138 \n  \n  \n    F \n    Admit \n    22 \n  \n  \n    F \n    Reject \n    351"
  },
  {
    "objectID": "coding_practice/coding-practice-10-simpsons.html",
    "href": "coding_practice/coding-practice-10-simpsons.html",
    "title": "Conditional probabilities coding practice",
    "section": "",
    "text": "Today’s data comes from a study of conducted in Whickham, England. In this study, the researchers recorded each participant’s age, smoking status at the start of the study, and their health outcome 20 years later.\nThe data is in the mosaicData package. You may have to install the package first! Then run the following code:\n\nlibrary(tidyverse)\nlibrary(mosaicData)\n\nWe will work with the Whickham data. You should open its Help file and take a view of the data before proceeding. Note that “factor” can be though of as a categorical variable. Make sure you understand the data before proceeding!\nDiscuss with your group: What would you expect the relationship between smoking status and health outcome to be?\n\nCreate an appropriate visualization depicting the relationship between smoking status and health outcome. Make sure you have informative labels and titles.\n\n\n\n\n\nUsing wrangling code, calculate the conditional probabilities of death of each smoking status. Your resulting table/data frame should only retain the variables for smoke status, outcome, and the conditional probabilities in a meaningful order. Also, please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, briefly describe the relationship and whether or not it is what you expected. You may want to discuss the visualization from the previous exercise as well.\n\nUsing case_when(), create a new variable for future use called age_cat that takes the values as follows:\n\n\n“18-44”: if someone is less than or equal to 44 years old\n“45-64”: if someone is between 45 and 64 years old, inclusive\n“65+”: if someone is older than 64\n\n\n\n\n\nRe-create your first visualization from Exercise 1, this time faceting by age_cat. Make sure you have informative labels and titles.\n\n\n\n\n\nElaborate on your table from Exercise 2 above by breaking it down by age category. Your resulting table/data frame should only retain the variables for smoke status, age category, outcome, and the conditional probabilities in a meaningful order. Once again, please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, compare the two visualizations and the two summary tables. What changed, and what might explain the change?\nAnswer:\nWhen finished, knit one more time and submit the HTML to Canvas!"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#uc-berkeley-admissions-cont.",
    "href": "slides/slides-10-simpsons.html#uc-berkeley-admissions-cont.",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions (cont.)",
    "text": "UC Berkeley admissions (cont.)"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#where-we-are-going",
    "href": "slides/slides-11-bootstrap.html#where-we-are-going",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Where we are going",
    "text": "Where we are going\nWe are leaving the world of EDA and beginning to enter the world of inference and modeling!\n\nWant to answer questions about a population, but must rely on a sample\nCollect data from sample –> calculate statistics\nWhat can we say about the statistics?\nData are random! So how sure are we about our conclusions?\n\n\nStatistics starts here!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#inferential-questions",
    "href": "slides/slides-11-bootstrap.html#inferential-questions",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Inferential questions",
    "text": "Inferential questions\n\nI want to know the true average number of hours of sleep Middlebury students get a night. Based on a sample of students, what might be a “good estimate” of the true average?\nIs the true average number of of hours of Middlebury students get a night less than 7 hours?\n\nQuestions here are about population parameter (in this case, \\(\\mu\\))\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#activity",
    "href": "slides/slides-11-bootstrap.html#activity",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Activity",
    "text": "Activity\nWhile you’re coming into the room, please take:\n\n1 pink card\n1 white card\n\n\nOn the pink card, write down an estimate of the average number of hours of sleep you received this past week.\nOn white card, write a 1 if this number you wrote down on the pink card is greater than or equal to 7, and a 0 otherwise\nThen bring these to Prof. Tang"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#variability-of-statistic",
    "href": "slides/slides-11-bootstrap.html#variability-of-statistic",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Variability of statistic",
    "text": "Variability of statistic\n\nTwo datasets collected under identical procedures will differ. As a result, value of the point estimate we obtain are also different\n\nActivity cont.\n\nThus, there exists the notion of a sampling distribution of the statistic: how the statistic behaves under repeated random samples obtained via the same sampling procedure\n\nThe variability associated with the sampling distribution of the statistic is called the standard error\n\nNote: “error” \\(\\neq\\) bad\n\nThis is in contrast to the standard deviation, which describes variability in the individual data points and not the statistic\n\nPopulation distribution vs. sample distribution vs. sampling distribution"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#sampling-distribution",
    "href": "slides/slides-11-bootstrap.html#sampling-distribution",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nOf course, sampling distribution of the statistic depends on underlying distribution of the population\nSometimes, we assume that the population/data have a very specific behavior, and this allows us to exactly define/quantify the sampling distribution\n\nWe will see this in a couple of weeks\n\nIf we don’t want to make assumptions, what do we do?\n\nCould conduct a census! That way we can answer any questions we want about the population. But that’s impractical…\nHow to obtain more samples cheaply and quickly?"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#procedure",
    "href": "slides/slides-11-bootstrap.html#procedure",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Procedure",
    "text": "Procedure\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#activity-1",
    "href": "slides/slides-11-bootstrap.html#activity-1",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Activity",
    "text": "Activity\n\nTarget population:\nSampling method:\nPopulation parameter:\nStatistics we can calculate:"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#why-resample-with-replacement",
    "href": "slides/slides-11-bootstrap.html#why-resample-with-replacement",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Why resample with replacement?",
    "text": "Why resample with replacement?\n\nWe want to understand the sampling error of the sampling distribution!\n\nWhat would the bootstrap samples \\(\\vec{x}^*_b\\) look like if we sampled without replacement?\n\n\nSampling without replacement -> zero variation in the resampled statistics\n\nResampling with replacement will give us “new” datasets that are similar to original sample distribution but not exactly the same!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#remarks",
    "href": "slides/slides-11-bootstrap.html#remarks",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Remarks",
    "text": "Remarks\n\n\nRelies on having a representative original sample!\n\n\nResampling from initial sample should be roughly equivalent to sampling directly from the population\n\nRequires computational tools!\n\nWe need \\(B\\) to be large enough to accurately capture variability. \\(B=5000\\) or \\(B=10000\\) sufficient in this class\nMore complex problems will require larger \\(B\\)\n\nBootstrapping can fail!\nBootstrapping is not a solution to small sample sizes!!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#point-estimate",
    "href": "slides/slides-11-bootstrap.html#point-estimate",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Point estimate",
    "text": "Point estimate\n\n\\(\\bar{x}\\) is often times a sensible estimate for \\(\\mu\\)\n\\(\\bar{x}\\) is an example of a point estimate: a single number used to estimate a true but unknown population parameter\n\ni.e. a point estimate is a statistic with a specific purpose\nOther examples include \\(s\\) for \\(\\sigma\\), observed proportion \\(\\hat{p}\\) for true proportion \\(p\\),\n\n\nWhat are desirable characteristics of a “good” point estimate?\n\n\nDo we believe that \\(\\bar{x} = \\mu\\) or \\(\\hat{p} = p\\)?"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#demonstration",
    "href": "slides/slides-11-bootstrap.html#demonstration",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Demonstration",
    "text": "Demonstration\n\nActivity cont.\nLive code demonstration"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#housekeeping",
    "href": "slides/slides-12-bootstrap_ci.html#housekeeping",
    "title": "Bootstrap Confidence Intervals",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours 3-4pm\nMidterm tomorrows! Bring a calculator."
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-recap",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap recap",
    "text": "Bootstrap recap\nTaking new samples each time is costly! Bootstrap distribution is an approximation of the sampling distribution of the statistic!\nProcedure:\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nAnalogy: would you rather go fishing with a single pole or a large net?\n\nA range of plausible values gives us a better chance at capturing the parameter\n\nA confidence interval provides such a range of values (more rigorous definition coming soon)\n\n“Interval” = we specify a lower bound and an upper bound\nConfidence intervals are not unique! Depending on the method you use, you might get different intervals"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap confidence intervals",
    "text": "Bootstrap confidence intervals\n\n\n\nLet’s continue with the data collected from our activity. We have the following bootstrap distribution of sample means, obtained from \\(B=\\) 5000 iterations:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution",
    "text": "Bootstrap distribution\n\n\n\nLet’s continue with the data collected from our activity. We have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere is the bootstrap distribution centered?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-percentile-interval",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-percentile-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap percentile interval",
    "text": "Bootstrap percentile interval\n\nThe \\(\\gamma \\times 100\\)% bootstrap percentile interval is obtained by finding the bounds of the middle \\(\\gamma \\times 100\\)% of the bootstrap distribution\n\n\ne.g. If I want a 90% bootstrap percentile interval, where would the bounds be?\n\n\nCalled “percentile interval” because the bounds are the \\((1-\\gamma)/2\\) and \\((1+\\gamma)/2\\) percentiles of the bootstrap distribution\n\ne.g. if \\(\\gamma = 0.80\\), then the bounds would be \\((1-0.80)/2 = 0.10\\) and \\((1+0.80)/2 = 0.90\\) percentiles\n\nFor our purposes, “bootstrap confidence interval” will be equivalent to “bootstrap percentile interval”"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval",
    "href": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval",
    "text": "Interpreting a confidence interval\n\nOur 90% confidence interval is: (0.3, 0.8) or (0.5, 0.9). Does this mean there is a 90% chance/probability that the true proportion lies in the interval?\n\n\nAnswer: NO\n\n\nRemember: bootstrap distribution is based on our original sample\n\nIf we started with a different original sample \\(\\vec{x}\\), then our estimated 90% confidence interval would also be different\n\n\nWhat a confidence interval (CI) represents: if we take many independent repeated samples from this population using the same method and calculate a \\(\\gamma \\times 100\\) % CI for the parameter in the exact same way, then in theory, \\(\\gamma \\times 100\\) % of these intervals should capture/contain the parameter\n\n\n\\(\\gamma\\) represents the long-run proportion of CIs that theoretically contain the true parameter\nHowever, we never know if any particular interval(s) actually do!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "href": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval (cont.)",
    "text": "Interpreting a confidence interval (cont.)\n\nCorrect interpretation (generic): We are \\(\\gamma \\times 100\\) % confident that the population parameter is between the lower bound and upper bound.\n\n\nInterpret our bootstrap CI in context\n\nAgain: why is this interpretation incorrect? “There is a 90% chance/probability that the true parameter value lies in the interval.”"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "href": "slides/slides-12-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Obtaining bootstrap confidence interval",
    "text": "Obtaining bootstrap confidence interval\n\n\n\n\n\n\nSection A 90% confidence interval for \\(p_{A}\\): (0.3, 0.8)\nSection B 90% confidence interval for \\(p_{B}\\): (0.5, 0.9)"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html",
    "href": "slides/slides-11-bootstrap.html",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "",
    "text": "Midterm review problems released\nWednesday office hours 3-4pm\nMidterm this Thursday in class! Bring a calculator.\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 4526 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Decision, Gender, Dept\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nWe are leaving the world of EDA and beginning to enter the world of inference and modeling!\n\nWant to answer questions about a population, but must rely on a sample\nCollect data from sample –> calculate statistics\nWhat can we say about the statistics?\nData are random! So how sure are we about our conclusions?\n\n\nStatistics starts here!\n\n\n\n\nStatistical inference is the process of using sample data to make conclusions about the underlying population the sample came from\n\nEstimation: using the sample to estimate a plausible values for the unknown parameter\nTesting: evaluating whether our observed sample provides evidence for or against some claim about the population\n\n\n\n\n\nI want to know the true average number of hours of sleep Middlebury students get a night. Based on a sample of students, what might be a “good estimate” of the true average?\nIs the true average number of of hours of Middlebury students get a night less than 7 hours?\n\nQuestions here are about population parameter (in this case, \\(\\mu\\))\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics\n\n\n\n\n\n\nTarget population:\nSampling method:\nPopulation parameter:\nStatistics we can calculate:\n\n\n\n\n\n\\(\\bar{x}\\) is often times a sensible estimate for \\(\\mu\\)\n\\(\\bar{x}\\) is an example of a point estimate: a single number used to estimate a true but unknown population parameter\n\ni.e. a point estimate is a statistic with a specific purpose\nOther examples include \\(s\\) for \\(\\sigma\\), observed proportion \\(\\hat{p}\\) for true proportion \\(p\\),\n\n\nWhat are desirable characteristics of a “good” point estimate?\n\n\nDo we believe that \\(\\bar{x} = \\mu\\)?\n\n\n\n\n\n\nTwo datasets collected under identical procedures will differ. As a result, value of the point estimate we obtain are also different\n\nActivity cont.\n\nThus, there exists the notion of a sampling distribution of the statistic: how the statistic behaves under repeated random samples obtained via the same sampling procedure\n\nThe variability associated with the sampling distribution of the statistic is called the standard error\n\nNote: “error” \\(\\neq\\) bad\n\nThis is in contrast to the standard deviation, which describes variability in the individual data points and not the statistic\n\nPopulation distribution vs. sample distribution vs. sampling distribution\n\n\n\n\n\nOf course, sampling distribution of the statistic depends on underlying distribution of the population\nSometimes, we assume that the population/data have a very specific behavior, and this allows us to exactly define/quantify the sampling distribution\n\nWe will see this in a couple of weeks\n\nIf we don’t want to make assumptions, what do we do?\n\nCould conduct a census! That way we can answer any questions we want about the population. But that’s impractical…\nHow to obtain more samples cheaply and quickly?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html",
    "href": "slides/slides-12-bootstrap_ci.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "Office hours 3-4pm\nMidterm tomorrows! Bring a calculator."
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#remarks",
    "href": "slides/slides-12-bootstrap_ci.html#remarks",
    "title": "Bootstrap Confidence Intervals",
    "section": "Remarks",
    "text": "Remarks\n\n\nWhat is a virtue of a “good” confidence interval?\n\n\nHow do you expect the interval to change as the original sample size \\(n\\) changes?\nHow do you expect the interval to change as level of confidence \\(\\gamma\\) changes?\n\nOnce again, relies on a representative original sample!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#your-turn",
    "href": "slides/slides-12-bootstrap_ci.html#your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Your turn!",
    "text": "Your turn!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#inference",
    "href": "slides/slides-11-bootstrap.html#inference",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Inference",
    "text": "Inference\nStatistical inference is the process of using sample data to make conclusions about the underlying population the sample came from\n\nEstimation: using the sample to estimate a plausible values for the unknown parameter\nTesting: evaluating whether our observed sample provides evidence for or against some claim about the population"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#estimation-questions",
    "href": "slides/slides-11-bootstrap.html#estimation-questions",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Estimation questions",
    "text": "Estimation questions\n\nI want to know the true average number of hours of sleep Middlebury students get a night.\n\nBased on a sample of students, what might be a “good estimate” of the true average?\n\nWhat proportion of Middlebury students get a night less than 7 hours?\n\nBased on a sample of students, what might be a “good estimate” of the true proportion?\n\nQuestions here are about population parameter\n\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics"
  },
  {
    "objectID": "live_code/bootstrap_dist.html",
    "href": "live_code/bootstrap_dist.html",
    "title": "Bootstrap distribution demo",
    "section": "",
    "text": "library(tidyverse)\n\n# \"set seed\" for reproducibility\nset.seed(1)\n\n# our original sample\nx_orig <- c(\"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\")\n\n# sample size stored as variable for reproducibility\nn <- length(x_orig)\n\n# number of bootstrap samples to take\nB <- 5000\n\n# vector to store bootstrap statistics\n# starts off as vector full of NAs of length B\nbootstrap_props <- rep(NA, B)\n\n# for loop\nfor(b in 1:B){\n  # obtain bootstrap resample (will change every iteration)\n  x_b <- sample(x = x_orig, size = n, replace = TRUE)\n  \n  # calculate bootstrap statistic (will change every iteration)\n  boot_mean <- mean(x_b == \"yes\")\n  \n  # store into b-th position, replacing the NA\n  bootstrap_props[b] <- boot_mean\n}\n\n# visualize bootstrap dist.\n\n## first create data frame\nboot_df <- data.frame(props = bootstrap_props) \n\n## ggplot\nggplot(boot_df, aes(x = props))+\n  geom_histogram(bins = 10, col = \"white\") +\n  labs(title = \"Bootstrap distribution\",\n       subtitle = \"Population: STAT 201A students\",\n       x = \"Proportion who drink coffee\")"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#why-bootstrap",
    "href": "slides/slides-12-bootstrap_ci.html#why-bootstrap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Why bootstrap?",
    "text": "Why bootstrap?\n\nSample distribution describes how statistic behaves under repeated sampling from population\nLet’s continue with the data collected from our activity.\n\nI repeatedly take SRS of \\(n=5\\) values from the population and calculate \\(\\hat{p}\\). Sampling distribution of \\(\\hat{p}\\) is as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaking new samples each time is costly! Bootstrap distribution is an approximation of the sampling distribution of the statistic"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-procedure-recap",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-procedure-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap procedure recap",
    "text": "Bootstrap procedure recap\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution from activity",
    "text": "Bootstrap distribution from activity\n\n\n\nWe have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-dist.-continued",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-dist.-continued",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap dist. continued",
    "text": "Bootstrap dist. continued\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice where the bootstrap distribution is centered\nWhat do we do with the bootstrap distribution?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#answering-estimation-question",
    "href": "slides/slides-12-bootstrap_ci.html#answering-estimation-question",
    "title": "Bootstrap Confidence Intervals",
    "section": "Answering estimation question",
    "text": "Answering estimation question\nRecall our research question: What proportion of STAT 201A/STAT 201B students get at least 7 hours of sleep a night?\n\nCould respond using our single point estimate: \\(\\hat{p}_{A} = 0.6\\) or \\(\\hat{p}_{B} = 0.7\\)\nBut due to variability, we recognize that the point estimate will rarely (if ever) equal population parameter\nRather than report a single number, why not report a range of values?\n\n\nThis is possible only if we have a distribution to work with!!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#recap",
    "href": "slides/slides-12-bootstrap_ci.html#recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Recap",
    "text": "Recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nLet’s return to the data collected from our activity.\n\nI will repeatedly take SRS of \\(n=10\\) values from the population (call this \\(\\vec{x}\\)) and calculate \\(\\hat{p}\\). Sampling distribution of \\(\\hat{p}\\) is as follows:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nComparing changes in \\(\\gamma \\times 100\\) % CI for sample sizes: \\(n = 5\\), \\(n = 10\\), and \\(n = 17\\):\n\n\n`summarise()` has grouped output by 'n_lab'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\nWhat do you notice?\n\n\n\n\n\nSection A\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0.2, 1)\n\n\nn = 10\n(0.3, 0.8)\n\n\nn = 17\n(0.41, 0.76)\n\n\n\n\n\n\nSection B\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0.4, 1)\n\n\nn = 10\n(0.5, 0.9)\n\n\nn = 17\n(0.53, 0.88)"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-1",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-1",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nWhat do you think happens as we increase \\(\\gamma\\) from \\(0\\) to \\(1\\)?\n\nYour turn to try!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-cont.",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals (cont.)",
    "text": "Comparing confidence intervals (cont.)\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#live-code-your-turn",
    "href": "slides/slides-12-bootstrap_ci.html#live-code-your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Live code + your turn!",
    "text": "Live code + your turn!\n\nLive code:\n\nin-line code\n\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "coding_practice/coding-practice-12-bootstrap.html",
    "href": "coding_practice/coding-practice-12-bootstrap.html",
    "title": "Bootstrap confidence intervals",
    "section": "",
    "text": "We will work with the average hours of sleep each class reported. In the following code chunk, please delete the line of code that does not correspond to your section.\n\nlibrary(tidyverse)\nlibrary(readr)\n\n# SECTION A DATA\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/sectionA_week4_sleep.csv\"\n\n# SECTION B DATA \nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/sectionB_week4_sleep.csv\"\n\n\nsleep <- read_csv(url_file)\n\nWe will intialize a pseudo-random-number-generator using the set.seed() function. You can choose any whole number to input as the parameter to this function. If I have the same seed and code and you, then I can reproduce the same random results.\n\nset.seed(201)\n\n\nCreate a variable that represents and stores the target sample size: 10. Then, take a random sample of size 10 of sleep hours from our population. Store your sample into a variable called x.\n\n\n# create a variable for sample size\n\n# obtain and store our sample\n\n\nWe will take 5000 bootstrap iterations. Store this value as a variable for reproducibility.\n\n\n# store number of bootstrap iterations\n\n\nObtain a bootstrap distribution of sample means using your original sample. Remember to store the bootstrap statistics somewhere! Please use a meaningful variable name. It may be useful to look at and modify the live code from previous class (on website)\n\n\n\n\n\nThe quantile() function obtains percentiles for us. It requires two arguments: a numeric vector and a percentile level (between 0 and 1). For example, quantile(x, 0.5) finds the 50-th percentile of the vector x.\n\nUsing this function, obtain the bounds for a 80%, 90%, and 99% bootstrap confidence interval, respectively. Store these bounds as variables.\n\n# 80%\n\n# 90%\n\n# 99%\n\n\nReport the three confidence intervals here in the format of (lower, upper) using in-line code.\n\n80% CI:\n90%: CI:\n99% CI:\n\nHow do the confidence interval widths change as the level of confidence increases?\n\nAnswer:\n\nInterpret one of your confidence intervals in context. Use in-line code in your answer.\n\nAnswer:"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#housekeeping",
    "href": "slides/slides-13-intro-testing.html#housekeeping",
    "title": "Introduction to Hypothesis Testing",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours change this week\nMid-semester feedback survey results"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#testing",
    "href": "slides/slides-13-intro-testing.html#testing",
    "title": "Introduction to Hypothesis Testing",
    "section": "Testing",
    "text": "Testing\nWe are now entering into second branch of inference-related tasks: testing.\n\nWe have some “claim”/question about the target population, and we use sampled data to provide evidence for or against the claim/question.\nEspecially important in experiments where we want to learn the effect of some new drug\nWe will use the hypothesis testing framework to formalize the process of making decisions about research claims.\n\nBecause claim is about target population, we will almost always formulate claims in terms of population parameters\nThen we use sample statistics to provide the evidence for/against"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#running-example-sex-discrimination-study",
    "href": "slides/slides-13-intro-testing.html#running-example-sex-discrimination-study",
    "title": "Introduction to Hypothesis Testing",
    "section": "Running example: sex discrimination study",
    "text": "Running example: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#data",
    "href": "slides/slides-13-intro-testing.html#data",
    "title": "Introduction to Hypothesis Testing",
    "section": "Data",
    "text": "Data\nFor each of the 48 supervisors, the following were recorded:\n\nThe sex of the candidate in the file (male/female)\nThe decision (promote/not promote)\n\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nAre we prepared to answer our research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\nWhat evidence do we have?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#evidence",
    "href": "slides/slides-13-intro-testing.html#evidence",
    "title": "Introduction to Hypothesis Testing",
    "section": "Evidence",
    "text": "Evidence\nConditional probability of getting promoted by sex:\n\n\n# A tibble: 2 × 3\n# Groups:   sex [2]\n  sex    decision cond_prob\n  <chr>  <chr>        <dbl>\n1 female promote      0.583\n2 male   promote      0.875\n\n\n\nThe key question: does the difference we found provide convincing evidence that individuals who identify as female are unfairly discriminated against?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-1-define-hypotheses",
    "href": "slides/slides-13-intro-testing.html#step-1-define-hypotheses",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 1: Define hypotheses",
    "text": "Step 1: Define hypotheses\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\nWe define hypotheses to translate our research question/claim into statistical notation\nWe always define two hypotheses in context: a null hypothesis and an alternative hypothesis\nNull hypothesis \\(H_{0}\\): the hypothesis that represents “business as usual”/status quo/nothing unusual or noteworthy\nAlternative hypothesis \\(H_{A}\\): claim the researchers want to demonstrate\n\n\nIt will not always be obvious what \\(H_{0}\\) should be, but you will develop intuition for this over time!"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#defining-hypotheses-in-context",
    "href": "slides/slides-13-intro-testing.html#defining-hypotheses-in-context",
    "title": "Introduction to Hypothesis Testing",
    "section": "Defining hypotheses in context",
    "text": "Defining hypotheses in context\nResearch question: do the majority of STAT 201A/STAT 201B students get at least 7 hours of sleep?\n\nDefine \\(p\\) as the true proportion of STAT 201A/STAT 201B who get at least 7 hours of sleep on average\n\n\n\n\\(H_{0}\\): \\(p \\leq 0.5\\)\n\\(H_{A}\\): \\(p > 0.5\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-2-collect-data-and-calculate-sample-statistics",
    "href": "slides/slides-13-intro-testing.html#step-2-collect-data-and-calculate-sample-statistics",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 2: Collect data and calculate sample statistics",
    "text": "Step 2: Collect data and calculate sample statistics\nSuppose I collect a sample of \\(n= 10\\) students from each class:\n\n\n\n\n\nIn STAT 201A sample: 6 students received at least 7 hours of sleep, and 4 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.6\n\n\nIn STAT 201B sample: 7 students received at least 7 hours of sleep, and 3 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.7\n\n\n\n\n\nAre we prepared to answer our research question based on this evidence?\n\nDue to variability in data and \\(\\hat{p}\\) we should ask: do the data provide convincing evidence that the majority of students get at least 7 hours of sleep?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#running-example-2-sex-discrimination-study",
    "href": "slides/slides-13-intro-testing.html#running-example-2-sex-discrimination-study",
    "title": "Introduction to Hypothesis Testing",
    "section": "Running example 2: sex discrimination study",
    "text": "Running example 2: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#defining-hypotheses-here",
    "href": "slides/slides-13-intro-testing.html#defining-hypotheses-here",
    "title": "Introduction to Hypothesis Testing",
    "section": "Defining hypotheses here",
    "text": "Defining hypotheses here\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "href": "slides/slides-13-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 3: Determine if we have “convincing evidence”",
    "text": "Step 3: Determine if we have “convincing evidence”\n“Convincing evidence” for us means that it would be highly unlikely to observe the data we did (or data even more extreme) if \\(H_{0}\\) were true!\n\nWe will calculate a p-value: the probability of observing data as or more extreme than we did assuming \\(H_{0}\\) true\n\nNote: p is not the same as true proportion \\(p\\)!\n\nHighly unlikely is vague and needs to defined by the researcher, ideally before seeing data.\n\nIf we want to answer the research question with a binary yes/no, we need some threshold to compare the p-value to. This is called a significance level \\(\\alpha\\)\nCommon choices are \\(\\alpha = 0.05\\), \\(\\alpha = 0.01\\) (more on this later)!\n\nFor our example, we will choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\)",
    "text": "Simulating under \\(H_{0}\\)\n-"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nWe have to simulate our data under the assumption that \\(H_{0}\\) is true (recall \\(H_0\\): \\(p \\leq 0.5\\))\nImagine a big bag with pink and purple slips of paper\n\nPink = people who got at least 7 hours of sleep\nPurple = people who got less than 7 hours\n\nWhat proportion of the slips in the bowl should be pink vs purple?\n\nTo simulate under \\(H_{0}\\), no more than 50% of the slip should be pink\n\nWe want convincing evidence even in the most “borderline” case, so we will choose 50% of the slips to be pink."
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nActivity: we now replicate our original sample, this time sampling from this bag of paper slips\n\nWe repeatedly take samples from the null distribution, using original sample size \\(n =\\) 10\nFor each sample, calculate the simulated proportion of pink slips, \\(\\hat{p}_{sim}\\)\n\nLive code?\n\n\n\nset.seed(2) # reproducibility\nB <- 5000 # number of simulations to do to gather enough evidence\nn <- 10 # size of our original sample\np_null_vec <- rep(NA, B) # vector to store the simulated proportions\nfor(b in 1:B){\n  # sample() takes a random sample\n  null_samp <- sample(x = c(\"pink\", \"purple\"), # pink and purple slips\n                      size = n, # sample of size n\n                      replace = T, # tell R that my bowl has infinitely many marbles \n                      prob = c(0.5, 0.5)) # 50% of slips are pink and 50% are purple\n  \n  # calculate and store the proportion of pink slips in this simulation\n  p_null_vec[b] <- sum(null_samp == \"pink\")/n\n}"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#null-distribution-of-statistic",
    "href": "slides/slides-13-intro-testing.html#null-distribution-of-statistic",
    "title": "Introduction to Hypothesis Testing",
    "section": "Null distribution of statistic",
    "text": "Null distribution of statistic\nWe can visualize the distribution of \\(\\hat{p}_{sim}\\) assuming \\(H_{0}\\) true:\n\n\nThis is called the null distribution of the sample statistic, which is the distribution of the statistic assuming \\(H_{0}\\) is true\n\nWhere is the null distribution of \\(\\hat{p}\\) centered? Why does that “make sense”?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#obtain-p-value-step-3-cont.",
    "href": "slides/slides-13-intro-testing.html#obtain-p-value-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Obtain p-value (step 3 cont.)",
    "text": "Obtain p-value (step 3 cont.)\nWe can directly obtain (technically estimate) the p-value using our null distribution and our observed \\(\\hat{p}\\)!\n\n\n\n\n\n\n\n\n\nOut of 5000 replications, we saw 1946 instances of \\(\\hat{p}_{sim} \\geq \\hat{p}\\)\np-value is \\(\\frac{ 1946}{5000} \\approx\\) 0.39\n\n\n\n\n\n\n\n\nOut of 5000 replications, we saw 853 instances of \\(\\hat{p}_{sim} \\geq \\hat{p}\\)\np-value is \\(\\frac{ 853}{5000} \\approx\\) 0.17"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#comparing-null-to-observed",
    "href": "slides/slides-13-intro-testing.html#comparing-null-to-observed",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comparing null to observed",
    "text": "Comparing null to observed\nLet’s return to our original goal of Step 3! We need to find the p-value: the probability of observing data as or more extreme as ours, assuming \\(H_{0}\\) were true.\n\nOur observed data were \\(\\hat{p} =\\) 0.6 (STAT 201A) or \\(\\hat{p} =\\) 0.7 (STAT 201B)\n\\(H_{0}\\): \\(p \\leq 0.5\\) and \\(H_{A}\\): \\(p > 0.5\\)\n\nWhat does “as or more extreme” mean in this context?\nHow can we use the null distribution to obtain this probability?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#how-to-obtain-p-value",
    "href": "slides/slides-13-intro-testing.html#how-to-obtain-p-value",
    "title": "Introduction to Hypothesis Testing",
    "section": "How to obtain p-value?",
    "text": "How to obtain p-value?\n\nHow to obtain this probability? It depends!\n\nOption 1: if we have assumptions about how our data behave, we can obtain this probability using theory/math (next week)\nOption 2: if we don’t want to make assumptions, why not simulate?\n\nWe will call this option “simulating under \\(H_{0}\\)”\n\n\n\nThis is the step that requires the most “work”, and what exactly you do will depend on the the type of data and the research question/claim you have\n\nRemark: hypothesis tests, like confidence intervals, are not unique!"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "href": "slides/slides-13-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 4: Interpret p-value and make decision",
    "text": "Step 4: Interpret p-value and make decision\n\nInterpret the p-value in context\n\n\nAssuming \\(H_{0}\\) true, the probability of observing a sample proportion as or more extreme as ours (0.6 or 0.7) is 0.39 or 0.17\n\n\nMake a decision about research claim/question by comparing p-value to significance level \\(\\alpha\\)\n\nIf p-value \\(< \\alpha\\), we reject \\(H_{0}\\) (it was highly unlikely to observe our data given our selected threshold)\nIf p-value \\(\\geq \\alpha\\), we fail to reject \\(H_{0}\\) (we did not have enough evidence against the null)\n\n\nNote: we never “accept \\(H_{A}\\)”!\n\n\n\nSince our p value is greater than \\(\\alpha = 0.05\\), we fail to reject \\(H_{0}\\). The data do not provide sufficient evidence to suggest that the majority of STAT 201A/STAT 201B students get more than 7 hours of sleep."
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#summary",
    "href": "slides/slides-13-intro-testing.html#summary",
    "title": "Introduction to Hypothesis Testing",
    "section": "Summary",
    "text": "Summary\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain p-value\n\nWe did this using by simulating under the null distribution\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-14-randomization.html#housekeeping",
    "href": "slides/slides-14-randomization.html#housekeeping",
    "title": "Hypothesis Testing with Randomization",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours change this week"
  },
  {
    "objectID": "slides/slides-14-randomization.html#recap",
    "href": "slides/slides-14-randomization.html#recap",
    "title": "Hypothesis Testing with Randomization",
    "section": "Recap",
    "text": "Recap\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain p-value by modeling randomness that would occur if \\(H_{0}\\) was true\n\nWe did this using by simulating under the null distribution\n\nReport p-value and make a decision and conclusion in context"
  },
  {
    "objectID": "slides/slides-14-randomization.html#running-example-sex-discrimination-study",
    "href": "slides/slides-14-randomization.html#running-example-sex-discrimination-study",
    "title": "Hypothesis Testing with Randomization",
    "section": "Running example: sex discrimination study",
    "text": "Running example: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#defining-hypotheses",
    "href": "slides/slides-14-randomization.html#defining-hypotheses",
    "title": "Hypothesis Testing with Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\n\nWhat is/are the variables(s) here? What types of variables are they?\n\nWe need to construct hypotheses where \\(H_{0}\\) is “status quo” and \\(H_{A}\\) is the claim researchers have\n\\(H_{0}\\): the variables sex and decision are independent.\n\ni.e. any observed difference in promotion rates is due to variability\n\n\\(H_{A}\\): the variables sex and decision are not independent, and equally-qualified female personnel are less likely to be promoted than male personnel"
  },
  {
    "objectID": "slides/slides-14-randomization.html#data",
    "href": "slides/slides-14-randomization.html#data",
    "title": "Hypothesis Testing with Randomization",
    "section": "Data",
    "text": "Data\nFor each of the 48 supervisors, the following were recorded:\n\nThe sex of the candidate in the file (male/female)\nThe decision (promote/not promote)\n\n\n\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\n\nAre we prepared to answer our research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\nWhat evidence do we have?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#data-cont.",
    "href": "slides/slides-14-randomization.html#data-cont.",
    "title": "Hypothesis Testing with Randomization",
    "section": "Data (cont.)",
    "text": "Data (cont.)\nConditional probability of getting promoted by sex:\n\ndiscrimination |>\n  count(sex, decision) |>\n  group_by(sex) |>\n  mutate(cond_prob = n/sum(n)) |>\n  filter(decision == \"promote\") |>\n  select(-n)\n\n\n\n# A tibble: 2 × 3\n# Groups:   sex [2]\n  sex    decision cond_prob\n  <chr>  <chr>        <dbl>\n1 female promote      0.583\n2 male   promote      0.875\n\n\n\nIs the observed difference -0.2916667 convincing evidence? We need to examine variability in the data, assuming \\(H_{0}\\) true.\nLet’s set \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#comprehension-questions",
    "href": "slides/slides-13-intro-testing.html#comprehension-questions",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat are the similarities/differences between the bootstrap distribution of a sample statistic and the simulated null distribution?\nDo you understand what a p-value represents, and how we obtain it from the null distribution?\nWhat role does \\(\\alpha\\) play? Why is it important to set \\(\\alpha\\) early on?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-2-collect-and-summarize-data",
    "href": "slides/slides-13-intro-testing.html#step-2-collect-and-summarize-data",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 2: Collect and summarize data",
    "text": "Step 2: Collect and summarize data\nSuppose I collect a sample of \\(n= 10\\) students from each class:\n\n\n\n\n\nIn STAT 201A sample: 6 students received at least 7 hours of sleep, and 4 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.6\n\n\nIn STAT 201B sample: 7 students received at least 7 hours of sleep, and 3 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.7\n\n\n\n\n\nAre we prepared to answer our research question based on this evidence?\n\nDue to variability in data and \\(\\hat{p}\\) we should ask: do the data provide convincing evidence that the majority of students get at least 7 hours of sleep?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#summary-of-testing-framework",
    "href": "slides/slides-13-intro-testing.html#summary-of-testing-framework",
    "title": "Introduction to Hypothesis Testing",
    "section": "Summary of testing framework",
    "text": "Summary of testing framework\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain/estimate p-value by modeling randomness that would occur if the \\(H_{0}\\) were true\n\nWe did this using by simulating under the null distribution\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#errors-in-decision",
    "href": "slides/slides-13-intro-testing.html#errors-in-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\nIn Step 4, we make a decision but it could be wrong! (Unfortunately, we will never know)\nWe always fall into one of the following four scenarios:\n\n\n\n\n\n\n\n\n\n\nIdentify which cells are good scenarios, and which are bad"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#errors-in-decision-1",
    "href": "slides/slides-13-intro-testing.html#errors-in-decision-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\n\n\nWhat kind of error could we have made in our example?\n\nIt is important to weight the consequences of making each type of error!\n\nWe have some control in this - how? Through \\(\\alpha\\)!"
  },
  {
    "objectID": "slides/slides-14-randomization.html#running-example-cpr",
    "href": "slides/slides-14-randomization.html#running-example-cpr",
    "title": "Hypothesis Testing with Randomization",
    "section": "Running example: CPR",
    "text": "Running example: CPR\nAn experiment was conducted, consisting of two treatments on 90 patients who underwent CPR for a heart attack and subsequently went to the hospital. Each patient was randomly assigned to either:\n\ntreatment group: received a blood thinner\ncontrol group: did not receive a blood thinner\n\n\nFor each patient, the outcome recorded was whether they survived for at least 24 hours.\n\n\n`summarise()` has grouped output by 'group'. You can override using the\n`.groups` argument.\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\n\nWhat is/are the variables(s) here? What types of variables are they?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#collect-data",
    "href": "slides/slides-14-randomization.html#collect-data",
    "title": "Hypothesis Testing with Randomization",
    "section": "Collect data",
    "text": "Collect data\nUsing the data, obtain the observed difference in sample proportions.\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\n\n\np_hat_c <- cpr |>\n  filter(group == \"control\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull()\np_hat_t <- cpr |>\n  filter(group == \"treatment\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull()\nobs_diff <- p_hat_t - p_hat_c\n\n\n\n\n\\(\\hat{p}_{C} = \\frac{11}{50} = 0.22\\)\n\\(\\hat{p}_{T} = \\frac{14}{40} = 0.35\\)\nObserved difference: \\(\\hat{p}_{T} - \\hat{p}_{C} = 0.13\\)\n\n\n\n\nIs this “convincing evidence” that blood thinner usage after CPR is effective?\nSet \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#defining-hypotheses-1",
    "href": "slides/slides-14-randomization.html#defining-hypotheses-1",
    "title": "Hypothesis Testing with Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\nThe researchers are interested in learning if the blood thinner treatment was effective.\n\nIn words, try to determine \\(H_{0}\\) and \\(H_{A}\\).\n\n\nLet \\(p_{T}\\) and \\(p_{C}\\) denote the proportion of patients who survive when receiving the thinner (Treatment) and when not receiving the treatment (Control), respectively\n\n\n\n\nOption 1\n\n\\(H_{0}\\): \\(p_{T} \\leq p_{C}\\)\n\\(H_{A}\\): \\(p_{T} > p_{C}\\)\n\n\n\n\nOption 2 (preferred)\n\n\\(H_{0}\\): \\(p_{T} - p_{C} \\leq 0\\)\n\\(H_{A}\\): \\(p_{T} - p_{C}> 0\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null",
    "href": "slides/slides-14-randomization.html#simulate-under-null",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nSimulating under \\(H_{0}\\) means operating in a hypothetical word where sex and decision are independent.\n\nThis means that knowing the sex of the candidate should have no bearing on the decision to promote or not\n\nWe will perform a simulation called a randomization test where we randomly re-assign decision and sex outcome pairs to see what would have happened if the bankers’ decision had been independent of candidate’s sex (i.e. if \\(H_{0}\\) true)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#visualizing-null-distribution",
    "href": "slides/slides-14-randomization.html#visualizing-null-distribution",
    "title": "Hypothesis Testing with Randomization",
    "section": "Visualizing null distribution",
    "text": "Visualizing null distribution\n\n\n\n\n\n\nHow would we obtain the p-value in this problem?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#calculate-p-value",
    "href": "slides/slides-14-randomization.html#calculate-p-value",
    "title": "Hypothesis Testing with Randomization",
    "section": "Calculate p-value",
    "text": "Calculate p-value\n\n\n\n\n\n\n\n\n\nWe observed 148 out of 1000 simulations where the difference in proportions under \\(H_{0}\\) was as or more extreme than our observed difference of 0.13\nSo p-value is 0.148"
  },
  {
    "objectID": "slides/slides-14-randomization.html#interpret-and-make-conclusion",
    "href": "slides/slides-14-randomization.html#interpret-and-make-conclusion",
    "title": "Hypothesis Testing with Randomization",
    "section": "Interpret and make conclusion",
    "text": "Interpret and make conclusion\nThe researchers are interested in learning if the blood thinner treatment was effective.\nOur p-value is 0.148 and our selected significance level was \\(\\alpha = 0.05\\).\n\n\nMake a decision and conclusion about the research question in context."
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null-code",
    "href": "slides/slides-14-randomization.html#simulate-under-null-code",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null (code)",
    "text": "Simulate under null (code)\nLive code"
  },
  {
    "objectID": "slides/slides-14-randomization.html#where-were-going-today",
    "href": "slides/slides-14-randomization.html#where-were-going-today",
    "title": "Hypothesis Testing with Randomization",
    "section": "Where we’re going today",
    "text": "Where we’re going today\n\nWe will see another kinds of hypotheses for different types of research questions\nHypothesis testing framework is the same, but will change how we obtain null distribution\nTry to see the big picture"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test",
    "href": "slides/slides-14-randomization.html#randomization-test",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test",
    "text": "Randomization test\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nWrite down “promote” on 35 cards and “not promote” on 13 cards. Repeat the following:\n\nThoroughly shuffle these 48 cards.\nDeal out a stack of 24 cards to represent males, and the remaining 24 cards to represent females\n\nThis is how we simulate independence under \\(H_{0}\\)\n\nCalculate the proportion of “promote” cards in each stack, \\(\\hat{p}_{m, sim}\\) and \\(\\hat{p}_{f, sim}\\)\nCalculate and record the difference \\(\\hat{p}_{f,sim} - \\hat{p}_{m,sim}\\) (order of difference doesn’t matter so long as you are consistent)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test-code",
    "href": "slides/slides-14-randomization.html#randomization-test-code",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test (code)",
    "text": "Randomization test (code)\nLet’s perform one iteration of the simulation.\n\n# reproducibility\nset.seed(1)\nn_female <- sum(discrimination$sex == \"female\")\nn_male <- sum(discrimination$sex == \"male\")\n\n# create cards\ncards <- discrimination$decision\n\n# shuffle cards\nshuffled <- sample(cards)\n\n\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    8 \n    16 \n    24 \n  \n  \n    male \n    5 \n    19 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nUnder this simulation, 0.6666667 of females were promoted, and 0.7916667 of males were promoted. Simulated difference: -0.125"
  },
  {
    "objectID": "slides/slides-14-randomization.html#null-distribution",
    "href": "slides/slides-14-randomization.html#null-distribution",
    "title": "Hypothesis Testing with Randomization",
    "section": "Null distribution",
    "text": "Null distribution\n\n\n\nRepeat the previous step 1000 times:"
  },
  {
    "objectID": "slides/slides-14-randomization.html#obtain-p-value",
    "href": "slides/slides-14-randomization.html#obtain-p-value",
    "title": "Hypothesis Testing with Randomization",
    "section": "Obtain p-value",
    "text": "Obtain p-value\nRecall, the observed difference in our data was \\(\\hat{p}_{f} - \\hat{p}_{m} =\\) -0.2916667.\n\np-value is probability of observing data as or more extreme than our original data, given \\(H_{0}\\) true.\n\nWhere does “as or more extreme” correspond to on our plot?\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut of 1000 simulations under \\(H_{0}\\), 29 resulted in a difference in promotion rates as or more extreme than our observed\nSo the p-value is 0.029"
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-conclusion",
    "href": "slides/slides-14-randomization.html#making-conclusion",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making conclusion",
    "text": "Making conclusion\nOur research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\\(H_{0}\\): sex and decision are independent\n\\(H_{A}\\): sex and decision are not independent and equally-qualified female personnel are less likely to get promoted than male personnel by male supervisors\n\\(\\alpha = 0.05\\)\n\n\n\nInterpret our p-value in context.\nMake a decision in response to the research question."
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-conclusion-answer",
    "href": "slides/slides-14-randomization.html#making-conclusion-answer",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making conclusion (answer)",
    "text": "Making conclusion (answer)\n\nAssuming that sex and decision are independent, the probability of observing a difference in promotion rates as or more extreme as we did is 0.029.\nBecause the observed p-value of 0.029 is less than our significant level 0.05, we reject \\(H_{0}\\). The data provide strong evidence of sex discrimination against female candidates by the male supervisors.\n\nWhat kind of error could we have made?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null-1",
    "href": "slides/slides-14-randomization.html#simulate-under-null-1",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nWe will once again perform a randomization test to try and simulate the difference in proportions under \\(H_{0}\\)\n\nUnder \\(H_{0}\\), treatment group is no better than control group, so let’s simulate assuming that outcome and treatment are independent\n\nWrite down died on 65 cards, and survived on 25 cards. Then repeat several times:\n\nShuffle cards well\nDeal out 50 to be Control group, and remaining 40 to be Treatment group\nCalculate proportions of survival \\(\\hat{p}_{C, sim}\\) and \\(\\hat{p}_{T, sim}\\)\nObtain and record the simulated difference \\(\\hat{p}_{T, sim} - \\hat{p}_{C, sim}\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test-activity",
    "href": "slides/slides-14-randomization.html#randomization-test-activity",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test (activity)",
    "text": "Randomization test (activity)\nTry it!"
  },
  {
    "objectID": "live_code/intro_testing.html",
    "href": "live_code/intro_testing.html",
    "title": "Null distribution of sample proportion",
    "section": "",
    "text": "library(tidyverse)\nDefine \\(p\\) as the true proportion of students who get at least 7 hours of sleep on average. Our hypotheses were:\n\\(H_{0}\\): \\(p \\leq 0.5\\)\n\\(H_{A}\\): \\(p > 0.5\\)"
  },
  {
    "objectID": "live_code/intro_testing.html#simulating-null-distribution",
    "href": "live_code/intro_testing.html#simulating-null-distribution",
    "title": "Null distribution of sample proportion",
    "section": "Simulating null distribution",
    "text": "Simulating null distribution\nThe example below demonstrates how to obtain a null distribution for \\(\\hat{p}\\) under \\(H_{0}\\). We said:\n\npink slips represent students who get at least 7 hours, and\npurple slips represent students who do not get at least 7 hours\n\n\nset.seed(2)\nB <- 5000\nn <- 10\np_null_vec <- rep(NA, B)\nfor(b in 1:B){\n  null_samp <- sample(x = c(\"pink\", \"purple\"),\n                      size = n, \n                      replace = T, \n                      prob = c(0.5, 0.5)) \n  \n  p_null_vec[b] <- sum(null_samp == \"pink\")/n\n}\n\nThe code above repeatedly for 5000 iterations draws a new sample of size 10 from the world assuming \\(H_{0}\\) is true (in this case, \\(p = 0.5\\)). At every iteration, we record the proportion of pink slips in the sample of size 10 to represent the proportion of people who got at least 7 hours of sleep."
  },
  {
    "objectID": "live_code/intro_testing.html#visualizing-null-distribution",
    "href": "live_code/intro_testing.html#visualizing-null-distribution",
    "title": "Null distribution of sample proportion",
    "section": "Visualizing null distribution",
    "text": "Visualizing null distribution\nWe can visualize the null distribution by:\n\nCreating a data frame of our vector of simulated null statistics p_null_vec\nPiping into ggplot()\n\n\n\ndata.frame(<variable name> = <vector>)creates a data frame from vectors, and we can set the column/variable names.\nIn the code here, data.frame(p_sim = p_null_vec) creates a data frame with a variable called p_sim. The values that comprise that variable come from p_null_vec.\n\nnull_df <- data.frame(p_sim = p_null_vec)\nggplot(null_df, aes(x = p_sim))+\n  geom_histogram(binwidth = 0.1,col = \"white\")+\n  labs(x = \"Null dist. of proportion of students getting at least 7 hours\") +\n  theme_minimal()\n\n\n\n\nWe can add a vertical line to our plot to show where the observed \\(\\hat{p}\\) falls in the null distribution."
  },
  {
    "objectID": "practice_probs/practice-13-intro_testing.html",
    "href": "practice_probs/practice-13-intro_testing.html",
    "title": "Hypothesis testing",
    "section": "",
    "text": "For each of the research statements below, determine whether it represents a null hypothesis claim or an alternative hypothesis claim.\n\nThe number of hours that grade-school children spend doing homework predicts their future success on standardized tests.\nKing cheetahs on average run the same speed as standard spotted cheetahs.\nFor a particular student, the probability of correctly answer a 5-option multiple choice test is larger than 0.2 (i.e. better than guessing)\nThe probability of getting in a car accident is the same if using a cell phone then if not using a cell phone.\n\nWrite out the null and alternative hypotheses in words and also in statistical notation for each of the following situations. When writing in statistical notation, be sure to define quantities in context.\n\nNew York is known as “the city that never sleeps”. A random sample of 25 New Yorkers were asked how much they sleep they get per night. Does these data providing convincing evidence that New Yorkers on average sleep less than 8 hours per night?\nA study suggests that 25% of 25 year-olds have gotten married. You believe that this is incorrect and decide to collect your own data to conduct a hypothesis test.\n\nA Survey USA poll conducted in Seattle, WA in May 2021 reports that of the 650 respondents (adults living in this area), 159 support proposals to defund police departments.\n\nA journals writing a news story on the poll results wants to use the headline: “More than 1 in 5 adults living in Seattle support proposals to defund police departments”. You caution the journalist that they should first conduct a hypothesis test to see if the poll data provide convincing evidence for this claim. Write the hypotheses for this test using proper notation, defining any necessary quantities.\nDescribe in words a simulation scheme that would be appropriate for this situation. Also describe how the p-value can be calculated using the simulation results.\nThe histogram below shows the distribution of 1000 simulated proportions under \\(H_{0}\\). Estimate the p-value using the plot and use it to evaluate your hypotheses (i.e. make a conclusion). Assume a significance level of 0.05.\n\n\n\\((^*)\\) In a large university where 60% of the full-time students are employed at least 5 hours per week, the members of the Statistics Department faculty wonder if the same proportion of their students work at least 5 hours per week. They randomly sample 25 of their majors and find that 12 of the students work 5 or more hours per week.\nTwo sampling distributions were created to describe the variability in the proportion of statistics majors who work at least 5 hours per week: a null distribution and a bootstrap distribution. In both cases, \\(B=1000\\) simulations were generated.\n\n\nWhich distribution(s) was/were obtained by sampling with replacement, and which distribution(s) was/were obtained by sampling without replacement?\nEstimate the standard error of the simulated proportions based on each distribution. Are the two standard errors you estimated roughly equal?\nUsing the appropriate histogram, test the claim that 70% of statistics majors, like their peers, work at least 5 hours per week. State the hypotheses, find the p-value, and conclude in the context of the problem. Use a significance level of 0.10.\nUsing the appropriate histogram, find a 90% bootstrap confidence interval for the true proportions of statistics majors who work at least 5 hours per week. Interpret the confidence interval in the context of the problem.\nBriefly comment on how your conclusions in (c) and (d) compare.\n\nA study conducted in 2020 found that the U.S. adjusted divorce rate was 14 per 100 married women. Joe is suspicious and disagrees with the stated divorce rate. Joe somehow collected data from 323 married or previously-married women, and asked them if they had a divorce in 2020. 55 of the women responded that they indeed had a divorce in 2020.\n\nWrite out the hypotheses corresponding to this scenario.\nDescribe in words a simulation scheme that would be appropriate for this situation. Also describe how the p-value can be calculated using the simulation results.\nThe histogram below shows the distribution of 1000 simulated proportions under \\(H_{0}\\). Estimate the p-value using the plot and use it to evaluate Joe’s hypotheses (i.e. make a conclusion). Assume a significance level of 0.05.\n\nJoe has some free time and also created a 90% bootstrap confidence interval for the divorce rate.\n\n\n\nHe obtained the following interval: (0.133, 0.204). Interpret this interval in context.\nBased on this interval, would it be appropriate for Joe to conclude that the study’s reported rate was wrong? Explain your reasoning.\nHow do your conclusions from (c) and (e) compare?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-decision-and-conclusion",
    "href": "slides/slides-14-randomization.html#making-decision-and-conclusion",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making decision and conclusion",
    "text": "Making decision and conclusion\nOur research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\\(H_{0}\\): sex and decision are independent\n\\(H_{A}\\): sex and decision are not independent and equally-qualified female personnel are less likely to get promoted than male personnel by male supervisors\n\\(\\alpha = 0.05\\)\n\n\n\nInterpret our p-value in context.\nMake a decision and conclusion in response to the research question."
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-decision-and-conclusion-answer",
    "href": "slides/slides-14-randomization.html#making-decision-and-conclusion-answer",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making decision and conclusion (answer)",
    "text": "Making decision and conclusion (answer)\n\nAssuming that sex and decision are independent, the probability of observing a difference in promotion rates as or more extreme as we did is 0.029.\nBecause the observed p-value of 0.029 is less than our significant level 0.05, we reject \\(H_{0}\\). The data provide strong evidence of sex discrimination against female candidates by the male supervisors.\n\nWhat kind of error could we have made?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#comprehension-questions",
    "href": "slides/slides-14-randomization.html#comprehension-questions",
    "title": "Hypothesis Testing with Randomization",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat were the similarities and differences between:\n\nhypothesis test for independence\nhypothesis test for two proportions\n\nHow do the randomization tests today differ from the test for one proportion that we learned last class?"
  },
  {
    "objectID": "live_code/randomization_two_props.html",
    "href": "live_code/randomization_two_props.html",
    "title": "Randomization for difference in proportions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\nWe are using the cpr data from the openintro library. Define \\(p_{T}\\) as the proportion of treatment group who survived, \\(p_{C}\\) as the proportion of control group who survived. Our hypotheses were:\n\\(H_{0}\\): \\(p_{T} - p_{C} \\leq 0\\) versus \\(H_{A}\\): \\(p_{T} - p_{C} > 0\\)"
  },
  {
    "objectID": "live_code/randomization_two_props.html#simulating-null-distribution",
    "href": "live_code/randomization_two_props.html#simulating-null-distribution",
    "title": "Randomization for difference in proportions",
    "section": "Simulating null distribution",
    "text": "Simulating null distribution\nWe will store some values as objects in R for reproducibility.\n\n# get the observed outcomes as a vector\noutcomes <- cpr$outcome\n\n# store number of treatment and control observations from original sample\nn_t <- sum(cpr$group == \"treatment\")\nn_t\n\n[1] 40\n\nn_c <- sum(cpr$group == \"control\")\nn_c\n\n[1] 50\n\n# get observed difference in proportions\n\n# option 1\nobs_diff <- cpr |>\n  group_by(group) |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull(p) |>\n  diff() # defaults to taking second value minus first\n\n# option 2\ncond_probs <- cpr |>\n  group_by(group) |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull(p)\nobs_dff <- cond_probs[2] - cond_probs[1]\nobs_diff\n\n[1] 0.13\n\n\nNow we will perform the randomization test!\n\n\nIf you only pass in a vector as the argument to sample() without specifying the size of the sample, you will get a shuffled version of the vector back as output. That is, the function will resample without replacement from the vector, with the size being the same size as the vector.\n\nset.seed(310)\nB <- 1000\ndiff_sims <- rep(NA , B)\nfor(b in 1:B){\n  # shuffle the outcomes. See comment for more details.\n  shuffled <- sample(outcomes)\n  \n  # deal out first n_t cards to treatment group\n  treat_sim <- shuffled[1:n_t]\n  \n  # deal out remaining n_c cards to control group\n  control_sim <- shuffled[-c(1:n_t)]\n  \n  # calculate proportion of survival in each group\n  p_t_sim <- sum(treat_sim == \"survived\")/n_t\n  p_c_sim <- sum(control_sim == \"survived\")/n_c\n  \n  # calculate difference and store. \n  # I will do treatment - control because it mirrors how obs_diff is calculated\n  diff_sims[b] <- p_t_sim - p_c_sim\n}"
  },
  {
    "objectID": "slides/slides-14-randomization.html",
    "href": "slides/slides-14-randomization.html",
    "title": "Hypothesis Testing with Randomization",
    "section": "",
    "text": "Office hours change this week"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#housekeeping",
    "href": "slides/slides-15-single-mean.html#housekeeping",
    "title": "Hypothesis testing for a mean",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours tomorrow: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#recap",
    "href": "slides/slides-15-single-mean.html#recap",
    "title": "Hypothesis testing for a mean",
    "section": "Recap",
    "text": "Recap\n\nWe have seen how to perform hypothesis tests for questions involving the following:\n\nA single proportion (STAT 201 sleep)\nIndependence of two categorical variables (banker sex discrimination)\n\nThink of as one population\n\nDifference in two proportions (blood thinner)\n\nThink of as two populations\n\n\nWe are now going to see another hypothesis test, this time for numerical data"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#running-example-form-hypotheses",
    "href": "slides/slides-15-single-mean.html#running-example-form-hypotheses",
    "title": "Hypothesis testing for a mean",
    "section": "Running example + form hypotheses",
    "text": "Running example + form hypotheses\nWe will use the duke_forest dataset provided in openintro. It provides data on some houses that were sold in the Duke Forest neighborhood of Durham, NC in November 2020.\n\nBefore we look at the data, we should form our hypotheses. Suppose I am interested in learning if the average price of houses in Duke Forest is $500,000 or not.\n\nWhat might our hypotheses be?\n\n\n\\(H_{0}\\): \\(\\mu = 50\\) versus \\(H_{A}\\): \\(\\mu \\neq 50\\), where \\(\\mu\\) is the average house of prices in Duke Forest in $10,000\nTerminology: I will refer to \\(\\mu_{0} = 50\\) as my “null hypothesized value”. (i.e. the specific value of \\(\\mu\\) in \\(H_{0}\\))"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#collect-data",
    "href": "slides/slides-15-single-mean.html#collect-data",
    "title": "Hypothesis testing for a mean",
    "section": "Collect data",
    "text": "Collect data\n\n\n\n\n\n\n\n\nThe observed/sample mean housing price is $55.99k from a sample of 98 houses.\n\nNow we must determine if we have “convincing evidence”! Choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#simulating-null-distribution",
    "href": "slides/slides-15-single-mean.html#simulating-null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Simulating null distribution",
    "text": "Simulating null distribution\nTo simulate from the null distribution, we need to operate in a world where \\(H_{0}\\) is true\n\nSo, I need to repeatedly simulate data sets of size 98 where the true mean is \\(50\\), without change anything else about the data sets.\nIf I don’t want to make any assumptions about how the data behave, how might I do that?"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#bootstrap-to-the-rescue",
    "href": "slides/slides-15-single-mean.html#bootstrap-to-the-rescue",
    "title": "Hypothesis testing for a mean",
    "section": "Bootstrap to the rescue",
    "text": "Bootstrap to the rescue\n\nRecall the bootstrap: we repeatedly took resamples with replacement from our original data, of same size as original data\n\nAssuming the original data was representative, each one of these bootstrapped data sets gives us a plausible “new” sample of data, from which we can calculate statistics of interest\n\n\n\n\n\n\n\n\n\n\n\n\n\nReminder ourselves: Where is the bootstrap distribution centered?"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#bootstrap-to-null-distribution",
    "href": "slides/slides-15-single-mean.html#bootstrap-to-null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Bootstrap to null distribution",
    "text": "Bootstrap to null distribution\n\n\n\n\n\n\n\n\n\nThis is not the null distribution! The null distribution should be centered at \\(\\mu_{0} = 50\\).\nHowever, the null distribution should have the same variability in \\(\\bar{x}\\) as the bootstrap distribution.\n\n\n\n\nSo to get the null distribution, why not just shift the bootstrap distribution to be centered where we want it to be?"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#shifting-to-the-bootstrap-distribution",
    "href": "slides/slides-15-single-mean.html#shifting-to-the-bootstrap-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Shifting to the bootstrap distribution",
    "text": "Shifting to the bootstrap distribution\n\nIn this example, bootstrap distribution is centered at \\(\\bar{x} = 55.99\\)\nIn order to center this distribution at \\(\\mu_{0} = 50\\), just subtract \\(55.99 - 50 = 5.99\\) from every single bootstrapped mean\n\nThis will give us a simulated distribution for \\(\\bar{x}\\) centered at \\(\\mu_{0} = 50\\), which is exactly the null distribution!\n\nWe call this “shifting the bootstrap distribution”, because we simply shift where the bootstrap distribution is centered\n\n\n\n\n\nmu0 <- 50\n# how much to shift by, where xbar is sample mean housing prices\nshift <- xbar - mu0\n# shift my vector of bootstrapped sample means\nnull_dist <- boot_means - shift"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#null-distribution",
    "href": "slides/slides-15-single-mean.html#null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Null distribution",
    "text": "Null distribution\n\n\n\n\n\n\n\nNotice where the distributions are centered"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#obtain-the-p-value",
    "href": "slides/slides-15-single-mean.html#obtain-the-p-value",
    "title": "Hypothesis testing for a mean",
    "section": "Obtain the p-value",
    "text": "Obtain the p-value\n\\(H_{0}\\): \\(\\mu = 50\\) versus \\(H_{A}\\): \\(\\mu \\neq 50\\)\nOur observed sample mean housing price is 55.99.\n\n\n\n\n\n\nWhat does it mean to be “as or more extreme” now?"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#two-sided-alternative-hypothesis",
    "href": "slides/slides-15-single-mean.html#two-sided-alternative-hypothesis",
    "title": "Hypothesis testing for a mean",
    "section": "Two-sided alternative hypothesis",
    "text": "Two-sided alternative hypothesis\n\nThis is the first time we’ve seen a two-sided hypothesis\nSince the alternative is “double sided”, we can be extreme in both the positive and negative direction!"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#obtain-the-p-value-cont.",
    "href": "slides/slides-15-single-mean.html#obtain-the-p-value-cont.",
    "title": "Hypothesis testing for a mean",
    "section": "Obtain the p-value (cont.)",
    "text": "Obtain the p-value (cont.)\nLet \\(shift\\) represent the amount we shifted the distribution by:\n\\[shift = 55.99 - 50 = 5.99\\]\nSimulated means as or more extreme than \\(\\mu_{0} + shift\\) or \\(\\mu_{0} - shift\\) will contribute:\n\n\n\n\n\n\n\n\n\nsum( (null_dist >= mu0 + shift) | (null_dist <= mu0 - shift))/B\n\n[1] 0.0098"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#make-decision-and-conclusion",
    "href": "slides/slides-15-single-mean.html#make-decision-and-conclusion",
    "title": "Hypothesis testing for a mean",
    "section": "Make decision and conclusion",
    "text": "Make decision and conclusion\n\nMake a decision and conclusion in the context of the research question.\n\n\nSince our p-value of 0.0098 is less than the significance level of 0.05, we reject \\(H_{0}\\). We have convincing evidence to suggest that the true average housing price of homes in Duke Forest in 2020 was not $500k."
  },
  {
    "objectID": "slides/slides-15-single-mean.html",
    "href": "slides/slides-15-single-mean.html",
    "title": "Hypothesis testing for a mean",
    "section": "",
    "text": "Office hours tomorrow: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-15-single-mean.html#comprehension-questions",
    "href": "slides/slides-15-single-mean.html#comprehension-questions",
    "title": "Hypothesis testing for a mean",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhy did we shift the bootstrap distribution?\nHow do we estimate the p-value in the case of a two-sided alternative hypothesis?"
  },
  {
    "objectID": "live_code/randomization_two_props.html#obtain-p-value",
    "href": "live_code/randomization_two_props.html#obtain-p-value",
    "title": "Randomization for difference in proportions",
    "section": "Obtain p-value",
    "text": "Obtain p-value\nWe need to find how many simulated null differences in proportions were greater than or equal to our observed difference of obs_diff = 0.13.\n\np_val <- sum(diff_sims >= obs_diff) / B\np_val\n\n[1] 0.148"
  },
  {
    "objectID": "homework/hw5_r.html",
    "href": "homework/hw5_r.html",
    "title": "STAT 201: Problem Set 5 (R)",
    "section": "",
    "text": "In every code chunk where you perform random sampling, set a seed at the top of the chunk. I don’t care what seed you choose so long as you set a seed!\nMake your code as reproducible as possible. You should avoid “hard-coding” values. Instead, store values as variables for future use.\nNote: you will practice typing in mathematical notation in the narrative using Latex. To write the greek letter mu, type in \\(\\mu\\) in the narrative. You can add subscropts like this: \\(\\mu_{H}\\). To write a “does not equal” sign, type \\(\\neq\\) into the narrative.\nThe dataset is adapted from Little et al. (2007), and contains voice measurements from individuals both with and without Parkinson’s Disease (PD), a progressive neurological disorder that affects the motor system. The aim of Little et al.’s study was to examine whether they could diagnose PD by examining the spectral (sound-wave) properties of patients’ voices.\n147 measurements were taken from patients with PD, and 48 measurements were taken from healthy controls. For the purposes of this lab, you may assume that measurements are representative of the underlying populations (PD vs. healthy).\nThe variables in the dataset are as follows:\nThe data are stored in a variable called parksinsons. Run the following code chunk and take a look at the data before getting started."
  },
  {
    "objectID": "homework/hw5_r.html#part-1",
    "href": "homework/hw5_r.html#part-1",
    "title": "STAT 201: Problem Set 5 (R)",
    "section": "Part 1",
    "text": "Part 1\nResearchers suspect that patients with PD are less able to control their vocal muscles, and thus may have a greater voice jitter compared to healthy volunteers. Thus, they are interested in whether the mean jitter in voice recordings among patients with PD is greater than the mean jitter in voice recordings among healthy patients. The researchers select the 0.01 significance level.\n\nWrite out the null hypothesis and alternative hypotheses for the question in symbols, defining quantities when necessary.\n\nAnswer:\n\\(H_{0}\\):\n\\(H_{1}\\):\n\nDescribe in words how you would obtain 5000 simulations from the null distribution using a randomization test. (Hint: this should be very similar to the sex discrimination or the CPR example.) Then, describe how you would estimate the p-value using this null distribution. Be as specific as possible!\n\nAnswer:\n\nIt will be helpful to define some variables here. To make your life easier, create objects/variables to represent the following quantities:\n\nThe number of healthy patients\nThe number of PD patients\nThe vector of voice jitters\n\n\n\n\n\n\nSimulate the null distribution according to your description above. Store the results into a vector called null_dist_pt1.\n\n\n# set a seed using the set.seed() function\n\n\nWhat is your p-value, decision, and conclusion in context of the research question? Use in-line code for reproducibility.\n\n\n\n\nAnswer:\n\nWhat is the probability you’ve made a Type 1 error? If you cannot tell for sure, explain why. Similarly, what is the probability you’ve made a Type 2 error? If you cannot tell for sure, explain why.\n\nAnswer:"
  },
  {
    "objectID": "homework/hw5_r.html#part-2",
    "href": "homework/hw5_r.html#part-2",
    "title": "STAT 201: Problem Set 5 (R)",
    "section": "Part 2",
    "text": "Part 2\nWe will now answer the following question: is there enough evidence to suggest that the mean HNR in the voice recordings of the PD patients is significantly different from 21.5 at the \\(\\alpha=\\) 0.10 significance level?\n\nWrite out the null and alternative hypotheses for this question using symbols, defining any quantities as necessary.\n\nAnswer:\n\nDescribe in words how you would obtain 5000 simulations from the null distribution. Then, describe how you would estimate the p-value using this null distribution. Be as specific as possible!\n\nAnswer:\n\nTo make your life easier, create the following objects/variables.\n\n\nhnr_pd: a vector of HNR for the PD patients only (you may want to use some combination of filter() and pull() to obtain this)\nn_pd: the number of PD patients\nxbar_pd: the observed/sample mean HNR of PD patients\nmu_h0: the null hypothesized value for the population parameter\n\n\n\n\n\nSimulate the null distribution according to your description above. Store the results into a vector called null_dist_pt2.\n\n\n\n\n\nVisualize your null distribution. Make sure your visualization has informative axis labels and/or title.\n\n\n\n\n\nEstimate the p-value. Then answer the following: what is your p-value, decision, and conclusion in the context of the research question? Use in-line code for reproducibility!\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "live_code/randomization_two_props.html#visualize-null-distribution",
    "href": "live_code/randomization_two_props.html#visualize-null-distribution",
    "title": "Randomization for difference in proportions",
    "section": "Visualize null distribution",
    "text": "Visualize null distribution"
  },
  {
    "objectID": "practice_probs/practice-15-ht-basics.html",
    "href": "practice_probs/practice-15-ht-basics.html",
    "title": "Misc. hypothesis testing practice",
    "section": "",
    "text": "For each of the statements (a) - (d), indicate if they are true or false interpretation of the following confidence interval. If false, provide or a reason or correction to the misinterpretation.\n“You collect a large sample and calculate a 95% confidence interval for the average number of cans of soda consumed annually per adult to be (440, 520), i.e. on average, adults in the US consume just under two cans of soda per day”.\n\n95% of adults in the US consume between 440 and 520 cans of soda per year.\nThere is a 95% chance that the true population average per adult yearly soda consumption is between 440 and 520 cans.\nThe true population average per adult soda consumption is between 440 and 520 cans, with 95% confidence.\nThe average soda consumption of the people who were is sampled is between 440 and 520 cans of soda per year, with 95% confidence.\n\nA food safety inspector is called upon to investigate a restaurant with a few customer reports of poor sanitation practices. The food safety inspector uses a hypothesis testing framework to evaluate whether regulations are not being met. If the inspector determines the restaurant is in gross violation, its license to serve food will be revoked.\n\nWrite the hypotheses in words (no population parameters necessary).\nWhat is a Type I error in this context?\nWhat is a Type II error in this context?\nWhich error is more problematic for the restaurant owner? For the diners? Why?\nDo you think the diners would prefer a higher or lower significance level \\(\\alpha\\) compared to what the restaurant owner prefers? Explain.\n\nConsider the following simple random sample \\(x = (47, 4, 92, 47, 12, 8)\\).\nWhich of the following sets of values could be a possible bootstrap sample from the observe data above? If a set of values could not be a bootstrap sample, determine why not.\n\n\\((47, 47, 47, 47, 47, 47)\\)\n\\((92, 4, 13,8, 47, 4)\\)\n\\((4, 8, 12, 12, 47)\\)\n\\((12, 4, 8, 8, 92, 12)\\)\n\\((8, 47, 12, 12, 8, 4, 92)\\)\n\nFor each of the following statements (a)-(e), indicate if they are a true or false interpretation of the p-value. If false, provide a reason or correction to the misinterpretation.\n“You are wondering if the average amount of cereal in a 10 oz. cereal box is greater than 10 oz. You collect 50 boxes of cereal marketed as 10 oz, conduct simulation-based hypothesis test, and obtain a p-value of 0.23.”\n\nThe probability that the average weight of all cereal boxes is 10 oz. is 0.23.\nThe probability that the average weight of all cereal boxes is something greater than 10 oz. is 0.23.\nBecause the p-value is 0.23, the average weight of all cereal boxes is 10 oz.\nBecause the p-value is small, the population average must be just barely about 10 oz.\nIf \\(H_{0}\\) is true, the probability of observing another sample with an average as or more extreme as the data is 0.23."
  },
  {
    "objectID": "slides/worksheet-16-normal.html",
    "href": "slides/worksheet-16-normal.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\nknitr::opts_chunk$set(echo = F) \n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "practice_probs/practice-16-normal.html",
    "href": "practice_probs/practice-16-normal.html",
    "title": "Normal distribution",
    "section": "",
    "text": "True or false? Briefly explain why.\nAmong applicants to one law school, the average LSAT was about 169, the standard deviation about 9, and the highest score was 178. The distribution of the LSAT scores follows the normal curve.\nIn a law school class, the entering students averaged 160 on the LSAT. The variance was 64. The histogram of LSAT scores followed the normal curve reasonable well.\n\nAbout what percentage of the class scores below 152?\nOne student was 0.5 standard deviations above average on the LSAT. About what percentage of the students had lower scores than he did?\n\n\n\n\nWeights of 10-year-old girls are known to be Normally distributed with mean of 70 pounds and standard deviation of 13 pounds. Find the probability that a 10-year-old girl weighs between 60 and 85 pounds two ways:\n\nOptional, but helpful: draw a sketch of the curve and shade in the region of interest.\nWrite the probability of interest in \\(P()\\) form. Then write the R code necessary to find this probability, and actually execute the code to obtain the probability.\nConfirm your solution in (b) by transforming to z-scores first, then using code again to obtain the probability.\n\nConsider the same scenario as in 3. Without using any code than what is provided below, find the 60th percentile for the weight of 10-year-old girls.\n\nqnorm(0.6, mean = 0, sd = 1)\n\n[1] 0.2533471\n\n\nThe length of human pregnancies from contraception to birth varies according to a distribution that is approximately normal with mean 266 days and standard deviation 16 days. Without using code, obtain the following:\n\nBetween what values do the lengths of the middle 95% of all pregnancies fall?\nHow short are the shortest 2.5% of all pregnancies? How long do the longest 2.5% last?"
  },
  {
    "objectID": "slides/slides-17-clt.html#housekeeping",
    "href": "slides/slides-17-clt.html#housekeeping",
    "title": "Central Limit Theorem",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours tomorrow: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-17-clt.html#recap",
    "href": "slides/slides-17-clt.html#recap",
    "title": "Central Limit Theorem",
    "section": "Recap",
    "text": "Recap\n\n\n\n\nNormal distribution: symmetric, bell-shaped curve that is described by mean \\(\\mu\\) and standard deviation \\(\\sigma\\)\n\nCommon model used to describe behavior of continuous variables\n\nUse area under the Normal curve to obtain probabilities\n68-95-99.7 rule\nz-score standardizes observations to allow for easier comparison: \\(z = \\frac{x- \\mu}{\\sigma}\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#where-were-going",
    "href": "slides/slides-17-clt.html#where-were-going",
    "title": "Central Limit Theorem",
    "section": "Where we’re going",
    "text": "Where we’re going\n\nWe are going to learn one of the BIGGEST theorems in Statistics\nUses the Normal distribution, and will be immensely helpful for inference tasks of confidence intervals and hypothesis testing"
  },
  {
    "objectID": "slides/slides-17-clt.html#central-limit-theorem-clt",
    "href": "slides/slides-17-clt.html#central-limit-theorem-clt",
    "title": "Central Limit Theorem",
    "section": "Central Limit Theorem (CLT)",
    "text": "Central Limit Theorem (CLT)\n\nAssume that you have a sufficiently large sample of \\(n\\) independent values \\(x_{1},\\ldots, x_{n}\\) from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nThen the distribution of sample means is approximately Normal:\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\n\nThat is, the sampling distribution of the sample mean is approximately normal with mean \\(\\mu\\) and standard error \\(\\sigma/\\sqrt{n}\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#activity",
    "href": "slides/slides-17-clt.html#activity",
    "title": "Central Limit Theorem",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "slides/slides-17-clt.html#examples",
    "href": "slides/slides-17-clt.html#examples",
    "title": "Central Limit Theorem",
    "section": "Examples",
    "text": "Examples"
  },
  {
    "objectID": "slides/slides-17-clt.html#proportion",
    "href": "slides/slides-17-clt.html#proportion",
    "title": "Central Limit Theorem",
    "section": "Proportion",
    "text": "Proportion\n\nRemember that a proportion is a mean:\n\\[\n\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}, \\qquad x_{i} =\\{0, 1\\}\n\\]\n\nTypically, \\(x_{i} = 1\\) is read as “success” and \\(x_{i} = 0\\) as “failure”, so \\(p\\) is probability or proportion of success\n\nSo the CLT applies to sampling distribution of sample proportions as well!\nCLT for sample proportions: if we have \\(n\\) independent binary observations with \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\), then:\n\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\nWhat do the conditions \\(np \\geq 10\\) and \\(n(1-p)\\geq 10\\) mean?\n\n```"
  },
  {
    "objectID": "slides/slides-17-clt.html#example",
    "href": "slides/slides-17-clt.html#example",
    "title": "Central Limit Theorem",
    "section": "Example",
    "text": "Example\nA poll of 100 randomly sampled registered voters in a town was conducted, asking voters if they support legalized marijuana. It was found that 60% of respondents were in support.\n\nWhat is the population parameter? What is the point estimate/statistic?\n\n\nFind a (symmetric) 90% confidence interval for the true proportion of town residents in favor of legalized marijuana.\n\n\n\nConditions for CLT met?\n\n\nIndependence: random sample\nSuccess-failure condition: \\(n\\hat{p} =100(0.6) = 60 \\geq 10\\) and \\(n(1-\\hat{p}) = 100(0.4) = 40 \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#height-example",
    "href": "slides/slides-17-clt.html#height-example",
    "title": "Central Limit Theorem",
    "section": "Height example",
    "text": "Height example\n\n\n\nThe average height of all NBA players in the 2008-9 season is 79.21 inches, with a standard deviation of 3.57 inches. We randomly sample \\(20\\) of these players and record their heights.\n\n\n\nWhat is the sampling distribution of the sample mean heights?"
  },
  {
    "objectID": "slides/slides-17-clt.html#height-example-solution",
    "href": "slides/slides-17-clt.html#height-example-solution",
    "title": "Central Limit Theorem",
    "section": "Height example: solution",
    "text": "Height example: solution\n\nWe have independent samples, but not a large sample size. However, the histogram of the data looks approximately Normal (no clear outliers).\nCLT applies! By CLT: \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(79.21, \\frac{3.57}{\\sqrt{20}}\\right)\\)\nIf the data instead looked like the following, I would say normality condition is violated:"
  },
  {
    "objectID": "slides/slides-17-clt.html#bank-example",
    "href": "slides/slides-17-clt.html#bank-example",
    "title": "Central Limit Theorem",
    "section": "Bank example",
    "text": "Bank example\nCustomers are standing in line at a bank. The service time for each customer \\(i\\) is represented by \\(X_{i}\\). Suppose that the average service time for all customers is 5 minutes, with a standard deviation of 6 minutes.\n\nAssume that a bank currently has 36 customers in it, and all customers are independent of each other. What is the probability that the average service time of all these customers is less than 4 minutes?"
  },
  {
    "objectID": "slides/slides-17-clt.html#bank-example-solution",
    "href": "slides/slides-17-clt.html#bank-example-solution",
    "title": "Central Limit Theorem",
    "section": "Bank example: solution",
    "text": "Bank example: solution\n\nWe want \\(\\text{Pr}(\\bar{X} < 4)\\)\nConditions for CLT met: independence (random sample) and sufficiently large sample size \\((n=36)\\).\n\nSo by CLT, \\(\\bar{X} \\overset{\\cdot}{\\sim}N(5, \\frac{6}{\\sqrt{36}}) = N(5, 1)\\)\n\nUsing 68-95-99.7 rule, probability that the average service time of all these customers is less than 4 minutes is about \\(1 - (0.34 + 0.5) = 0.16\\)\n\npnorm(4, 5, 1) = 0.159"
  },
  {
    "objectID": "slides/slides-17-clt.html#mms-example",
    "href": "slides/slides-17-clt.html#mms-example",
    "title": "Central Limit Theorem",
    "section": "M&M’s example",
    "text": "M&M’s example\nMars, Inc. is the company that makes M&M’s. In 2008, Mars changed their color distribution to have 13% red candies.\n\n\nLet \\(p\\) be the proportion of red M&M’s in a random sample of \\(n\\) M&M’s. What is the distribution of \\(\\hat{p}\\) if we take random sample of size:\n\n\\(n = 100\\)\n\\(n = 10\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#why-is-clt-so-important",
    "href": "slides/slides-17-clt.html#why-is-clt-so-important",
    "title": "Central Limit Theorem",
    "section": "Why is CLT so important?",
    "text": "Why is CLT so important?\n\nAllows statisticians safely assume that the mean’s sampling distribution is approximately Normal. The Normal distribution has nice properties and is easy to work with.\nCan be applied to both continuous and discrete numeric data!\nDoes not depend on the underlying distribution of the data.\n\n\nFor many of these reasons, we can use the CLT for inference!"
  },
  {
    "objectID": "slides/slides-17-clt.html#clt-assumptions",
    "href": "slides/slides-17-clt.html#clt-assumptions",
    "title": "Central Limit Theorem",
    "section": "CLT assumptions",
    "text": "CLT assumptions\n\nRemark #1: does not require any assumption about how the data \\(x_{1},\\ldots, x_{n}\\) behave so long as the following assumptions hold:\n\nIndependent samples: usually achieved by random sampling\nSufficiently large sample size \\(n\\), where large is in relation to total size of population\n\nRemark #2: if the data \\(x_{1},\\ldots, x_{n}\\) are known to be Normal and independent, then the distribution of sample means is exactly Normal, even for small \\(n\\)\n\nFor this reason, if \\(n\\) is small we require the data to be Normal\nHow to know? We replace (2) above with the normality condition:\n\nIf \\(n\\) is small \\((n < 30)\\): we assume data are approximately normal if there are no clear outliers\nIf \\(n\\) is larger \\((30 \\leq n < ?)\\): we assume data are approximately normal if there are no particularly extreme outliers"
  },
  {
    "objectID": "slides/slides-17-clt.html#clt-for-proportions",
    "href": "slides/slides-17-clt.html#clt-for-proportions",
    "title": "Central Limit Theorem",
    "section": "CLT for proportions",
    "text": "CLT for proportions\nCLT for sample proportions: if we have \\(n\\) independent binary observations with \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\), then:\n\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\n\nWhat do the conditions \\(np \\geq 10\\) and \\(n(1-p)\\geq 10\\) mean?\n\nFor this reason, this is called the “success-failure” condition for CLT for proportions"
  },
  {
    "objectID": "slides/slides-17-clt.html#mms-example-solution",
    "href": "slides/slides-17-clt.html#mms-example-solution",
    "title": "Central Limit Theorem",
    "section": "M&M’s example: solution",
    "text": "M&M’s example: solution\nWe have independence due to the random sample. Need to check success-failure condition:\n\n\n\nIf \\(n= 100\\):\n\n\\(np = 100(0.13) = 13 \\geq 10\\)\n\\(n(1-p) = 100(0.87) = 87 \\geq 10\\)\n\nSo CLT applies:\n\n\n\\[\n\\begin{align*}\n\\hat{p} &\\overset{\\cdot}{\\sim} N\\left(0.13, \\sqrt{\\frac{0.13(1-0.13)}{100}}\\right) \\\\\n&= N(0.13, 0.034 )\n\\end{align*}\n\\]\n\n\n\nIf \\(n = 10\\):\n\n\\(np = 10(0.13) = 1.3 < 10\\)\n\nSuccess-failure condition not met. Cannot use CLT."
  },
  {
    "objectID": "slides/slides-17-clt.html#mms-example-cont.",
    "href": "slides/slides-17-clt.html#mms-example-cont.",
    "title": "Central Limit Theorem",
    "section": "M&M’s example (cont.)",
    "text": "M&M’s example (cont.)\nThe following histograms display sampling distributions for \\(\\hat{p}\\) = proportion of red candies in random samples of size \\(n = \\{10, 50, 100, 200\\}\\):"
  },
  {
    "objectID": "slides/slides-17-clt.html#mathematical-cis",
    "href": "slides/slides-17-clt.html#mathematical-cis",
    "title": "Central Limit Theorem",
    "section": "Mathematical CIs",
    "text": "Mathematical CIs\n\nRather than using simulation techniques (i.e. bootstrap) to obtain the sampling distribution, the CLT gives us the sampling distribution of a mean “for free”\n\n(assuming conditions are met)\n\nFormula for a (symmetric) \\(\\gamma \\times 100\\%\\) confidence interval:\n\\[\n\\text{point estimate} \\pm \\underbrace{\\text{critical value} \\times \\text{SE}}_{\\text{Margin of Error}}\n\\]\n\npoint estimate: the “best guess” statistic from our observed data (e.g. \\(\\hat{p}\\) and \\(\\bar{x}\\))\nSE: standard error of the statistic\ncritical value: percentile that guarantees the \\(\\gamma\\times 100\\). This will vary depending on your data/assumptions"
  },
  {
    "objectID": "slides/slides-17-clt.html#ci-for-a-single-proportion",
    "href": "slides/slides-17-clt.html#ci-for-a-single-proportion",
    "title": "Central Limit Theorem",
    "section": "CI for a single proportion",
    "text": "CI for a single proportion\nSuppose that I have a sample of \\(n\\) binary values, and I would like to obtain a \\(\\gamma \\times 100\\%\\) confidence interval for the probability of success \\(p\\).\n\nIf assumptions of CLT for sample proportions hold:\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\nHow do we know if success-failure condition holds without knowing \\(p\\)? Let’s use our best guess: \\(\\hat{p}\\)\n\nSo need \\(n\\hat{p}\\) and \\(n(1-\\hat{p})\\) both \\(\\geq 10\\)\n\n\n\nPoint estimate: observed \\(\\hat{p}\\) from our sample\nStandard error: \\(\\sqrt{p(1-p)/n}\\)\n\nBut we still don’t have \\(p\\)! Instead use the following approximation for CI: \\(\\text{SE}(\\hat{p}) \\approx \\sqrt{\\hat{p}(1-\\hat{p})/n}\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#critical-value",
    "href": "slides/slides-17-clt.html#critical-value",
    "title": "Central Limit Theorem",
    "section": "Critical value",
    "text": "Critical value\n\nAt this point: \\(\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\right)\\)\nIf we want a \\(\\gamma \\times 100\\%\\) CI for \\(p\\), we just need the bounds of the middle \\(\\gamma \\times 100\\%\\) of the Normal distribution above!\n\nThese are the \\((1-\\gamma)/2\\) and \\((1+\\gamma)/2\\) percentiles\nBut…we still don’t know \\(p\\)\n\n\n\nCritical value: instead, we use the percentiles of the standard normal \\(N(0,1)\\) distribution: \\(z_{(1-\\gamma)/2}^{*}\\) and \\(z_{(1+\\gamma)/2}^{*}\\)\n\nSince the normal distribution is symmetric, \\(z_{(1+\\gamma)/2}^{*} = - z_{(1-\\gamma)/2}^{*}\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#example-cont.",
    "href": "slides/slides-17-clt.html#example-cont.",
    "title": "Central Limit Theorem",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nFind a (symmetric) 90% confidence interval for the true proportion of town residents in favor of legalized marijuana.\n\n\nGathering components for CI:\n\n\nPoint estimate: \\(\\hat{p}\\) = 0.6\nStandard error: \\(\\text{SE}(\\hat{p}) \\approx \\sqrt{\\frac{0.6(0.4)}{100}} \\approx 0.049\\)\n\nCritical value: what percentiles do we want?\n\n\n\\(z_{0.95}^{*} =\\) qnorm(0.95, mean = 0, sd = 1) \\(\\approx 1.645\\)\n\n\n\nSo our 90% confidence interval for \\(p\\) is:\n\\[\n0.6 \\pm 1.645(0.049) = (0.519, 0.681)\n\\]\n\n\n\nInterpret the confidence interval in context!"
  },
  {
    "objectID": "slides/slides-17-clt.html#towards-a-ci-for-a-single-proportion",
    "href": "slides/slides-17-clt.html#towards-a-ci-for-a-single-proportion",
    "title": "Central Limit Theorem",
    "section": "Towards a CI for a single proportion",
    "text": "Towards a CI for a single proportion\nSuppose that I have a sample of \\(n\\) binary (0/1) values. I want a \\(\\gamma \\times 100\\%\\) confidence interval for the probability of success \\(p\\) using the sample.\n\nIf assumptions of CLT for sample proportions hold, then we know\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\nWe can use/manipulate this result to obtain a confidence interval for the unknown \\(p\\)!\nHow do we know if success-failure condition holds without knowing \\(p\\)?\n\nLet’s use our best guess: \\(\\hat{p}\\)\nSuccess-failure condition for inference: \\(n\\hat{p}\\) and \\(n(1-\\hat{p})\\) both \\(\\geq 10\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#ci-for-single-proportion",
    "href": "slides/slides-17-clt.html#ci-for-single-proportion",
    "title": "Central Limit Theorem",
    "section": "CI for single proportion",
    "text": "CI for single proportion\nSo the formula for a (symmetric) \\(\\gamma\\times 100\\%\\) CI for \\(p\\) is:\n\n\\[\n\\hat{p} \\pm z_{(1+\\gamma)/2}^{*}\\times \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]where the critical value is obtained from \\(N(0,1)\\) distribution\n\n\nCome take STAT 311 to see why this is our CI!"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#housekeeping",
    "href": "slides/slides-18-ci-mean.html#housekeeping",
    "title": "Confidence Intervals for a Mean",
    "section": "Housekeeping",
    "text": "Housekeeping"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#recap",
    "href": "slides/slides-18-ci-mean.html#recap",
    "title": "Confidence Intervals for Means",
    "section": "Recap",
    "text": "Recap\n\n\n\n\nCentral Limit Theorem: if we have a sufficiently large sample of \\(n\\) independent observations from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\)\nWhen considering the special case of sample proportions, if success-failure condition is met, we have \\(\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\\)\nTo obtain a \\(\\gamma\\times 100\\%\\) CI for a mean, we use\n\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\n\nWe needed to replace the standard error with an estimate"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#checking-normality",
    "href": "slides/slides-18-ci-mean.html#checking-normality",
    "title": "Confidence Intervals for Means",
    "section": "Checking normality",
    "text": "Checking normality\n\nRemember, CLT requires a sufficiently large sample size \\(n\\) or assumption of Normality of the underlying data.\nNo perfect way to check Normality, but rule of thumb:\n\nIf \\(n < 30\\) small: check that there are no clear outliers\nIf \\(n \\geq 30\\) large: check that there are no particularly extreme outliers"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#ci-for-a-single-mean-known-variance",
    "href": "slides/slides-18-ci-mean.html#ci-for-a-single-mean-known-variance",
    "title": "Confidence Intervals for Means",
    "section": "CI for a single mean (known variance)",
    "text": "CI for a single mean (known variance)\nSuppose we want a \\(\\gamma\\times 100\\%\\) CI for population mean \\(\\mu\\).\n\nWhat would your “best guess” point estimate for \\(\\mu\\) be?\n\n\nIf CLT holds, then we know\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\nSo our \\(\\gamma \\times 100\\%\\) CI for \\(\\mu\\) is:\n\\[\n\\text{point estimate} \\pm \\underbrace{\\text{critical value} \\times \\text{SE}}_{\\text{Margin of Error}} = \\bar{x} \\pm z_{(1+\\gamma)/2}^* \\times \\frac{\\sigma}{\\sqrt{n}}\n\\]"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-age-at-marriage",
    "href": "slides/slides-18-ci-mean.html#example-age-at-marriage",
    "title": "Confidence Intervals for Means",
    "section": "Example: age at marriage",
    "text": "Example: age at marriage\n\n\n\nIn 2006-2010, the CDC conducted a thorough survey asking US women their age at first marriage. The standard deviation of the responses is 4.72 years. Suppose we randomly sample 25 US women and ask them their age at first marriage (plotted below). Their average age at marriage was 23.32.\n\n\n\n\n\n\n\n\nWhat is/are the population parameter(s)? What is the statistic?\n\n\n\nWe will obtain an 80% confidence interval for the mean age of US women at first marriage.\n\n\n\nAre conditions of CLT met?\nIf so, what does CLT tell us?"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-age-at-marriage-cont.",
    "href": "slides/slides-18-ci-mean.html#example-age-at-marriage-cont.",
    "title": "Confidence Intervals for Means",
    "section": "Example: age at marriage (cont.)",
    "text": "Example: age at marriage (cont.)\n\nObtain an 80% confidence interval for the mean age of US women at first marriage.\n\n\n\n\nBy CLT: \\[\\bar{X} \\overset{\\cdot}{\\sim}N\\left(\\mu, \\frac{4.72}{\\sqrt{25}}\\right) = N(\\mu, 0.944)\\]\n\nCollect necessary components:\n\n\nPoint estimate: \\(\\bar{x} = 23.32\\)\nStandard error: \\(0.944\\)\nCritical value: \\(z_{0.9}^{*} =\\) qnorm(0.9, 0, 1) \\(= 1.28\\)\n\n\nSo our 80% confidence interval is \\(23.32 \\pm 1.28 \\times 0.944 = (22.11, 24.53)\\)\n\n\n\nInterpret this interval!"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#utility-of-this-model",
    "href": "slides/slides-18-ci-mean.html#utility-of-this-model",
    "title": "Confidence Intervals for Means",
    "section": "Utility of this model",
    "text": "Utility of this model\n\nThe previous formula for the confidence interval for \\(\\mu\\) relies on knowing \\(\\sigma\\)\nBut wait…\n\nWant to construct a CI for \\(\\mu\\) because we don’t know its value\nIf we don’t know \\(\\mu\\), it seems highly unlikely that we would know \\(\\sigma\\)!\n\nSo in practice, we will have to estimate standard error for \\(\\bar{X}\\):\n\n\n\\[\n    \\text{SE}\\approx \\frac{s}{\\sqrt{n}}\n\\]\nwhere \\(s\\) is the observed sample standard deviation\n\n\nRecall we did something similar for CI for \\(p\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#variance-issue",
    "href": "slides/slides-18-ci-mean.html#variance-issue",
    "title": "Confidence Intervals for Means",
    "section": "Variance issue",
    "text": "Variance issue\n\nReplacing \\(s\\) for \\(\\sigma\\) works well enough when \\(n\\) is extremely large so we can estimate \\(\\sigma\\) accurately\nHowever, estimating variance is extremely difficult when \\(n\\) is small, and still not great for large \\(n\\)\nSo if \\(\\sigma\\) is unknown, we cannot use the Normal approximation to model \\(\\bar{X}\\) for inferential tasks\nInstead, we will use a new distribution for inference calculations, called the \\(t\\)-distribution"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#quick-remarks",
    "href": "slides/slides-18-ci-mean.html#quick-remarks",
    "title": "Confidence Intervals for a Mean",
    "section": "Quick remarks",
    "text": "Quick remarks\n\nIf \\(n\\) small, \\(\\sigma\\) unknown, but underlying distribution is Normal, then CLT says \\(\\bar{X} \\sim N(\\mu, \\sigma/\\sqrt{n})\\) exactly\n\nBUT in order to use this result for CIs, we need to know \\(\\sigma\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#t-distribution",
    "href": "slides/slides-18-ci-mean.html#t-distribution",
    "title": "Confidence Intervals for Means",
    "section": "\\(t\\)-distribution",
    "text": "\\(t\\)-distribution\n\nThe \\(t\\)-distribution is symmetric and bell-curved (like the Normal distribution)\nHas “thicker tails” than the Normal distribution (the tails decay more slowly)\n\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-distribution is always centered at 0\nOne parameter: degrees of freedom (df) defines exact shape of the \\(t\\)\n\nDenoted \\(t_{df}\\) (e.g. \\(t_{1}\\) or \\(t_{20}\\))\n\n\n\n\n\nAs \\(df\\) increase, \\(t\\) resembles the \\(N(0,1)\\). When \\(df \\geq 30\\), the \\(t_{df}\\) is nearly identical to \\(N(0,1)\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#working-with-t-distribution",
    "href": "slides/slides-18-ci-mean.html#working-with-t-distribution",
    "title": "Confidence Intervals for Means",
    "section": "Working with \\(t\\) distribution",
    "text": "Working with \\(t\\) distribution\n\n\n\nLet’s draw pictures for the following:\n\nWhat proportion of the \\(t_{2}\\)-distribution falls below -1.5?\nWhat value of the \\(t_{2}\\)-distribution has \\(70\\%\\) area lying below it?"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#t-distribution-in-r",
    "href": "slides/slides-18-ci-mean.html#t-distribution-in-r",
    "title": "Confidence Intervals for Means",
    "section": "\\(t\\) distribution in R",
    "text": "\\(t\\) distribution in R\n\npnorm(x, mean, sd) and qnorm(%, mean, sd) used to find probabilities and percentiles for the Normal distribution\nAnalogous functions for \\(t\\)-distribution: pt(x, df) and qt(%, df)\n\n\n\n\n\n\n\n\n\n\n\npt(-1.5,df =2) = 0.1361966\n\n\n\n\n\n\n\n\n\n\nqt(0.7, df =2) = 0.6172134"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#ci-for-a-single-mean-unknown-variance",
    "href": "slides/slides-18-ci-mean.html#ci-for-a-single-mean-unknown-variance",
    "title": "Confidence Intervals for Means",
    "section": "CI for a single mean (unknown variance)",
    "text": "CI for a single mean (unknown variance)\n\nStill require independent observations and the Normality condition for CLT\nGeneral formula for \\(\\gamma \\times 100\\%\\) CI is the same, but we simply change what goes into the margin of error.\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{x} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s}{\\sqrt{n}}\n\\end{align*}\n\\]\n\n\n\\(df = n-1\\)\ncritical value \\(t^*_{df, (1+\\gamma)/2}\\) = \\((1+\\gamma)/2\\) percentile of the \\(t_{df}\\) distribution"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-age-at-marriage-cont.-1",
    "href": "slides/slides-18-ci-mean.html#example-age-at-marriage-cont.-1",
    "title": "Confidence Intervals for Means",
    "section": "Example: age at marriage (cont.)",
    "text": "Example: age at marriage (cont.)\nLet’s return to the age at marriage example. Once again let’s obtain an 80% confidence interval for the average age of first marriage for US women, but now suppose we don’t know \\(\\sigma\\).\n\nIn our sample of \\(n = 25\\) women, we observed a sample mean of \\(23.32\\) years and a sample standard deviation of \\(s = 4.03\\) years.\n\n\n\n\n\nPoint estimate: \\(\\bar{x} = 23.32\\)\nStandard error: \\(\\widehat{\\text{SE}} = \\frac{s}{\\sqrt{n}}= \\frac{4.03}{\\sqrt{25}} = 0.806\\)\nCritical value:\n\n\\(df = n-1 = 24\\)\n\\(t_{24}^*\\) = qt(0.9, df =24) = 1.32\n\n\n\nSo our 80% confidence interval for \\(\\mu\\) is:\n\\[\n23.32 \\pm 1.32 \\times 0.806 = (22.26, 24.38)\n\\]"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#comparing-cis",
    "href": "slides/slides-18-ci-mean.html#comparing-cis",
    "title": "Confidence Intervals for Means",
    "section": "Comparing CIs",
    "text": "Comparing CIs\n\n\nKnown variance:\n80% CI: (22.11, 24.53)\n\nUnknown variance:\n80% CI: (22.26, 24.38)\n\n\n\n\nHow do the two intervals compare?\n\nInterpretation of CI does not change even if we use a different model!"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#examples",
    "href": "slides/slides-18-ci-mean.html#examples",
    "title": "Confidence Intervals for Means",
    "section": "Examples",
    "text": "Examples\nAssume that all conditions necessary for inference are satisfied.\n\n\n\nqnorm(0.90) = 1.28\nqnorm(0.95) = 1.64\nqnorm(0.975) = 1.96\n\n\n\nqt(0.90, df = 35) = 1.31\nqt(0.95, df = 35) = 1.69\nqt(0.975, df = 35) = 2.03\n\n\n\nqt(0.90, df = 36) = 1.31\nqt(0.95, df = 36) = 1.69\nqt(0.975, df = 36) = 2.03\n\n\n\n\n\nA 90% confidence interval for a population mean \\(\\mu\\) is given as \\((18.985, 21.015)\\). The interval was obtained based on a SRS for 36 observations. Calculate the sample mean and sample standard deviation.\nThe standard deviation for students at particular Ivy League college is 250 points. Two students, Raina and Luke, want to estimate the average SAT score of students at this college. They want their margin of error to be no more than 25 points.\n\nRaina wants to use a 90% confidence level. How large a sample does Raina need to collect?\nLuke wants to use a 95% confidence level. Without calculations, determine whether Luke’s sample should be larger or smaller than Raina’s. Explain your reasoning.\nCalculate the minimum sample size for Luke."
  },
  {
    "objectID": "practice_probs/practice-17-clt.html",
    "href": "practice_probs/practice-17-clt.html",
    "title": "CLT and CIs for proportion",
    "section": "",
    "text": "A survey found that American families generate an average of 17.2 pounds of glass garbage each year. Assume that the standard deviation is 2.5 pounds.\nSuppose we randomly survey 40 families. Set up a calculation for (and if you have access to R, actually calculate) the probability that the mean of glass garbage of these 40 families is less than 18 pounds.\nDefine what a sampling distribution of the sample proportion is. Describe how the shape, center, and spread of the sampling distribution change as the sample size increases when \\(p=0.2\\).\nA survey of 1509 high school seniors who took the SAT and who completed an optional web survey shows that 55% of high school seniors are fairly certain that they will participate in a study abroad program in college.\n\nIs this sample a representative sample from the population of all high school seniors in the US? Explain.\nSuppose the conditions for inference are met, regardless of your answer in (a). Using a mathematical model, construct a 90% confidence interval for the proportion of high school seniors who are fairly certain they will participate in a study abroad program in college. Interpret this interval in context.\nBased on this interval, would it be appropriate to claim that the majority of high school seniors are fairly certain they will participate in a study abroad program in college?\n\n\\((^*)\\) The average teacher salary in Vermont is $62,483. Suppose that the distribution of teacher salaries is approximately normal with standard deviation $7000.\n\nWhat is the probability that a randomly selected Vermont teacher makes less than $60,000 per year?\nIf we randomly sample 25 Vermont teachers and obtain their salaries, what is the probability that the mean of their salaries is less than $60,000 per year?\nCompare the probabilities in (a) and (b), and explain mathematically why one is larger than the other.\nHow would your answers to (a) and (b) change if the distribution of teacher salaries was not normal?"
  },
  {
    "objectID": "slides/slides-17-clt.html",
    "href": "slides/slides-17-clt.html",
    "title": "Central Limit Theorem",
    "section": "",
    "text": "Office hours tomorrow: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-17-clt.html#comprehension-questions",
    "href": "slides/slides-17-clt.html#comprehension-questions",
    "title": "Central Limit Theorem",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat is the main takeaway of the CLT?\nWhat are the assumptions of the CLT?\nHow do we construct a \\(\\gamma \\times 100\\%\\) confidence interval using a mathematical model?"
  },
  {
    "objectID": "slides/slides-17-clt.html#normality-condition",
    "href": "slides/slides-17-clt.html#normality-condition",
    "title": "Central Limit Theorem",
    "section": "Normality condition",
    "text": "Normality condition\n\nDo you believe the large sample size/normality condition is satisified in the following two samples?\n\n\n\n\n\n\nSample 1: small \\(n < 30\\). But histogram and boxplot reveals no clear outliers, so I would say normality condition is met.\nSample 2: larger \\(n \\geq 30\\). Even though \\(n\\) is larger, there is a particularly extreme outlier, so I would say normality condition is not met."
  },
  {
    "objectID": "slides/slides-17-clt.html#proportion-as-a-mean",
    "href": "slides/slides-17-clt.html#proportion-as-a-mean",
    "title": "Central Limit Theorem",
    "section": "Proportion as a mean",
    "text": "Proportion as a mean\nRemember \\(\\hat{p}\\) is a sample mean! So the CLT applies to proportions as well!\n\\[\n\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i} \\qquad \\qquad x_{i} =\\{0, 1\\}\n\\]\n\nTypically, \\(x_{i} = 1\\) is read as “success” and \\(x_{i} = 0\\) as “failure”, so \\(p\\) is the population-level probability of success"
  },
  {
    "objectID": "slides/slides-17-clt.html#towards-a-ci-for-a-single-proportion-cont.",
    "href": "slides/slides-17-clt.html#towards-a-ci-for-a-single-proportion-cont.",
    "title": "Central Limit Theorem",
    "section": "Towards a CI for a single proportion (cont.)",
    "text": "Towards a CI for a single proportion (cont.)\n\nPoint estimate: observed \\(\\hat{p}\\) from our sample\nStandard error: \\(\\sqrt{p(1-p)/n}\\)\n\nBut we still don’t have \\(p\\)!\nInstead, use the following approximation for CI:\n\n\n\n\\[\\text{SE}(\\hat{p}) \\approx \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\n\nCritical value: to obtain the middle \\(\\gamma \\times 100\\%\\) part, we use the \\((1-\\gamma)/2\\) and \\((1+\\gamma)/2\\) percentiles of the \\(N(0,1)\\) distribution\n\n\\(z_{(1-\\gamma)/2}^{*}\\) (lower bound) and \\(z_{(1+\\gamma)/2}^{*}\\) (upper bound)\nNote: \\(z_{(1+\\gamma)/2}^{*} = - z_{(1-\\gamma)/2}^{*}\\)"
  },
  {
    "objectID": "slides/slides-17-clt.html#warm-up",
    "href": "slides/slides-17-clt.html#warm-up",
    "title": "Central Limit Theorem",
    "section": "Warm-up",
    "text": "Warm-up\n\nLet \\(Z \\sim N(0,1)\\). If the 10th percentile of \\(Z\\) is -1.28, what is the 90th percentile?\nLet \\(X \\sim N(0,2)\\). If the 10th percentile of \\(X\\) is -2.56, what is the 90th percentile? Or can you not say without code?\nLet \\(Y \\sim N(2,1)\\). If the 10th percentile of \\(Y\\) is 0.72, what is the 90th percentile? Or can you not say without code?"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#paired-data",
    "href": "slides/slides-18-ci-mean.html#paired-data",
    "title": "Confidence Intervals for Means",
    "section": "Paired data",
    "text": "Paired data\nSuppose we have two sets of observations/data \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\ldots x_{n})\\) and \\(\\boldsymbol{y} = (y_{1}, y_{2}, \\ldots, y_{n})\\)\n\nThe data are considered paired data if each \\(x_{i}\\) corresponds to exactly one \\(y_{i}\\)\nExample: your score on the midterm and your score on the final\nWhen analyzing paired data, we are typically interested in the difference in outcomes of each pair of observations"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#paired-differences",
    "href": "slides/slides-18-ci-mean.html#paired-differences",
    "title": "Confidence Intervals for Means",
    "section": "Paired differences",
    "text": "Paired differences\n\nLet \\(d_{i} = y_{i} - x_{i}\\) for each \\(i = 1,\\ldots, n\\) be the observed differences\nThe \\(d_{i}\\) come from larger population with true mean difference \\(\\mu_{d}\\) and standard deviation of differences \\(\\sigma_{d}\\)\nThe sample mean difference and sample standard deviation of the differences are\n\n\n\\[\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_{i} \\qquad \\qquad s_{d} = \\frac{1}{n-1}\\sum_{i=1}^{n} (d_{i} - \\bar{d})^2 \\]"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#clt-for-mean-difference-in-pairs",
    "href": "slides/slides-18-ci-mean.html#clt-for-mean-difference-in-pairs",
    "title": "Confidence Intervals for Means",
    "section": "CLT for mean difference in pairs",
    "text": "CLT for mean difference in pairs\n\nSuppose the \\(n\\) observational units are independent and the distribution of the differences is approximately normal. Then CLT says:\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\nWe are usually interested in performing inference for \\(\\mu_{d}\\) when both \\(\\mu_{d}\\) and \\(\\sigma_{d}\\) unknown\nOur formula for \\(\\gamma\\times 100\\%\\) CI for \\(\\mu_{d}\\) is analogous to the formula for one mean when \\(\\sigma\\) unknown:\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{d} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s_{d}}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#ci-for-mean-difference-in-pairs",
    "href": "slides/slides-18-ci-mean.html#ci-for-mean-difference-in-pairs",
    "title": "Confidence Intervals for Means",
    "section": "CI for mean difference in pairs",
    "text": "CI for mean difference in pairs\n\nWe are usually interested in performing inference for \\(\\mu_{d}\\) when both \\(\\mu_{d}\\) and \\(\\sigma_{d}\\) unknown\nOur formula for \\(\\gamma\\times 100\\%\\) CI for \\(\\mu_{d}\\) is analogous to the formula for one mean when \\(\\sigma\\) unknown:\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{d} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s_{d}}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-zinc",
    "href": "slides/slides-18-ci-mean.html#example-zinc",
    "title": "Confidence Intervals for Means",
    "section": "Example: zinc",
    "text": "Example: zinc\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Let’s answer this using a 95% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n  bottom surface\n1  0.430   0.415\n2  0.266   0.238\n3  0.567   0.390\n4  0.531   0.410\n5  0.707   0.605\n6  0.716   0.609\n\n\n\nAre the data paired? Does CLT apply?"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-zinc-cont.",
    "href": "slides/slides-18-ci-mean.html#example-zinc-cont.",
    "title": "Confidence Intervals for Means",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\n\npoint estimate: \\(\\bar{d} = 0.0804\\)\nSE \\(\\approx\\) \\(\\frac{s_{d}}{\\sqrt{n}} = \\frac{0.052}{\\sqrt{10}} = 0.016\\)\n\ncritical value: what code would you write?\n\n\n\\(df = n-1 = 9\\)\n\\(t_{9, 0.975}^{*} =\\) qt(0.975,9) \\(= 2.26\\)\n\n\n\n\n\nSo our 95% confidence interval is:\n\\[0.0804 \\pm 2.26(0.016) = (0.044, 0.117)\\]\n\n\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Explain."
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-zinc-cont.-1",
    "href": "slides/slides-18-ci-mean.html#example-zinc-cont.-1",
    "title": "Confidence Intervals for a Mean",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#difference-of-two-means",
    "href": "slides/slides-18-ci-mean.html#difference-of-two-means",
    "title": "Confidence Intervals for Means",
    "section": "Difference of two means",
    "text": "Difference of two means\nNow consider two populations under the condition that the data/populations are not paired.\nWe might be interested in learning about whether or not the means of each population are equal (think about the voice jitter homework problem)!\n\nLet \\(\\mu_{1}\\) and \\(\\mu_{2}\\) represent the population means for the two populations 1 and 2\nSamples of size \\(n_{1}\\) and \\(n_{2}\\) from each population, respectively\nWe might think it reasonable to use \\(\\bar{x}_{1} - \\bar{x}_{2}\\) as a point estimate for \\(\\mu_{1} - \\mu_{2}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#conditions-for-inference",
    "href": "slides/slides-18-ci-mean.html#conditions-for-inference",
    "title": "Confidence Intervals for Means",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nNow that we have two populations, conditions for CLT and use of the \\(t\\)-distribution for inference will look slightly different:\n\nIndependence (extended): need data within and between the two groups\n\ne.g.the two data sets come from independent random samples or from a randomized experiment\n\nNormality: we need to check for approximate normality for both groups separately"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#formula-for-ci-for-difference-in-two-means",
    "href": "slides/slides-18-ci-mean.html#formula-for-ci-for-difference-in-two-means",
    "title": "Confidence Intervals for a Mean",
    "section": "Formula for CI for difference in two means",
    "text": "Formula for CI for difference in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\npoint estimate: \\(\\bar{x}_{1} - \\bar{x}_{2}\\)\n\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\ni.e. \\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\n\\(\\widehat{\\text{SE}} = \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\ni.e. \\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-birth-term",
    "href": "slides/slides-18-ci-mean.html#example-birth-term",
    "title": "Confidence Intervals for Means",
    "section": "Example: birth term",
    "text": "Example: birth term\nThe births dataset from openintro contains a random sample of births for babies in NC where the mother was or was not a smoker. We will consider the birth weights of babies who were carried to full term.\n\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: mothers who smoke (in NC)\nPopulation 2: mothers who don’t smoke (in NC)\n\n\nResearch question: are average birth weight of full term babies different between smoking and non-smoking mothers? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{smoke} - \\mu_{non}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-birth-term-cont.",
    "href": "slides/slides-18-ci-mean.html#example-birth-term-cont.",
    "title": "Confidence Intervals for Means",
    "section": "Example: birth term (cont.)",
    "text": "Example: birth term (cont.)\n\nAre average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\n\n\n\n\n\n\nstatus\nn\nxbar\ns\n\n\n\n\nHealthy\n48\n0.163\n0.058\n\n\nPD\n147\n0.321\n0.208\n\n\n\n\n\n\n\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 28\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\nDo assumptions for CLT hold?\n\n\nIndependence: random sample!\nNormality condition: \\(n \\geq 30\\) in both groups with no particularly extreme outliers\n\n\n\nSet-up/find the following:\n\n\nPoint estimate\nStandard error\nCode for critical value"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-birth-term-cont.-1",
    "href": "slides/slides-18-ci-mean.html#example-birth-term-cont.-1",
    "title": "Confidence Intervals for Means",
    "section": "Example: birth term (cont.)",
    "text": "Example: birth term (cont.)\n\n\n\n\nPoint estimate: \\(\\bar{x}_{\\text{PD}} - \\bar{x}_{\\text{H}} = 0.32 - 0.16 = 0.158\\)\nSE \\(\\approx \\sqrt{\\frac{s_{\\text{PD}}^2}{n_{\\text{PD}}} + \\frac{s_{\\text{H}}^2}{n_{\\text{H}}}} = \\sqrt{\\frac{0.21^2}{147} + \\frac{0.06^2}{48}} = 0.019\\)\nCritical value:\n\n\\(df = \\min\\{n_{\\text{PD}} -1, n_{\\text{H}} -1 \\} = \\min\\{147 - 1, 48- 2\\} = 47\\)\nWant \\(0.975\\)-th percentile of \\(t_{47}\\) distribution: qt(0.975, df =47) = 2.01\n\n\n\n\nPutting everything together, our 95% CI for \\(\\mu_{s} - \\mu_{n}\\) is: \\[\n0.158 \\pm 2.01 \\times 0.019 = (0.12, 0.196)\n\\]\nAre average voice shimmers different between people with and without Parkinson’s? Briefly explain why or why not."
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#temp",
    "href": "slides/slides-18-ci-mean.html#temp",
    "title": "Confidence Intervals for a Mean",
    "section": "Temp",
    "text": "Temp\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nPoint estimate\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\ni.e. \\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\text{SE} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\ni.e. \\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#ci-for-differences-in-two-means",
    "href": "slides/slides-18-ci-mean.html#ci-for-differences-in-two-means",
    "title": "Confidence Intervals for a Mean",
    "section": "CI for differences in two means",
    "text": "CI for differences in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nPoint estimate\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\text{SE} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#ci-for-difference-in-two-means",
    "href": "slides/slides-18-ci-mean.html#ci-for-difference-in-two-means",
    "title": "Confidence Intervals for Means",
    "section": "CI for difference in two means",
    "text": "CI for difference in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nPoint estimate\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\text{SE} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-voice-jitter",
    "href": "slides/slides-18-ci-mean.html#example-voice-jitter",
    "title": "Confidence Intervals for Means",
    "section": "Example: voice jitter",
    "text": "Example: voice jitter\nLet’s consider the voice shimmer of PD vs non-PD patients.\n\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: people with Parkinson’s Disease\nPopulation 2: people without Parkinson’s Disease\n\n\nResearch question: are average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-voice-shimmer",
    "href": "slides/slides-18-ci-mean.html#example-voice-shimmer",
    "title": "Confidence Intervals for Means",
    "section": "Example: voice shimmer",
    "text": "Example: voice shimmer\nLet’s consider the voice shimmer of PD vs non-PD patients from last week’s homework.\n\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: people with Parkinson’s Disease\nPopulation 2: people without Parkinson’s Disease\n\n\nResearch question: are average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\)"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-voice-shimmer-cont.",
    "href": "slides/slides-18-ci-mean.html#example-voice-shimmer-cont.",
    "title": "Confidence Intervals for Means",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\nAre average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\n\n\n\n\n\n\nstatus\nn\nxbar\ns\n\n\n\n\nHealthy\n48\n0.163\n0.058\n\n\nPD\n147\n0.321\n0.208\n\n\n\n\n\n\n\n\n\n\nDo assumptions for CLT hold?\n\n\nIndependence: random sample!\nNormality condition: \\(n \\geq 30\\) in both groups with no particularly extreme outliers\n\n\n\nSet-up/find the following:\n\n\nPoint estimate\nStandard error\nCode for critical value"
  },
  {
    "objectID": "slides/slides-18-ci-mean.html#example-voice-shimmer-cont.-1",
    "href": "slides/slides-18-ci-mean.html#example-voice-shimmer-cont.-1",
    "title": "Confidence Intervals for Means",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\n\n\n\nPoint estimate: \\(\\bar{x}_{\\text{PD}} - \\bar{x}_{\\text{H}} = 0.32 - 0.16 = 0.158\\)\nSE \\(\\approx \\sqrt{\\frac{s_{\\text{PD}}^2}{n_{\\text{PD}}} + \\frac{s_{\\text{H}}^2}{n_{\\text{H}}}} = \\sqrt{\\frac{0.21^2}{147} + \\frac{0.06^2}{48}} = 0.019\\)\nCritical value:\n\n\\(df = \\min\\{n_{\\text{PD}} -1, n_{\\text{H}} -1 \\} = \\min\\{147 - 1, 48- 1\\} = 47\\)\nWant \\(0.975\\)-th percentile of \\(t_{47}\\) distribution: qt(0.975, df =47) = 2.01\n\n\n\n\nPutting everything together, our 95% CI for \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\) is: \\[\n0.158 \\pm 2.01 \\times 0.019 = (0.12, 0.196)\n\\]\n\nInterpret this CI in context. Note: direction of difference matters!\nAre average voice shimmers different between people with and without Parkinson’s? Briefly explain why or why not."
  },
  {
    "objectID": "live_code/ht_diff_means.html",
    "href": "live_code/ht_diff_means.html",
    "title": "HT: Difference in means",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/parkinsons.csv\"\nparkinsons <- read_csv(url_file)\n\n\nGet summary statistics\n\nx_pd <- parkinsons |>\n  filter(status == \"PD\") |>\n  pull(shimmer)\nx_healthy <- parkinsons |>\n  filter(status == \"Healthy\") |>\n  pull(shimmer)\nn1 <- length(x_pd)\nn2 <- length(x_healthy)\nxbar1 <- mean(x_pd)\nxbar2 <- mean(x_healthy)\ns1 <- sd(x_pd)\ns2 <- sd(x_healthy)\n\n\n\nObtain quantities for CI\n\npoint_est <- xbar1 - xbar2\nSE <- sqrt(s1^2/n1 + s2^2/n2)\ndf <- min(n1-1, n2-1)\ncv <- qt(0.975, df = df)\n\nlower <- point_est - cv * SE\nupper <- point_est + cv * SE\n\nOur 95% CI for the difference in voice shimmers (PD - non PD) is (0.12 , 0.197)."
  },
  {
    "objectID": "live_code/ht_diff_means.html#get-summary-statistics",
    "href": "live_code/ht_diff_means.html#get-summary-statistics",
    "title": "HT: Difference in means",
    "section": "Get summary statistics",
    "text": "Get summary statistics\n\nx_pd <- parkinsons |>\n  filter(status == \"PD\") |>\n  pull(shimmer)\nx_healthy <- parkinsons |>\n  filter(status == \"Healthy\") |>\n  pull(shimmer)\nn1 <- length(x_pd)\nn2 <- length(x_healthy)\nxbar1 <- mean(x_pd)\nxbar2 <- mean(x_healthy)\ns1 <- sd(x_pd)\ns2 <- sd(x_healthy)"
  },
  {
    "objectID": "live_code/ht_diff_means.html#obtain-quantities-for-ci",
    "href": "live_code/ht_diff_means.html#obtain-quantities-for-ci",
    "title": "HT: Difference in means",
    "section": "Obtain quantities for CI",
    "text": "Obtain quantities for CI\n\npoint_est <- xbar1 - xbar2\npoint_est\n\n[1] 0.1582457\n\nSE <- sqrt( s1^2/n1 + s2^2/n2)\nSE\n\n[1] 0.01906297\n\ndf <- min(n1-1, n2-1)\ndf\n\n[1] 47\n\ncv <- qt(0.975, df = df)\ncv\n\n[1] 2.011741\n\nlower <- point_est - cv * SE\nupper <- point_est + cv * SE\n\nOur 95% CI for the different in voice shimmers (PD - non PD) is (0.12 , 0.197)."
  },
  {
    "objectID": "project/project_description.html",
    "href": "project/project_description.html",
    "title": "Final project",
    "section": "",
    "text": "Deliverable\nDate\nTime\n\n\n\n\nGroup creation\nThursday 4/10\nBeginning of class\n\n\nProposal for data collection\nWednesday 4/16\n11:59pm\n\n\nRevised proposal for data collection (if applicable)\nSunday 4/20\n11:59pm\n\n\nCollect your data\nAnytime between proposal approval and Sunday 5/04\n\n\n\nExcel/GoogleSheets of your data\nMonday 5/05\nBeginning of class\n\n\nRough draft of report\nSunday 5/11\n11:59pm\n\n\nFinal Presentation\nThursday 5/15\n9am-12pm (slides due at 8am)\n\n\nFinal report (rendered version and .qmd) and data with data dictionary\nSunday 12/18 (tentative)\n11:59pm\n\n\nReflection*\nSunday 12/18 (tentative)\n11:59pm\n\n\n\n*Reflection should be submitted individually. All other deliverables are one-per-group."
  },
  {
    "objectID": "project/project_description.html#description",
    "href": "project/project_description.html#description",
    "title": "Final project",
    "section": "Description",
    "text": "Description\nAs a final project, you will work (optionally) in groups to collect and analyze data from fellow Middlebury students! The final project will give you a chance to demonstrate and celebrate your mastery over the the statistics and data science concepts you have learned this entire semester! You and your group will come up with a list of research questions that you will subsequently answer using appropriate statistical methods.\nIn particular, your group will:\n\ncome up with a list of inferential research questions you are interested in answering\ndetermine your target population, create a list of variables you’d like to observe, and devise an appropriate sampling strategy\nhave a finalized data set that anyone can access and use, accompanied by a “data dictionary”\npresent your project to the class\nsubmit a well-written, professional report\nsubmit a reflection on the project, which will include a rubric for how much each team member contributed\n\nYou should have fun and be creative with this project!! Your research questions can be serious or funny (so long as they are PG-13 and below!)\n\nWeek 12 of the semester will be mostly devoted to project work time."
  },
  {
    "objectID": "project/project_description.html#requirements",
    "href": "project/project_description.html#requirements",
    "title": "Final project",
    "section": "Requirements",
    "text": "Requirements\nThe following looks like a lot, but is meant to provide you structure for strong final project that you are proud of!\n\n\nGroup creation\n\n\nEach group will ideally contain three people.\nBy the due date listed in the table above, you should either:\n\nform a group of three on your own and then e-mail Prof. Tang your decision, cc-ing everyone in the group\nform a group of two and then e-mail Prof. Tang your decision, cc-ing the other person in the group.\ne-mail Prof. Tang if you would like to work alone\n\n\n\nProposal for data collection\n\n\nBy the due date listed in the table above, your group should submit to Canvas a document detailing the following:\n\nYour target population(s) of interest\nA list of research questions your group is interested in exploring/answering. You should have at least one question per group member, but more is better!\n\nNote: we have not learned about regression yet. But we will soon learn linear regression, which answers questions about how changes in variable \\(x\\) might lead to changes in continuous variable \\(y\\)\n\nA list of variables you will observe/collect from each observational unit that you may be useful and/or required for answering your research question(s).\n\nYou should plan to collect at least four numerical variables (at least two of which are continuous), and at least two categorical variables\n\nA detailed description of how you plan to collect your data (i.e. survey students)\n\nHow many people do you plan to include in your data?\nHow will you have people submit their data? (e.g. fill out a paper form, GoogleForm)\nIf you want to conduct an observational study: will you implement SRS, stratified, clustering, etc? How exactly will you implement this sampling method?\nIf you want to conduct an experiment: will you randomly recruit people to your study? How will you randomly assign treatments? (Make sure your experiment is ethical!!)\n\nA rough description of the statistical methods you might use to answer each question you listed in (2).\n\nThis might be along the lines of “hypothesis test for a single mean” or “confidence interval for a proportion” or “linear regression” along with a one-two sentence justification for the method is appropriate.\nIt is possible that we haven’t yet learned a method to answer some of your questions. If so, please indicate this on your proposal along with a brief justification for why you think what we have currently learned doesn’t apply.\n\n\n\nOnce you have submitted your proposal, Prof. Tang will give you feedback. Based on the feedback, your group will either have to submit a revised proposal, or you will be given the okay to go forth and collect your data.\n\n\n\nData set\n\n\nOnce you have collected your data, you should compile it all into a single Excel or GoogleSheets. Please give each variable an informative one-word name (use underscores to make longer names). This should be submitted to Canvas by the beginning of Week 12. If you link a GoogleSheets, please ensure that you give me access!"
  },
  {
    "objectID": "homework/hw6_r.html",
    "href": "homework/hw6_r.html",
    "title": "STAT 201: Problem Set 6 (R)",
    "section": "",
    "text": "In every code chunk where you perform random sampling, set a seed at the top of the chunk. I don’t care what seed you choose so long as you set a seed!\nMake your code as reproducible as possible. You should avoid “hard-coding” values. Instead, store values as variables for future use.\nNote: you will practice typing in mathematical notation in the narrative using Latex. This is done using two dollar signs, and then typing Latex code between the dollar signs. To write the Greek letter mu, type \\(\\mu\\) in the narrative. You can add subscripts like this: \\(\\mu_{H}\\). To write a “does not equal” sign, type \\(\\neq\\) into the narrative.\nThe dataset is adapted from Little et al. (2007), and contains voice measurements from individuals both with and without Parkinson’s Disease (PD), a progressive neurological disorder that affects the motor system. The aim of Little et al.’s study was to examine whether they could diagnose PD by examining the spectral (sound-wave) properties of patients’ voices.\n147 measurements were taken from patients with PD, and 48 measurements were taken from healthy controls. For the purposes of this lab, you may assume that measurements are representative of the underlying populations (PD vs. healthy).\nThe variables in the dataset are as follows:\nThe data are stored in a variable called parksinsons. Run the following code chunk and take a look at the data before getting started."
  },
  {
    "objectID": "homework/hw6_r.html#part-1",
    "href": "homework/hw6_r.html#part-1",
    "title": "STAT 201: Problem Set 6 (R)",
    "section": "Part 1",
    "text": "Part 1\nResearchers suspect that patients with PD are less able to control their vocal muscles, and thus may have a greater voice jitter compared to healthy volunteers. Thus, they are interested in whether the mean jitter in voice recordings among patients with PD is greater than the mean jitter in voice recordings among healthy patients. The researchers select the 0.01 significance level.\n\nWrite out the null hypothesis and alternative hypotheses for the question in statistical notation, defining quantities when necessary.\n\nAnswer:\n\nDescribe in words how you would obtain 5000 simulations from the null distribution. (Hint: this should be very similar to the sex discrimination or CPR examples from class.) Then, describe how you would estimate the p-value using this null distribution. Be as specific as possible!\n\nAnswer:\n\nIt will be helpful to define some variables here. To make your life easier, create the following objects/variables in R to represent the following quantities:\n\n\nn: The number of total patients\nn_h: The number of healthy patients\nn_pd: The number of PD patients\njitters: The vector of voice jitters\n\n\n\n\n\nSimulate the null distribution according to your description above. Store the results into a vector called null_dist_pt1.\n\n\n\n\n\nWhat is your p-value, decision, and conclusion in the context of the research question? Is it possible that you’ve made an error? If so, which one?\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "homework/hw6_r.html#part-2",
    "href": "homework/hw6_r.html#part-2",
    "title": "STAT 201: Problem Set 6 (R)",
    "section": "Part 2",
    "text": "Part 2\nWe will now answer the following question: is there enough evidence to suggest that the mean HNR in the voice recordings of PD patients is significantly different from 21.5 at the \\(\\alpha= 0.10\\) significance level?\n\nWrite out the null and alternative hypotheses for this question using symbols, defining any quantities as necessary.\n\nAnswer:\n\nDescribe in words how you would obtain 5000 simulations from the null distribution. Then, describe how you would estimate the p-value using this null distribution. Be as specific as possible!\n\nAnswer:\n\nTo make your life easier, create the following objects/variables.\n\n\nhnr_pd: a vector of HNR for the PD patients only (you may want to use some combination of filter() and pull() to obtain this)\nn_pd: the number of PD patients (though you should have already defined this in problem 3)\nxbar_pd: the observed/sample mean HNR of PD patients\nmu_h0: the null hypothesized value for the population parameter\n\n\n\n\n\nSimulate the null distribution according to your description above. Store the results into a vector called null_dist_pt2.\n\n\n\n\n\nVisualize your null distribution. Make sure your visualization has informative axis labels and title.\n\n\n\n\n\nEstimate the p-value. Then answer the following: what is your p-value, decision, and conclusion in the context of the research question?\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "project/project_description.html#deadlines",
    "href": "project/project_description.html#deadlines",
    "title": "Final project",
    "section": "Deadlines",
    "text": "Deadlines\n\n\n\nDeliverable\nDate\nTime\n\n\n\n\nGroup creation\nWednesday 10/30\nBeginning of class\n\n\nProposal for data collection\nMonday 11/04\n11:59pm\n\n\nRevised proposal for data collection (if applicable)\nSaturday 11/09\n11:59pm\n\n\nCollect your data\nAnytime between proposal approval and Thanksgiving break\n\n\n\nExcel/GoogleSheets of your data\nSunday 12/01\n11:59pm\n\n\nRough draft of report\nSunday 12/08\n11:59pm\n\n\nFinal presentations (Section AZ)\nWednesday 12/11\n7-10pm (slides due at 6pm)\n\n\nFinal presentations (Section BY)\nThursday 12/12\n9am-12pm (slides due at 8am)\n\n\nFinal report (knitted version and .Rmd) and data with data dictionary\nSunday 12/15 (tentative)\n11:59pm\n\n\nReflection*\nSudday 12/15 (tentative)\n11:59pm\n\n\n\n*Reflection should be submitted individually. All other deliverables are one-per-group."
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#housekeeping",
    "href": "slides/slides-19-ht-prop.html#housekeeping",
    "title": "Hypothesis testing with CLT",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nHomework 6 due tonight\nModified office hours"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#recap",
    "href": "slides/slides-19-ht-prop.html#recap",
    "title": "Hypothesis testing with CLT",
    "section": "Recap",
    "text": "Recap\n\nCLT -> sampling distribution for sample means -> confidence intervals for populations means\nNow we’re returning to hypothesis testing!\n\nTwo sets of hypotheses (competing claims)\nCollect data, calculate a statistic from the observed data, set significance level\nObtain p-value from the null distribution: sampling distribution assuming if \\(H_{0}\\) were true\n\np-value: probability of observing data as or more extreme as our own, assuming \\(H_{0}\\) true\n\nMake a decision"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#hypothesis-testing-using-mathematical-model",
    "href": "slides/slides-19-ht-prop.html#hypothesis-testing-using-mathematical-model",
    "title": "Hypothesis testing with CLT",
    "section": "Hypothesis testing using mathematical model",
    "text": "Hypothesis testing using mathematical model\n\nWe learned how to conduct hypothesis tests (HTs) using simulation to obtain null distribution\nBut we can also use CLT to obtain null distribution!\nSo the only step that will “look different” is #3: how we obtain our null distribution and p-value\n\nLooks different depending on type of data\n\nMake a conclusion in terms of \\(H_{A}\\)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#define-hypotheses",
    "href": "slides/slides-19-ht-prop.html#define-hypotheses",
    "title": "Hypothesis testing with CLT",
    "section": "1. Define hypotheses",
    "text": "1. Define hypotheses\nWant to conduct a hypothesis test about a population proportion.\n\n\n\n\\(H_{0}: p = p_{0}\\)\n\\(H_{A}: p \\neq p_{0}\\) or \\(H_{A}: p > p_{0}\\) or \\(H_{A}: p < p_{0}\\)\n\n\n\n\\(H_{0}: p \\geq p_{0}\\)\n\\(H_{A}: p < p_{0}\\)\n\n\n\n\\(H_{0}: p \\leq p_{0}\\)\n\\(H_{A}: p > p_{0}\\)\n\n\n\n\nRemember, \\(p_{0}\\) is our “null hypothesized value”: the population proportion if \\(H_{0}\\) were true"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#collect-data-set-significance",
    "href": "slides/slides-19-ht-prop.html#collect-data-set-significance",
    "title": "Hypothesis testing with CLT",
    "section": "2. Collect data, set significance",
    "text": "2. Collect data, set significance\n\nObtain observed sample proportion \\(\\hat{p}_{obs}\\)\nSet \\(\\alpha\\) significance level"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#null-distribution-and-p-value",
    "href": "slides/slides-19-ht-prop.html#null-distribution-and-p-value",
    "title": "Hypothesis testing with CLT",
    "section": "3. Null distribution and p-value",
    "text": "3. Null distribution and p-value\nRecall CLT for sample proportion: if we have \\(n\\) independent binary observations that satisfy the success-failure condition, then\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}} \\right)\n\\]\n\nThis is the sampling distribution of \\(\\hat{p}\\)\nBut we want the null distribution of \\(\\hat{p}\\): the sampling distribution under \\(H_{0}\\)\nWe should operate in a world where \\(H_{0}\\) is true, which means we operate assuming \\(p =p_{0}\\)\nSo to use CLT, we must satisfy:\n\nIndependence\nSuccess-failure condition under \\(H_{0}\\): \\(np_{0} \\geq 10\\) and \\(n(1-p_{0}) \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#null-distribution-and-p-value-cont.",
    "href": "slides/slides-19-ht-prop.html#null-distribution-and-p-value-cont.",
    "title": "Hypothesis testing with CLT",
    "section": "3. Null distribution and p-value (cont.)",
    "text": "3. Null distribution and p-value (cont.)\nIf CLT holds and \\(H_{0}\\) is true, then our null distribution is:\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p_{0}, \\sqrt{\\frac{p_{0} (1-p_{0})}{n}} \\right)\n\\]\n\nWe can standardize the null distribution by taking z-score:\n\n\n\\[\nZ = \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#null-distribution-and-p-value-cont.-1",
    "href": "slides/slides-19-ht-prop.html#null-distribution-and-p-value-cont.-1",
    "title": "Hypothesis testing with CLT",
    "section": "3. Null distribution and p-value (cont.)",
    "text": "3. Null distribution and p-value (cont.)\n\np-value requires us to compare our observed data to the null distribution\nCalculate a test statistic: a quantity that assesses how consistent your sample data are with \\(H_{0}\\)\n\nOur test statistic here is:\n\n\n\\[z =\\frac{\\hat{p}_{\\text{obs}} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}}\\]\n\n\nIf \\(|z|\\) large, then that usually means \\(\\hat{p}\\) is extremely unusual for \\(H_{0}\\), which is convincing evidence against \\(H_{0}\\)\n\np-value is then \\(\\text{Pr}(Z \\geq z)\\) or \\(\\text{Pr}(Z \\leq z)\\) (or both), depending on \\(H_{A}\\)\n\nEasily obtained using pnorm()"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-taste-test",
    "href": "slides/slides-19-ht-prop.html#example-taste-test",
    "title": "Hypothesis testing with CLT",
    "section": "Example: taste test",
    "text": "Example: taste test\nSome people claim that they can tell the difference between a diet soda and a regular soda in the first sip. A researcher wanted to test this claim using a hypothesis test at the 0.05 significance level.\n\nHe randomly sampled 80 such people.\nHe then filled 80 plain white cups with soda, half diet and half regular through random assignment, and asked each person to take one sip from their cup and identify the soda as diet or regular.\n53 participants correctly identified the soda.\n\n\nLet \\(p\\) be the probability/rate of correctly identifying soda type among people who think they can tell the difference."
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-taste-test-cont.",
    "href": "slides/slides-19-ht-prop.html#example-taste-test-cont.",
    "title": "Hypothesis testing with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\nDefine hypotheses\n\n\\(H_{0}\\): \\(p = 0.5\\) (random guessing)\n\\(H_{A}\\): \\(p > 0.5\\) (better than random guessing)\nNote: \\(p_{0} = 0.5\\) is our null hypothesized value!\n\nCollect data\n\n\\(\\hat{p}_{\\text{obs}} = \\frac{53}{80} = 0.6625\\)\n\n\n\nNote: significance level already determined to be 0.05"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#make-decision-and-conclude",
    "href": "slides/slides-19-ht-prop.html#make-decision-and-conclude",
    "title": "Hypothesis testing with CLT",
    "section": "4. Make decision and conclude",
    "text": "4. Make decision and conclude\nSince our p-value of 0.0019 is less than our significance level of 0.05, we reject \\(H_{0}\\). The data provide strong evidence that the rate of correctly identifying a soda for these people is better than random guessing."
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-taste-test-cont.-1",
    "href": "slides/slides-19-ht-prop.html#example-taste-test-cont.-1",
    "title": "Hypothesis testing with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\nObtain null distribution and p-value\n\n\nCheck conditions for inference satisfied\n\n\nIndependence: random sample\nsuccess-failure: \\(np_{0} = 80(0.5) = 40 \\geq 10\\) and \\(n(1-p_{0}) = 40 \\geq 10\\)\n\n\nNull distribution\n\n\n\\[\\hat{p} \\overset{\\cdot}{\\sim} N\\left(0.5, \\sqrt{\\frac{0.5(1-0.5)}{80}} = 0.056 \\right)\\]\n\n\nTest statistic:\n\n\n\\[z = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} = \\frac{0.6625 - 0.5}{0.056} = 2.90\\]\n\ni.e. if \\(H_{0}\\) true, our observed \\(\\hat{p}_{obs}\\) is 2.90 SDs above the mean"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#p-value-derivation-extra",
    "href": "slides/slides-19-ht-prop.html#p-value-derivation-extra",
    "title": "Hypothesis testing with CLT",
    "section": "p-value derivation (extra)",
    "text": "p-value derivation (extra)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-mms",
    "href": "slides/slides-19-ht-prop.html#example-mms",
    "title": "Hypothesis testing with CLT",
    "section": "Example: M&M’s",
    "text": "Example: M&M’s\nM&M’s reported that 14% of its candies are yellow. We are interested in testing this claim. In a random sample of 100 M&M’s, 9 were found to be yellow. Conduct a hypothesis test at the \\(0.10\\) level.\n\\(p =\\) true proportion of yellow M&M’s\n\n\n\n\nWrite out null and alternative hypotheses\nCollect data (i.e. obtain our observed statistics)\ni) Verify conditions for CLT are met\n\n\n\n\n\\(H_{0}: p = 0.14\\) versus \\(H_{A}: p \\neq 0.14\\)\n\\(\\hat{p}_{obs} = \\frac{9}{100} = 0.09\\)\ni) Independence: random sample\nSuccess-failure: \\(np_{0} = 100(0.14) = 14 \\geq 10\\) and \\(n(1-p_{0}) = 86 \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-mms-cont.",
    "href": "slides/slides-19-ht-prop.html#example-mms-cont.",
    "title": "Hypothesis testing with CLT",
    "section": "Example: M&M’s (cont.)",
    "text": "Example: M&M’s (cont.)\n\n\n\n\nii) Obtain null distribution\niii) Obtain test statistic \\(z\\)\n\n\n\n\nii) By CLT, our null distribution is \\(\\hat{p} \\overset{\\cdot}{\\sim} N\\left(0.14, \\sqrt{\\frac{0.14(1-0.14)}{100}} \\right)\\)\n\\(\\quad =N(0.14, 0.035)\\)\n\niii) \\(z = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} = \\frac{0.09 - 0.14}{0.035} = -1.43\\)\n\n\n\n\n\n\n\n\niv) Obtain p-value. Write out in \\(\\text{Pr}()\\) notation or in code what we want to find. Drawing a picture may help!\n\n\n\n\niv) Since \\(H_{A}\\) is two-sided, we want \\[\\begin{align*}\n   \\text{p-value} &= \\text{Pr}(Z \\leq -1.43 \\cup Z \\geq 1.43) \\\\\n&= \\text{Pr}(Z \\leq -1.43) + \\text{Pr}(Z \\geq 1.43)  \\\\\n&= 2\\times \\text{Pr}(Z \\geq 1.43) \\\\\n&= \\texttt{2 * (1 - pnorm(1.43))} \\\\\n&= 0.153\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-mms-cont.-1",
    "href": "slides/slides-19-ht-prop.html#example-mms-cont.-1",
    "title": "Hypothesis testing with CLT",
    "section": "Example: M&M’s (cont.)",
    "text": "Example: M&M’s (cont.)\n\n\nMake a decision and conclusion in context.\n\n\nSince our p-value of 0.153 is greater than our significance level of 0.10, we fail to reject \\(H_{0}\\). The data are not strong enough to suggest that the true proportion of yellow M&Ms is different from 14%."
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#example-taste-test-cont.-2",
    "href": "slides/slides-19-ht-prop.html#example-taste-test-cont.-2",
    "title": "Hypothesis testing with CLT",
    "section": "4. Example: taste test (cont.)",
    "text": "4. Example: taste test (cont.)\n\n\nCalculate p-value\n\n\nRemember \\(H_{A}: p > 0.5\\)\n\n\n\n\\[\n\\text{p-value} = \\text{Pr}(Z \\geq z) = \\text{Pr}(Z \\geq 2.90) = \\texttt{1 - pnorm(2.90, 0, 1) = 0.0019}\n\\]\n\n\nDecision and conclusion\n\nSince our p-value of 0.0019 is less than our significance level of 0.05, we reject \\(H_{0}\\). The data provide strong evidence that the rate of correctly identifying a soda for these people is better than random guessing."
  },
  {
    "objectID": "practice_probs/practice-19-ht-prop.html",
    "href": "practice_probs/practice-19-ht-prop.html",
    "title": "HT for single proportion",
    "section": "",
    "text": "A recent poll found that 11% of US adults say they have smoked cigarettes in the past week, a historical low. In a random sample of 730 randomly selected students at four-year colleges, it was found that 66 students have smoked cigarettes in the past week. Test that claim that the smoking rate of students at four-year colleges is the same the national US adult average at the 0.05 significance level.\nAn apple farmer has historically lost an average of 4% of his trees each year. He believes that he has been losing more trees lately.\n\nIn a sample of 300 trees, 20 have died. Test the farmer’s claim at the 0.01 level.\nHow would the situation change if the farmer’s sample size had been 200 instead of 300?\n\n\n\n\n\n\n\\((^*)\\) A survey was conducted on 850 randomly sampled student loan borrowers, asking them if they owed more than $30,000 in student debt. A 95% confidence interval for the true proportion of student loan borrowers with at $30,000 of debt was found to be (0.135, 0.185).\n\nBased on this information, out of the 850 respondents, how many answered “yes” to the question? Justify your answer.\nUse hypothesis testing to examine the claim that fewer than 18.2% of all student loan borrowers owe at least $30,000 at the 0.05 significance level."
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#difference-of-two-proportions",
    "href": "slides/slides-19-ht-prop.html#difference-of-two-proportions",
    "title": "Hypothesis testing with CLT",
    "section": "Difference of two proportions",
    "text": "Difference of two proportions\nSuppose we have two populations 1 and 2, and want to conduct a hypothesis test for the difference in population proportions: \\(p_{1} - p_{2}\\)\n\nWe have samples of size \\(n_{1}\\) and \\(n_{2}\\)\nReasonable point estimate: \\(\\hat{p}_{1, obs} - \\hat{p}_{2,obs}\\)\nApply same process as in previous test for a single proportion, this time working with the sampling distribution of the difference of two sample proportions"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#sampling-dist.-of-difference-of-two-proportions",
    "href": "slides/slides-19-ht-prop.html#sampling-dist.-of-difference-of-two-proportions",
    "title": "Hypothesis testing with CLT",
    "section": "Sampling dist. of difference of two proportions",
    "text": "Sampling dist. of difference of two proportions\n\nIn order to use CLT approximation, we have to ensure conditions are met:\n\nIndependence (extended): data are independent within and between groups\nSuccess-failure (extended): success-failure conditions holds for both groups (must perform four total checks)\n\nIf above hold, then:\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}} \\right)\n\\]\nwhere \\(p_{1}\\) and \\(p_{2}\\) are the population proportions"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#hypothesis-test-for-difference-in-proportions",
    "href": "slides/slides-19-ht-prop.html#hypothesis-test-for-difference-in-proportions",
    "title": "Hypothesis testing with CLT",
    "section": "Hypothesis test for difference in proportions",
    "text": "Hypothesis test for difference in proportions\n\nDefine hypotheses. Hypothesis tests for difference in proportions in this class will take the form:\n\n\n\\[\n\\begin{align*}\nH_{0}: \\ &p_{1} = p_{2} \\qquad \\Rightarrow \\qquad  H_{0}: p_{1} - p_{2} = 0 \\\\\nH_{A}: \\ &p_{1} \\neq p_{2} \\qquad \\Rightarrow \\qquad  H_{A}: p_{1} - p_{2} \\neq 0 \\\\\n\\text{ or }\\ &p_{1} < p_{2}  \\qquad \\Rightarrow \\qquad   \\qquad \\  p_{1} - p_{2} < 0 \\\\\n\\text{ or }\\ &p_{1} > p_{2} \\qquad \\Rightarrow \\qquad   \\qquad \\  p_{1} - p_{2} > 0\n\\end{align*}\n\\]\n\n\nCollect data/summarise (i.e. obtain \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\))"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#pooled-proportion",
    "href": "slides/slides-19-ht-prop.html#pooled-proportion",
    "title": "Hypothesis testing with CLT",
    "section": "Pooled proportion",
    "text": "Pooled proportion\n\nTo obtain null distribution, we would need to know \\(p_{1}\\) and \\(p_{2}\\) to verify success-failure conditions\nWe obviously don’t have these values, so maybe use \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\)?\nBut wait! If \\(H_{0}: p_{1} = p_{2}\\), then \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\) in theory come from the same population\n\nSo under this null hypothesis, we use a special proportion called the pooled proportion to check the success-failure conditions:\n\n\n\n\\[\n\\hat{p}_{pooled} = \\frac{\\text{total # of successes from both samples}}{\\text{combined sample size}} = \\frac{n_{1} \\hat{p}_{1,obs} + n_{2} \\hat{p}_{2,obs}}{n_{1} + n_{2}}\n\\]\n\n\nThis is the best estimate of both \\(p_{1}\\) and \\(p_{2}\\) if null hypothesis of \\(p_{1} = p_{2}\\) is true!"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#hypothesis-test-cont.",
    "href": "slides/slides-19-ht-prop.html#hypothesis-test-cont.",
    "title": "Hypothesis testing with CLT",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\n\nObtain null distribution (first verify conditions for inference using \\(\\hat{p}_{pooled}\\))\n\nIf conditions satisfied, then we have the “general” sampling distribution of \\(\\hat{p}_{1} - \\hat{p}_{2}\\) from previous slide.\nBut to obtain the null distribution, we assume \\(H_{0}: p_{1} - p_{2} = 0\\) is true, and will estimate \\(p_{1}\\) and \\(p_{2}\\) using \\(\\hat{p}_{pooled}\\) to approximate standard error:\n\n\n\n\\[\n\\begin{align*}\n\\hat{p}_{1} - \\hat{p}_{2} &\\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}}  \\right) \\qquad \\text{(CLT)} \\\\ &\\overset{\\cdot}{\\sim} N\\big(0, \\underbrace{\\sqrt{\\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{1}} + \\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{2}}}}_{\\widehat{\\text{SE}}_{0}} \\big) \\qquad (H_{0})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#hypothesis-test-cont.-1",
    "href": "slides/slides-19-ht-prop.html#hypothesis-test-cont.-1",
    "title": "Hypothesis testing with CLT",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\nObtain test-statistic:\n\\[\nz = \\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}} \\approx \\frac{(\\hat{p}_{1,obs} - \\hat{p}_{2,obs}) - 0}{\\widehat{\\text{SE}}_{0}}\n\\]\n\nTo obtain p-value, we want \\(\\text{Pr}(Z \\geq z)\\) and/or \\(\\text{Pr}(Z \\leq z)\\) where \\(Z \\sim N(0,1)\\)\n\nObtain using pnorm(z, 0, 1)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#test-statistic-and-p-value",
    "href": "slides/slides-19-ht-prop.html#test-statistic-and-p-value",
    "title": "Hypothesis testing with CLT",
    "section": "3. Test statistic and p-value",
    "text": "3. Test statistic and p-value\n\np-value requires us to compare our observed data to the null distribution\nCalculate a test statistic: a quantity that assesses how consistent your sample data are with \\(H_{0}\\)\n\nOur test statistic is of the form:\n\n\n\\[z =\\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}}\\]\n\n\nFor this specific test:\n\n\n\\[z =\\frac{\\hat{p}_{\\text{obs}} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}}\\]\n\n\nIf \\(|z|\\) large, then that usually means \\(\\hat{p}\\) is extremely unusual for \\(H_{0}\\), which is convincing evidence against \\(H_{0}\\)\n\np-value is then \\(\\text{Pr}(Z \\geq z)\\) or \\(\\text{Pr}(Z \\leq z)\\) (or both), depending on \\(H_{A}\\)\n\nEasily obtained using pnorm()"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#test-statistic",
    "href": "slides/slides-19-ht-prop.html#test-statistic",
    "title": "Hypothesis testing with CLT",
    "section": "3. Test statistic",
    "text": "3. Test statistic\n\np-value requires us to compare our observed data to the null distribution\nCalculate a test statistic: a quantity that assesses how consistent your sample data are with \\(H_{0}\\)\n\nOur test statistic is of the form:\n\n\n\\[\\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}}\\]\n\n\nFor this specific test, our test statistic is:\n\n\n\\[z =\\frac{\\hat{p}_{\\text{obs}} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}}\\]\nwhich is distributed \\(N(0,1)\\)"
  },
  {
    "objectID": "slides/slides-19-ht-prop.html#obtain-p-value",
    "href": "slides/slides-19-ht-prop.html#obtain-p-value",
    "title": "Hypothesis testing with CLT",
    "section": "Obtain p-value",
    "text": "Obtain p-value\n\nIf \\(|z|\\) large, then that usually means observed value is extremely unusual for \\(H_{0}\\), which is convincing evidence against \\(H_{0}\\)\np-value is then \\(\\text{Pr}(Z \\geq z)\\) or \\(\\text{Pr}(Z \\leq z)\\) (or both), depending on \\(H_{A}\\)\n\nEasily obtained using pnorm()"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#housekeeping",
    "href": "slides/slides-20-ht-diff-prop.html#housekeeping",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nNo office hours Friday"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#recap",
    "href": "slides/slides-20-ht-diff-prop.html#recap",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Recap",
    "text": "Recap\n\nHypothesis test for single proportion: \\(H_{0}: p = p_{0}\\) vs \\(H_{A}: p \\neq p_{0}\\) (or \\(>, <\\))\n\nNull distribution (assuming CLT holds under \\(H_{0}\\)):\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim}N\\left(p_{0}, \\sqrt{\\frac{p_{0} (1-p_{0})}{n}} \\right)\n\\]\nObtain test statistic and calculate p-value\n\\[\nz = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#difference-of-two-proportions",
    "href": "slides/slides-20-ht-diff-prop.html#difference-of-two-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Difference of two proportions",
    "text": "Difference of two proportions\nSuppose we have two populations 1 and 2, and want to conduct a hypothesis test for the difference in population proportions: \\(p_{1} - p_{2}\\)\n\nWe have samples of size \\(n_{1}\\) and \\(n_{2}\\)\nReasonable point estimate: \\(\\hat{p}_{1, obs} - \\hat{p}_{2,obs}\\)\nWe will now work with the sampling distribution of the difference of two sample proportions"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#sampling-dist.-of-difference-of-two-proportions",
    "href": "slides/slides-20-ht-diff-prop.html#sampling-dist.-of-difference-of-two-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Sampling dist. of difference of two proportions",
    "text": "Sampling dist. of difference of two proportions\n\nIn order to use CLT approximation, we have to ensure conditions are met:\n\nIndependence (extended): data are independent within and between groups\nSuccess-failure (extended): success-failure conditions holds for both groups (must perform four total checks)\n\nIf above hold, then:\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}} \\right)\n\\]\nwhere \\(p_{1}\\) and \\(p_{2}\\) are the population proportions"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#hypothesis-test-for-difference-in-proportions",
    "href": "slides/slides-20-ht-diff-prop.html#hypothesis-test-for-difference-in-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test for difference in proportions",
    "text": "Hypothesis test for difference in proportions\n\nDefine hypotheses. Hypothesis tests for difference in proportions in this class will take the form:\n\n\n\\[\n\\begin{align*}\nH_{0}: \\ &p_{1} = p_{2}  \\\\\nH_{A}: \\ &p_{1} \\neq p_{2}  \\\\\n\\text{ or }\\ &p_{1} < p_{2}   \\\\\n\\text{ or }\\ &p_{1} > p_{2}\n\\end{align*}\n\\]\n\n\nSet \\(\\alpha\\) and collect data/summarise (i.e. obtain \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\))"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#pooled-proportion",
    "href": "slides/slides-20-ht-diff-prop.html#pooled-proportion",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Pooled proportion",
    "text": "Pooled proportion\n\nTo verify success-failure conditions, need to know \\(p_{1}\\) and \\(p_{2}\\)\n\nWe don’t have these values, so maybe use \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\)?\n\nBut wait! If \\(H_{0}: p_{1} = p_{2}\\), then \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\)come from the same population\nSo under this null, we use a special proportion called the pooled proportion:\n\n\n\\[\n\\hat{p}_{pooled} = \\frac{\\text{total # of successes from both samples}}{\\text{combined sample size}}\n\\]\n\n\nThis is the best estimate of both \\(p_{1}\\) and \\(p_{2}\\) if \\(H_{0}: p_{1} = p_{2}\\) is true!\n\n\n\n\nFor this reason, use \\(\\hat{p}_{pooled}\\) to verify success-failure conditions"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#hypothesis-test-cont.",
    "href": "slides/slides-20-ht-diff-prop.html#hypothesis-test-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\n\nObtain null distribution\n\nIf conditions satisfied, then we know the sampling distribution of \\(\\hat{p}_{1} - \\hat{p}_{2}\\)\nTo obtain the null distribution we assume \\(H_{0}: p_{1} - p_{2} = 0\\) is true and we \\(\\hat{p}_{pooled}\\) to estimate \\(p_{1}\\) and \\(p_{2}\\) to approximate standard error:\n\n\n\n\\[\n\\begin{align*}\n\\hat{p}_{1} - \\hat{p}_{2} &\\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}}  \\right) \\qquad \\text{(CLT)} \\\\ &\\overset{\\cdot}{\\sim} N\\big(0, \\underbrace{\\sqrt{\\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{1}} + \\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{2}}}}_{\\widehat{\\text{SE}}_{0}} \\big) \\qquad (H_{0})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#hypothesis-test-cont.-1",
    "href": "slides/slides-20-ht-diff-prop.html#hypothesis-test-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\nObtain test-statistic:\n\\[\nz = \\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}} \\approx \\frac{(\\hat{p}_{1,obs} - \\hat{p}_{2,obs}) - 0}{\\widehat{\\text{SE}}_{0}}\n\\]\n\nTo obtain p-value, we want \\(\\text{Pr}(Z \\geq z)\\) and/or \\(\\text{Pr}(Z \\leq z)\\) where \\(Z \\sim N(0,1)\\)\n\nObtain using pnorm(z, 0, 1)"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling",
    "text": "Example: offshore drilling\nA survey asked 827 randomly sampled registered voters in California: Do you support or oppose about drilling for oil and natural gas of the Coast of California? Or do you now know enough to say? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?\n\n\n\nDefine parameters and hypotheses\n\n\nLet \\(p_{c}\\) be the proportion of registered voters from California who are college-graduates who support off-shore drilling\nLet \\(p_{nc}\\) be the proportion be of registered voters from California who are not college-graduates who support off-shore drilling\n\\(H_{0}: p_{nc} - p_{c} = 0\\) and \\(H_{A}: p_{nc} - p_{c} \\neq 0\\)"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-1",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nObtain observed proportions and pooled proportion.\n\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\n\n\\(\\hat{p}_{nc, obs}= \\frac{132}{389} = 0.339\\)\n\\(\\hat{p}_{c, obs}= \\frac{154}{438} = 0.352\\)\n\\(\\hat{p}_{pooled} =\\frac{132 + 154}{389 + 438} = \\frac{286}{827} = 0.346\\)\n\n\n\nCheck conditions for inference are satisfied."
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-2",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-2",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nConditions for inference:\n\nIndependence: random sample\nSuccess-failure:\n\n\\(n_{nc} \\hat{p}_{pooled} = 389 \\times 0.346 = 134.59 > 10\\)\n\\(n_{nc} (1 - \\hat{p}_{pooled}) = 389 \\times (1 - 0.346) = 254.41 > 10\\)\n\\(n_{c} \\hat{p}_{pooled} = 438 \\times 0.346 = 151.55 > 10\\)\n\\(n_{c} (1 - \\hat{p}_{pooled}) = 438 \\times (1 - 0.346) = 286.45 > 10\\)\n\n\nSince conditions are met, we can proceed"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#hypotheses-and-null-distribution",
    "href": "slides/slides-20-ht-diff-prop.html#hypotheses-and-null-distribution",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypotheses and null distribution",
    "text": "Hypotheses and null distribution\nWant to conduct a hypothesis test for the mean \\(\\mu\\) of a population.\n\nHypotheses: \\(H_0: \\mu= \\mu_{0}\\) versus \\(H_{A}: \\mu \\neq \\mu_{0} \\ (\\text{or } \\mu > \\mu_{0} \\text{ or } \\mu < \\mu_{0})\\)\nVerify conditions for CLT\n\nIndependence\nApproximate normality or large sample size\n\nIf conditions satisfied, the CLT under \\(H_{0}\\) gives us null distribution for \\(\\bar{X}\\):\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim}  N\\left(\\mu_{0}, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#z-test-and-t-test",
    "href": "slides/slides-20-ht-diff-prop.html#z-test-and-t-test",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "z-test and t-test",
    "text": "z-test and t-test\n\nIf \\(\\sigma\\) known, we perform a z-test where our test-statistic is:\n\n\n\\[z = \\frac{\\bar{x} - \\mu_{0}}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)\\]\nand we obtain our p-value using pnorm()\n\n\nIf \\(\\sigma\\) unknown, we perform a t-test by estimating \\(\\sigma\\) with \\(s\\). Our test statistic is:\n\n\n\\[\nt = \\frac{\\bar{x} - \\mu_{0}}{\\frac{s}{\\sqrt{n}}} \\sim t_{df} \\qquad df = n-1\n\\]\nand we obtain our p-value using pt()"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-height",
    "href": "slides/slides-20-ht-diff-prop.html#example-height",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height",
    "text": "Example: height\n\nIn the US, the average height for women is 5’3.5” or 63.5 inches\nLet’s conduct a hypothesis test to see if the average height of female-identifying students in STAT 201 is equal to national average.\n\nDefine parameters and hypotheses\n\nI took a random sample of 10 female-identifying students across both sections. Set \\(\\alpha = 0.10\\)"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-height-cont.",
    "href": "slides/slides-20-ht-diff-prop.html#example-height-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height (cont.)",
    "text": "Example: height (cont.)\n\n\n\n\n\n\n\nn\nmean\nsd\n\n\n\n\n10\n64\n2.748737\n\n\n\n\n\n\n\n\n\n\nAre conditions for inference met?\nIf so, what test (z-test or t-test) should we perform? What is our test-statistic?\n\n\n\n\nConditions:\n\nIndependence: random sample\nApproximate normality: \\(n = 10 < 30\\), but no clear outliers\n\nSince we don’t know \\(\\sigma\\), we perform a \\(t\\)-test:\n\n\\(t = \\frac{\\bar{x} - \\mu_{0}}{s / \\sqrt{n}} = \\frac{64 - 63.5}{2.749 / \\sqrt{10}} = 0.575\\)"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-height-cont.-1",
    "href": "slides/slides-20-ht-diff-prop.html#example-height-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height (cont.)",
    "text": "Example: height (cont.)\n\n\nDraw a picture and write code to find our p-value\n\n\n\\(df = n-1 = 9\\)\np-value is \\(\\text{Pr}(T \\geq 0.575) + \\text{Pr}(T \\leq -0.575) = 2\\times \\text{Pr}(T \\geq 0.575)\\) where \\(T \\sim t_{9}\\)\n\\(2 \\times \\texttt{(1-pt(0.575, 9))}\\) = 0.5793797\n\n\nMake a decision and conclusion in context\n\n\nSince our p-value is greater than 0.01, we fail to reject \\(H_{0}\\). The data do not provide sufficient evidence to suggest that the average height of female-identifying students in STAT 201 is different from national average."
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-3",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-3",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{nc} - \\hat{p}_{c}\\)\n\n\n\n\\[\n\\hat{p}_{nc} - \\hat{p}_{c} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.346(1 - 0.346)}{389} + \\frac{0.346(1 - 0.346)}{438}} = 0.033 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{nc, obs}- \\hat{p}_{c, obs}) - 0}{\\text{SE}_{0}} = \\frac{(0.339 - 0.352) - 0}{0.033} = -0.394\n\\]\n\n\n\nDraw picture and write code for p-value"
  },
  {
    "objectID": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-4",
    "href": "slides/slides-20-ht-diff-prop.html#example-offshore-drilling-cont.-4",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z) = 2 \\times \\text{Pr}(Z \\geq 0.394)\\)\n2 * (1 - pnorm(0.394)) = 0.694\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater the 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#housekeeping",
    "href": "slides/slides-20-ht-cont.html#housekeeping",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nNo office hours Friday"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#recap",
    "href": "slides/slides-20-ht-cont.html#recap",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Recap",
    "text": "Recap\n\nHypothesis test for single proportion: \\(H_{0}: p = p_{0}\\) vs \\(H_{A}: p \\neq p_{0}\\) (or \\(>, <\\))\n\nNull distribution (assuming CLT holds under \\(H_{0}\\)):\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim}N\\left(p_{0}, \\sqrt{\\frac{p_{0} (1-p_{0})}{n}} \\right)\n\\]\nObtain test statistic and calculate p-value\n\\[\nz = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#difference-of-two-proportions",
    "href": "slides/slides-20-ht-cont.html#difference-of-two-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Difference of two proportions",
    "text": "Difference of two proportions\nSuppose we have two populations 1 and 2, and want to conduct a hypothesis test for the difference in population proportions: \\(p_{1} - p_{2}\\)\n\nWe have samples of size \\(n_{1}\\) and \\(n_{2}\\)\nReasonable point estimate: \\(\\hat{p}_{1, obs} - \\hat{p}_{2,obs}\\)\nWe will now work with the sampling distribution of the difference of two sample proportions"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#sampling-dist.-of-difference-of-two-proportions",
    "href": "slides/slides-20-ht-cont.html#sampling-dist.-of-difference-of-two-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Sampling dist. of difference of two proportions",
    "text": "Sampling dist. of difference of two proportions\n\nIn order to use CLT approximation, we have to ensure conditions are met:\n\nIndependence (extended): data are independent within and between groups\nSuccess-failure (extended): success-failure conditions holds for both groups (must perform four total checks)\n\nIf above hold, then:\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}} \\right)\n\\]\nwhere \\(p_{1}\\) and \\(p_{2}\\) are the population proportions"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#hypothesis-test-for-difference-in-proportions",
    "href": "slides/slides-20-ht-cont.html#hypothesis-test-for-difference-in-proportions",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test for difference in proportions",
    "text": "Hypothesis test for difference in proportions\n\nDefine hypotheses. Hypothesis tests for difference in proportions in this class will take the form:\n\n\n\\[\n\\begin{align*}\nH_{0}: \\ &p_{1} = p_{2}  \\\\\nH_{A}: \\ &p_{1} \\neq p_{2}  \\\\\n\\text{ or }\\ &p_{1} < p_{2}   \\\\\n\\text{ or }\\ &p_{1} > p_{2}\n\\end{align*}\n\\]\n\n\nSet \\(\\alpha\\) and collect data/summarise (i.e. obtain \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\))"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#pooled-proportion",
    "href": "slides/slides-20-ht-cont.html#pooled-proportion",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Pooled proportion",
    "text": "Pooled proportion\n\nTo verify success-failure conditions, need to know \\(p_{1}\\) and \\(p_{2}\\)\n\nWe don’t have these values, so maybe use \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\)?\n\nBut wait! If \\(H_{0}: p_{1} = p_{2}\\), then maybe \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\) come from the same population\nSo under this null, we use a special proportion called the pooled proportion:\n\n\n\\[\n\\hat{p}_{pooled} = \\frac{\\text{total # of successes from both samples}}{\\text{combined sample size}}\n\\]\n\n\nThis is the best estimate of both \\(p_{1}\\) and \\(p_{2}\\) if \\(H_{0}: p_{1} = p_{2}\\) is true!\n\n\n\n\nFor this reason, use \\(\\hat{p}_{pooled}\\) to verify success-failure conditions"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#hypothesis-test-cont.",
    "href": "slides/slides-20-ht-cont.html#hypothesis-test-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\n\nObtain null distribution\n\nIf conditions satisfied, then we know the sampling distribution of \\(\\hat{p}_{1} - \\hat{p}_{2}\\)\nTo obtain the null distribution we assume \\(H_{0}: p_{1} - p_{2} = 0\\) is true and we \\(\\hat{p}_{pooled}\\) to estimate \\(p_{1}\\) and \\(p_{2}\\) to approximate standard error:\n\n\n\n\\[\n\\begin{align*}\n\\hat{p}_{1} - \\hat{p}_{2} &\\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}}  \\right) \\qquad \\text{(CLT)} \\\\ &\\overset{\\cdot}{\\sim} N\\big(0, \\underbrace{\\sqrt{\\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{1}} + \\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{2}}}}_{\\widehat{\\text{SE}}_{0}} \\big) \\qquad (H_{0})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#hypothesis-test-cont.-1",
    "href": "slides/slides-20-ht-cont.html#hypothesis-test-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\nObtain test-statistic:\n\\[\nz = \\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}} \\approx \\frac{(\\hat{p}_{1,obs} - \\hat{p}_{2,obs}) - 0}{\\widehat{\\text{SE}}_{0}}\n\\]\n\nTo obtain p-value, we want \\(\\text{Pr}(Z \\geq z)\\) and/or \\(\\text{Pr}(Z \\leq z)\\) where \\(Z \\sim N(0,1)\\)\n\nObtain using pnorm(z, 0, 1)"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling",
    "text": "Example: offshore drilling\nA survey asked 827 randomly sampled registered voters in California: Do you support or oppose drilling for oil and natural gas off the Coast of California? Or do you not know enough to say? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?\n\n\n\nDefine parameters and hypotheses\n\n\nLet \\(p_{c}\\) be the proportion of registered voters from California who are college-graduates who support off-shore drilling\nLet \\(p_{nc}\\) be the proportion be of registered voters from California who are not college-graduates who support off-shore drilling\n\\(H_{0}: p_{nc} - p_{c} = 0\\) and \\(H_{A}: p_{nc} - p_{c} \\neq 0\\)"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-1",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nObtain observed proportions and pooled proportion.\n\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\n\n\\(\\hat{p}_{nc, obs}= \\frac{132}{389} = 0.339\\)\n\\(\\hat{p}_{c, obs}= \\frac{154}{438} = 0.352\\)\n\\(\\hat{p}_{pooled} =\\frac{132 + 154}{389 + 438} = \\frac{286}{827} = 0.346\\)\n\n\n\nCheck conditions for inference are satisfied."
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-2",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-2",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nConditions for inference:\n\nIndependence: random sample\nSuccess-failure:\n\n\\(n_{nc} \\hat{p}_{pooled} = 389 \\times 0.346 = 134.59 \\geq 10\\)\n\\(n_{nc} (1 - \\hat{p}_{pooled}) = 389 \\times (1 - 0.346) = 254.41 \\geq 10\\)\n\\(n_{c} \\hat{p}_{pooled} = 438 \\times 0.346 = 151.55 \\geq 10\\)\n\\(n_{c} (1 - \\hat{p}_{pooled}) = 438 \\times (1 - 0.346) = 286.45 \\geq 10\\)\n\n\nSince conditions are met, we can proceed"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-3",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-3",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{nc} - \\hat{p}_{c}\\)\n\n\n\n\\[\n\\hat{p}_{nc} - \\hat{p}_{c} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.346(1 - 0.346)}{389} + \\frac{0.346(1 - 0.346)}{438}} = 0.033 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{nc, obs}- \\hat{p}_{c, obs}) - 0}{\\text{SE}_{0}} = \\frac{(0.339 - 0.352) - 0}{0.033} = -0.394\n\\]\n\n\n\nDraw picture and write code for p-value"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-4",
    "href": "slides/slides-20-ht-cont.html#example-offshore-drilling-cont.-4",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z) = 2 \\times \\text{Pr}(Z \\geq 0.394)\\)\n2 * (1 - pnorm(0.394)) = 0.694\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater the 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#hypotheses-and-null-distribution",
    "href": "slides/slides-20-ht-cont.html#hypotheses-and-null-distribution",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypotheses and null distribution",
    "text": "Hypotheses and null distribution\nWant to conduct a hypothesis test for the mean \\(\\mu\\) of a population.\n\nHypotheses: \\(H_0: \\mu= \\mu_{0}\\) versus \\(H_{A}: \\mu \\neq \\mu_{0} \\ (\\text{or } \\mu > \\mu_{0} \\text{ or } \\mu < \\mu_{0})\\)\nVerify conditions for CLT\n\nIndependence\nApproximate normality or large sample size\n\nIf conditions satisfied, the CLT under \\(H_{0}\\) gives us null distribution for \\(\\bar{X}\\):\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim}  N\\left(\\mu_{0}, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#z-test-and-t-test",
    "href": "slides/slides-20-ht-cont.html#z-test-and-t-test",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "z-test and t-test",
    "text": "z-test and t-test\n\nIf \\(\\sigma\\) known, we perform a z-test where our test-statistic is:\n\n\n\\[z = \\frac{\\bar{x} - \\mu_{0}}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)\\]\nand we obtain our p-value using pnorm()\n\n\nIf \\(\\sigma\\) unknown, we perform a t-test by estimating \\(\\sigma\\) with \\(s\\). Our test statistic is:\n\n\n\\[\nt = \\frac{\\bar{x} - \\mu_{0}}{\\frac{s}{\\sqrt{n}}} \\sim t_{df} \\qquad df = n-1\n\\]\nand we obtain our p-value using pt()"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-height",
    "href": "slides/slides-20-ht-cont.html#example-height",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height",
    "text": "Example: height\n\nIn the US, the average height for women is 5’3.5” or 63.5 inches\nLet’s conduct a hypothesis test to see if the average height of female-identifying students in STAT 201 is equal to national average.\n\nDefine parameters and hypotheses\n\nI took a random sample of 10 female-identifying students across both sections. Set \\(\\alpha = 0.10\\)"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-height-cont.",
    "href": "slides/slides-20-ht-cont.html#example-height-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height (cont.)",
    "text": "Example: height (cont.)\n\n\n\n\n\n\n\nn\nmean\nsd\n\n\n\n\n10\n64\n2.748737\n\n\n\n\n\n\n\n\n\n\nAre conditions for inference met?\nIf so, what test (z-test or t-test) should we perform? What is our test-statistic?\n\n\n\n\nConditions:\n\nIndependence: random sample\nApproximate normality: \\(n = 10 < 30\\), but no clear outliers\n\nSince we don’t know \\(\\sigma\\), we perform a \\(t\\)-test:\n\n\\(t = \\frac{\\bar{x} - \\mu_{0}}{s / \\sqrt{n}} = \\frac{64 - 63.5}{2.749 / \\sqrt{10}} = 0.575\\)"
  },
  {
    "objectID": "slides/slides-20-ht-cont.html#example-height-cont.-1",
    "href": "slides/slides-20-ht-cont.html#example-height-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: height (cont.)",
    "text": "Example: height (cont.)\n\n\nDraw a picture and write code to find our p-value\n\n\n\\(df = n-1 = 9\\)\np-value is \\(\\text{Pr}(T \\geq 0.575) + \\text{Pr}(T \\leq -0.575) = 2\\times \\text{Pr}(T \\geq 0.575)\\) where \\(T \\sim t_{9}\\)\n\\(2 \\times \\texttt{(1-pt(0.575, 9))}\\) = 0.5793797\n\n\nMake a decision and conclusion in context\n\n\nSince our p-value is greater than 0.10, we fail to reject \\(H_{0}\\). The data do not provide sufficient evidence to suggest that the average height of female-identifying students in STAT 201 is different from national average."
  },
  {
    "objectID": "practice_probs/practice-20-ht-cont.html",
    "href": "practice_probs/practice-20-ht-cont.html",
    "title": "More with HT",
    "section": "",
    "text": "Let’s return to the offshore drilling data from class.\n\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\nConduct a hypothesis test to determine if the data provide strong evidence that the proportion of college graduates who do not have an opinion on this issue is different than that of non-college graduates.\n\nNew York is known as “the city that never sleeps”. A random sample of 25 New Yorkers were asked how much sleep they get per night. Statistical summaries includes a sample mean hours of 7.73 and standard deviation of 0.77. The point estimate suggests New Yorkers sleep less than 8 hours a night on average. Is the result statistically significant at the 0.05 level? Make a conclusion based on the your decision.\n\\((^*)\\) According to a report on sleep deprivation by the Centers for Disease Control and Prevention, the proportion of California residents who reported insufficient rest or sleep during each of the preceding 30 days is 8.0%, while this proportion is 8.8% for Oregon residents. These data are based on simple random samples of 11,545 California and 4,691 Oregon residents.\n\nConduct a hypothesis test to determine if these data provide strong evidence the rate of sleep deprivation is different for the two states. (Reminder: Check conditions)\nIt is possible the conclusion of the test in part (a) is incorrect. If this is the case, what type of error was made?\n\nThe population of all verbal GRE scores are known to have a standard deviation of 8.5. A certain graduate department hopes to receive applicants with a verbal GRE scores over 210. This year, the mean verbal GRE scores for the 42 applicants was 212.79. Using a significance level of 0.05, is this new mean significantly greater than the desired mean of 210?"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html",
    "href": "slides/slides-21-ht-diff-means.html",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "",
    "text": "No office hours tomorrow\nDaylight savings this weekend\nData collection proposal due Monday 11/4 midnight!"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#recap",
    "href": "slides/slides-21-ht-diff-means.html#recap",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Recap",
    "text": "Recap\n\nTest for difference in two proportions\n\nLearned about \\(\\hat{p}_{pooled}\\)\n\nTest for a single mean\n\n\\(z\\)-test: we know \\(\\sigma\\), use standard Normal distribution\n\\(t\\)-test: we don’t know \\(\\sigma\\), use \\(t\\) distribution"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#paired-data-recap",
    "href": "slides/slides-21-ht-diff-means.html#paired-data-recap",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Paired data (recap)",
    "text": "Paired data (recap)\n\nRecall paired data: we have two set of data \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) where each \\(x_{i}\\) has a corresponding to one \\(y_{i}\\)\n\nCan obtain differences \\(d_{i} = y_{i} - x_{i}\\)\nWe are interested in the true mean difference \\(\\mu_{d}\\)\n\nRecall: if observational units are independent and the differences are approximately Normal, then CLT gives us:\n\n\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}}\\right)\n\\]\n\n\nWe don’t typically know \\(\\sigma_{d}\\), so replace with sample \\(s_{d}\\) (and then use \\(t\\) distribution)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#hypothesis-test",
    "href": "slides/slides-21-ht-diff-means.html#hypothesis-test",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\nHypotheses: \\(H_0: \\mu_{d} = \\mu_{0}\\) versus \\(H_{A}: \\mu_{d} \\neq \\mu_0\\) (or \\(>\\) or \\(<\\) )\nObtain summary statistics \\(\\bar{d}_{obs}\\) and \\(s_{d}\\)\n\nCheck if CLT holds. If so, what is our null distribution?\n\n\n\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_0, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\n\n\n\nBecause we don’t know \\(\\sigma_{d}\\), our test statistic here is:\n\n\n\n\\[\nt = \\frac{\\bar{d}_{obs} - \\mu_0}{\\frac{s_{d}}{\\sqrt{n}}} \\sim t_{df}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-zinc-revisited",
    "href": "slides/slides-21-ht-diff-means.html#example-zinc-revisited",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: zinc (revisited)",
    "text": "Example: zinc (revisited)\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is greater than that of surface water? Let’s now answer this using a hypothesis test at the 0.05 level.\n\n\n\nDefine parameters and hypotheses\n\n\nLet \\(\\mu_{d}\\) be the true mean difference between zinc concentrations (bottom-surface)\n\\(H_{0}: \\mu_{d} = 0\\) versus \\(H_{A}: \\mu_{d} > 0\\)\n\nLast week, we saw conditions for CLT were satisfied"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-zinc-cont.",
    "href": "slides/slides-21-ht-diff-means.html#example-zinc-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\n\npoint estimate: \\(\\bar{d} = 0.0804\\)\nSE \\(\\approx\\) \\(\\frac{s_{d}}{\\sqrt{n}} = \\frac{0.052}{\\sqrt{10}} = 0.016\\)\n\ncritical value: what code would you write?\n\n\n\\(df = n-1 = 9\\)\n\\(t_{9, 0.975}^{*} =\\) qt(0.975,9) \\(= 2.26\\)\n\n\n\n\n\nSo our 95% confidence interval is:\n\\[0.0804 \\pm 2.26(0.016) = (0.044, 0.117)\\]\n\n\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Explain."
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#housekeeping",
    "href": "slides/slides-21-ht-diff-means.html#housekeeping",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nNo office hours tomorrow\nDaylight savings this weekend\nData collection proposal due Monday 11/4 midnight!"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#sampling-distribution-for-difference-in-means",
    "href": "slides/slides-21-ht-diff-means.html#sampling-distribution-for-difference-in-means",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Sampling distribution for difference in means",
    "text": "Sampling distribution for difference in means\n\nTwo populations, interest in \\(\\mu_{1} - \\mu_{2}\\) (or other order)\nSamples of size \\(n_{1}\\) and \\(n_{2}\\)\nIf CLT holds, we learned sampling distribution of difference in sample means is:\n\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(\\mu_{1} - \\mu_{2}, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\]\n\n\nWhen we don’t know the population standard deviations, we replace the \\(\\sigma\\) with \\(s\\) and use a \\(t\\) distribution\nSame thing will happen for hypothesis test!\n\n\nSame conditions for inference: independence (extended) and approximate normality/large sample size (extended)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#hypothesis-test-1",
    "href": "slides/slides-21-ht-diff-means.html#hypothesis-test-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Hypothesis test",
    "text": "Hypothesis test\nHypotheses \\(H_{0}: \\mu_{1} = \\mu_{2}\\) versus \\(H_{A}: \\mu_{1} \\neq \\mu_{2}\\) (or \\(>\\) or \\(<\\))\n\nIf CLT holds, our null distribution for the difference in sample means is:\n\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(0, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}} }\\right)\n\\]\n\n\n\nIn practice, use \\(s_{1}\\) and \\(s_{2}\\). So our test-statistic is…\n\n\n\n\\[\nt= \\frac{\\text{point est} - \\text{null value} }{\\widehat{\\text{SE}}_{0}} = \\frac{(\\bar{x}_{1} - \\bar{x}_{2}) - 0}{\\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}} \\sim t_{df}\n\\]\nwhere \\(df = \\min(n_{1}-1, n_{2}-1)\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#activity",
    "href": "slides/slides-21-ht-diff-means.html#activity",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Activity",
    "text": "Activity\nMunchkins!"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-zinc-cont.-1",
    "href": "slides/slides-21-ht-diff-means.html#example-zinc-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\nFind the test-statistic"
  },
  {
    "objectID": "live_code/ht_diff_means_b.html",
    "href": "live_code/ht_diff_means_b.html",
    "title": "HT for difference in means",
    "section": "",
    "text": "chocolate <- c(18, 16, 19, 19, 18, 17, 16, 19, 19, 18, 16, 19, 16, 18, 15, 16, 18, 16) \nglazed <- c(16, 15, 16, 17, 15, 14, 15, 17, 18, 16, 15)\n\n\nsd_c <- sd(chocolate)\nsd_c\n\n[1] 1.377931\n\nsd_g <- sd(glazed)\nsd_g\n\n[1] 1.167748\n\nxbar_c <- mean(chocolate)\nxbar_c\n\n[1] 17.38889\n\nxbar_g <- mean(glazed)\nxbar_g\n\n[1] 15.81818\n\n# check conditions\nhist(chocolate)\n\n\n\nhist(glazed)\n\n\n\nn_c <- length(chocolate)\nn_c\n\n[1] 18\n\nn_g <- length(glazed)\nn_g\n\n[1] 11\n\nse <- sqrt(sd_c^2 / n_c + sd_g^2/n_g)\ntest_stat <- ((xbar_c - xbar_g) - 0)/se\ntest_stat\n\n[1] 3.279075\n\ndf <- min(n_c - 1, n_g - 1)\n2*(1-pt(test_stat, df))\n\n[1] 0.008301925"
  },
  {
    "objectID": "live_code/ci_diff_means.html",
    "href": "live_code/ci_diff_means.html",
    "title": "CI: Difference in means",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/parkinsons.csv\"\nparkinsons <- read_csv(url_file)\n\n\nGet summary statistics\n\nx_pd <- parkinsons |>\n  filter(status == \"PD\") |>\n  pull(shimmer)\nx_healthy <- parkinsons |>\n  filter(status == \"Healthy\") |>\n  pull(shimmer)\nn1 <- length(x_pd)\nn2 <- length(x_healthy)\nxbar1 <- mean(x_pd)\nxbar2 <- mean(x_healthy)\ns1 <- sd(x_pd)\ns2 <- sd(x_healthy)\n\n\n\nObtain quantities for CI\n\npoint_est <- xbar1 - xbar2\nSE <- sqrt(s1^2/n1 + s2^2/n2)\ndf <- min(n1-1, n2-1)\ncv <- qt(0.975, df = df)\n\nlower <- point_est - cv * SE\nupper <- point_est + cv * SE\n\nOur 95% CI for the difference in voice shimmers (PD - non PD) is (0.12 , 0.197)."
  },
  {
    "objectID": "live_code/ht_diff_means_a.html",
    "href": "live_code/ht_diff_means_a.html",
    "title": "HT for difference in means",
    "section": "",
    "text": "library(tidyverse)\nchocolate <- c(20, 18, 17, 17, 17, 17, 16, 17, 18, 19, 17, 19, 17, 18 ) \nglazed <- c(15, 15, 15, 16, 17, 15, 15, 15, 15, 15, 15, 15, 16, 14, 15,15 )\n\n# check conditions\nhist(chocolate)\n\n\n\nhist(glazed)\n\n\n\nxbar_c <- mean(chocolate)\nxbar_c\n\n[1] 17.64286\n\nxbar_g <- mean(glazed)\nxbar_g\n\n[1] 15.1875\n\nsd_c <- sd(chocolate)\nsd_c\n\n[1] 1.081818\n\nsd_g <- sd(glazed)\nsd_g\n\n[1] 0.6551081\n\nn_c <- length(chocolate)\nn_c\n\n[1] 14\n\nn_g <- length(glazed)\nn_g\n\n[1] 16\n\ndf <- min(n_c - 1, n_g - 1)\ndf\n\n[1] 13\n\npoint_est <- xbar_c - xbar_g\nse <- sqrt(sd_c^2/n_c + sd_g^2/n_g)\ntest_stat <- (point_est - 0)/se\n2*(1-pt(test_stat, df))\n\n[1] 5.276221e-06"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#housekeeping",
    "href": "slides/slides-23-slr-intro.html#housekeeping",
    "title": "Introduction to Simple Linear Regression",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nHomework 7 due tonight!\nLast problem set is assigned today! Atypical due date: Wednesday 11/13"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitting-a-line-to-data",
    "href": "slides/slides-23-slr-intro.html#fitting-a-line-to-data",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting a line to data",
    "text": "Fitting a line to data\n\nHopefully we are all familiar with the equation of a line: \\(y = mx + b\\)\n\nIntercept \\(b\\) and slope \\(m\\) determine specific line\nThis function is deterministic: as long as we know \\(x\\), we know value of \\(y\\) exactly\n\nLinear regression: statistical method where the relationship between variable \\(x\\) and variable \\(y\\) is modeled as a line + error:\n\n\n\\[\ny = \\underbrace{\\beta_{0} + \\beta_{1} x}_{\\text{line}} + \\underbrace{\\epsilon}_{\\text{error}}\n\\]"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#linear-regression-model",
    "href": "slides/slides-23-slr-intro.html#linear-regression-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\nWe have two variables:\n\n\\(y\\) is response variable. Must be continuous numerical.\n\\(x\\) is explanatory variable, also called the predictor variable\n\nCan be numerical or categorical\n\n\n\\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the model parameters (intercept and slope)\n\nEstimated using the data, with point estimates \\(b_{0}\\) and \\(b_{1}\\)\n\n\\(\\epsilon\\) (epsilon) represents the error\n\nAccounts for variability: we do not expect all data to fall perfectly on the line!\nSometimes we drop the \\(\\epsilon\\) term for convenience"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#linear-relationship",
    "href": "slides/slides-23-slr-intro.html#linear-relationship",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear relationship",
    "text": "Linear relationship\nSuppose we have the following data:\n\n\n\n\n\n\nObservations won’t fall exactly on a line, but do fall around a straight line, so maybe a linear relationship makes sense!"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitted-values",
    "href": "slides/slides-23-slr-intro.html#fitted-values",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values",
    "text": "Fitted values\nSuppose we have some specific estimates \\(b_0\\) and \\(b_{1}\\). We could fit the linear relationship using these values as:\n\\[\n\\hat{y} = b_{0} + b_{1} x\n\\]\n\nThe hat on \\(y\\) signifies that this is an estimate: the estimated/fitted value of \\(y\\) given these specific values of \\(x\\), \\(b_{0}\\) and \\(b_{1}\\)\n\nWe observe \\(y\\), but can obtain a corresponding estimate \\(\\hat{y}\\)\n\nNote that the fitted value is obtained without the error"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitted-values-cont.",
    "href": "slides/slides-23-slr-intro.html#fitted-values-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values (cont.)",
    "text": "Fitted values (cont.)\n\n\n\n\n\n\nSuppose our estimated line is the yellow one\nEvery observed value \\(y_{i}\\) has a corresponding fitted value \\(\\hat{y}_{i}\\); the above plot just shows three specific examples"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#residual",
    "href": "slides/slides-23-slr-intro.html#residual",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual",
    "text": "Residual\nResiduals are the remaining variation in the data after fitting a model.\n\\[\n\\text{data} = \\text{fit} + \\text{residual}\n\\]\n\nFor each observation \\(i\\), we obtain residual \\(e_{i}\\) via:\n\n\n\\[y_{i} = \\hat{y}_{i} + e_{i} \\quad \\Rightarrow \\quad e_{i} = \\hat{y}_{i} - y_{i}\\]\n\n\nResidual = difference between observed and expected\nSince each observation has a fitted value, each observation has a residual\n\nIn the linear regression case, the residual is indicated by the vertical dashed line\n\nWhat is the ideal value for a residual?"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#residual-plot",
    "href": "slides/slides-23-slr-intro.html#residual-plot",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot",
    "text": "Residual plot\n\nResiduals are very helpful in evaluating how well a model fits a set of data\nResidual plot: original \\(x\\) values plotted against their corresponding residuals on \\(y\\)-axis"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#residual-plot-cont.",
    "href": "slides/slides-23-slr-intro.html#residual-plot-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot (cont.)",
    "text": "Residual plot (cont.)\nResidual plots can be useful for identifying characteristics/patterns that remain in the data even after fitting a model.\n\n\nJust because you fit a model to data, does not mean the model is a good fit!\n\n\n\n\n\n\n\n\n\nCan you identify any patterns remaining in the residuals?\n\nSorry! The residuals shown here are taken as \\(y_{i} - \\hat{y}_{i}\\)!"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#describing-linear-relationships",
    "href": "slides/slides-23-slr-intro.html#describing-linear-relationships",
    "title": "Introduction to Simple Linear Regression",
    "section": "Describing linear relationships",
    "text": "Describing linear relationships\nDifferent data may exhibit different strength of linear relationships:\n\n\n\n\n\n\nCan we quantify the strength of the linear relationship?"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#correlation",
    "href": "slides/slides-23-slr-intro.html#correlation",
    "title": "Introduction to Simple Linear Regression",
    "section": "Correlation",
    "text": "Correlation\n\nCorrelation is describes the strength of a linear relationship between two variables\n\nThe observed sample correlation is denoted by \\(R\\)\nFormula (not important): \\(R = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left(\\frac{x_{i} - \\bar{x}}{s_x} \\right)\\left(\\frac{y_{i} - \\bar{y}}{s_y} \\right)\\)\n\n\n\n\n\nAlways takes a value between -1 and 1\n\n-1 = perfectly linear and negative\n1 = perfectly linear and positive\n0 = no linear relationship\n\nNonlinear trends, even when strong, sometimes produce correlations that do not reflect the strength of the relationship"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#different-lines",
    "href": "slides/slides-23-slr-intro.html#different-lines",
    "title": "Introduction to Simple Linear Regression",
    "section": "Different lines",
    "text": "Different lines\nThe following display the same set of 50 observations.\n\n\n\n\n\n\n\n\n\nWhich line would you say fits the data the best?\n\n\n\n\nThere are infinitely many choices of \\((b_{0}, b_{1})\\) that could be used to create a line\nWe want the BEST choice (i.e. the one that gives us the “line of best fit”)\n\n\nHow to define “best”?"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#line-of-best-fit",
    "href": "slides/slides-23-slr-intro.html#line-of-best-fit",
    "title": "Introduction to Simple Linear Regression",
    "section": "Line of best fit",
    "text": "Line of best fit\nOne way to define a “best” is to choose the specific values of \\((b_{0}, b_{1})\\) that minimize the total residuals across all \\(n\\) data points. Results in following possible criterion:\n\nLeast absolute criterion: minimize sum of residual magnitudes:\n\n\n\\[\n|e_{1} | + |e_{2}| + \\ldots + |e_{n}|\n\\]\n\n\n\nLeast squares criterion: minimize sum of squared residuals:\n\n\n\n\\[\ne_{1}^2 + e_{2}^2 +\\ldots + e_{n}^2\n\\]\n\n\nThe choice of \\((b_{0}, b_{1})\\) that satisfy least squares criterion yields the least squares line, and will be our criterion for “best”\nOn previous slide, yellow line is the least squares line, whereas pink line is the least absolute line"
  },
  {
    "objectID": "coding_practice/coding-practice-22-pivoting.html",
    "href": "coding_practice/coding-practice-22-pivoting.html",
    "title": "Pivoting + HT coding practice",
    "section": "",
    "text": "library(tidyverse)\ndiamond_price <- read_csv(\"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/diamonds.csv\")\n\n\nWrangle/manipulate the diamond_price data frame into the long format. Ensure that the variable names you end up choosing are informative/meaningful. Store the resulting data frame into a new data frame called diamond_price_long.\n\n\n\n\n\nUsing your new data frame, check if the conditions for the CLT-based hypothesis test are satisfied.\n\n\n\n\nAnswer:\n\n(Optional) Obtain your test statistic and p-value. Report your p-value using in-line code.\n\n\n\n\nAnswer:\n\n(Optional) Conduct your simulation-based hypothesis test for the same set of hypotheses. Report your p-value using in-line code.\n\n\n\n\nAnswer:\nOnce finished, knit once more and submit the HTML to Canvas!"
  },
  {
    "objectID": "live_code/pivoting.html",
    "href": "live_code/pivoting.html",
    "title": "Pivoting in R",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "live_code/pivoting.html#pivot_longer",
    "href": "live_code/pivoting.html#pivot_longer",
    "title": "Pivoting in R",
    "section": "pivot_longer()",
    "text": "pivot_longer()\nLet’s take a look at first few observations of the relig_income data frame from the openintro package:\n\nrelig_income |>\n  head()\n\n# A tibble: 6 × 11\n  religion  `<$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  <chr>       <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>      <dbl>\n1 Agnostic       27        34        60        81        76       137        122\n2 Atheist        12        27        37        52        35        70         73\n3 Buddhist       27        21        30        34        33        58         62\n4 Catholic      418       617       732       670       638      1116        949\n5 Don’t kn…      15        14        15        11        10        35         21\n6 Evangeli…     575       869      1064       982       881      1486        949\n# ℹ 3 more variables: `$100-150k` <dbl>, `>150k` <dbl>,\n#   `Don't know/refused` <dbl>\n\n\nThis data is currently in “wide” format: a row has more than one observation. That is, the same outcome variable appears in multiple columns. In the relig_income data, the outcome observation that spans across several columns is income range. The different incomes columns are essentially different levels of the same categorical variable.\nSuppose I want to obtain the conditional probability of income bracket by religion type. These probabilities are VERY difficult to obtain with the data frame as is. Would would be extremely useful is if we could create a single categorical variable for the income range.\nWe will manipulate the data frame to the “long” format: the outcome variable only exists in one column, and a second column/variable tells us the different levels. Each row has one observation, but the units of observation are repeated down one column.\n\n\nThis is helpful for us to perform group_by() or facet_wrap().\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhat are the units of observation in the relig_income data?\n\n\n\nWe will do this with the pivot_longer() function. This function requires a couple of arguments:\n\ncols: which columns to pivot into a “longer” format. That is, the columns that we should “move”\nnames_to: a string character that provides the new column name for the categorical variable you are creating\nvalues_to: a string character that provides the new variable name for the response/outcome variable that is common across all levels of the categorical variable\n\n\nrelig_income_long <- relig_income |>\n  pivot_longer(cols = 2:11, names_to = \"income_range\",  values_to = \"count\")\nrelig_income_long \n\n# A tibble: 180 × 3\n   religion income_range       count\n   <chr>    <chr>              <dbl>\n 1 Agnostic <$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic >150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\n\n\nNote that the unit of observation is repeated down several rows!\nThe following achieve the same result:\n\nrelig_income |>\n  pivot_longer(cols = -c(1), names_to = \"income_range\",  values_to = \"count\")\n\n# A tibble: 180 × 3\n   religion income_range       count\n   <chr>    <chr>              <dbl>\n 1 Agnostic <$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic >150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\nrelig_income |>\n  pivot_longer(cols = !religion, names_to = \"income_range\",  values_to = \"count\")\n\n# A tibble: 180 × 3\n   religion income_range       count\n   <chr>    <chr>              <dbl>\n 1 Agnostic <$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic >150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\nNow it is extremely easy to obtain conditional probabilities:\n\nrelig_income_long |>\n  group_by(religion) |>\n  mutate(cond_prob = count/sum(count)) |>\n  filter(income_range == \"$30-40k\") |>\n  select(religion, income_range, cond_prob) |>\n  head()\n\n# A tibble: 6 × 3\n# Groups:   religion [6]\n  religion           income_range cond_prob\n  <chr>              <chr>            <dbl>\n1 Agnostic           $30-40k         0.0981\n2 Atheist            $30-40k         0.101 \n3 Buddhist           $30-40k         0.0827\n4 Catholic           $30-40k         0.0832\n5 Don’t know/refused $30-40k         0.0404\n6 Evangelical Prot   $30-40k         0.104"
  },
  {
    "objectID": "live_code/pivoting.html#pivot_wider",
    "href": "live_code/pivoting.html#pivot_wider",
    "title": "Pivoting in R",
    "section": "pivot_wider()",
    "text": "pivot_wider()\nWe can also pivot from long to wide format. Let’s look at the fish_encounters data.\n\nfish_encounters |>\n  head()\n\n# A tibble: 6 × 3\n  fish  station  seen\n  <fct> <fct>   <int>\n1 4842  Release     1\n2 4842  I80_1       1\n3 4842  Lisbon      1\n4 4842  Rstr        1\n5 4842  Base_TD     1\n6 4842  BCE         1\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSuppose our observation unit of interest is fish. Explain why this data frame is in the long format.\n\n\n\nWe want to pivot the data such that each fish is an observation, and we can easily see which stations it was observed at. We can do this using the pivot_wider() function, which takes two arguments:\n\nnames_from: the name of the variable(s) in the data frame to get the name of the output column.\nvalues_from: the name of the variable(s) in the data frame to get the cell values from\n\nThat is, the input to names_from should be the categorical variable(s), and the different levels of this categorical variable will be the new column names. What should we fill these cells with? The values specified by values_from.\n\nfish_encounters |>\n  pivot_wider(names_from = station, values_from = seen)\n\n# A tibble: 19 × 12\n   fish  Release I80_1 Lisbon  Rstr Base_TD   BCE   BCW  BCE2  BCW2   MAE   MAW\n   <fct>   <int> <int>  <int> <int>   <int> <int> <int> <int> <int> <int> <int>\n 1 4842        1     1      1     1       1     1     1     1     1     1     1\n 2 4843        1     1      1     1       1     1     1     1     1     1     1\n 3 4844        1     1      1     1       1     1     1     1     1     1     1\n 4 4845        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n 5 4847        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA\n 6 4848        1     1      1     1      NA    NA    NA    NA    NA    NA    NA\n 7 4849        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n 8 4850        1     1     NA     1       1     1     1    NA    NA    NA    NA\n 9 4851        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n10 4854        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n11 4855        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n12 4857        1     1      1     1       1     1     1     1     1    NA    NA\n13 4858        1     1      1     1       1     1     1     1     1     1     1\n14 4859        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n15 4861        1     1      1     1       1     1     1     1     1     1     1\n16 4862        1     1      1     1       1     1     1     1     1    NA    NA\n17 4863        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n18 4864        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n19 4865        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA\n\n\n\n\n\n\nNote that there are some NA values after pivoting. From the Help file, this is because misses were not directly recorded in the original form of the data. Try adding the argument values_fill = 0 to the pivot_wider() function."
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#linear-regression-model-1",
    "href": "slides/slides-23-slr-intro.html#linear-regression-model-1",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nRemember, our linear regression model is:\n\\[\ny = \\beta_{0} + \\beta_{1}x + \\epsilon\n\\]\n\nWhile not wrong, it can be good practice to be specific about an observation \\(i\\):\n\\[\ny_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i}, \\qquad i = 1,\\ldots, n\n\\]\n\n\nHere, we are stating that each observation \\(i\\) has a specific:\n\nexplanatory variable value \\(x_{i}\\)\nresponse variable value \\(y_{i}\\)\nerror/randomness \\(\\epsilon_{i}\\)"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#conditions-for-the-least-squares-line-line",
    "href": "slides/slides-23-slr-intro.html#conditions-for-the-least-squares-line-line",
    "title": "Introduction to Simple Linear Regression",
    "section": "Conditions for the least squares line (LINE)",
    "text": "Conditions for the least squares line (LINE)\nLike when using CLT, we should check some conditions before saying a linear regression model is appropriate!\n\nAssume for now that \\(x\\) is continuous numerical.\n\n\nLinearity: data should show a linear trend between \\(x\\) and \\(y\\)\nIndependence: the observations \\(i\\) are independent of each other\n\ne.g. random sample\nNon-example: time-series data\n\nNormality/nearly normal residuals: the residuals should appear approximately Normal\n\nPossible violations: outliers, influential points (more on this later)\n\nEqual variability: variability of points around the least squares line remains roughly constant"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#running-example",
    "href": "slides/slides-23-slr-intro.html#running-example",
    "title": "Introduction to Simple Linear Regression",
    "section": "Running example",
    "text": "Running example\nWe will see how to check for these four LINE conditions using the cherry data from openintro.\n\n\n\n\n\n\n\ndiam\nvolume\n\n\n\n\n8.3\n10.3\n\n\n8.6\n10.3\n\n\n8.8\n10.2\n\n\n10.5\n16.4\n\n\n10.7\n18.8\n\n\n\n\n\n\n\nExplanatory variable \\(x\\): diam\nResponse variable \\(y\\): volume"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#linearity",
    "href": "slides/slides-23-slr-intro.html#linearity",
    "title": "Introduction to Simple Linear Regression",
    "section": "1. Linearity",
    "text": "1. Linearity\nAssess before fitting the linear regression model by making a scatterplot of \\(x\\) vs. \\(y\\):\n\n\n\n\n\n\nDoes there appear to be a linear relationship between diameter and volume?\n\nI would say yes"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#independence",
    "href": "slides/slides-23-slr-intro.html#independence",
    "title": "Introduction to Simple Linear Regression",
    "section": "2. Independence",
    "text": "2. Independence\nAssess before fitting the linear regression model by understanding how your data were sampled.\n\nThe cherry data do not explicitly say that the trees were randomly sampled, but it might be a reasonable assumption\n\n\nAn example where independence is violated:\n\n\n\n\n\n\n\n\nHere, the data are a time series, where observation at time point \\(i\\) depends on the observation at time \\(i-1\\).\n\nSuccessive/consecutive observations are highly correlated"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#nearly-normal-residuals",
    "href": "slides/slides-23-slr-intro.html#nearly-normal-residuals",
    "title": "Introduction to Simple Linear Regression",
    "section": "3. Nearly normal residuals",
    "text": "3. Nearly normal residuals\nAssess after fitting the model by obtaining residuals and making a histogram.\n\nRemember, residuals are \\(\\hat{y}_{i} - y_{i}\\)\n\n\n\n\n\ncherry |>\n  mutate(volume_hat = -36.94 + 5.07*diam) |>\n  mutate(residual = volume_hat - volume) \n\n\n\n\n\n \n  \n    diam \n    volume \n    volume_hat \n    residual \n  \n \n\n  \n    8.3 \n    10.3 \n    5.108 \n    -5.192 \n  \n  \n    8.6 \n    10.3 \n    6.628 \n    -3.672 \n  \n  \n    8.8 \n    10.2 \n    7.641 \n    -2.559 \n  \n  \n    10.5 \n    16.4 \n    16.253 \n    -0.147 \n  \n  \n    10.7 \n    18.8 \n    17.266 \n    -1.534 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo the residuals appear approximately Normal?\n\nI think so!"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#equal-variance",
    "href": "slides/slides-23-slr-intro.html#equal-variance",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance",
    "text": "4. Equal variance\nAssess after fitting the model by examining a residual plot and looking for patterns.\n\n\nA good residual plot:\n\n\n\n\n\n\nA bad residual plot:\n\n\n\n\n\n\n\nWe usually have a horizontal line at 0 to compare residuals to"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitting-the-model",
    "href": "slides/slides-23-slr-intro.html#fitting-the-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting the model",
    "text": "Fitting the model\n\n\n\nAt this point, it is time to actually fit our model\n\\[\n\\text{volume} = \\beta_{0} + \\beta_{1} \\text{diameter} +\\epsilon\n\\]\n\nAfter fitting the model, we get the following estimates: \\(b_{0}= -36.94\\) and \\(b_{1} = 5.07\\). So our fitted model is:\n\n\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nRemember: the “hat” denotes an estimated/fitted value!\n\n\n\nWe will soon see how \\(b_{0}\\) and \\(b_{1}\\) are calculated and how to interpret them\nThe next two checks can only occur after fitting the model."
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#equal-variance-cont.",
    "href": "slides/slides-23-slr-intro.html#equal-variance-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance (cont.)",
    "text": "4. Equal variance (cont.)\nLet’s examine the residual plot of our fitted model for the cherry data:\n\n\n\n\n\n\nBased on this plot, I would say there is a definite pattern in the residuals and equal variance condition is not perfectly met.\n\nSome of the variability in the errors appear related to diameter"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#parameter-estimates",
    "href": "slides/slides-23-slr-intro.html#parameter-estimates",
    "title": "Introduction to Simple Linear Regression",
    "section": "Parameter estimates",
    "text": "Parameter estimates\n\nLike in previous topics, we have to estimate the parameters using data\nWe want to estimate \\(\\beta_{0}\\) and \\(\\beta_{1}\\) using the \\((x_{i}, y_{i})\\)\n\nIn practice, we let software do this for us\n\nHowever, we can derive the least-squares estimates using properties of the least-squares line"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#estimating-slope-and-intercept",
    "href": "slides/slides-23-slr-intro.html#estimating-slope-and-intercept",
    "title": "Introduction to Simple Linear Regression",
    "section": "Estimating slope and intercept",
    "text": "Estimating slope and intercept\n\n\nFirst obtain \\(b_{1}\\):\n\n\\[\nb_{1} =\\frac{s_{y}}{s_{x}} R\n\\]\nwhere:\n\n\n\\(s_{x}\\) and \\(s_{y}\\) are the sample standard deviations of the explanatory and response variables\n\\(R\\) is the correlation between \\(x\\) and \\(y\\)\n\n\n\nThen obtain \\(b_{0}\\):\n\n\\[b_{0} = \\bar{y} - b_{1} \\bar{x}\\] where\n\n\n\\(\\bar{y}\\) is the sample mean of the response variable\n\\(x\\) is the sample mean of the explanatory variable\n\n\n\n\n\n\nTake STAT 0211 or 0311 to see where these formulas come from!"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitting-cherry-model",
    "href": "slides/slides-23-slr-intro.html#fitting-cherry-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting cherry model",
    "text": "Fitting cherry model\nVerify estimates \\(b_{0} = -36.94\\) and \\(b_{1} = 5.07\\) from our model for the cherry data:\n\ncherry |>\n  pivot_longer(cols = c(diam, volume), names_to = \"variable\", values_to = \"val\") |>\n  select(-height) |>\n  group_by(variable) |>\n  summarise(mean = mean(val), s = sd(val)) \n\n\n\n\n\n \n  \n    variable \n    mean \n    s \n  \n \n\n  \n    diam \n    13.248 \n    3.138 \n  \n  \n    volume \n    30.171 \n    16.438 \n  \n\n\n\n\n\n\nR <- cor(cherry$diam, cherry$volume)\nR\n\n[1] 0.9671194\n\n\n\n\n\n\n\n\n\nSet-up the calculations:\n\n\\(b_{1} = \\frac{s_{y}}{s_{x}} R\\)\n\\(b_{0} = \\bar{y} -b_{1} \\bar{x}\\)\n\n\n\n\n\n\\(b_{1} = \\frac{16.438}{3.138} \\times 0.967 = 5.07\\)\n\\(b_{0} = 30.171 - 5.07 \\times 13.248 = -36.94\\)"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#fitting-cherry-model-by-hand",
    "href": "slides/slides-23-slr-intro.html#fitting-cherry-model-by-hand",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting cherry model (by hand)",
    "text": "Fitting cherry model (by hand)\nVerify estimates \\(b_{0} = -36.94\\) and \\(b_{1} = 5.07\\) from our model for the cherry data:\n\ncherry |>\n  pivot_longer(cols = c(diam, volume), names_to = \"variable\", values_to = \"val\") |>\n  select(-height) |>\n  group_by(variable) |>\n  summarise(mean = mean(val), s = sd(val)) \n\n\n\n\n\n \n  \n    variable \n    mean \n    s \n  \n \n\n  \n    diam \n    13.248 \n    3.138 \n  \n  \n    volume \n    30.171 \n    16.438 \n  \n\n\n\n\n\n\nR <- cor(cherry$diam, cherry$volume)\nR\n\n[1] 0.9671194\n\n\n\n\n\n\n\n\n\nSet-up the calculations:\n\n\\(b_{1} = \\frac{s_{y}}{s_{x}} R\\)\n\\(b_{0} = \\bar{y} -b_{1} \\bar{x}\\)\n\n\n\n\n\n\\(b_{1} = \\frac{16.438}{3.138} \\times 0.967 = 5.07\\)\n\\(b_{0} = 30.171 - 5.07 \\times 13.248 = -36.94\\)"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html#residual-cont.",
    "href": "slides/slides-23-slr-intro.html#residual-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual (cont.)",
    "text": "Residual (cont.)\n\n\n\n\n\n\nResidual values for the three highlighted observations:\n\n\n\n\n \n  \n    x \n    y \n    y_hat \n    residual \n  \n \n\n  \n    -2.991 \n    2.481 \n    -0.130 \n    -2.611 \n  \n  \n    -1.005 \n    -1.302 \n    0.691 \n    1.994 \n  \n  \n    3.990 \n    3.929 \n    2.757 \n    -1.172"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#linear-regression-model",
    "href": "slides/slides-24-slr-interpretation.html#linear-regression-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\nWe have two variables:\n\n\\(y\\) is response variable. Must be continuous numerical.\n\\(x\\) is explanatory variable, also called the predictor variable\n\nCan be numerical or categorical\n\n\n\\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the model parameters (intercept and slope)\n\nEstimated using the data, with point estimates \\(b_{0}\\) and \\(b_{1}\\)\n\n\\(\\epsilon\\) (epsilon) represents the error\n\nAccounts for variability: we do not expect all data to fall perfectly on the line!\nSometimes we drop the \\(\\epsilon\\) term for convenience"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#linear-relationship",
    "href": "slides/slides-24-slr-interpretation.html#linear-relationship",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear relationship",
    "text": "Linear relationship\nSuppose we have the following data:\n\n\n\n\n\n\nObservations won’t fall exactly on a line, but do fall around a straight line, so maybe a linear relationship makes sense!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#fitted-values",
    "href": "slides/slides-24-slr-interpretation.html#fitted-values",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values",
    "text": "Fitted values\nSuppose we have some specific estimates \\(b_0\\) and \\(b_{1}\\). We could fit the linear relationship using these values as:\n\\[\n\\hat{y} = b_{0} + b_{1} x\n\\]\n\nThe hat on \\(y\\) signifies that this is an estimate: the estimated/fitted value of \\(y\\) given these specific values of \\(x\\), \\(b_{0}\\) and \\(b_{1}\\)\n\nWe observe \\(y\\), but can obtain a corresponding estimate \\(\\hat{y}\\)\n\nNote that the fitted value is obtained without the error"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#fitted-values-cont.",
    "href": "slides/slides-24-slr-interpretation.html#fitted-values-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values (cont.)",
    "text": "Fitted values (cont.)\n\n\n\n\n\n\nSuppose our estimated line is the yellow one\nEvery observed value \\(y_{i}\\) has a corresponding fitted value \\(\\hat{y}_{i}\\); the above plot just shows three specific examples"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#residual",
    "href": "slides/slides-24-slr-interpretation.html#residual",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual",
    "text": "Residual\nResiduals are the remaining variation in the data after fitting a model.\n\\[\n\\text{data} = \\text{fit} + \\text{residual}\n\\]\n\nFor each observation \\(i\\), we obtain residual \\(e_{i}\\) via:\n\n\n\\[y_{i} = \\hat{y}_{i} + e_{i} \\quad \\Rightarrow \\quad e_{i} = \\hat{y}_{i} - y_{i}\\]\n\n\nResidual = difference between observed and expected\nSince each observation has a fitted value, each observation has a residual\n\nIn the linear regression case, the residual is indicated by the vertical dashed line\n\nWhat is the ideal value for a residual?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#residual-cont.",
    "href": "slides/slides-24-slr-interpretation.html#residual-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual (cont.)",
    "text": "Residual (cont.)\n\n\n\n\n\n\nResidual values for the three highlighted observations:\n\n\n\n\n \n  \n    x \n    y \n    y_hat \n    residual \n  \n \n\n  \n    -2.991 \n    2.481 \n    -0.130 \n    -2.611 \n  \n  \n    -1.005 \n    -1.302 \n    0.691 \n    1.994 \n  \n  \n    3.990 \n    3.929 \n    2.757 \n    -1.172"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#residual-plot",
    "href": "slides/slides-24-slr-interpretation.html#residual-plot",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot",
    "text": "Residual plot\n\nResiduals are very helpful in evaluating how well a model fits a set of data\nResidual plot: original \\(x\\) values plotted against their corresponding residuals on \\(y\\)-axis"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#residual-plot-cont.",
    "href": "slides/slides-24-slr-interpretation.html#residual-plot-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot (cont.)",
    "text": "Residual plot (cont.)\nResidual plots can be useful for identifying characteristics/patterns that remain in the data even after fitting a model.\n\n\nJust because you fit a model to data, does not mean the model is a good fit!\n\n\n\n\n\n\n\n\n\nCan you identify any patterns remaining in the residuals?\n\nSorry! The residuals shown here are taken as \\(y_{i} - \\hat{y}_{i}\\)!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#describing-linear-relationships",
    "href": "slides/slides-24-slr-interpretation.html#describing-linear-relationships",
    "title": "Introduction to Simple Linear Regression",
    "section": "Describing linear relationships",
    "text": "Describing linear relationships\nDifferent data may exhibit different strength of linear relationships:\n\n\n\n\n\n\nCan we quantify the strength of the linear relationship?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#correlation",
    "href": "slides/slides-24-slr-interpretation.html#correlation",
    "title": "Introduction to Simple Linear Regression",
    "section": "Correlation",
    "text": "Correlation\n\nCorrelation is describes the strength of a linear relationship between two variables\n\nThe observed sample correlation is denoted by \\(R\\)\nFormula (not important): \\(R = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left(\\frac{x_{i} - \\bar{x}}{s_x} \\right)\\left(\\frac{y_{i} - \\bar{y}}{s_y} \\right)\\)\n\n\n\n\n\nAlways takes a value between -1 and 1\n\n-1 = perfectly linear and negative\n1 = perfectly linear and positive\n0 = no linear relationship\n\nNonlinear trends, even when strong, sometimes produce correlations that do not reflect the strength of the relationship"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#different-lines",
    "href": "slides/slides-24-slr-interpretation.html#different-lines",
    "title": "Introduction to Simple Linear Regression",
    "section": "Different lines",
    "text": "Different lines\nThe following display the same set of 50 observations.\n\n\n\n\n\n\n\n\n\nWhich line would you say fits the data the best?\n\n\n\n\nThere are infinitely many choices of \\((b_{0}, b_{1})\\) that could be used to create a line\nWe want the BEST choice (i.e. the one that gives us the “line of best fit”)\n\n\nHow to define “best”?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#line-of-best-fit",
    "href": "slides/slides-24-slr-interpretation.html#line-of-best-fit",
    "title": "Introduction to Simple Linear Regression",
    "section": "Line of best fit",
    "text": "Line of best fit\nOne way to define a “best” is to choose the specific values of \\((b_{0}, b_{1})\\) that minimize the total residuals across all \\(n\\) data points. Results in following possible criterion:\n\nLeast absolute criterion: minimize sum of residual magnitudes:\n\n\n\\[\n|e_{1} | + |e_{2}| + \\ldots + |e_{n}|\n\\]\n\n\n\nLeast squares criterion: minimize sum of squared residuals:\n\n\n\n\\[\ne_{1}^2 + e_{2}^2 +\\ldots + e_{n}^2\n\\]\n\n\nThe choice of \\((b_{0}, b_{1})\\) that satisfy least squares criterion yields the least squares line, and will be our criterion for “best”\nOn previous slide, yellow line is the least squares line, whereas pink line is the least absolute line"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#linear-regression-model-1",
    "href": "slides/slides-24-slr-interpretation.html#linear-regression-model-1",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nRemember, our linear regression model is:\n\\[\ny = \\beta_{0} + \\beta_{1}x + \\epsilon\n\\]\n\nWhile not wrong, it can be good practice to be specific about an observation \\(i\\):\n\\[\ny_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i}, \\qquad i = 1,\\ldots, n\n\\]\n\n\nHere, we are stating that each observation \\(i\\) has a specific:\n\nexplanatory variable value \\(x_{i}\\)\nresponse variable value \\(y_{i}\\)\nerror/randomness \\(\\epsilon_{i}\\)"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#conditions-for-the-least-squares-line-line",
    "href": "slides/slides-24-slr-interpretation.html#conditions-for-the-least-squares-line-line",
    "title": "Introduction to Simple Linear Regression",
    "section": "Conditions for the least squares line (LINE)",
    "text": "Conditions for the least squares line (LINE)\nLike when using CLT, we should check some conditions before saying a linear regression model is appropriate!\n\nAssume for now that \\(x\\) is continuous numerical.\n\n\nLinearity: data should show a linear trend between \\(x\\) and \\(y\\)\nIndependence: the observations \\(i\\) are independent of each other\n\ne.g. random sample\nNon-example: time-series data\n\nNormality/nearly normal residuals: the residuals should appear approximately Normal\n\nPossible violations: outliers, influential points (more on this later)\n\nEqual variability: variability of points around the least squares line remains roughly constant"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#running-example",
    "href": "slides/slides-24-slr-interpretation.html#running-example",
    "title": "Introduction to Simple Linear Regression",
    "section": "Running example",
    "text": "Running example\nWe will see how to check for these four LINE conditions using the cherry data from openintro.\n\n\n\n\n\n\n\ndiam\nvolume\n\n\n\n\n8.3\n10.3\n\n\n8.6\n10.3\n\n\n8.8\n10.2\n\n\n10.5\n16.4\n\n\n10.7\n18.8\n\n\n\n\n\n\n\nExplanatory variable \\(x\\): diam\nResponse variable \\(y\\): volume"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#linearity",
    "href": "slides/slides-24-slr-interpretation.html#linearity",
    "title": "Introduction to Simple Linear Regression",
    "section": "1. Linearity",
    "text": "1. Linearity\nAssess before fitting the linear regression model by making a scatterplot of \\(x\\) vs. \\(y\\):\n\n\n\n\n\n\nDoes there appear to be a linear relationship between diameter and volume?\n\nI would say yes"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#independence",
    "href": "slides/slides-24-slr-interpretation.html#independence",
    "title": "Introduction to Simple Linear Regression",
    "section": "2. Independence",
    "text": "2. Independence\nAssess before fitting the linear regression model by understanding how your data were sampled.\n\nThe cherry data do not explicitly say that the trees were randomly sampled, but it might be a reasonable assumption\n\n\nAn example where independence is violated:\n\n\n\n\n\n\n\n\nHere, the data are a time series, where observation at time point \\(i\\) depends on the observation at time \\(i-1\\).\n\nSuccessive/consecutive observations are highly correlated"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#fitting-the-model",
    "href": "slides/slides-24-slr-interpretation.html#fitting-the-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting the model",
    "text": "Fitting the model\n\n\n\nAt this point, it is time to actually fit our model\n\\[\n\\text{volume} = \\beta_{0} + \\beta_{1} \\text{diameter} +\\epsilon\n\\]\n\nAfter fitting the model, we get the following estimates: \\(b_{0}= -36.94\\) and \\(b_{1} = 5.07\\). So our fitted model is:\n\n\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nRemember: the “hat” denotes an estimated/fitted value!\n\n\n\nWe will soon see how \\(b_{0}\\) and \\(b_{1}\\) are calculated and how to interpret them\nThe next two checks can only occur after fitting the model."
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#nearly-normal-residuals",
    "href": "slides/slides-24-slr-interpretation.html#nearly-normal-residuals",
    "title": "Introduction to Simple Linear Regression",
    "section": "3. Nearly normal residuals",
    "text": "3. Nearly normal residuals\nAssess after fitting the model by obtaining residuals and making a histogram.\n\nRemember, residuals are \\(\\hat{y}_{i} - y_{i}\\)\n\n\n\n\n\ncherry |>\n  mutate(volume_hat = -36.94 + 5.07*diam) |>\n  mutate(residual = volume_hat - volume) \n\n\n\n\n\n \n  \n    diam \n    volume \n    volume_hat \n    residual \n  \n \n\n  \n    8.3 \n    10.3 \n    5.108 \n    -5.192 \n  \n  \n    8.6 \n    10.3 \n    6.628 \n    -3.672 \n  \n  \n    8.8 \n    10.2 \n    7.641 \n    -2.559 \n  \n  \n    10.5 \n    16.4 \n    16.253 \n    -0.147 \n  \n  \n    10.7 \n    18.8 \n    17.266 \n    -1.534 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo the residuals appear approximately Normal?\n\nI think so!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#equal-variance",
    "href": "slides/slides-24-slr-interpretation.html#equal-variance",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance",
    "text": "4. Equal variance\nAssess after fitting the model by examining a residual plot and looking for patterns.\n\n\nA good residual plot:\n\n\n\n\n\n\nA bad residual plot:\n\n\n\n\n\n\n\nWe usually have a horizontal line at 0 to compare residuals to"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#equal-variance-cont.",
    "href": "slides/slides-24-slr-interpretation.html#equal-variance-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance (cont.)",
    "text": "4. Equal variance (cont.)\nLet’s examine the residual plot of our fitted model for the cherry data:\n\n\n\n\n\n\nBased on this plot, I would say the equal variance condition is not perfectly met.\n\nSome of the variability in the errors appear related to diameter"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#parameter-estimates",
    "href": "slides/slides-24-slr-interpretation.html#parameter-estimates",
    "title": "SLR coefficient estimates",
    "section": "Parameter estimates",
    "text": "Parameter estimates\n\nLike in previous topics, we have to estimate the parameters using data\nWe want to estimate \\(\\beta_{0}\\) and \\(\\beta_{1}\\) using the \\((x_{i}, y_{i})\\)\n\nIn practice, we let software do this for us\n\nHowever, we can derive the least-squares estimates using properties of the least-squares line"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#estimating-slope-and-intercept",
    "href": "slides/slides-24-slr-interpretation.html#estimating-slope-and-intercept",
    "title": "SLR coefficient estimates",
    "section": "Estimating slope and intercept",
    "text": "Estimating slope and intercept\n\n\nFirst obtain \\(b_{1}\\):\n\n\\[\nb_{1} =\\frac{s_{y}}{s_{x}} R\n\\]\nwhere:\n\n\n\\(s_{x}\\) and \\(s_{y}\\) are the sample standard deviations of the explanatory and response variables\n\\(R\\) is the correlation between \\(x\\) and \\(y\\)\n\n\n\nThen obtain \\(b_{0}\\):\n\n\\[b_{0} = \\bar{y} - b_{1} \\bar{x}\\] where\n\n\n\\(\\bar{y}\\) is the sample mean of the response variable\n\\(x\\) is the sample mean of the explanatory variable\n\n\n\n\n\n\nTake STAT 0211 or 0311 to see where these formulas come from!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#fitting-cherry-model-by-hand",
    "href": "slides/slides-24-slr-interpretation.html#fitting-cherry-model-by-hand",
    "title": "SLR coefficient estimates",
    "section": "Fitting cherry model (by hand)",
    "text": "Fitting cherry model (by hand)\n\n\n\nVerify estimates \\(b_{0} = -36.94\\) and \\(b_{1} = 5.07\\) from our model for the cherry data:\n\n\n\ncherry |>\n  pivot_longer(cols = c(diam, volume), \n               names_to = \"variable\", \n               values_to = \"val\") |>\n  select(-height) |>\n  group_by(variable) |>\n  summarise(mean = mean(val), s = sd(val)) \n\n\n\n\n\n \n  \n    variable \n    mean \n    s \n  \n \n\n  \n    diam \n    13.248 \n    3.138 \n  \n  \n    volume \n    30.171 \n    16.438 \n  \n\n\n\n\n\n\n\nR <- cor(cherry$diam, cherry$volume)\nR\n\n[1] 0.9671194\n\n\n\nWhat does this value of \\(R\\) tell us?\n\n\n\n\n\n\n\n\n\n\nSet-up the calculations:\n\n\\(b_{1} = \\frac{s_{y}}{s_{x}} R\\)\n\\(b_{0} = \\bar{y} -b_{1} \\bar{x}\\)\n\n\n\n\n\n\\(b_{1} = \\frac{16.438}{3.138} \\times 0.967 = 5.07\\)\n\\(b_{0} = 30.171 - 5.07 \\times 13.248 = -36.94\\)\nWhat do these numbers really mean?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#housekeeping",
    "href": "slides/slides-24-slr-interpretation.html#housekeeping",
    "title": "SLR coefficient estimates",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nNo TA hours tonight\nWill discuss details of Midterm 2 next week!\nRevisions for proposals due Saturday 11:59pm"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#intercept-interpretation",
    "href": "slides/slides-24-slr-interpretation.html#intercept-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Intercept interpretation",
    "text": "Intercept interpretation\nOur fitted model is \\(\\hat{y} = b_{0} + b_{1}x\\).\n\nTo interpret the estimate of the intercept coefficient \\(b_{0}\\), simply plug in \\(x= 0\\):\n\n\\[\n\\hat{y} = b_{0} + b_{1} x = b_{0} + b_{1}(0) = b_{0}\n\\]\n\nSo, the intercept describes the average/expected value of the response variable \\(y\\) if \\(x=0\\)"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#intercept-in-cherry-model",
    "href": "slides/slides-24-slr-interpretation.html#intercept-in-cherry-model",
    "title": "SLR coefficient estimates",
    "section": "Intercept in cherry model",
    "text": "Intercept in cherry model\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nInterpretation of intercept in context: for a tree with a diameter of 0 inches, the expected volume would be -36.94 cubic feet\n\nThis interpretation is mathematically correct, but practically speaking is useless\n\nThe intercept’s interpretation only makes sense when a value of \\(x=0\\) for the explanatory variable is plausible!\n\nThis is typically not the case/relevant in many applications\nTrees with 0 diameter are not able to sampled"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#slope-interpretation",
    "href": "slides/slides-24-slr-interpretation.html#slope-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Slope interpretation",
    "text": "Slope interpretation\n\nLet \\(\\hat{y}_{1}\\) be the estimated response for a given value of \\(x\\), so \\(\\hat{y}_{1} = b_{0} + b_{1} x\\)\nWhat happens when we increase \\(x\\) by 1?\nLet \\(\\hat{y}_{2}\\) be the estimated response for \\(x +1\\):\n\n\n\\[\n\\begin{align*}\n\\hat{y}_{2} &= b_{0} + b_{1} (x + 1)  \\\\\n&= \\color{orange}{b_{0} + b_{1}x}  + b_{1} \\\\\n&= \\color{orange}{\\hat{y}_{1}} + b_{1} \\Rightarrow \\\\\nb_{1} &= \\hat{y}_{2} - \\hat{y}_{1}\n\\end{align*}\n\\]\n\n\nInterpretation: for a 1 unit increase in the explanatory variable \\(x\\), we expect the response variable to change by \\(b_{1}\\) units"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#slope-in-cherry-model",
    "href": "slides/slides-24-slr-interpretation.html#slope-in-cherry-model",
    "title": "SLR coefficient estimates",
    "section": "Slope in cherry model",
    "text": "Slope in cherry model\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nInterpretation in context: for every 1 inch increase in diameter, we expect that volume of cherry trees to increase by 5.07 cubic feet"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-elmhurst",
    "href": "slides/slides-24-slr-interpretation.html#example-elmhurst",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst",
    "text": "Example: elmhurst\nThe elmhurst dataset from openintro provides a random sample of 50 students gift aid for students at Elmhurst College.\n\nWe will examine the relationship between the family income of the student and the gift aid that student received (in $1000s)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre the first two conditions of LINE satisfied?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-elmhurst-cont.",
    "href": "slides/slides-24-slr-interpretation.html#example-elmhurst-cont.",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst (cont.)",
    "text": "Example: elmhurst (cont.)\n\n\n\n\n\nWe run the model in R, and the output looks something like this:\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    24.319 \n    1.291 \n    18.831 \n    0 \n  \n  \n    family_income \n    -0.043 \n    0.011 \n    -3.985 \n    0 \n  \n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nThe values in the estimate column are our \\(b_{0}\\) and \\(b_{1}\\):\n\n\n\\(b_{0} =\\) ? and \\(b_{1} =\\) ?\nWhat do you think the second column is?\n\n\n\nWrite out our fitted model in context"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-elmhurst-model",
    "href": "slides/slides-24-slr-interpretation.html#example-elmhurst-model",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst model",
    "text": "Example: elmhurst model\n\\[\n\\widehat{\\text{aid}} = 24.319 + -0.043 \\times \\text{family_income}\n\\]\n\nBefore we interpret the coefficients, we should verify that the linear model is appropriate for the data!\n\n\n\n\n\n\n\n\n\n\nDo you believe the last two conditions of LINE are satisfied?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-elmhurst-interpretation",
    "href": "slides/slides-24-slr-interpretation.html#example-elmhurst-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst interpretation",
    "text": "Example: elmhurst interpretation\n\\[\n\\widehat{\\text{aid}} = 24.319 + -0.043 \\times \\text{family_income}\n\\]\n\n\n\n\nInterpret the slope in context\nInterpret the intercept in context\nIs the meaning of the intercept relevant?\n\n\n\n\nSlope: for every $1000 increase in family income, we expect that the student’s gift aid will decrease by $43.\nIntercept: for a student whose family income is $0, we expect that average amount of aid they will receive is $2.4319^{4}\nSince a family could have an income of $0, the intercept does seem relevant"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#words-of-caution",
    "href": "slides/slides-24-slr-interpretation.html#words-of-caution",
    "title": "SLR coefficient estimates",
    "section": "Words of caution",
    "text": "Words of caution\n\nThe estimates from the fitted model will always be imperfect\n\nThe linear equation is good at capturing trends, no individual outcome will be perfectly predicted\n\nDo not try to use the model for \\(x\\) values beyond the range of the observed \\(x\\)!\n\nThe true relationship between \\(x\\) and \\(y\\) is almost always much more complex than our simple line\nWe do not know how the relationship behaves outside our limited window"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#extrapolation",
    "href": "slides/slides-24-slr-interpretation.html#extrapolation",
    "title": "SLR coefficient estimates",
    "section": "Extrapolation",
    "text": "Extrapolation\nSuppose we would like to use our fitted model to estimate the expected gift aid for someone whose family income is $1,000,000:\n\n\nFind the estimated gift aid (careful with units)\n\n\n\\(\\widehat{\\text{aid}} = 24.319 + -0.043 \\times 1000 = -18.681\\)\nThis is ridiculous!\n\nThis is an example of extrapolation: using the model to estimate values outside the scope of the original data\n\nWe should never extrapolate!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#describing-the-fit",
    "href": "slides/slides-24-slr-interpretation.html#describing-the-fit",
    "title": "SLR coefficient estimates",
    "section": "Describing the fit",
    "text": "Describing the fit\n\nRecall sample correlation \\(R\\) describes the linear relationship between variables \\(x\\) and \\(y\\)\nWe typically use the coefficient of determination or \\(R^2\\) (R-squared) to describe strength of linear fit\n\nDescribes amount of variation in \\(y\\) that is explained by predictor \\(x\\) in the least squares line\n\nIt turns out that \\(R^2\\) in SLR is exactly … \\(R\\) squared (i.e. the square of the sample correlation)\n\n\nWhat are the possible values of \\(R^2\\)? What are desirable values of \\(R^2\\)?"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-elmhurst-model-fit",
    "href": "slides/slides-24-slr-interpretation.html#example-elmhurst-model-fit",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst model fit",
    "text": "Example: elmhurst model fit\n\n\n\n\nThe sample correlation between family income and aid is \\(R=\\) -0.499\nSo the coefficient of determination is \\(R^2 = (-0.499)^2 = 0.249\\)\n\nInterpretation: using a linear model, about 24.9% of the variability in aid received by the student is explained by family income"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#categorical-predictor-with-two-levels",
    "href": "slides/slides-24-slr-interpretation.html#categorical-predictor-with-two-levels",
    "title": "SLR coefficient estimates",
    "section": "Categorical predictor with two levels",
    "text": "Categorical predictor with two levels\n\nRemember that the different groupings/categories of categorical variables are called levels\n\nNow assume that \\(x\\) is categorical with two levels\n\nRunning example: the possum data from openintro\n\nResponse variable: tail_l (tail length in cm)\nExplanatory variable: pop (either Vic or other)\n\nMaybe we would think to write our regression as\n\n\n\\[\\text{tail length} = \\beta_{0} + \\beta_{1} \\text{pop} + \\epsilon\\]\n\n\n\nWhy doesn’t this work?\n\n\nFunctions require a numerical input!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#indicator-variables",
    "href": "slides/slides-24-slr-interpretation.html#indicator-variables",
    "title": "SLR coefficient estimates",
    "section": "Indicator variables",
    "text": "Indicator variables\nWe need a mechanism to convert the categorical levels into numerical form!\n\n\n\nThis is achieved through an indicator variable which takes the value 1 for one specific level and the value 0 otherwise:\n\n\n\\[\n\\text{pop_other} = \\begin{cases}\n0 & \\text{ if  pop = Vic} \\\\\n1 & \\text{ if  pop = other}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n \n  \n    tail_l \n    pop \n    pop_new \n  \n \n\n  \n    38.0 \n    other \n    1 \n  \n  \n    34.0 \n    Vic \n    0 \n  \n  \n    36.0 \n    Vic \n    0 \n  \n  \n    36.5 \n    Vic \n    0 \n  \n  \n    41.5 \n    other \n    1 \n  \n\n\n\n\n\n\n\n\n\nThe level that corresponds to 0 is called the base level\n\nSo Vic is the base level\nChoosing which level is the base level can sometimes be important"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#example-possum-model",
    "href": "slides/slides-24-slr-interpretation.html#example-possum-model",
    "title": "SLR coefficient estimates",
    "section": "Example: possum model",
    "text": "Example: possum model\nThis yields the SLR model\n\\[\\text{tail length} = \\beta_{0} + \\beta_{1} \\text{pop_other} + \\epsilon\\]\n\nOur estimates are as follows:\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    35.935 \n    0.253 \n    142.065 \n    0 \n  \n  \n    popother \n    1.927 \n    0.339 \n    5.690 \n    0 \n  \n\n\n\n\n\n\n\n\nWrite out the equation of our fitted model"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#interpretation-of-coefficients",
    "href": "slides/slides-24-slr-interpretation.html#interpretation-of-coefficients",
    "title": "SLR coefficient estimates",
    "section": "Interpretation of coefficients",
    "text": "Interpretation of coefficients\nOur fitted model is:\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927 \\times \\text{pop_other}\\]\n\nLet’s interpret the intercept by plugging in \\(0\\) for the explanatory variable:\n\n\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times 0 = 35.935\\]\n\n\nBut wait, when is \\(\\text{pop_other} = 0\\)? When the possum is from Victoria!\nSo when \\(x\\) is categorical, the interpretation of \\(b_{0}\\) is the expected value of the response variable for the base level of \\(x\\)\n\n\n\n\n\nInterpret \\(b_{0}\\) in context\n\n\n\n\nThe expected tail length of possums from Victoria is 35.935 cm"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#intercept-for-categorical-x",
    "href": "slides/slides-24-slr-interpretation.html#intercept-for-categorical-x",
    "title": "SLR coefficient estimates",
    "section": "Intercept for categorical \\(x\\)",
    "text": "Intercept for categorical \\(x\\)\nOur fitted model is:\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927 \\times \\text{pop_other}\\]\n\nLet’s interpret the intercept by plugging in \\(0\\) for the explanatory variable:\n\n\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times 0 = 35.935\\]\n\n\nBut wait, when is \\(\\text{pop_other} = 0\\)? When the possum is from Victoria!\n\nSo when \\(x\\) is categorical, the interpretation of \\(b_{0}\\) is the expected value of the response variable for the base level of \\(x\\)\n\n\nInterpret \\(b_{0}\\) in context\n\n\nThe expected tail length of possums from Victoria is 35.935 cm"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#slope-for-categorical-x",
    "href": "slides/slides-24-slr-interpretation.html#slope-for-categorical-x",
    "title": "SLR coefficient estimates",
    "section": "Slope for categorical \\(x\\)",
    "text": "Slope for categorical \\(x\\)\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times \\text{pop_other}\\]\n\\[\n\\text{pop_other} = \\begin{cases}\n0 & \\text{ if  pop = Vic} \\\\\n1 & \\text{ if  pop = other}\n\\end{cases}\n\\]\n\nRemember, the slope coefficient is interpreted as the expected change in \\(y\\) for a one unit increase in \\(x\\)\n\nWhat does it mean for the indicator variable to increase by one unit here?\n\n\n\\(\\text{pop_other}\\) increases by one unit by going from 0 to 1. This corresponds to a pop value of “other”\n\n\nWhen \\(x\\) is categorical, the interpretation of \\(b_{1}\\) is the expected change in \\(y\\) when moving from the base level to the non-base level\n\n\nTry interpreting \\(b_{1}\\) in context!"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#slope-for-categorical-x-cont.",
    "href": "slides/slides-24-slr-interpretation.html#slope-for-categorical-x-cont.",
    "title": "SLR coefficient estimates",
    "section": "Slope for categorical \\(x\\) (cont.)",
    "text": "Slope for categorical \\(x\\) (cont.)\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times \\text{pop_other}\\]\n\\[\n\\text{pop_other} = \\begin{cases}\n0 & \\text{ if  pop = Vic} \\\\\n1 & \\text{ if  pop = other}\n\\end{cases}\n\\]\n\nInterpretation of slope: possums from outside of Victoria are expected to have tail lengths about 1.927 cm longer than possums from Victoria\nNote: interpretations for \\(b_{0}\\) and \\(b_{1}\\) for categorical \\(x\\) are the same as for numerical \\(x\\), but they have more specific/nuanced interpretations when placed in context"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#remark",
    "href": "slides/slides-24-slr-interpretation.html#remark",
    "title": "SLR coefficient estimates",
    "section": "Remark",
    "text": "Remark\n\nWhen \\(x\\) is categorical, the LINE conditions still need to hold\nWhen \\(x\\) only has two levels, the Linearity assumption will always be satisfied\nWe need to evaluate Nearly normal residuals and Equal variance for each level:"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#possum-example-cont.",
    "href": "slides/slides-24-slr-interpretation.html#possum-example-cont.",
    "title": "SLR coefficient estimates",
    "section": "possum example (cont.)",
    "text": "possum example (cont.)"
  },
  {
    "objectID": "live_code/slr1.html",
    "href": "live_code/slr1.html",
    "title": "Linear regression in R",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "slides/slides-23-slr-intro.html",
    "href": "slides/slides-23-slr-intro.html",
    "title": "Introduction to Simple Linear Regression",
    "section": "",
    "text": "Homework 7 due tonight!\nLast problem set is assigned today! Atypical due date: Wednesday 11/13"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html",
    "href": "slides/slides-24-slr-interpretation.html",
    "title": "SLR coefficient estimates",
    "section": "",
    "text": "No TA hours tonight\nWill discuss details of Midterm 2 next week!\nRevisions for proposals due Saturday 11:59pm"
  },
  {
    "objectID": "slides/slides-24-slr-interpretation.html#assessing-linear-fit",
    "href": "slides/slides-24-slr-interpretation.html#assessing-linear-fit",
    "title": "SLR coefficient estimates",
    "section": "Assessing linear fit",
    "text": "Assessing linear fit\n\nWhen \\(x\\) is categorical, the LINE conditions still need to hold\nWhen \\(x\\) only has two levels, the Linearity assumption will always be satisfied\nWe need to evaluate Nearly normal residuals and Equal variance for each level:"
  },
  {
    "objectID": "practice_probs/practice-24-slr.html",
    "href": "practice_probs/practice-24-slr.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "\\((^*)\\) Researchers studying anthropometry collected body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender for 507 physically active individuals. They are interested in the relationship between height (cm) and shoulder girth (cm). They would like create linear regression model for height using shoulder girth as the predictor.\n\n\n\n\n\n\nThe mean shoulder girth is 107.20 cm with a standard deviation of 10.37 cm. The mean height is 171.14 cm with a standard deviation of 9.41 cm. The correlation between height and shoulder girth is 0.67.\n\nWrite the equation of the fitted regression line for predicting height.\nInterpret the slope and intercept in context.\nCalculate the \\(R^2\\) of the regression line and interpret it in context.\nA one year old has a shoulder girth of 56 cm. Would it be appropriate to use this linear model to predict the height of this child? If so, obtain the predicted height. If not, explain why not.\n\n2. Data on a random sample of 100 births for babies in North Carolina were obtained. We’d like to fit a linear regression model for the birth weight of the baby in pounds (weight) based on if the baby was born premature (premature). The premature variable is categorical with two levels: “premie” (if baby was born premature) and “full term” (if the baby was not born premature).\nWe run the model in R. The estimated coefficients are as follows:\n\nbirths_lm <- lm(weight ~ premature, data = births)\ncoef(births_lm)\n\n    (Intercept) prematurepremie \n       7.426357       -2.716833 \n\n\n\nWhich level of the variable premature is the base level? How can you tell?\nWrite out the fitted model for estimated birth weight of a baby.\nInterpret the slope and intercept of the model in context.\nWhat is the estimated weight of a baby born premature?"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#housekeeping",
    "href": "slides/slides-25-slr-inference.html#housekeeping",
    "title": "Inference in SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nLast set of homework problems are released today!\nOffice hours changed this week:\n\nToday: 2-3pm only\nWednesday 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#variability-of-coefficient-estimates",
    "href": "slides/slides-25-slr-inference.html#variability-of-coefficient-estimates",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates\n\nRemember, a linear regression is fit using a sample of data\nDifferent samples from the same population will yield different point estimates of \\((b_{0}, b_{1})\\)\n\nI will generate 30 data points under the following model: \\(y = 1 + 0.5x+\\epsilon\\)\n\nHow? Randomly generate some \\(x\\) and \\(\\epsilon\\) values and then plug into model to get corresponding \\(y\\)\n\nFit SLR to these \\((x,y)\\) data, and obtain estimates \\((b_{0}, b_{1})\\)\nRepeat this 50 times"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#variability-of-coefficient-estimates-1",
    "href": "slides/slides-25-slr-inference.html#variability-of-coefficient-estimates-1",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#what-are-we-interested-in",
    "href": "slides/slides-25-slr-inference.html#what-are-we-interested-in",
    "title": "Inference in SLR",
    "section": "What are we interested in?",
    "text": "What are we interested in?\nRemember: we fit SLR to understand how \\(x\\) is (linearly) related to \\(y\\):\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\n\nWhat would a value of \\(\\beta_{1} = 0\\) mean?\n\n\nIf \\(\\beta_{1} = 0\\), then the effect of \\(x\\) disappears and there is in fact no linear relationship between \\(x\\) and \\(y\\)\n\nWe don’t know \\(\\beta_{1}\\), so let’s look at estimate \\(b_{1}\\):\n\n\nIs an estimate of \\(b_{1}= 0\\) a convincing evidence of no relationship? What if \\(b_{1} = 0.1\\)?\n\nIt depends! We saw that \\(b_{1}\\) varies by sample! So let’s perform inference for \\(\\beta_{1}\\)"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#running-example-teaching-evaluations",
    "href": "slides/slides-25-slr-inference.html#running-example-teaching-evaluations",
    "title": "Inference in SLR",
    "section": "Running example: teaching evaluations",
    "text": "Running example: teaching evaluations\nData on 463 courses at UT Austin were obtained to answer the question: “What factors explain differences in instructor teaching evaluation scores?”\n\nOne hypothesis was that more attractive instructors receive better teaching evaluations\nWe will look at the variables:\n\nscore: course instructor’s average teaching score, where average is calculated from all students in that course. Scores ranged from 1-5, with 1 being lowest.\nbty_avg: course instructor’s average “beauty” score, where average is calculated from six student evaluations of “beauty”. Scores ranged from 1-10, with 1 being lowest.\n\n\n\n\n\nDoes this line really have a non-zero slope?"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#hypothesis-test-for-slope",
    "href": "slides/slides-25-slr-inference.html#hypothesis-test-for-slope",
    "title": "Inference in SLR",
    "section": "Hypothesis test for slope",
    "text": "Hypothesis test for slope\n\nWe have the following hypotheses:\n\n\\(H_{0}: \\beta_{1} = 0\\): the true linear model has slope zero\n\\(H_{A}: \\beta_{1} \\neq 0\\): the true linear model has a non-zero slope. An instructor’s average beauty score is predictive of their average teaching evaluation score.\n\nTo assess, we do what we usually do:\n\nCheck if methods are appropriate\nIf so: obtain an estimate, identify/estimate standard error of the estimate, find an appropriate test statistic, and calculate p-value\n\n\nThe output from lm() actually does all of this for us, but we will see how the test statistic and p-value are calculated!"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#teaching-evaluations-model-assessment",
    "href": "slides/slides-25-slr-inference.html#teaching-evaluations-model-assessment",
    "title": "Inference in SLR",
    "section": "Teaching evaluations: model assessment",
    "text": "Teaching evaluations: model assessment\nWe fit the model in R, and obtain the following plots.\n\nAre all conditions of LINE met?"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#looking-at-lm-output",
    "href": "slides/slides-25-slr-inference.html#looking-at-lm-output",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\nlibrary(broom)\neval_mod <- lm(score ~ bty_avg, data = evals)\neval_mod |>\n  tidy()\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\nAssuming the linear model is appropriate, interpret the coefficients!\n\n\nIntercept: an instructor with an average beauty score of 0 would be expected to have an average evaluation score of 3.88\nSlope: for every one point increase in average beauty score an instructor receives, their evaluation score is expected to incrase by 0.067 points"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#making-conclusion",
    "href": "slides/slides-25-slr-inference.html#making-conclusion",
    "title": "Inference in SLR",
    "section": "Making conclusion",
    "text": "Making conclusion\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\n\n\n\nWhat would your p-value be if your alternative was \\(H_{A}: \\beta_{1} > 0\\)? What would your conclusion be?\n\n\n\n\nThe p-value would simply be half of the p-value reported in the table above\nThe data provide convincing evidence that there is a positive relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#confidence-intervals",
    "href": "slides/slides-25-slr-inference.html#confidence-intervals",
    "title": "Inference in SLR",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\nWe can also construct confidence intervals using the output from lm()! Remember:\n\\[\n\\text{CI} = \\text{point est.} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nCritical value also comes from \\(t_{n-2}\\) distribution\nSuppose we want a 95% confidence intervals for \\(\\beta_{1}\\):\n\n\nWhat code would you use to obtain critical value?\n\nqt(0.975, 461) = 1.97\n\nSo our 95% CI for \\(\\beta_{1}\\) is: \\(0.067 \\pm 1.97 \\times 0.016 = (0.035, 0.099)\\)"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#running-example-evals-data",
    "href": "slides/slides-25-slr-inference.html#running-example-evals-data",
    "title": "Inference in SLR",
    "section": "Running example: evals data",
    "text": "Running example: evals data\nData on 463 courses at UT Austin were obtained to answer the question: “What factors explain differences in instructor teaching evaluation scores?”\n\nOne hypothesis was that more attractive instructors receive better teaching evaluations\nWe will look at the variables:\n\nscore: course instructor’s average teaching score, where average is calculated from all students in that course. Scores ranged from 1-5, with 1 being lowest.\nbty_avg: course instructor’s average “beauty” score, where average is calculated from six student evaluations of “beauty”. Scores ranged from 1-10, with 1 being lowest."
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#teaching-evaluations-data",
    "href": "slides/slides-25-slr-inference.html#teaching-evaluations-data",
    "title": "Inference in SLR",
    "section": "Teaching evaluations data",
    "text": "Teaching evaluations data\n\n\nDoes this line really have a non-zero slope?"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#remarks",
    "href": "slides/slides-25-slr-inference.html#remarks",
    "title": "Inference in SLR",
    "section": "Remarks",
    "text": "Remarks\n\nNote: for \\(\\beta_{1}\\), the null hypothesis is always of the form \\(H_{0}: \\beta_{1} = 0\\)\nLINE conditions must be met for underlying mathematical and probability theory to hold here! If not met, simulation-based methods would be a better choice\nHere, the Independence conditions did not seem to be met\n\nTake STAT 412 or other course to learn how to incorporate dependencies between observations!\n\nSo what can we say?\n\nThe results suggested by our inference should be viewed as preliminary, and not conclusive\nFurther investigation is certainly warranted!\nChecking LINE can be very subjective, but that’s how real-world analysis will be!"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#looking-at-lm-output-1",
    "href": "slides/slides-25-slr-inference.html#looking-at-lm-output-1",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\n\n\nestimate: the observed point estimate (\\(b_{0}\\) or \\(b_{1}\\))\nstd.error: the estimated standard error of the estimate\n\n\n\nstatistic: the value of the test statistic\np.value: p-value associated with the two-sided alternative \\(H_{A}: \\beta_{1} \\neq 0\\)\n\n\n\n\nLet’s confirm the test statistic calculation:\n\n\n\\[\nt = \\frac{\\text{observed} - \\text{null}}{\\text{SE}_{0}} =\\frac{b_{1,obs} - \\beta_{1, 0}}{\\widehat{\\text{SE}}_{0}} = \\frac{0.066637 - 0}{0.0162912} = 4.0903823 \\sim t_{df}\n\\]\nwhere \\(df = n-2\\)"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#looking-at-lm-output-cont.",
    "href": "slides/slides-25-slr-inference.html#looking-at-lm-output-cont.",
    "title": "Inference in SLR",
    "section": "Looking at lm() output (cont.)",
    "text": "Looking at lm() output (cont.)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\nLet’s confirm the p-value calculation:\n\\[\\text{p-value} = \\text{Pr}(T \\geq 4.09) + \\text{Pr}(T \\leq -4.09)\\] where \\(T \\sim t_{461}\\)\n\nSo our p-value is: 2 * (1 - pt(4.09, 461)) = 5.0827307^{-5}"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#p-value-and-conclusion",
    "href": "slides/slides-25-slr-inference.html#p-value-and-conclusion",
    "title": "Inference in SLR",
    "section": "p-value and conclusion",
    "text": "p-value and conclusion\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\nLet’s confirm the p-value calculation:\n\\[\\text{p-value} = \\text{Pr}(T \\geq 4.09) + \\text{Pr}(T \\leq -4.09)\\] where \\(T \\sim t_{461}\\)\n\nSo our p-value is: 2 * (1 - pt(4.09, 461)) = 5.0827307^{-5}\nAssuming the LINE conditions are met: since our p-value 5.0827307^{-5} is extremely small, we would reject \\(H_{0}\\) at any reasonable significant level. Thus, the data provide convincing evidence that there is a linear relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#different-h_a",
    "href": "slides/slides-25-slr-inference.html#different-h_a",
    "title": "Inference in SLR",
    "section": "Different \\(H_{A}\\)",
    "text": "Different \\(H_{A}\\)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\n\n\nWhat would your p-value be if your alternative was \\(H_{A}: \\beta_{1} > 0\\)? What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\geq 4.09)\\) = (1-pt(4.09, 461) = 2.5413653^{-5}\nThe data provide convincing evidence that there is a positive relationship between instructor’s beauty score and evaluation score.\n\n\n\nWhat would your p-value be if your alternative was \\(H_{A}: \\beta_{1} < 0\\)? What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\leq 4.09)\\) = pt(4.09, 461) = 0.9999745\nThe data do not provide convincing evidence that there is a negative relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-25-slr-inference.html#recap",
    "href": "slides/slides-25-slr-inference.html#recap",
    "title": "Inference in SLR",
    "section": "Recap",
    "text": "Recap\n\nLearned how to interpret slope and intercept of fitted model\n\n\\(b_0\\) is expected value of response when \\(x=0\\)\n\\(b_{1}\\) is expected change in \\(y\\) for a one unit increase in \\(x\\)\n\nWhen explanatory \\(x\\) is categorical, we have a slightly more nuanced interpretation\nCoefficient of determination \\(R^2\\) assesses strength of linear model fit"
  },
  {
    "objectID": "live_code/slr_extras.html",
    "href": "live_code/slr_extras.html",
    "title": "broom and factors for SLR",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\nLet’s bring back our cherry_lm model:"
  },
  {
    "objectID": "live_code/slr1.html#pretty-output-using-broom",
    "href": "live_code/slr1.html#pretty-output-using-broom",
    "title": "Linear regression in R",
    "section": "Pretty output using broom",
    "text": "Pretty output using broom\nThe broom package has a function that turns the output from lm() into tidy, data frame form. We simply pass in the fitted model into the function of interest!\n\n\nInstall the package either by typing install.packages(\"broom\") in your Console, or in the Packages pane.\n\ntidy()\nThe function tidy() turns the information about the coefficients into a nice data frame:\n\nlibrary(broom)\ntidy(elmhurst_lm)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  <chr>            <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4\n\n\nSince this is in data frame form, each column is a variable, and all of our dplyr wrangling functions work!\n\ntidy(elmhurst_lm) |>\n  pull(estimate)\n\n[1] 24.31932901 -0.04307165\n\n\n\n\nglance()\nThe function glance() turns the extra information about the model fit into nice data frame:\n\nglance(elmhurst_lm)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.249         0.233  4.78      15.9 0.000229     1  -148.  302.  308.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(elmhurst_lm) |>\n  pull(r.squared)\n\n[1] 0.2485582\n\n\n\n\naugment()\nThe function augment() takes a fitted SLR model input, and combines the x and y variables from the original data frame (i.e. family_income and gift_aid) with extra variables whose values come from the model fit\n\naugment(elmhurst_lm) |>\n  slice(1:3)\n\n# A tibble: 3 × 8\n  gift_aid family_income .fitted .resid   .hat .sigma  .cooksd .std.resid\n     <dbl>         <dbl>   <dbl>  <dbl>  <dbl>  <dbl>    <dbl>      <dbl>\n1     21.7         92.9     20.3   1.40 0.0204   4.83 0.000915      0.296\n2     27.5          0.25    24.3   3.16 0.0727   4.81 0.0185        0.686\n3     27.8         53.1     22.0   5.72 0.0321   4.76 0.0245        1.22 \n\n\nYou can see we have the new variables:\n\n.fitted: the fitted (estimated) values \\(\\hat{y}\\) for the corresponding observation\n.resid: the residual for the observation\n\n\n\nThe periods are important!\nWe can use the output from augment to plot histogram of residuals:\n\naugment(elmhurst_lm) |>\n  ggplot(aes(x = .resid)) +\n  geom_histogram(bins = 15)"
  },
  {
    "objectID": "midterms.html#preparation-1",
    "href": "midterms.html#preparation-1",
    "title": "Midterms",
    "section": "Preparation",
    "text": "Preparation\n\nThe best preparation you can do for the midterm is to go back through your notes and homework and be honest with yourself about what you do/don’t understand. This means going through the painful process of looking at feedback on Canvas. For the concepts that you need to practice more, try more problems (see below)!\nAnother way to prepare is to create your own study guide with summaries and examples of important concepts. As you study, it would be a good idea to compile a list of questions that you might have.\nWork on the practice problems that were distributed at the end of classes but not assigned.\nFor extra practice, additional review problems will soon be made available below. These questions are not necessarily representative of the typical scope and difficulty of individual exam questions. This review is not comprehensive, nor does it represent the expected amount of time for it will take for you to complete the midterm.\n\nExtra problems here and here\nVideo recap of probability"
  },
  {
    "objectID": "midterms.html#midterm-1",
    "href": "midterms.html#midterm-1",
    "title": "Midterms",
    "section": "Midterm 1",
    "text": "Midterm 1\n\nLogistics\n\nWhen and where: Thursday, 3/13/25 during class (75 minutes)\nWhat: content through end of Week 4 (i.e. through Simpson’s Paradox)\n\nThis includes homework and coding practices\nThe midterm will be done entirely in a .qmd that will be made available to you at the start of class 11:15am on 3/13. The midterm ends at 12:30pm, but you will have an extra 5 minutes to render the assignment and submit to Gradescope. If your submission is not in by 12:35pm, you will receive an automatic 25% penalty.\nNon-coding concepts are also fair game for the midterm!\n\nImportant: Prof. Tang will be proctoring the exam\n\nHowever, Prof. Tang will not help de-bug code or fix rendering issues.\n\nYou will not have a problem set assigned this week!\nFriday 3/14 office hours will be moved to Wednesday 3/12 3:15-4:15pm instead.\nThis midterm will be open note in the sense that your notes, my slides, and your homework/coding practices are all available to you.\n\n\n\nPreparation\n\nThe best preparation you can do for the midterm is to go through your homework and coding practices and be honest with yourself about what you do/don’t understand. This means going through the painful process of looking at feedback on Gradescope. For the concepts that you need to practice more, try more problems (see below)!\nJust because the midterm is open note, this does not mean you cannot study and prepare. You will not have time to try and re-learn what all the functions we learned do!\n\nI suggest going through each of the ggplot and dplyr functions that we’ve seen in the course and ensuring you know how they work and when to use them!\n\nFor extra practice, additional coding problems are made available below. These questions are not necessarily representative of the typical scope and difficulty of individual exam questions. This review is not comprehensive, nor does it represent the expected amount of time for it will take for you to complete the midterm.\n\nIn-class practice: rendered version\n\nSolutions (note that many problems have many different solutions)\n\nPractice 1: rendered version (solutions)\n\n.qmd template  .qmd \n\nPractice 2: rendered version (solutions)\n\n.qmd template  .qmd"
  },
  {
    "objectID": "midterms.html#preparation-2",
    "href": "midterms.html#preparation-2",
    "title": "Midterms",
    "section": "Preparation",
    "text": "Preparation\n\nThe best preparation you can do for the midterm is to go back through your notes and homework and be honest with yourself about what you do/don’t understand. This means going through the painful process of looking at feedback on Canvas. For the concepts that you need to practice more, try more problems (see below)!\nAnother way to prepare is to create your own study guide with summaries and examples of important concepts. As you study, it would be a good idea to compile a list of questions that you might have.\nWork on the practice problems that were distributed at the end of classes but not assigned.\nFor extra practice, additional review problems will soon be made available below. These questions are not necessarily representative of the typical scope and difficulty of individual exam questions. This review is not comprehensive, nor does it represent the expected amount of time for it will take for you to complete the midterm.\n\nExtra problems here and here\nVideo recap of probability"
  },
  {
    "objectID": "homework/hw8_r.html",
    "href": "homework/hw8_r.html",
    "title": "STAT 201: Homework 8 (R)",
    "section": "",
    "text": "We will examine data that were collected at Baystate Medical Center, Springfield, MA during 1986 on the birth weights of 189 babies, along with descriptive information about the mother. Researchers wanted to learn about risk factors for underweight babies. The variables are:\n\nlow: indicator of bwt less than 2.5 kg\nage: mother’s age in years\nlwt: mother’s weight in pounds at last menstrual period\nrace: mother’s race (1 = white, 2 = black, 3 = other)\nsmoke: smoking status during pregnancy (no or yes)\nptl: number of previous premature labours\nht: history of hypertension (0 = no, 1 = yes)\nui: presence of uterine irritability (0 = no, 1 = yes)\nftv: number of physician visits during the first trimester\nbwt: birth weight in grams\n\n\nLoad in the tidyverse and broom packages below. Then run the code chunk and take a look at the data.\n\n\nlibrary(readr)\nbirthwt <- read.csv(\"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/birthwt.csv\")\n# load other necessary packages here\n\n\nModify your data frame so that it only contains data for mothers with no history of hypertension.\n\n\n\n\n\nUsing your new data frame, fit a linear regression model for the birth weight of the baby using the smoke status of the mother as the explanatory variable. Store this as an object called birth_lm, then display summary information of the coefficients of birth_lm (“tidy” or not are both fine).\n\n\n\n\n\nProvide an example/scenario where the independence condition would be violated.\n\nAnswer:\n\nCheck if the normality condition is satisfied. Briefly explain in words why or why not. Be sure to have informative axis labels and title. Make sure the residuals are of the form \\(\\hat{y} - y\\).\n\n\n\n\nAnswer:\n\nBased off the model output, is there evidence of a linear relationship between the mother’s smoke status and the birth weight of the baby (for mothers with no history of hypertension)? Why or why not?\n\nAnswer:\n\nUsing code, obtain the \\(R^2\\) of the model and store it as a variable called r2. Using in-line code, report the the \\(R^2\\) of the model and interpret what it means in context.\n\n\n\n\nAnswer:\n\nDoes a significant linear relationship between \\(x\\) and \\(y\\) imply that a model is actually useful? Use your answers above to answer this question.\n\nAnswer:"
  },
  {
    "objectID": "coding_practice/coding-practice-25-slr.html",
    "href": "coding_practice/coding-practice-25-slr.html",
    "title": "SLR coding practice",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\nlibrary(broom)\n\n\nUsing the possum data from openintro, fit a linear regression for the length of heads for a possum using their tail lengths as a predictor. Store the model output as a variable called possum_lm and display information about the coefficients in tidy form using the appropriate function.\n\n\n\n\n\nCreate a residual plot of the fitted model using the augment() function and ggplot(). Try adding a horizontal dashed line at 0!\n\n\n\n\n\nSuppose we found a tail of a possum on the ground! We measure the tail to be 36.1 cm. Being as reproducible as possible, obtain the estimated head length of this squirrel by doing the following:\n\n\nCreate variable called x_pred that stores the value of the explanatory variable we’d like to obtain a prediction for.\nObtain the estimated coefficients from the tidy output by pull()-ing the relevant column. Store them as a variable called possum_coeffs.\nIndexing coeffs (i.e. using bracket notation) and using x, obtain the estimated head length and store this as a value called head_l_pred.\n\n\n# create x_pred\n\n# create possum_coeffs\n\n# create head_l_pred\n\nReport your answer using in-line code.\nAnswer:"
  },
  {
    "objectID": "live_code/slr_extras.html#pretty-output-using-broom",
    "href": "live_code/slr_extras.html#pretty-output-using-broom",
    "title": "broom and factors for SLR",
    "section": "Pretty output using broom",
    "text": "Pretty output using broom\nThe broom package has a function that turns the output from lm() into tidy, data frame form. We simply pass in the fitted model into the function of interest!\n\n\nInstall the package either by typing install.packages(\"broom\") in your Console, or in the Packages pane.\n\ntidy()\nThe function tidy() turns the information about the coefficients into a nice data frame:\n\nlibrary(broom)\ntidy(cherry_lm)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -36.9      3.37      -11.0 7.62e-12\n2 diam            5.07     0.247      20.5 8.64e-19\n\n\nSince this is in data frame, each column is a variable, and all of our dplyr wrangling functions work!\n\ntidy(cherry_lm) |>\n  pull(estimate)\n\n[1] -36.943459   5.065856\n\n\n\n\nglance()\nThe function glance() turns the extra information about the model fit into nice data frame:\n\nglance(cherry_lm)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.935         0.933  4.25      419. 8.64e-19     1  -87.8  182.  186.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(cherry_lm) |>\n  pull(r.squared)\n\n[1] 0.9353199\n\n\n\n\naugment()\nThe function augment() adds information about observations to the dataset:\n\naugment(cherry_lm) |>\n  slice(1:3)\n\n# A tibble: 3 × 8\n  volume  diam .fitted .resid   .hat .sigma .cooksd .std.resid\n   <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>      <dbl>\n1   10.3   8.3    5.10   5.20 0.115    4.20  0.110       1.30 \n2   10.3   8.6    6.62   3.68 0.105    4.26  0.0492      0.914\n3   10.2   8.8    7.64   2.56 0.0992   4.30  0.0222      0.635\n\n\nYou can see the original x and y values (diam and volume), as well as:\n\n.fitted: the fitted (estimated) values \\(\\hat{y}\\) for the corresponding observation\n.resid: the residual for the observation (taken as \\(y - \\hat{y}\\)…)\n\n\n\nThe periods are important!\nWe can use the output from augment to plot residuals:\n\naugment(cherry_lm) |>\n  ggplot(aes(x = diam, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\")"
  },
  {
    "objectID": "live_code/slr_extras.html#factors-in-r",
    "href": "live_code/slr_extras.html#factors-in-r",
    "title": "broom and factors for SLR",
    "section": "factors in R",
    "text": "factors in R\nHow does lm() choose which level should be the base level?\n\nPre-specified as factor: In R, variables can be coded as “factor” variables where there is a specific numeric ordering under the hood. How can we tell? Using the str() function, we can find the data structure of a given variable:\n\nstr(possum$pop)\n\n Factor w/ 2 levels \"Vic\",\"other\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe can see that the pop variable has two levels, and the order goes “Vic” then “other”. So “Vic” is taken as the base level.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIf you want a different base level, we can change it using mutate()!\n\npossum |> \n  mutate(pop = factor(pop, levels = c(\"other\", \"Vic\"))) |>\n  pull(pop) |>\n  str()\n\n Factor w/ 2 levels \"other\",\"Vic\": 2 2 2 2 2 2 2 2 2 2 ...\n\n\n\n\n\nNot-specified: if your categorical variable is coded as a character/string variable and not a factor, the default base level is the first level in alphabetic order.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIf you don’t like this behavior, you can mutate() any variable to be a factor variable.\n\ndata.frame(fruit = c(\"apple\", \"kiwi\")) |>\n  mutate(fruit_factor = factor(fruit, levels = c(\"kiwi\", \"apple\"))) |>\n  pull(fruit_factor) |>\n  str()\n\n Factor w/ 2 levels \"kiwi\",\"apple\": 2 1"
  },
  {
    "objectID": "slides/slides-25-slr-inference.html",
    "href": "slides/slides-25-slr-inference.html",
    "title": "Inference in SLR",
    "section": "",
    "text": "Last set of homework problems are released today!\nOffice hours changed this week:\n\nToday: 2-3pm only\nWednesday 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "live_code/slr_bootstrap.html",
    "href": "live_code/slr_bootstrap.html",
    "title": "Bootstrapping for slope",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\nlibrary(broom)"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html",
    "href": "slides/slides-26-slr-simulation.html",
    "title": "Inference in SLR",
    "section": "",
    "text": "Last set of homework problems are released today!\nOffice hours changed this week:\n\nToday: 2-3pm only\nWednesday 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#recap",
    "href": "slides/slides-26-slr-simulation.html#recap",
    "title": "Simulation-based inference in SLR",
    "section": "Recap",
    "text": "Recap\n\nPoint estimates \\((b_{0}, b_{1})\\) also have variability as their specific values depend on a given set of data\nWe saw how to use output from lm() to test hypotheses about and create confidence intervals for \\(\\beta_{0}\\) and \\(\\beta_{1}\\)\n\nRelies on LINE conditions being met\n\nLet’s turn to simulation-based techniques (good refresher before midterm!)"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#variability-of-coefficient-estimates",
    "href": "slides/slides-26-slr-simulation.html#variability-of-coefficient-estimates",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates\n\nRemember, a linear regression is fit using a sample of data\nDifferent samples from the same population will yield different point estimates of \\((b_{0}, b_{1})\\)\n\nI will generate 30 data points under the following model: \\(y = 1 + 0.5x+\\epsilon\\)\n\nHow? Randomly generate some \\(x\\) and \\(\\epsilon\\) values and then plug into model to get corresponding \\(y\\)\n\nFit SLR to these \\((x,y)\\) data, and obtain estimates \\((b_{0}, b_{1})\\)\nRepeat this 50 times"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#variability-of-coefficient-estimates-1",
    "href": "slides/slides-26-slr-simulation.html#variability-of-coefficient-estimates-1",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#what-are-we-interested-in",
    "href": "slides/slides-26-slr-simulation.html#what-are-we-interested-in",
    "title": "Inference in SLR",
    "section": "What are we interested in?",
    "text": "What are we interested in?\nRemember: we fit SLR to understand how \\(x\\) is (linearly) related to \\(y\\):\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\n\nWhat would a value of \\(\\beta_{1} = 0\\) mean?\n\n\nIf \\(\\beta_{1} = 0\\), then the effect of \\(x\\) disappears and there is in fact no linear relationship between \\(x\\) and \\(y\\)\n\nWe don’t know \\(\\beta_{1}\\), so let’s look at estimate \\(b_{1}\\):\n\n\nIs an estimate of \\(b_{1}= 0\\) a convincing evidence of no relationship? What if \\(b_{1} = 0.1\\)?\n\nIt depends! We saw that \\(b_{1}\\) varies by sample! So let’s perform inference for \\(\\beta_{1}\\)"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#running-example-evals-data",
    "href": "slides/slides-26-slr-simulation.html#running-example-evals-data",
    "title": "Inference in SLR",
    "section": "Running example: evals data",
    "text": "Running example: evals data\nData on 463 courses at UT Austin were obtained to answer the question: “What factors explain differences in instructor teaching evaluation scores?”\n\nOne hypothesis was that more attractive instructors receive better teaching evaluations\nWe will look at the variables:\n\nscore: course instructor’s average teaching score, where average is calculated from all students in that course. Scores ranged from 1-5, with 1 being lowest.\nbty_avg: course instructor’s average “beauty” score, where average is calculated from six student evaluations of “beauty”. Scores ranged from 1-10, with 1 being lowest."
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#teaching-evaluations-data",
    "href": "slides/slides-26-slr-simulation.html#teaching-evaluations-data",
    "title": "Inference in SLR",
    "section": "Teaching evaluations data",
    "text": "Teaching evaluations data\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nDoes this line really have a non-zero slope?"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#hypothesis-test-for-slope",
    "href": "slides/slides-26-slr-simulation.html#hypothesis-test-for-slope",
    "title": "Inference in SLR",
    "section": "Hypothesis test for slope",
    "text": "Hypothesis test for slope\n\nWe have the following hypotheses:\n\n\\(H_{0}: \\beta_{1} = 0\\): the true linear model has slope zero\n\\(H_{A}: \\beta_{1} \\neq 0\\): the true linear model has a non-zero slope. An instructor’s average beauty score is predictive of their average teaching evaluation score.\n\nTo assess, we do what we usually do:\n\nCheck if methods are appropriate\nIf so: obtain an estimate, identify/estimate standard error of the estimate, find an appropriate test statistic, and calculate p-value\n\n\nThe output from lm() actually does all of this for us, but we will see how the test statistic and p-value are calculated!"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#teaching-evaluations-model-assessment",
    "href": "slides/slides-26-slr-simulation.html#teaching-evaluations-model-assessment",
    "title": "Inference in SLR",
    "section": "Teaching evaluations: model assessment",
    "text": "Teaching evaluations: model assessment\nWe fit the model in R, and obtain the following plots.\n\nAre all conditions of LINE met?\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#looking-at-lm-output",
    "href": "slides/slides-26-slr-simulation.html#looking-at-lm-output",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\nlibrary(broom)\neval_mod <- lm(score ~ bty_avg, data = evals)\neval_mod |>\n  tidy()\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\nAssuming the linear model is appropriate, interpret the coefficients!\n\n\nIntercept: an instructor with an average beauty score of 0 would be expected to have an average evaluation score of 3.88\nSlope: for every one point increase in average beauty score an instructor receives, their evaluation score is expected to incrase by 0.067 points"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#looking-at-lm-output-1",
    "href": "slides/slides-26-slr-simulation.html#looking-at-lm-output-1",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\n\n\nestimate: the observed point estimate (\\(b_{0}\\) or \\(b_{1}\\))\nstd.error: the estimated standard error of the estimate\n\n\n\nstatistic: the value of the test statistic\np.value: p-value associated with the two-sided alternative \\(H_{A}: \\beta_{1} \\neq 0\\)\n\n\n\n\nLet’s confirm the test statistic calculation:\n\n\n\\[\nt = \\frac{\\text{observed} - \\text{null}}{\\text{SE}_{0}} =\\frac{b_{1,obs} - \\beta_{1, 0}}{\\widehat{\\text{SE}}_{0}} = \\frac{0.066637 - 0}{0.0162912} = 4.0903823 \\sim t_{df}\n\\]\nwhere \\(df = n-2\\)"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#p-value-and-conclusion",
    "href": "slides/slides-26-slr-simulation.html#p-value-and-conclusion",
    "title": "Inference in SLR",
    "section": "p-value and conclusion",
    "text": "p-value and conclusion\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\nLet’s confirm the p-value calculation:\n\\[\\text{p-value} = \\text{Pr}(T \\geq 4.09) + \\text{Pr}(T \\leq -4.09)\\] where \\(T \\sim t_{461}\\)\n\nSo our p-value is: 2 * (1 - pt(4.09, 461)) = 5.0827307^{-5}\nAssuming the LINE conditions are met: since our p-value 5.0827307^{-5} is extremely small, we would reject \\(H_{0}\\) at any reasonable significant level. Thus, the data provide convincing evidence that there is a linear relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#different-h_a",
    "href": "slides/slides-26-slr-simulation.html#different-h_a",
    "title": "Inference in SLR",
    "section": "Different \\(H_{A}\\)",
    "text": "Different \\(H_{A}\\)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\n\n\nWhat would your p-value be if your alternative was \\(H_{A}: \\beta_{1} > 0\\)? What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\geq 4.09)\\) = (1-pt(4.09, 461) = 2.5413653^{-5}\nThe data provide convincing evidence that there is a positive relationship between instructor’s beauty score and evaluation score.\n\n\n\nWhat would your p-value be if your alternative was \\(H_{A}: \\beta_{1} < 0\\)? What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\leq 4.09)\\) = pt(4.09, 461) = 0.9999745\nThe data do not provide convincing evidence that there is a negative relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#confidence-intervals",
    "href": "slides/slides-26-slr-simulation.html#confidence-intervals",
    "title": "Simulation-based inference in SLR",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nCompare to our 95% CI for \\(\\beta_{1}\\) using mathematical model: (0.035, 0.099)"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#remarks",
    "href": "slides/slides-26-slr-simulation.html#remarks",
    "title": "Inference in SLR",
    "section": "Remarks",
    "text": "Remarks\n\nNote: for \\(\\beta_{1}\\), the null hypothesis is always of the form \\(H_{0}: \\beta_{1} = 0\\)\nLINE conditions must be met for underlying mathematical and probability theory to hold here! If not met, simulation-based methods would be a better choice\nHere, the Independence conditions did not seem to be met\n\nTake STAT 412 or other course to learn how to incorporate dependencies between observations!\n\nSo what can we say?\n\nThe results suggested by our inference should be viewed as preliminary, and not conclusive\nFurther investigation is certainly warranted!\nChecking LINE can be very subjective, but that’s how real-world analysis will be!"
  },
  {
    "objectID": "live_code/slr_bootstrap.html#bootstrap-distribution-of-b_1",
    "href": "live_code/slr_bootstrap.html#bootstrap-distribution-of-b_1",
    "title": "Bootstrapping for slope",
    "section": "Bootstrap distribution of \\(b_{1}\\)",
    "text": "Bootstrap distribution of \\(b_{1}\\)\n\nset.seed(311)\nn <- nrow(evals)\nB <- 1000\nb1_boot <- rep(NA, B)\n\n# option 1\nfor(b in 1:B){\n  # create a vector of indices for sampling row-by-row:\n  resamp_inds <- sample(1:n, size = n, replace = T)\n  \n  # create new data frame by grabbing the resampled rows\n  evals_resamp <- evals[resamp_inds,]\n  \n  # fit lm on new model and grab the corresponding coefficient\n  coefs <- coef(lm(score ~ bty_avg, data = evals_resamp))\n  b1_boot[b] <- coefs[2]\n}\n\n\n# option 2: dplyr (slower)\nset.seed(311)\nb1_boot <- rep(NA, B)\nfor(b in 1:B){\n  # create new data frame using sample_n() to sample rows\n  evals_resamp <- evals |>\n    sample_n(size = n, replace = T)\n  \n  # get coefficient using broom functions\n  b1_boot[b] <- lm(score ~ bty_avg, data = evals_resamp) |>\n    tidy() |>\n    slice(2) |>\n    pull(estimate)\n}\n\nVisualize the bootstrap distribution:"
  },
  {
    "objectID": "live_code/slr_bootstrap.html#bootstrap-ci-for-beta_1",
    "href": "live_code/slr_bootstrap.html#bootstrap-ci-for-beta_1",
    "title": "Bootstrapping for slope",
    "section": "Bootstrap CI for \\(\\beta_{1}\\)",
    "text": "Bootstrap CI for \\(\\beta_{1}\\)\n\n\n\nWe will obtain the 95% bootstrap interval:\n\nboot_ci <- quantile(b1_boot, c(0.025, 0.975))\nboot_ci\n\n     2.5%     97.5% \n0.0329399 0.1012776 \n\n\nVisualize bootstrap distribution and CI, and compare to 95% CI obtained via mathematical model:"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#housekeeping",
    "href": "slides/slides-26-slr-simulation.html#housekeeping",
    "title": "Simulation-based inference in SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nLast set of homework problems are released today!\nOffice hours changed this week:\n\nWednesday (today!) 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#bootstrapping",
    "href": "slides/slides-26-slr-simulation.html#bootstrapping",
    "title": "Simulation-based inference in SLR",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nRepeat \\(B\\) times:\n\nSample with replacement from the original data, of the same sample size as the original data\nCalculate the quantity of interest using the resampled data\n\n\nIn the case of SLR: what exactly should we be “resampling”? What is the quantity/quantities of interest?"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#bootstrapping-for-slr",
    "href": "slides/slides-26-slr-simulation.html#bootstrapping-for-slr",
    "title": "Simulation-based inference in SLR",
    "section": "Bootstrapping for SLR",
    "text": "Bootstrapping for SLR\n\nFor a given observation \\(i\\), we need to keep \\((x_{i}, y_{i})\\) together\n\nWant to keep pairs of score and bty_avg together, but different pairs may be re-sampled\nWe will re-sample with replacement row-by-row\n\nFor each re-sampled dataset, fit a linear regression model and record \\(b_{1}\\)\n\n\nThis yields bootstrap distribution of estimated slope coefficients!"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#live-code-for-bootstrapped-slope",
    "href": "slides/slides-26-slr-simulation.html#live-code-for-bootstrapped-slope",
    "title": "Simulation-based inference in SLR",
    "section": "Live code for bootstrapped slope",
    "text": "Live code for bootstrapped slope\n\n\n\n\n\nBootstrap distribution of \\(b_{1}\\):\n\n\n\n\n\n\n95% bootstrap CI for \\(\\beta_{1}\\): (0.033, 0.101):"
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#bootstrap-dist.",
    "href": "slides/slides-26-slr-simulation.html#bootstrap-dist.",
    "title": "Simulation-based inference in SLR",
    "section": "Bootstrap dist.",
    "text": "Bootstrap dist."
  },
  {
    "objectID": "slides/slides-26-slr-simulation.html#hypotheses",
    "href": "slides/slides-26-slr-simulation.html#hypotheses",
    "title": "Simulation-based inference in SLR",
    "section": "Hypotheses",
    "text": "Hypotheses\nRecall our hypotheses:\n\\[\nH_{0}: \\beta_{1} = 0 \\qquad \\text{vs.} \\qquad H_{A}: \\beta_{1} \\neq 0 \\text{ (or >, <)}\n\\]"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html",
    "href": "slides/slides-26-slr-bootstrap-ci.html",
    "title": "Simulation-based CIs for SLR",
    "section": "",
    "text": "Last set of homework problems are released today!\nOffice hours changed this week:\n\nWednesday (today!) 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#recap",
    "href": "slides/slides-26-slr-bootstrap-ci.html#recap",
    "title": "Simulation-based CIs for SLR",
    "section": "Recap",
    "text": "Recap\n\nPoint estimates \\((b_{0}, b_{1})\\) also have variability as their specific values depend on a given set of data\nWe saw how to use output from lm() to test hypotheses about and create confidence intervals for \\(\\beta_{0}\\) and \\(\\beta_{1}\\)\n\nRelies on LINE conditions being met\n\nLet’s turn to simulation-based techniques (good refresher before midterm!)"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#bootstrapping",
    "href": "slides/slides-26-slr-bootstrap-ci.html#bootstrapping",
    "title": "Simulation-based CIs for SLR",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nRepeat \\(B\\) times:\n\nSample with replacement from the original data, of the same sample size as the original data\nCalculate the quantity of interest using the resampled data\n\n\nIn the case of SLR: what exactly should we be “resampling”? What is the quantity/quantities of interest?"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#bootstrapping-for-slr",
    "href": "slides/slides-26-slr-bootstrap-ci.html#bootstrapping-for-slr",
    "title": "Simulation-based CIs for SLR",
    "section": "Bootstrapping for SLR",
    "text": "Bootstrapping for SLR\n\nFor a given observation \\(i\\), we need to keep \\((x_{i}, y_{i})\\) together\n\nWant to keep pairs of score and bty_avg together, but different pairs may be re-sampled\nWe will re-sample with replacement row-by-row\n\nFor each re-sampled dataset, fit a linear regression model and record \\(b_{1}\\)\n\n\nThis yields bootstrap distribution of estimated slope coefficients!"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#live-code-for-bootstrapped-slope",
    "href": "slides/slides-26-slr-bootstrap-ci.html#live-code-for-bootstrapped-slope",
    "title": "Simulation-based CIs for SLR",
    "section": "Live code for bootstrapped slope",
    "text": "Live code for bootstrapped slope\n\n\n\n\n\nBootstrap distribution of \\(b_{1}\\):\n\n\n\n\n\n\n95% bootstrap CI for \\(\\beta_{1}\\): (0.033, 0.101):"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#confidence-intervals",
    "href": "slides/slides-26-slr-bootstrap-ci.html#confidence-intervals",
    "title": "Simulation-based CIs for SLR",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\nCompare to our 95% CI for \\(\\beta_{1}\\) using mathematical model: (0.035, 0.099)"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#hypotheses",
    "href": "slides/slides-26-slr-bootstrap-ci.html#hypotheses",
    "title": "Simulation-based inference in SLR",
    "section": "Hypotheses",
    "text": "Hypotheses\nRecall our hypotheses:\n\\[\nH_{0}: \\beta_{1} = 0 \\qquad \\text{vs.} \\qquad H_{A}: \\beta_{1} \\neq 0 \\text{ (or >, <)}\n\\]"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#housekeeping",
    "href": "slides/slides-26-slr-bootstrap-ci.html#housekeeping",
    "title": "Simulation-based CIs for SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nOffice hours changed this week:\n\nWednesday (today!) 4-5pm\nFriday: cancelled, moved to next week before midterm\n\nCoding practice due tonight"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#looking-towards-testing",
    "href": "slides/slides-26-slr-bootstrap-ci.html#looking-towards-testing",
    "title": "Simulation-based CIs for SLR",
    "section": "Looking towards testing",
    "text": "Looking towards testing\nRecall our hypotheses for the slope: \\(H_{0}: \\beta_{1} = 0\\) versus \\(H_{A}: \\beta_{1} \\neq 0\\)\n\nHow might we use simulation to test these hypotheses? (i.e. how can we simulate “null world”?)"
  },
  {
    "objectID": "slides/slides-26-slr-bootstrap-ci.html#evals-data",
    "href": "slides/slides-26-slr-bootstrap-ci.html#evals-data",
    "title": "Simulation-based CIs for SLR",
    "section": "evals data",
    "text": "evals data\nFirst six observations:\n\n\n\n\n \n  \n    course_id \n    prof_id \n    score \n    bty_avg \n  \n \n\n  \n    1 \n    1 \n    4.7 \n    5 \n  \n  \n    2 \n    1 \n    4.1 \n    5 \n  \n  \n    3 \n    1 \n    3.9 \n    5 \n  \n  \n    4 \n    1 \n    4.8 \n    5 \n  \n  \n    5 \n    2 \n    4.6 \n    3 \n  \n  \n    6 \n    2 \n    4.3 \n    3 \n  \n\n\n\n\n\n\nRecall our model:\n\\[\\underbrace{\\text{score}}_{y} = \\beta_{0} + \\beta_{1} \\underbrace{\\text{bty_avg}}_{x} + \\epsilon\\]\n\n\nWe can index to denote specific row/observation pairs \\((x_{i}, y_{i})\\)\n\ne.g. \\((x_{1}, y_{1}) = (5, 4.7 )\\)"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#housekeeping",
    "href": "slides/slides-27-slr-randomization.html#housekeeping",
    "title": "Simulation-based HTs for SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\nData for end of class (copy when needed):\n\nlibrary(readr)\nbirthwt <- read.csv(\"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/birthwt.csv\")\n\n\nOffice hours changed this week:\n\nFriday: cancelled, moved to next week before midterm\n\nHomework 8 due tonight\nOffice hours next week:\n\nMonday 2:00-4:00pm\nTuesday: 11am-12:00pm, 4:00-5:00pm"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#simulation-based-ht-for-slope",
    "href": "slides/slides-27-slr-randomization.html#simulation-based-ht-for-slope",
    "title": "Simulation-based HTs for SLR",
    "section": "Simulation-based HT for slope",
    "text": "Simulation-based HT for slope\nRecall our hypotheses for the slope: \\(H_{0}: \\beta_{1} = 0\\) versus \\(H_{A}: \\beta_{1} \\neq 0\\)\n\nHow might we use simulation to test these hypotheses? (i.e. how can we simulate “null world”?)\n\n\nUnder \\(H_{0}\\), there is no relationship between \\(x\\) and \\(y\\), so we can shuffle/permute/break up the \\((x_{i}, y_{i})\\) under \\(H_{0}\\)\n\ni.e. there is no special correspondence between \\(x_{i}\\) and \\(y_{i}\\)"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#randomization-test-demonstration",
    "href": "slides/slides-27-slr-randomization.html#randomization-test-demonstration",
    "title": "Simulation-based HTs for SLR",
    "section": "Randomization test (demonstration)",
    "text": "Randomization test (demonstration)\nHere’s how it would look like using cards. Repeat the following \\(B\\) times:\n\nWrite down all \\(x_1,\\ldots, x_{n}\\) values and all \\(y_{1},\\ldots, y_{n}\\) values on cards.\nShuffle the response variable cards to get \\(y_{1}^{shuff}, \\ldots, y_{n}^{shuff}\\)\nDeal out the shuffled responses to pair with an explanatory: \\((x_{1}, y_{1}^{shuff}),\\ldots, (x_{n}, y_{n}^{shuff})\\)\nFit linear regression model to these shuffled data and record \\(b_{1}\\)\n\n\n\nConvince yourself this corresponds to \\(H_0: \\beta_{1} = 0\\)!\nWe are not sampling with replacement"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#evals",
    "href": "slides/slides-27-slr-randomization.html#evals",
    "title": "Simulation-based HTs for SLR",
    "section": "evals",
    "text": "evals\nLet’s return to our evals data and model: \\(\\text{score} = \\beta_{0} + \\beta_{1} \\text{bty_avg} + \\epsilon\\)\n\n\n\nFirst six rows of original data:\n\n\n\n\n \n  \n    course_id \n    bty_avg \n    score \n  \n \n\n  \n    1 \n    5 \n    4.7 \n  \n  \n    2 \n    5 \n    4.1 \n  \n  \n    3 \n    5 \n    3.9 \n  \n  \n    4 \n    5 \n    4.8 \n  \n  \n    5 \n    3 \n    4.6 \n  \n  \n    6 \n    3 \n    4.3 \n  \n\n\n\n\n\n\n\n\nFirst six rows of one iteration of shuffled data:\n\n\n\n\n \n  \n    course_id \n    bty_avg \n    score \n    score_shuff \n  \n \n\n  \n    1 \n    5 \n    4.7 \n    4.5 \n  \n  \n    2 \n    5 \n    4.1 \n    3.9 \n  \n  \n    3 \n    5 \n    3.9 \n    3.7 \n  \n  \n    4 \n    5 \n    4.8 \n    3.8 \n  \n  \n    5 \n    3 \n    4.6 \n    4.7 \n  \n  \n    6 \n    3 \n    4.3 \n    4.6"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#evals-null-distribution",
    "href": "slides/slides-27-slr-randomization.html#evals-null-distribution",
    "title": "Simulation-based HTs for SLR",
    "section": "evals null distribution",
    "text": "evals null distribution\n\\(H_{0}: \\beta_{1} = 0\\) (there is no linear relationship between score and bty_avg)\n\\(H_{A}: \\beta_{1} > 0\\) (there is a positive linear relationship between score and bty_avg)"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#p-value",
    "href": "slides/slides-27-slr-randomization.html#p-value",
    "title": "Simulation-based HTs for SLR",
    "section": "p-value",
    "text": "p-value\n\nscore_lm <- lm(score ~ bty_avg, data = evals)\ntidy(score_lm)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880338 \n    0.0761430 \n    50.961213 \n    0.00e+00 \n  \n  \n    bty_avg \n    0.066637 \n    0.0162912 \n    4.090382 \n    5.08e-05 \n  \n\n\n\n\n\n\nCompare our observed fitted \\(b_{1,obs} = 0.067\\) coefficient to null distribution:\n\n\n\n\n\n\n\n\n\n\n\n\nRecall: \\(H_{A}: \\beta_{1} > 0\\)\np-value is calculated as \\(\\frac{\\text{number of simulated } b_{1} > 0.067}{B} = 0\\)"
  },
  {
    "objectID": "slides/slides-27-slr-randomization.html#your-turn",
    "href": "slides/slides-27-slr-randomization.html#your-turn",
    "title": "Simulation-based HTs for SLR",
    "section": "Your turn!!",
    "text": "Your turn!!\n\\[\\text{score} = \\beta_{0} + \\beta_{1} \\text{bty_avg} + \\epsilon\\]\nIn groups, obtain the null distribution for this \\(H_{0}\\) via simulation and visualize it using ggplot with informative title and axis labels. (You could be expected to do something like this for your midterm…)\n\nSuggestion: in a relevant place in your code, use the data frame evals to create a new data frame called evals_null\n\nevals_null should have a variable called score_shuffle that represents the shuffled scores"
  },
  {
    "objectID": "live_code/slr-ht-randomization.html",
    "href": "live_code/slr-ht-randomization.html",
    "title": "Hypothesis test for SLR with simulation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\n\n\nset.seed(116)\nB <- 1000\nb1_null <- rep(NA, B)\nscores <- evals |>\n  pull(score)\nfor(b in 1:B){\n  score_shuff <- sample(scores)\n  evals_null <- evals |>\n    mutate(score_shuffle = score_shuff)\n  null_lm <- lm(score_shuffle ~ bty_avg, data = evals_null)\n  b1_null[b] <- coef(null_lm)[2]\n}"
  },
  {
    "objectID": "coding_practice/coding-practice-27-slr-randomization.html",
    "href": "coding_practice/coding-practice-27-slr-randomization.html",
    "title": "Hypothesis test for SLR with simulation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)\nFeel free to type View(evals) in your console to look at the data!"
  },
  {
    "objectID": "coding_practice/coding-practice-27-slr-randomization.html#obtain-null-distribution",
    "href": "coding_practice/coding-practice-27-slr-randomization.html#obtain-null-distribution",
    "title": "Hypothesis test for SLR with simulation",
    "section": "Obtain null distribution",
    "text": "Obtain null distribution\n\n# set a seed\n\n\n# define/create necessary quantities\n\n\n# code for null distribution"
  },
  {
    "objectID": "coding_practice/coding-practice-27-slr-randomization.html#visualize-your-null-distribution",
    "href": "coding_practice/coding-practice-27-slr-randomization.html#visualize-your-null-distribution",
    "title": "Hypothesis test for SLR with simulation",
    "section": "Visualize your null distribution",
    "text": "Visualize your null distribution"
  },
  {
    "objectID": "live_code/mlr-intro.html",
    "href": "live_code/mlr-intro.html",
    "title": "Introduction to MLR",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "live_code/mlr-intro.html#birth-weight-data",
    "href": "live_code/mlr-intro.html#birth-weight-data",
    "title": "Introduction to MLR",
    "section": "Birth weight data",
    "text": "Birth weight data\nBaystate Medical Center, Springfield, MA during 1986 on the birth weights of 189 babies, along with descriptive information about the mother\n\nlibrary(readr)\nbirthwt <- read.csv(\"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/birthwt.csv\")\n\nWe want to understand risk factors for a baby’s birth weight (bwt). Homework 8 explores the effect of mother’s smoke status on birth weight of baby.\nLet’s look at a different variable: race of mother\n\nVariable race is numerical where 1 = white, 2 = black, 3 = other\n\n\n# wrong! This is bad!!\nlm(bwt ~ race, data = birthwt) |>\n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3230.     117.      27.5  1.17e-67\n2 race           -155.      57.0     -2.71 7.26e- 3"
  },
  {
    "objectID": "live_code/mlr-intro.html#converting-to-factor",
    "href": "live_code/mlr-intro.html#converting-to-factor",
    "title": "Introduction to MLR",
    "section": "Converting to factor",
    "text": "Converting to factor\nWe need to convert race variable to categorical!\n\nbirthwt2 <- birthwt |>\n  mutate(race = case_when(race == 1 ~ \"white\",\n                          race == 2 ~ \"black\",\n                          race == 3 ~ \"other\")) |>\n  mutate(race = factor(race, levels = c(\"white\", \"black\", \"other\")))\n\nstr(birthwt2$race)\n\n Factor w/ 3 levels \"white\",\"black\",..: 2 3 1 1 1 3 1 3 1 1 ...\n\n\nLet’s go ahead and fit this model using lm() as we usually would and look at the tidy output:\n\nbwt_lm <- lm(bwt ~ race, data = birthwt2)\ntidy(bwt_lm)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3103.      72.9     42.5  8.53e-98\n2 raceblack      -383.     158.      -2.42 1.63e- 2\n3 raceother      -297.     114.      -2.61 9.65e- 3\n\n\nLet’s write out the form of the linear regression model:"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html",
    "href": "slides/slides-28-mlr-intro.html",
    "title": "Introduction to Multiple Linear Regression",
    "section": "",
    "text": "Study for midterm!"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#multiple-linear-regression",
    "href": "slides/slides-28-mlr-intro.html#multiple-linear-regression",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nWe have seen simple linear regression, which is where we have one explanatory variableLinear regression can naturally extend to include more than one explanatory variable\n\nSeems natural: usually several factors affect behavior of phenomena\n\nMultiple linear regression takes the form: \\[y = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\ldots + \\beta_{p} x_{p} + \\epsilon\\]\n\nNow there are \\(p\\) different explanatory variables \\(x_{1},\\ldots, x_{p}\\) per observation\nStill one response \\(y\\) and error \\(\\epsilon\\) per observation\n\nRepresents a holistic approach for modeling all of the variables simultaneously"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#birth-weight-data",
    "href": "slides/slides-28-mlr-intro.html#birth-weight-data",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Birth weight data",
    "text": "Birth weight data\nBaystate Medical Center, Springfield, MA during 1986 on the birth weights of 189 babies, along with descriptive information about the mother\n\n\n\n\nWant to understand risk factors for a baby’s birth weight (bwt)\nHomework 8 explores the effect of mother’s smoke status on birth weight of baby\nLet’s look at a different variable: race of mother\n\nVariable race numerical where 1 = white, 2 = black, 3 = other\n\n\n\n\n\n'data.frame':   189 obs. of  10 variables:\n $ low  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ age  : int  19 33 20 21 18 21 22 17 29 26 ...\n $ lwt  : int  182 155 105 108 107 124 118 103 123 113 ...\n $ race : int  2 3 1 1 1 3 1 3 1 1 ...\n $ smoke: chr  \"no\" \"no\" \"yes\" \"yes\" ...\n $ ptl  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ ht   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ ui   : int  1 0 0 1 1 0 0 0 0 0 ...\n $ ftv  : int  0 3 1 2 0 0 1 1 1 0 ...\n $ bwt  : int  2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ..."
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#converting-to-factor",
    "href": "slides/slides-28-mlr-intro.html#converting-to-factor",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Converting to factor",
    "text": "Converting to factor\nWe need to convert variable race to categorical! Does not make sense to do “math” on variable:\n\nbirthwt2 <- birthwt |>\n  mutate(race = case_when(race == 1 ~ \"white\",\n                          race == 2 ~ \"black\",\n                          race == 3 ~ \"other\")) |>\n  mutate(race = factor(race, levels = c(\"white\", \"black\", \"other\")))\n\nstr(birthwt2)\n\n'data.frame':   189 obs. of  10 variables:\n $ low  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ age  : int  19 33 20 21 18 21 22 17 29 26 ...\n $ lwt  : int  182 155 105 108 107 124 118 103 123 113 ...\n $ race : Factor w/ 3 levels \"white\",\"black\",..: 2 3 1 1 1 3 1 3 1 1 ...\n $ smoke: chr  \"no\" \"no\" \"yes\" \"yes\" ...\n $ ptl  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ ht   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ ui   : int  1 0 0 1 1 0 0 0 0 0 ...\n $ ftv  : int  0 3 1 2 0 0 1 1 1 0 ...\n $ bwt  : int  2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ..."
  },
  {
    "objectID": "practice_probs/practice-midterm2-coding.html",
    "href": "practice_probs/practice-midterm2-coding.html",
    "title": "Extra practice problems: coding",
    "section": "",
    "text": "Almost all of following problems should require to use R in some way. Remember to check conditions where appropriate!\n\nAn apple farmer has historically lost an average of 4% of his trees each year. He believes that he has been losing more trees lately. In a random sample of 200 trees, 12 have died.\n\nUsing an appropriate method, test the farmer’s claim at the 0.01 level.\nUsing the data from his sample, obtain a 90% confidence interval for the farmer’s loss rate of trees.\n\n\n\n\n\n\n\n\n\nRecall that the starbucks data from openintro has several different types of food items. We’d like to know if the average calories in hot breakfast items are different from the average calories of sandwich items. Answer this two ways: 1) using an appropriate hypothesis test and 2) using an appropriate confidence interval. Try to do one via mathematical model (if appropriate) and another via simulation.\nWorking with the starbucks data again: Using an appropriate method, obtain a 95% confidence interval for the mean calorie per carbohydrate of bakery type items.\nTake a look at the Help file of the satgpa data from openintro. Fit a linear model where we use math SAT percentiles to estimate the first year college GPA. Check if your model is appropriate. If so, is a student’s performance on the math section of the SAT predictive of their first-year GPA?\nYawning. Take a look at the Help file for the yawn data from openintro. Write down null and alternative hypotheses (in words or in notation is) that correspond to the research question implied in the Help file Description. Make a plot of the data that would be appropriate/helpful exploratory analysis for the researchers. Then using simulation, test your hypotheses at the 0.05 significance level. Optional but good practice before coding: describe in words how you would implement the simulation using props/cards. Make a conclusion in context."
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#housekeeping",
    "href": "slides/slides-28-mlr-intro.html#housekeeping",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nStudy for midterm!"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#interpreting-coefficients",
    "href": "slides/slides-28-mlr-intro.html#interpreting-coefficients",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpreting coefficients",
    "text": "Interpreting coefficients\n\\[\n\\widehat{\\text{birth_wt}} = 3102.72 + -383.03 \\text{raceBlack} + -297.44 \\text{raceOther}\n\\]\n\n\\(\\widehat{\\text{birth_wt}} = 3102.72 -383.03 \\times \\color{orange}{0} -297.44 \\times \\color{orange}{0}\\)\nThe estimated birth weight of babies whose mothers are White is 3102.72 grams\n\nMore generally: \\(b_{0}\\) is the estimated value of the response variable for the base level\n\n\nWhat is the interpretation of \\(b_{1}\\) = -383.03? Of \\(b_{2}\\) = -297.44?\n\n\nBabies whose mothers are Black have an estimated birth weight about 383.03 grams less than babies whose mothers are White\nBabies whose mothers are race “Other” (i.e. not Black or White) have an estimated birth weight about 297.44 grams less than babies whose mothers are White"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#general-interpretation",
    "href": "slides/slides-28-mlr-intro.html#general-interpretation",
    "title": "Introduction to Multiple Linear Regression",
    "section": "General interpretation",
    "text": "General interpretation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3102.7188\n72.92298\n42.547890\n0.0000000\n\n\nraceblack\n-383.0264\n157.96382\n-2.424773\n0.0162741\n\n\nraceother\n-297.4352\n113.74198\n-2.614999\n0.0096546\n\n\n\n\n\n\nWhen fitting a regression model with a categorical variable with \\(k > 2\\) levels, the software will always provide a coefficient for \\(k-1\\) of the levels\n\n\nThe base level does not receive a coefficient\n\nInterpretation of the coefficient associated with a non-base level is the expected change in the response relative to the base level\n\nNote: the fitted model has more than one “slope” coefficient, but the race variable is still a single explanatory variable\nWhat happens if we explicitly want to include more than one explanatory variable?"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#birthweight-data-cont.",
    "href": "slides/slides-28-mlr-intro.html#birthweight-data-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Birthweight data (cont.)",
    "text": "Birthweight data (cont.)\nSuppose we would also like to include the mother’s age (age) and weight at last period (lwt) into the model:\n\\[\\text{birth_wt} = \\beta_{0} + \\beta_{1} \\text{raceBlack} + \\beta_{2} \\text{raceOther} + \\beta_{3} \\text{age} + \\beta_4 \\text{lwt} + \\epsilon\\]\n\nJust as in the case of SLR, the estimates of \\(\\beta_{0},\\ldots, \\beta_{4}\\) parameters are chosen via the squared deviation criterion"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#multiple-regression-in-r",
    "href": "slides/slides-28-mlr-intro.html#multiple-regression-in-r",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Multiple regression in R",
    "text": "Multiple regression in R\nVery easy to code:\n\nbwt_mlr <- lm(bwt ~ race + age + lwt, data = birthwt2)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.147482 \n    314.722327 \n    7.8200600 \n    0.0000000 \n  \n  \n    raceblack \n    -447.614691 \n    161.369310 \n    -2.7738527 \n    0.0061108 \n  \n  \n    raceother \n    -239.356515 \n    115.188920 \n    -2.0779474 \n    0.0391022 \n  \n  \n    age \n    1.298831 \n    10.107701 \n    0.1284991 \n    0.8978943 \n  \n  \n    lwt \n    4.619545 \n    1.787729 \n    2.5840294 \n    0.0105407 \n  \n\n\n\n\n\n\nSimply identify the estimated coefficients from the output to obtain fitted model\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{birth_wt}} &= 2461.15  -447.61 \\text{raceBlack} -239.36 \\text{raceOther} +  1.3 \\text{age}  \\\\\n& \\quad + 4.62 \\text{lwt}\n\\end{align*}\n\\]\n\n\nNote that the number of explanatory variables need not equal the number of parameters in the model!"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#interpretation",
    "href": "slides/slides-28-mlr-intro.html#interpretation",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nWhen we have more than one predictor variable, interpretation of the coefficients requires a bit of care\n\nMultiple moving parts\n\nInterpretation of a particular coefficient \\(b_{m}\\) relies on “holding the other variables fixed/constant” (assuming the model is appropriate)\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{birth_wt}} &= 2461.15  -447.61 \\text{raceBlack} -239.36 \\text{raceOther} + \\color{orange}{1.3} \\text{age}  \\\\\n& \\quad + 4.62 \\text{lwt}\n\\end{align*}\n\\]\n\n\nFor every one year older the mother is, the baby’s birth weight is expected to increase by \\(\\color{orange}{1.3}\\) grams, holding all other variables constant\n\nInterpret the coefficient associated with the mother’s weight (lwt)"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#interpretation-cont.",
    "href": "slides/slides-28-mlr-intro.html#interpretation-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation (cont.)",
    "text": "Interpretation (cont.)\n\\[\n\\begin{align*}\n\\widehat{\\text{birth_wt}} &= 2461.15  -447.61 \\text{raceBlack} -239.36 \\text{raceOther} +  1.3 \\text{age}  \\\\\n& \\quad + \\color{orange}{4.62} \\text{lwt}\n\\end{align*}\n\\]\n\nFor every one pound heavier the mother’s weight at last period was, the baby’s birth weight is expected to increase by \\(\\color{orange}{4.62}\\) grams, holding all other variables constant"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#more-isnt-always-better",
    "href": "slides/slides-28-mlr-intro.html#more-isnt-always-better",
    "title": "Introduction to Multiple Linear Regression",
    "section": "More isn’t always better",
    "text": "More isn’t always better\n\nYou might be tempted to throw in all available predictors into your model! Don’t fall into temptation!\nQuality over quantity\nFor SLR, we used the coefficient of determination \\(R^2\\) to assess how good the model was\n\n\\(R^2\\) is less helpful when there are many variables\nWhy? The \\(R^2\\) will never decrease (and will almost always increase) when we include an additional predictor"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#adjusted-r2",
    "href": "slides/slides-28-mlr-intro.html#adjusted-r2",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nFor multiple linear regression, we use the adjusted \\(R^2\\) to assess the quality of model fit\n\n“Adjusted” for the presence of additional predictors\nTake STAT 211 to learn the formula and intuition behind it!\n\nAdjusted \\(R^2\\) is always less than \\(R^2\\)"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#adjusted-r2-cont.",
    "href": "slides/slides-28-mlr-intro.html#adjusted-r2-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Adjusted \\(R^2\\) (cont.)",
    "text": "Adjusted \\(R^2\\) (cont.)\n\n\n\nsummary(bwt_mlr)\n\n\nCall:\nlm(formula = bwt ~ race + age + lwt, data = birthwt2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2103.50  -429.68    41.74   486.10  1902.20 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 2461.147    314.722   7.820 3.97e-13 ***\nraceblack   -447.615    161.369  -2.774  0.00611 ** \nraceother   -239.357    115.189  -2.078  0.03910 *  \nage            1.299     10.108   0.128  0.89789    \nlwt            4.620      1.788   2.584  0.01054 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 704.9 on 184 degrees of freedom\nMultiple R-squared:  0.08536,   Adjusted R-squared:  0.06548 \nF-statistic: 4.293 on 4 and 184 DF,  p-value: 0.00241\n\n\n\n\nglance(bwt_mlr)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.0854 \n    0.0655 \n    704.9368 \n    4.293 \n    0.0024 \n    4 \n    -1505.128 \n    3022.256 \n    3041.707 \n    91436202 \n    184 \n    189"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#simpler-model",
    "href": "slides/slides-28-mlr-intro.html#simpler-model",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Simpler model",
    "text": "Simpler model\nLet’s see the model that does not include mother’s age in the model:\n\nbwt_mlr_no_age <- lm(bwt ~ race + lwt, data = birthwt2)\ntidy(bwt_mlr_no_age)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2486.9039 \n    241.9933 \n    10.2767 \n    0.0000 \n  \n  \n    raceblack \n    -451.8381 \n    157.5662 \n    -2.8676 \n    0.0046 \n  \n  \n    raceother \n    -241.3008 \n    113.8869 \n    -2.1188 \n    0.0354 \n  \n  \n    lwt \n    4.6634 \n    1.7501 \n    2.6646 \n    0.0084 \n  \n\n\n\n\n\n\n\nWrite out the fitted model. Interpret the intercept and the coefficient for lwt in context"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#simpler-model-cont.",
    "href": "slides/slides-28-mlr-intro.html#simpler-model-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Simpler model (cont.)",
    "text": "Simpler model (cont.)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2486.9039 \n    241.9933 \n    10.2767 \n    0.0000 \n  \n  \n    raceblack \n    -451.8381 \n    157.5662 \n    -2.8676 \n    0.0046 \n  \n  \n    raceother \n    -241.3008 \n    113.8869 \n    -2.1188 \n    0.0354 \n  \n  \n    lwt \n    4.6634 \n    1.7501 \n    2.6646 \n    0.0084 \n  \n\n\n\n\n\n\nIntercept: the birth weight of babies whose mothers are White and weigh 0 lbs have an estimated birth weight of 2486.9 grams\nCoefficient for lwt: for every one pound increase in the mother’s weight at last period, the birth weight of the baby is expected to increase by 4.66 grams, holding all other variables (i.e. race) constant"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#simpler-model-model-assessment",
    "href": "slides/slides-28-mlr-intro.html#simpler-model-model-assessment",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Simpler model: model assessment",
    "text": "Simpler model: model assessment\nLet’s compare the two models: one with age and one without age\n\n\n\ntidy(bwt_mlr)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.147482 \n    314.722327 \n    7.8200600 \n    0.0000000 \n  \n  \n    raceblack \n    -447.614691 \n    161.369310 \n    -2.7738527 \n    0.0061108 \n  \n  \n    raceother \n    -239.356515 \n    115.188920 \n    -2.0779474 \n    0.0391022 \n  \n  \n    age \n    1.298831 \n    10.107701 \n    0.1284991 \n    0.8978943 \n  \n  \n    lwt \n    4.619545 \n    1.787729 \n    2.5840294 \n    0.0105407 \n  \n\n\n\n\n\n\nglance(bwt_mlr)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.0853604 \n    0.065477 \n    704.9368 \n    4.293036 \n    0.0024104 \n    4 \n    -1505.128 \n    3022.256 \n    3041.707 \n    91436202 \n    184 \n    189 \n  \n\n\n\n\n\n\n\ntidy(bwt_mlr_no_age)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2486.9039 \n    241.9933 \n    10.2767 \n    0.0000 \n  \n  \n    raceblack \n    -451.8381 \n    157.5662 \n    -2.8676 \n    0.0046 \n  \n  \n    raceother \n    -241.3008 \n    113.8869 \n    -2.1188 \n    0.0354 \n  \n  \n    lwt \n    4.6634 \n    1.7501 \n    2.6646 \n    0.0084 \n  \n\n\n\n\n\n\nglance(bwt_mlr_no_age)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.0853 \n    0.0704 \n    703.0605 \n    5.7491 \n    9e-04 \n    3 \n    -1505.137 \n    3020.273 \n    3036.482 \n    91444408 \n    185 \n    189"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#comparing-models",
    "href": "slides/slides-28-mlr-intro.html#comparing-models",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Comparing models",
    "text": "Comparing models\nLet’s compare the model that includes age to the model without age:\n\n\n\ntidy(bwt_mlr) |>\n  select(term, estimate, p.value)\n\n\n\n\n\n \n  \n    term \n    estimate \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.1475 \n    0.0000 \n  \n  \n    raceblack \n    -447.6147 \n    0.0061 \n  \n  \n    raceother \n    -239.3565 \n    0.0391 \n  \n  \n    age \n    1.2988 \n    0.8979 \n  \n  \n    lwt \n    4.6195 \n    0.0105 \n  \n\n\n\n\n\n\nglance(bwt_mlr)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.0854 \n    0.0655 \n    704.9368 \n    4.293 \n    0.0024 \n    4 \n    -1505.128 \n    3022.256 \n    3041.707 \n    91436202 \n    184 \n    189 \n  \n\n\n\n\n\n\n\ntidy(bwt_mlr_no_age) |>\n  select(term, estimate, p.value)\n\n\n\n\n\n \n  \n    term \n    estimate \n    p.value \n  \n \n\n  \n    (Intercept) \n    2486.9039 \n    0.0000 \n  \n  \n    raceblack \n    -451.8381 \n    0.0046 \n  \n  \n    raceother \n    -241.3008 \n    0.0354 \n  \n  \n    lwt \n    4.6634 \n    0.0084 \n  \n\n\n\n\n\n\nglance(bwt_mlr_no_age)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.0853 \n    0.0704 \n    703.0605 \n    5.7491 \n    9e-04 \n    3 \n    -1505.137 \n    3020.273 \n    3036.482 \n    91444408 \n    185 \n    189 \n  \n\n\n\n\n\n\n\n\nWhat do you notice about the estimated coefficients, \\(R^2\\), and adjusted \\(R^2\\)?"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#fit-model",
    "href": "slides/slides-28-mlr-intro.html#fit-model",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Fit model",
    "text": "Fit model\n\nbwt_lm <- lm(bwt ~ race, data = birthwt2)\ntidy(bwt_lm)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3102.7188\n72.92298\n42.547890\n0.0000000\n\n\nraceblack\n-383.0264\n157.96382\n-2.424773\n0.0162741\n\n\nraceother\n-297.4352\n113.74198\n-2.614999\n0.0096546\n\n\n\n\n\n\nFitted model:\n\\[\n\\widehat{\\text{birth_wt}} = 3102.72  -383.03 \\text{raceBlack}  -297.44 \\text{raceOther}\n\\]\n\\[\\text{raceBlack} = \\begin{cases}1 & \\text{if race = Black}  \\\\ 0 & \\text{otherwise} \\end{cases} \\qquad \\text{raceOther} = \\begin{cases}1 & \\text{if race = Other}  \\\\ 0 & \\text{otherwise} \\end{cases}\\]\n\n\n\nEstimate the birth weight for babies whose mothers are White"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#multiple-linear-regression-1",
    "href": "slides/slides-28-mlr-intro.html#multiple-linear-regression-1",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nWe have seen simple linear regression, where we had one explanatory variable\nExtend to include multiple explanatory variables\n\nSeems natural: usually several factors affect behavior of phenomena\n\nMultiple linear regression takes the form: \\[y = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\ldots + \\beta_{p} x_{p} + \\epsilon\\]\n\nNow there are \\(p\\) different explanatory variables \\(x_{1},\\ldots, x_{p}\\) per observation\nStill one response \\(y\\) and error \\(\\epsilon\\) per observation\n\nRepresents a holistic approach for modeling all of the variables simultaneously"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#conditions",
    "href": "slides/slides-28-mlr-intro.html#conditions",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Conditions",
    "text": "Conditions\nWe still need LINE to hold\n\nLinearity: harder to assess now that multiple predictors are involved. Good idea to make several scatter plots\nIndependence: same as before\nNearly normal residuals: same as before\nEqual variance: residual plot has fitted values on the x-axis, instead of an explanatory variable"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#hypothesis-testing-in-mlr",
    "href": "slides/slides-28-mlr-intro.html#hypothesis-testing-in-mlr",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis testing in MLR",
    "text": "Hypothesis testing in MLR\n\nIn MLR, we are interested in the effect of a variable \\(m\\) on the response \\(y\\).\n\nNeed to account for presence of other predictors in the model\n\n\\(H_{0}: \\beta_m = 0\\), given other predictors in the model\n\\(H_{A}: \\beta_m \\neq 0\\), given other predictors in the model (or \\(>, <\\))\nWe can write down one null hypothesis for each coefficient in the model"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm",
    "href": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm()",
    "text": "Hypothesis tests from lm()\nReturning to the larger model:\n\\[\\text{birth_wt} = \\beta_{0} + \\beta_{1} \\text{raceBlack} + \\beta_{2} \\text{raceOther} + \\beta_{3} \\text{age} + \\beta_4 \\text{lwt} + \\epsilon\\]\n\nWe can test the following null hypotheses (no need to write down):\n\n\\(H_{0}: \\beta_{1} = 0\\), given age and lwt are included in the model\n\\(H_{0}: \\beta_{2} = 0\\), given age and lwt are included in the model\n\\(H_{0}: \\beta_{3} = 0\\), given race and lwt are included in the model\n\\(H_{0}: \\beta_{4} = 0\\), given race and age are included in the model"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm-1",
    "href": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm-1",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm()",
    "text": "Hypothesis tests from lm()\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.1475 \n    314.7223 \n    7.8201 \n    0.0000 \n  \n  \n    raceblack \n    -447.6147 \n    161.3693 \n    -2.7739 \n    0.0061 \n  \n  \n    raceother \n    -239.3565 \n    115.1889 \n    -2.0779 \n    0.0391 \n  \n  \n    age \n    1.2988 \n    10.1077 \n    0.1285 \n    0.8979 \n  \n  \n    lwt \n    4.6195 \n    1.7877 \n    2.5840 \n    0.0105 \n  \n\n\n\n\n\n\nOutput from lm() provides:\n\nTest statistic, which follows \\(t_{n-p}\\) where \\(p =\\) total number of unknown parameters (i.e. \\(\\beta\\) terms)\np-values for testing two-sided \\(H_{A}\\) provided\n\n\n\n\nBased on the model fit, which variables seem to be important predictors of birth weight of a baby? Why?"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm-cont.",
    "href": "slides/slides-28-mlr-intro.html#hypothesis-tests-from-lm-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm() (cont.)",
    "text": "Hypothesis tests from lm() (cont.)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.1475 \n    314.7223 \n    7.8201 \n    0.0000 \n  \n  \n    raceblack \n    -447.6147 \n    161.3693 \n    -2.7739 \n    0.0061 \n  \n  \n    raceother \n    -239.3565 \n    115.1889 \n    -2.0779 \n    0.0391 \n  \n  \n    age \n    1.2988 \n    10.1077 \n    0.1285 \n    0.8979 \n  \n  \n    lwt \n    4.6195 \n    1.7877 \n    2.5840 \n    0.0105 \n  \n\n\n\n\n\n\nlwt does seem to be an important predictor for birth weight, despite inclusion of race and age in the model\n\nLow p-value suggests it would be extremely unlikely to see data that produce \\(b_{4} = 4.62\\) if the true relationship between lwtand bwt was non-existent (i.e., if \\(\\beta_{4} = 0\\)) and the model also included age and race\n\nrace does seem to be an important predictor, despite inclusion of age and lwt\nage does not seem to be an important predictor after including race and lwt"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#remarks",
    "href": "slides/slides-28-mlr-intro.html#remarks",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Remarks",
    "text": "Remarks\n\nWe have only scratched the surface of MLR\nThings to consider:\n\nMulticollinearity (when the predictor variables are correlated with each other)\nModel selection\nMore than one categorical variable\nInteraction effects"
  },
  {
    "objectID": "slides/slides-28-mlr-intro.html#conditions-for-inference",
    "href": "slides/slides-28-mlr-intro.html#conditions-for-inference",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nWe still need LINE to hold\n\nLinearity: harder to assess now that multiple predictors are involved. Good idea to make several scatter plots\nIndependence: same as before\nNearly normal residuals: same as before\nEqual variance: residual plot has fitted values on the x-axis, instead of an explanatory variable"
  },
  {
    "objectID": "slides/worksheet-28-mlr-intro.html",
    "href": "slides/worksheet-28-mlr-intro.html",
    "title": "MLR Intro",
    "section": "",
    "text": "bwt_mlr <- lm(bwt ~ race + age + lwt, data = birthwt2)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    2461.147482 \n    314.722327 \n    7.8200600 \n    0.0000000 \n  \n  \n    raceblack \n    -447.614691 \n    161.369310 \n    -2.7738527 \n    0.0061108 \n  \n  \n    raceother \n    -239.356515 \n    115.188920 \n    -2.0779474 \n    0.0391022 \n  \n  \n    age \n    1.298831 \n    10.107701 \n    0.1284991 \n    0.8978943 \n  \n  \n    lwt \n    4.619545 \n    1.787729 \n    2.5840294 \n    0.0105407 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.0853604\n0.065477\n704.9368\n4.293036\n0.0024104\n4\n-1505.128\n3022.256\n3041.707\n91436202\n184\n189\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = bwt ~ race + age + lwt, data = birthwt2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2103.50  -429.68    41.74   486.10  1902.20 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 2461.147    314.722   7.820 3.97e-13 ***\nraceblack   -447.615    161.369  -2.774  0.00611 ** \nraceother   -239.357    115.189  -2.078  0.03910 *  \nage            1.299     10.108   0.128  0.89789    \nlwt            4.620      1.788   2.584  0.01054 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 704.9 on 184 degrees of freedom\nMultiple R-squared:  0.08536,   Adjusted R-squared:  0.06548 \nF-statistic: 4.293 on 4 and 184 DF,  p-value: 0.00241"
  },
  {
    "objectID": "project/project_description.html#report",
    "href": "project/project_description.html#report",
    "title": "Final project",
    "section": "Report",
    "text": "Report\nEach group will write a final report created in an .qmd file. You can download the template here:\n template \nExample projects from Fall 2024:\n\nExample 1\nExample 2\n\nYour report will be submitted both as a PDF and as a .qmd file. The code in your report should be as reproducible as possible (e.g. not hard coding specific values, setting a seed when appropriate). All tables should be beautiful!\nAdditionally, only the output/execution from the code relevant for the report should be visible to the reader, not the code itself. This means that as the viewer, I should not see any code or extraneous output. The former is achieved by setting the chunk header option echo = F. That being said, if there is some code that you believe is useful/important for the reader to see, you are welcome to make that code visible by setting echo = T.\nThe report does not have a minimum length, but should contain each of the following sections. The report should also have an informative, academically appropriate title along with each group member’s name.\n\nIntroduction\n\nThe introduction should introduce your research questions and the population(s) of interest. Your report should have at least one research question per team member. In the introduction, you should briefly motivate the research questions (i.e. explain why they were of interest to your group)!\n\nIt could be helpful to identify/label your research questions as “Question 1”, “Question 2”, etc. for easier reference moving forward.\n\n\n\n\nData collection\nThis section should describe your data and the sampling process: how the data were collected and a summary description of the variables you collected.\n\n\nMethods\nFor each research question, you should:\n\nIdentify the specific variables used to address the research question. Also describe if you had to create/mutate new variables or filter out/subset your analysis to focus on certain observations for this research question. For each analysis, please tell us the sample size you ended up with.\nInclude at least one visualization or table of summary statistics that will be useful/informative for answering the research question. Briefly interpret the visualization/summary table.\n\nIt is okay if if one visualization is complex enough to address multiple research questions!\n\nDescribe and justify the statistical method(s) that you will use to answer your research questions. Part of the “justification” component includes conditions being met, if applicable. For linear regression, you should only verify the “L” and the “I” at this point.\n\nBe specific about different groups/populations, direction of differences, explanatory vs response variable, etc.\nIf you are conducting a hypothesis test, don’t forget to define your hypotheses and set the significance level. If you are creating a confidence interval, be sure to specify the level of confidence.\n\n\n\n\nResults\n\nUsing appropriate code, conduct the statistical methods you described in the Methods section for each research question. Then interpret your results in context (i.e. use your interval/p-value/model to actually answer the question).\n\nIf you do linear regression, you should check the “N” and “E” conditions here.\n\nThe goal is not to do an exhaustive data analysis (i.e., do not calculate every statistic and procedure you have learned for every variable), but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results.\n\n\n\nDiscussion\nThis section is a conclusion and discussion. This will require:\n\nA summary of what you have learned about your research questions along with statistical arguments supporting your conclusions.\nA critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data/data collection and appropriateness of the statistical analysis should also be discussed here.\nA paragraph on what your group would do differently if you were able to start over with the project or what you would do next if you were going to continue work on the project should also be included."
  },
  {
    "objectID": "project/project_description.html#presentation",
    "href": "project/project_description.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\nEach group will present their work during the exam period. Presentation duration lengths (before questions) are:\n\nGroups of one: 5-7 minutes\nGroups of two: 7-9 minutes\nGroups of three: 9-11 minutes\n\nPart of your presentation grade will be sticking to the presentation duration. Your presentation will be followed by a few minutes for questions from the audience.\nYour presentation should be accompanied by slides that summarize and showcase your project. Introduce your research questions and data/data collection, showcase visualizations, and provide some conclusions. These slides should serve as a brief visual accompaniment and will be graded for content and quality. I recommend roughly one slide per minute of your presentation.\nThe slides are due to Canvas one hour before our final exam/presentation period.\n\nYou do not need to discuss all of your research questions if you don’t want to! You are not expected to have finished all your analyses by the time you present, but you should have some results (whether preliminary or finalized).\nIt’s most important that your audience understands the research questions you present, how you obtained your data, and how you plan to answer the research questions.\nPictures and summary tables are always preferred over sentences!\nA general recommendation is to have one slide per minute of the presentation.\nAll presenters should speak roughly an equal amount of time.\nMake sure the font is large enough. Also, less is more!\n\nPart of the presentation component is participation. You should be an engaged audience member. You will be asked to give feedback to a few groups and you are expected to ask questions.\n\nPresentation order\n\nLeBronJames (Dylan, Owen)\nLeMiddDash (Arthur, Hayes, Tommy)\nNo. (Natalie A., Calvin, Aaliyah)\nThe Trash CAN (Naomi, Conor, Aidan)\nThe Outlier (JuJu)\nStandard Deviants (Charlie, Haru, Luke)\nMinnie & Morgan\nCLIck (Lilah, Clio, Isa)\nI hate group names (Natalie O., Alden)"
  },
  {
    "objectID": "project/project_description.html#grading",
    "href": "project/project_description.html#grading",
    "title": "Final project",
    "section": "Grading",
    "text": "Grading\n\nGeneral grading structure\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\nContribution to group – Did you contribute meaningfully to all aspects of the project?\n\nA general breakdown of scoring for the final report and presentation is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\n\n\n\n\n\n\nComponent\nSection\nPoints\n\n\n\n\nProject proposal\n\n15 points\n\n\nInitial data set submission\n\n1 point\n\n\nRough draft\nPick one-two sections you’d like Prof. Tang to give feedback on!\n5 points\n\n\nPresentation\nPresentation style: well-practiced, equal distribution of speaking time, within time limit\n8 points\n\n\n\nSlides: content, quality\n5 points\n\n\n\nParticipation\n2 points\n\n\nFinal report\nIntroduction\n5 points\n\n\n\nData collection description\n5 points\n\n\n\nMethods\n25 points\n\n\n\nResults\n20 points\n\n\n\nDiscussion\n10 points\n\n\n\nClean code + reproducibility\n3 points\n\n\n\nSubmission of both PDF and .qmd report\n1 point\n\n\nReflection\n\n3 points\n\n\nMisc. items\nFinalized data set with accompanying dictionary (5/18)\n2 point\n\n\n\nContribution to group\n10 points\n\n\n\nDataFest project\n5 points\n\n\nTotal\n\n125 points"
  },
  {
    "objectID": "slides/slides-29-project.html#housekeeping",
    "href": "slides/slides-29-project.html#housekeeping",
    "title": "Final project",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nPlease sit with your final project group this week!\nOffice hours + additional 1:1 meetings available"
  },
  {
    "objectID": "slides/slides-29-project.html#final-report",
    "href": "slides/slides-29-project.html#final-report",
    "title": "Final project",
    "section": "Final report",
    "text": "Final report\n\nCollaborative working styles:\n\nPhysically work together on the same .Rmd document\nWork on separate .Rmd documents and then share code with each other (e.g. via a Googledoc) to compile one master .Rmd\nA combination of the above two as the project comes together\n\nRecommendations:\n\nClear your environment before running new, shared code\nKnit often"
  },
  {
    "objectID": "slides/slides-29-project.html#r-chunk-headers",
    "href": "slides/slides-29-project.html#r-chunk-headers",
    "title": "Final project",
    "section": "R chunk headers",
    "text": "R chunk headers\n\n\nIn .Rmd documents, we can control the behavior of specific code chunks by changing the settings in the chunk header:\n\n\n\n\n\n\n\nFor example, setting the option eval = F in the code chunk header means “do not evaluate the code in this chunk”.\n\n\n\n\nCode:\n\n\n\n\nOutput:"
  },
  {
    "objectID": "slides/slides-29-project.html#hiding-code",
    "href": "slides/slides-29-project.html#hiding-code",
    "title": "Final project",
    "section": "Hiding code",
    "text": "Hiding code\nWe can hide code from the viewer but still have it execute using the echo setting.\n\n\nCode:\n\n\n\nOutput:\n\n\n\n\n\n\n\nCode:\n\n\n\n\nOutput:"
  },
  {
    "objectID": "slides/slides-29-project.html#final-report-requirements",
    "href": "slides/slides-29-project.html#final-report-requirements",
    "title": "Final project",
    "section": "Final report: Requirements",
    "text": "Final report: Requirements\nReview the Report components on the Project description page."
  },
  {
    "objectID": "slides/slides-29-project.html#working-methods",
    "href": "slides/slides-29-project.html#working-methods",
    "title": "Final project",
    "section": "Working methods",
    "text": "Working methods\n\nCollaborative working styles:\n\nPhysically work together on the same .Rmd document\nWork on separate .Rmd documents and then share code with each other (e.g. via a Googledoc) to compile one master .Rmd\nA combination of the above two as the project comes together\n\nRecommendations:\n\nClear your environment before running new, shared code\nKnit often"
  },
  {
    "objectID": "slides/slides-29-project.html#rmd-template",
    "href": "slides/slides-29-project.html#rmd-template",
    "title": "Final project",
    "section": ".Rmd template",
    "text": ".Rmd template\nI have provided you with a .Rmd template for the final project. Feel free to add to/modify the template as your group sees fit!\n\nPlease ensure your .Rmd is in your STAT 201 folder\nThen, have a copy of your working dataset as a .csv file located in the same STAT 201 folder"
  },
  {
    "objectID": "slides/slides-29-project.html#data-file",
    "href": "slides/slides-29-project.html#data-file",
    "title": "Final project",
    "section": "Data file",
    "text": "Data file\n\nIn your group, everyone should have the same file name for the data.\nNow modify the second code chunk in the template to read in your data:\n\n\n\nNote: name the variable whatever you like (i.e. not need to use my_data, so long as your group is consistent.\n\n\nIf you prefer to use a .xlsx file, you will need to load the readxl package at the top of the document (may need to install first) and then modify the code to\n\n\n\nmy_data <- read_xlsx(\"data_file_name.xlsx\")"
  },
  {
    "objectID": "slides/slides-29-project.html#cleaning-your-data",
    "href": "slides/slides-29-project.html#cleaning-your-data",
    "title": "Final project",
    "section": "Cleaning your data",
    "text": "Cleaning your data\n\nYou might need to clean your data before working with it. This is probably most easily achieved within GoogleSheets or Excel rather than in R.\n\nE.g. a data entry is “6.4 hours” instead of 6.4, or there is inconsistent capitalization\n\nOnce/if your group has cleaned the data, you should replace the old data file in your STAT 201 folder with the cleaned version."
  },
  {
    "objectID": "project/final_project_template.html#introduction",
    "href": "project/final_project_template.html#introduction",
    "title": "STAT 201: Final Project Report Template",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "project/final_project_template.html#data-collection",
    "href": "project/final_project_template.html#data-collection",
    "title": "STAT 201: Final Project Report Template",
    "section": "Data Collection",
    "text": "Data Collection"
  },
  {
    "objectID": "project/final_project_template.html#methods",
    "href": "project/final_project_template.html#methods",
    "title": "STAT 201: Final Project Report Template",
    "section": "Methods",
    "text": "Methods"
  },
  {
    "objectID": "project/final_project_template.html#results",
    "href": "project/final_project_template.html#results",
    "title": "STAT 201: Final Project Report Template",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "project/final_project_template.html#discussion",
    "href": "project/final_project_template.html#discussion",
    "title": "STAT 201: Final Project Report Template",
    "section": "Discussion",
    "text": "Discussion"
  },
  {
    "objectID": "project/project_description.html#misc.-submission-items",
    "href": "project/project_description.html#misc.-submission-items",
    "title": "Final project",
    "section": "Misc. submission items",
    "text": "Misc. submission items\n\nFinalized data set + dictionary\nYou will be asked to submit your finalized, clean dataset. This may take the form of a .csv file or a link to a GoogleSheet. Please give each variable an informative one-word name. Alongside the submission, please include a separate file for the data dictionary: a bulleted list or table containing each variable name, a brief description of the variable, and the variable type. Include units if appropriate. If the variable is categorical, please provide all the levels as they appear in the cleaned data.\nThe purpose of the data dictionary is to enable future use of your data.\n\n\nReflection\nYou will be asked to write a brief reflection about the final project. There will be a few questions/prompts pertaining to your specific contribution, learning, and experience, along with an opportunity to comment on the group dynamics and working methods. The prompts/questions will be provided on the associated Canvas assignment."
  },
  {
    "objectID": "live_code/knitr.html",
    "href": "live_code/knitr.html",
    "title": "Knitting beautiful tables",
    "section": "",
    "text": "You may have noticed that the data frames are not the most beautiful in the knitted output. With the help of the knitr package, we can make the tables knit beautifully. When you knit for the first time, it may take a minute or two as more things get installed. Don’t panic! It will knit!\n\nAt the top of your document, load in the knitr package: library(knitr).\n\nYou may need to install this package first. Either do this in the “Packages” tab on the right, or in the Console by typing install.packages(\"knitr\").\n\nThen for any data frame/table you’d like to knit beautifully, just pipe directly to the kable() function. For example:\n\n\nlibrary(knitr)\nmod <- lm(volume ~ diam, data = cherry)\n## equivalently: kable(tidy(mod))\ntidy(mod) |>\n  kable()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-36.943459\n3.365145\n-10.97827\n0\n\n\ndiam\n5.065856\n0.247377\n20.47829\n0\n\n\n\n\n\nCompare this to when we don’t use kable():\n\ntidy(mod)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -36.9      3.37      -11.0 7.62e-12\n2 diam            5.07     0.247      20.5 8.64e-19\n\n\nYou can control the number of digits shown in the table:\n\ntidy(mod) |>\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-36.943\n3.365\n-10.978\n0\n\n\ndiam\n5.066\n0.247\n20.478\n0\n\n\n\n\n\nLook at the Help file for more customization!"
  },
  {
    "objectID": "practice_probs/practice-14-randomization.html",
    "href": "practice_probs/practice-14-randomization.html",
    "title": "Hypothesis testing with Randomization",
    "section": "",
    "text": "The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that they were gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable transplant indicates which group the patients were in: treatment (received transplant) or control (no transplant). The variable survived indicates whether the patient was alive at the end of the study or died. Of the 34 patients in the control group, 30 died. Of the 69 people in the treatment group, 45 died.\n\n\nWhat do the two plots above suggest about 1) if survival is independent of receiving a transplant and 2) the efficacy of heart transplants? Explain your reasoning.\nWhat proportion of patients in the treatment group and the control group died?\nWrite out a null and alternative hypothesis for investigating whether there is statistically significant evidence that the treatment is effective.\nThe paragraph below describes the set up for a randomization test if we did not have access to software. Fill in the blanks with a number or phrase using your answers to (b) and (c) for guidance:\nWe write the word ______ on _______ cards representing patients who were alive at the end of the study, and ______ on ______ cards representing the patients who were not. Then we shuffle these cards and split them into two groups: one group of size ______ representing treatment, and one group of size ______ representing _________. We calculate the difference between the proportion of ________ cards in the treatment and control groups (treatment - control) and record this value. We repeat this 1000 times to build a distribution centered at _______. This is called the ________ distribution. Lastly, we calculate the proportion of simulations where the simulated difference in proportions are _________. If this proportion is low, we conclude that that it is __________ to have observed our data by chance assuming ___________.\nWhat do the simulation results shown below suggest about the effectiveness of heart transplants?\n\nSuggest a more informative x-axis label for the plot above.\n\nUnderstanding cultural differences in tobacco use across different demographic groups can lead to improved health care education and treatment. A recent study dis-aggregated tobacco use across Asian American ethnic groups, including Asian-Indian (n = 4373), Chinese (n = 4736), and Filipino (n = 4912), in comparison to non-Hispanic Whites (n = 275025). The number of current smokers in each group at the time of study was reported as:\n\nAsian-Indian: 223\nChinese: 279\nFilipino: 609\nnon-Hispanic Whites: 50880\n\nTo determine whether the proportion of Asian-Indian Americans who are current smokers is different from the proportion of Chinese Americans who are smokers, a randomization simulation was performed.\n\nUsing both symbols and words, provide the parameter and statistic of interest for this study. Do you know the numerical value of either the parameter or statistic of interest? If so, provide it.\nThe histogram below provides the simulated null distribution obtained from 1000 repetitions. Estimate the standard error.\n\nConsider the hypothesis test to determine if there is a difference in proportion of Asian-Indian Americans as compared to Chinese Americans who are current smokers. Write out the null and alternative hypotheses, and estimate a p-value using the randomization histogram from (b). If the significance level is \\(\\alpha = 0.05\\), what is your decision and conclusion in the context of the problem?\nNow consider the following bootstrap distribution of the difference in sample proportions of current smokers (Filipino Americans minus Chinese Americans) in 1000 repetitions. Find a 95% bootstrap confidence interval for the true difference in the proportion of current smokers in the population. Interpret the interval in the context of the problem, assuming our sample is representative."
  },
  {
    "objectID": "slides/worksheet-16-normal.html#rules",
    "href": "slides/worksheet-16-normal.html#rules",
    "title": "Normal distribution",
    "section": "68-95-99.7 rules",
    "text": "68-95-99.7 rules"
  },
  {
    "objectID": "slides/worksheet-16-normal.html#finding-areas",
    "href": "slides/worksheet-16-normal.html#finding-areas",
    "title": "Normal distribution",
    "section": "Finding areas",
    "text": "Finding areas\nSuppose \\(X \\sim N(0,1)\\)\n\n\n\nArea less than -2 and greater than 2.\n\n\nArea between 0 and 1.\n\n\nArea to the right of 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\quad\\)\n\n\n\\(\\quad\\)\n\n\n\\(\\quad\\)\n\n\n\n\n\\(\\text{P}(\\qquad\\qquad\\qquad) \\approx\\)\n\n\n\\(\\quad\\)\n\n\n\\(\\quad\\)"
  },
  {
    "objectID": "slides/worksheet-16-normal.html#z-score-problem",
    "href": "slides/worksheet-16-normal.html#z-score-problem",
    "title": "Normal distribution",
    "section": "Z-score problem",
    "text": "Z-score problem\nThe distribution of SAT and ACT scores are both nearly Normal. The SAT has a mean of 1100 and standard deviation of 200, while the ACT has a mean of 21 and standard deviation of 6. Suppose Ann scored 1300 on her SAT and Tom scored 24 on his ACT. Who performed better?"
  },
  {
    "objectID": "slides/worksheet-16-normal.html#percentiles",
    "href": "slides/worksheet-16-normal.html#percentiles",
    "title": "Normal distribution",
    "section": "Percentiles",
    "text": "Percentiles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqnorm(0.25, mean = mu, sd = sigma)"
  },
  {
    "objectID": "slides/worksheet-16-normal.html#percentile-problems",
    "href": "slides/worksheet-16-normal.html#percentile-problems",
    "title": "Normal distribution",
    "section": "Percentile problems",
    "text": "Percentile problems\nSuppose SAT scores are Normally distributed with mean 1100 and standard deviation 200.\n\nEdward earned a 1030 on his SAT. We will find his percentile using code in two ways.\n\nFirst, draw a picture representing what we want to find. Then write code to find the percentile.\nFind Edward’s z-score. Write another line of code to find the percentile.\n\nWhat is the 97.5th percentile for SAT scores?\n\nWrite code to answer this question.\nWrite a different line of code to answer this question that involves a z-score.\n\nUnrelated to SAT scores: consider the standard normal \\(N(0,1)\\) distribution. The 25th percentile of this distribution is -0.67. Without doing any work beyond drawing a picture, what is the 75th percentile of the distribution?"
  },
  {
    "objectID": "slides/worksheet-16-normal.html#some-practice-problems",
    "href": "slides/worksheet-16-normal.html#some-practice-problems",
    "title": "Normal distribution",
    "section": "Some practice problems",
    "text": "Some practice problems\n\nIn a law school class, the entering students averaged 160 on the LSAT. The variance was 64. The histogram of LSAT scores followed the normal curve reasonable well.\n\nAbout what percentage of the class scores below 152?\nOne student was 0.5 standard deviations above average on the LSAT. About what percentage of the students had lower scores than he did?\n\nWeights of 10-year-old girls are known to be Normally distributed with mean of 70 pounds and standard deviation of 13 pounds. Find the probability that a 10-year-old girl weighs between 60 and 85 pounds two ways:\n\nOptional, but helpful: draw a sketch of the curve and shade in the region of interest.\nWrite the probability of interest in \\(P()\\) form. Then write the R code necessary to find this probability, and actually execute the code to obtain the probability.\nConfirm your solution in (b) by transforming to z-scores first, then using code again to obtain the probability.\n\nConsider the same scenario as in 2. Without using any code than what is provided below, find the 60th percentile for the weight of 10-year-old girls.\n\nqnorm(0.6, mean = 0, sd = 1)\n\n[1] 0.2533471\n\n\n\\((^*)\\) Suppose body temperatures are Normally distributed with mean \\(98.6^\\circ\\) F and standard deviation of \\(0.7^\\circ\\) F. Assuming this is true, answer the following:\n\nFevers \\(103^\\circ\\) F or higher are considered dangerous. What fraction of people would be expected to have such high a fever?\nAccording to quick Google search, a range for low-grade fever is between \\(99.5^\\circ\\) F and \\(100.3^\\circ\\) F. What is the probability of having a low-grade fever?\nWhat body temperatures would you consider as unusually low? Briefly explain why.\nProvide two intervals that each capture/contain 80% of body temperatures."
  },
  {
    "objectID": "slides/slides-07-wrangling.html",
    "href": "slides/slides-07-wrangling.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nRecall: data frames are objects in R that store tabular data in tidy form\nThe dplyr package uses the concept of functions as verbs that manipulate data frames\n\nselect(): pick columns by name\nslice(): pick rows using indices\nfilters(): pick rows matching criteria\ndistinct(): filter for unique rows\nmutate(): add new variables as columns\nsummarise(): reduce variables to quantitative values\ngroup_by(): for grouped operations based on a variable\nand many more!!!"
  },
  {
    "objectID": "slides/installation_instructions.html",
    "href": "slides/installation_instructions.html",
    "title": "Installation instructions",
    "section": "",
    "text": "Please install R and RStudio (in this order). Instructions are provided below depending on if you have a Mac/Windows or Linux. Be sure to verify that your installation was successful (see last part of this page). Please come by installation office hours if you have trouble or would like guidance during the installation process!"
  },
  {
    "objectID": "slides/installation_instructions.html#installing-r",
    "href": "slides/installation_instructions.html#installing-r",
    "title": "Installation instructions",
    "section": "Installing R",
    "text": "Installing R\n\nGo to the CRAN website and click on the appropriate link under “Download and Install R”. Then:\n\nWindows: click on the blue text that says “Install R for the first time”.\nmacOS: check your Mac OS system and if you have a chip (Apple icon -> About this Mac -> Overview)\n\nThen on the website, click the newest release that supports your current OS version. This will most likely be R-4.4.1-arm64.pkg or R-4.4.1-x86_64.pkg.\n\n\n\nA file will download, most likely to your Downloads folder. Run the file by clicking on it. Allow the app to make changes to your device if prompted.\nFollow the installation instructions, until you click on “Finish” to exit the installation setup. At this point, R should be successfully installed!"
  },
  {
    "objectID": "slides/installation_instructions.html#installing-rstudio",
    "href": "slides/installation_instructions.html#installing-rstudio",
    "title": "Installation instructions",
    "section": "Installing RStudio",
    "text": "Installing RStudio\n\nGo to this Posit website and scroll down a little until you see two steps. We already did Step 1!\nUnder Step 2, click the blue Download RStudio Desktop button recommended for your computer\n\nmacOS users: double check you have an OS that is recent enough! If not, find an older version of RStudio suitable for you OS.\n\nRun the downloaded RStudio Executable file until you hit the “Finish” button. It may be the case that you don’t have to click anything at all.\nAfter RStudio finishes downloading, a window like this might pop up. If so, go ahead and drag the RStudio icon into the Applications folder."
  },
  {
    "objectID": "slides/installation_instructions.html#installing-r-1",
    "href": "slides/installation_instructions.html#installing-r-1",
    "title": "Installation instructions",
    "section": "Installing R",
    "text": "Installing R\n\nFollow the instructions on for Steps 1 and 2 on this website."
  },
  {
    "objectID": "slides/installation_instructions.html#installing-rstudio-1",
    "href": "slides/installation_instructions.html#installing-rstudio-1",
    "title": "Installation instructions",
    "section": "Installing RStudio",
    "text": "Installing RStudio\n\nGo to step 3 of the same website"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#rstudio",
    "href": "slides/slides-02-toolkit-installation.html#rstudio",
    "title": "Toolkit",
    "section": "RStudio",
    "text": "RStudio\nTo open RStudio, simply double click on the RStudio icon (you do not need to click on the R icon)"
  },
  {
    "objectID": "slides/02-rstudio_help_sheet.html",
    "href": "slides/02-rstudio_help_sheet.html",
    "title": "RStudio Help Sheet",
    "section": "",
    "text": "A .qmd document in the Source pane might look like the following:\n\n\nWhat is the major difference between running code in an .qmd document in the Source pane versus running code in the Console?\n\nAll code gets run/executed in the Console\nThe Source pane is simply a text editor: you can write and save code here to edit later. When you run code in the Source pane, it actually gets executed in the Console.\n\nIn this course, we will almost always write our code in the Source pane within a .Rmd document.\nCode run in the Console will be “lost” whenever you quit RStudio.\n\n\n\nThe working directory is the default location where R will look for files you want to load and where it will put any files you save. All files are read in relation to the current working directory!\n\nWhere can we see the current working directory?\n\nWhat if we want to change the working directory?"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#your-file-system",
    "href": "slides/slides-02-toolkit-installation.html#your-file-system",
    "title": "Toolkit",
    "section": "Your file system",
    "text": "Your file system"
  },
  {
    "objectID": "homework/hw0.html",
    "href": "homework/hw0.html",
    "title": "Problem Set 0",
    "section": "",
    "text": "Due: 2/12/25 before class\nEither typed or written + scanned, submit a PDF to the corresponding Canvas assignment (via Gradescope) answering the following questions:\n\nWhat is your name and your preferred gender pronouns?\nWhat year are you at Middlebury?\nWhat classes are you most excited and nervous about this semester? (No offense taken or brownie points given if you list this course!)\nWhat is your major(s)/area of interest? If you don’t know, that’s also fine!\nWhy are you interested in taking this course?\nWhen and where did you take a Calculus class?\nDo you have any programming experience? If so, in what capacity?\nPlease identify which of my office hours times work for you, if any. (Monday 2-3pm, Friday 10-11am)\nIs there anything that might be important for me to know about demands on your time this semester? (e.g. clubs, sports, five-course semester)\nOptional: any questions for me?"
  },
  {
    "objectID": "slides/slides-00-welcome.html#first-assignment-submission",
    "href": "slides/slides-00-welcome.html#first-assignment-submission",
    "title": "Welcome!",
    "section": "First assignment + submission",
    "text": "First assignment + submission\n\nProblem Set 0: answers to a brief questionnaire are due before next class. See the course Schedule page for details!\nAll coding practice and homework assignments will be submitted to Gradescope via Canvas. You should all be able to access your Gradescope account using your Middlebury College credentials.\n\nOn Canvas, assignments can be found in both the Assignment tab and the Gradescope tab\nSubmissions can be resubmitted as many times as you like up until the due date\nWe will walk through how to submit an assignment together, but instructions + video can also be found here"
  },
  {
    "objectID": "slides/slides-00-welcome.html#population-and-samples",
    "href": "slides/slides-00-welcome.html#population-and-samples",
    "title": "Welcome!",
    "section": "Population and samples",
    "text": "Population and samples\n\nData do not come from thin air! Data have to be collected in some way.\nThis usually takes the form of sampling a subset of individuals from a target group of interest\n\nThe target group of interest is called the population\nThe subset of individuals from whom we actually collect data is the sample\n\nA case is a fancy term for saying one observational unit\n\nIn the kidney cancer example, the cases are counties\n\n\nWhat are the target populations and cases in the following?\n\nWhat is the average height of trees on Middlebury College campus?\nWhat proportion of current Middlebury professors attended a liberal arts college?\nOver the last five years, what is the average time to complete a degree for Middlebury students?"
  },
  {
    "objectID": "slides/slides-00-welcome.html#population-and-samples-cont.",
    "href": "slides/slides-00-welcome.html#population-and-samples-cont.",
    "title": "Welcome!",
    "section": "Population and samples (cont.)",
    "text": "Population and samples (cont.)\n\nTypically, the size of the sample is way smaller than the population. Why?\n\nIn the lucky event that we are able to collect data for every individual in the population, the sample is referred to as a census\n\nExample: the U.S. Census Bureau is responsible for producing data about the American people and economy. They collect data with different schemes and frequency:\n\nDecennial census\nAmerican community survey"
  },
  {
    "objectID": "slides/slides-00-welcome.html#parameters-and-statistics",
    "href": "slides/slides-00-welcome.html#parameters-and-statistics",
    "title": "Welcome!",
    "section": "Parameters and statistics",
    "text": "Parameters and statistics\n\nOften times, answering a research question simplifies to understanding a numerical summary.\n\n(Population) parameter: a numerical summary calculated from (or considered for calculation from) the entire population\n(Sample) statistic: a numerical summary calculated from a sample\n\nWhy do we differentiate? It’s always good to remember that we are trying to answer questions about the population!\nIn kidney cancer data, we might want to know a county’s true kidney cancer rate (for white males, 1980-1989)\n\nThis would be an example of a population parameter\nUnless all white males in the county responded, the reported rate is an example of a sample statistic"
  },
  {
    "objectID": "slides/slides-01-study-design.html#convenience-sampling",
    "href": "slides/slides-01-study-design.html#convenience-sampling",
    "title": "Study design",
    "section": "Convenience sampling",
    "text": "Convenience sampling\nThe worst kind of sampling (but often the easiest)!\n\nConvenience sampling takes place when cases that are easily accessible are more likely to be included in the sample\nExample:\n\nPopulation: students enrolled in statistics courses at Middlebury\nSample: students in STAT 201 AZ"
  },
  {
    "objectID": "slides/slides-01-study-design.html#variables-in-statistics",
    "href": "slides/slides-01-study-design.html#variables-in-statistics",
    "title": "Study design",
    "section": "Variables in statistics",
    "text": "Variables in statistics\n\nWhat is a variable?\n\n\nVariables in math represent a quantity that can change; not fixed. For us, it’s the same idea! A variable is a characteristic/number/quantity that can be measured or counted and can take different values\n\n\nLots of research questions revolve around asking how variable \\(x\\) affects variable \\(y\\)\nIf \\(y\\) is the primary variable of interest, i.e. the variable whose behavior we want to understand, it is called the response variable\nIf we try to understand how changing \\(x\\) affects \\(y\\), then \\(x\\) is called the explanatory variable\n\nIn scientific studies, explanatory variables can often be manipulated/controlled/observed by the researcher ahead of time"
  },
  {
    "objectID": "slides/slides-01-study-design.html#experiments-vs-observainal-studies",
    "href": "slides/slides-01-study-design.html#experiments-vs-observainal-studies",
    "title": "Study design",
    "section": "Experiments vs Observainal studies",
    "text": "Experiments vs Observainal studies\n\nObservational studies occur when a research observes cases without manipulating any variables\nExperiments are studies where the researcher assigns specific treatments to cases\n\nNote: experiments are often conducted in medical settings, hence the word “treatment”\n\nExample: I believe that students who take quizzes throughout the semester end up performing better on the final exam.\n\nObservational study: students optionally take quizzes\nExperiment: I choose half of the students to take quizzes and the other half to not take quizzes.\n\n\nAre treatments in experiments considered explanatory or response variables?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#randomized-experiments",
    "href": "slides/slides-01-study-design.html#randomized-experiments",
    "title": "Study design",
    "section": "Randomized experiments",
    "text": "Randomized experiments\n\nWhen the researcher randomly assigns the treatments, we have a randomized experiment\n\nRandomized experiments are critical when trying to assess the causal effect of the explanatory variable on the response variable\n\nNote: random assignment in experiments \\(\\ne\\) random sampling for participation in the sample\nContinuing example:\n\nRandomized experiment is achieved if I use SRS to determine who received which treatment\nBut the students who “participate” in the experiment were not obtained via SRS"
  },
  {
    "objectID": "slides/slides-01-study-design.html#experiments-vs-observational-studies",
    "href": "slides/slides-01-study-design.html#experiments-vs-observational-studies",
    "title": "Study design",
    "section": "Experiments vs Observational studies",
    "text": "Experiments vs Observational studies\n\nObservational studies occur when a research observes cases without manipulating any variables\nExperiments are studies where the researcher assigns specific treatments to cases\n\nNote: experiments are often conducted in medical settings, hence the word “treatment”\n\nExample: I want to design a study to learn if students who take quizzes throughout the semester end up performing better on the final exam.\n\nObservational study: students optionally take quizzes\nExperiment: I choose half of the students to take quizzes and the other half to not take quizzes.\n\n\nAre treatments in experiments considered explanatory or response variables?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#treatment-vs-control",
    "href": "slides/slides-01-study-design.html#treatment-vs-control",
    "title": "Study design",
    "section": "Treatment vs control",
    "text": "Treatment vs control\n\nTreatments are typically divided into two categories:\n\nControl group: establishes a baseline, and typically receives “zero amount” of the explanatory variable\nTreatment group(s): receive some “non-zero amount” of the explanatory variable\n\nQuiz example continued:\n\nControl group: no quizzes\nTreatment group 1: takes one quiz\nTreatment group 2: takes two quizzes\n\nHow to decide which case gets which treatment?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments-cont.",
    "href": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments-cont.",
    "title": "Study design",
    "section": "Reducing bias in human experiments (cont.)",
    "text": "Reducing bias in human experiments (cont.)\nCaveats:\n\nBlinding not always possible! It would be hard to give a placebo in the quiz experiment\nQuestion of ethics"
  },
  {
    "objectID": "live_code/intro_R.html#quarto-markdown-basics",
    "href": "live_code/intro_R.html#quarto-markdown-basics",
    "title": "Intro to R and Quarto Markdown",
    "section": "Quarto Markdown basics",
    "text": "Quarto Markdown basics\nHow do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right. These backs ticks must be aligned on the same tabulation.\nThis defines ______. All of our R code should go into one.\n\n\n\n\n\n\n\nWhat happens if we delete a back tick?\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n1.\n2.\n\nsqrt(4)\n\n[1] 2"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#quarto-markdown",
    "href": "slides/slides-02-toolkit-installation.html#quarto-markdown",
    "title": "Toolkit",
    "section": "Quarto Markdown",
    "text": "Quarto Markdown\n\nAllows us to create fully reproducible reports\nCan code in code chunks and type regular text/narrative outside of these chunks\nHow will we use Quarto Markdown?\n\nYou coding practice problems and some problems on your weekly assignments will be assigned as a Quarto Markdown document (.qmd)\nYou will almost always be provided with a template .qmd to start with (the exception being the end of the semester when you’ve mastered this material!)"
  },
  {
    "objectID": "slides/slides-02-toolkit.html",
    "href": "slides/slides-02-toolkit.html",
    "title": "Toolkit",
    "section": "",
    "text": "A few more homework problems released today. Yesterday and today’s problems are due to Gradescope by Monday 11:59pm\nOffice hours reminder!"
  },
  {
    "objectID": "slides/slides-02-toolkit.html#reproducibility",
    "href": "slides/slides-02-toolkit.html#reproducibility",
    "title": "Toolkit",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nAllows your code execution or an experiment to be repeated by another person\nGoals:\n\nAre the tables and figures generated directly from the code?\nDoes the code actually do what you think it does?\nCan your code be used for other data/analyses?"
  },
  {
    "objectID": "slides/slides-02-toolkit.html#toolkit",
    "href": "slides/slides-02-toolkit.html#toolkit",
    "title": "Toolkit",
    "section": "Toolkit",
    "text": "Toolkit\n\n\nWe will use the programming language R to write code\nHow will interact with the R code? In the integrated development environment called RStudio. Helps us be more productive with R\n\nR is like a car engine, and RStudio is like a car’s dashboard\n\nWe will liberate our programming by keeping code, narrative, and output all in the same interface using Quarto Markdown documents"
  },
  {
    "objectID": "slides/slides-02-toolkit.html#quarto-markdown",
    "href": "slides/slides-02-toolkit.html#quarto-markdown",
    "title": "Toolkit",
    "section": "Quarto Markdown",
    "text": "Quarto Markdown\n\nAllows us to create fully reproducible reports\nCan code in code chunks and type regular text/narrative outside of these chunks\nHow will we use Quarto Markdown?\n\nYou coding practice problems and some problems on your weekly assignments will be assigned as a Quarto Markdown document (.qmd)\nYou will almost always be provided with a template .qmd to start with (the exception being the end of the semester when you’ve mastered this material!)"
  },
  {
    "objectID": "slides/slides-02-toolkit.html#rstudio",
    "href": "slides/slides-02-toolkit.html#rstudio",
    "title": "Toolkit",
    "section": "RStudio",
    "text": "RStudio\nTo open RStudio, simply double click on the RStudio icon (you do not need to click on the R icon)"
  },
  {
    "objectID": "slides/slides-02-toolkit.html#make-a-folder",
    "href": "slides/slides-02-toolkit.html#make-a-folder",
    "title": "Toolkit",
    "section": "Make a folder",
    "text": "Make a folder\nCreate a new folder on your Desktop that is named STAT 201.\n\n\nAll of your files for this course should go into this folder!!!!"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#live-code-incremental-false",
    "href": "slides/slides-03-numerical-pt1.html#live-code-incremental-false",
    "title": "Numerical data",
    "section": "Live code {incremental: false}",
    "text": "Live code {incremental: false}\nFunctions to calculate sample mean, variance, and standard deviation in R:\n\nmean()\nvar()\nsd()"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#visualizing-univariate-numerical-data",
    "href": "slides/slides-03-numerical-pt1.html#visualizing-univariate-numerical-data",
    "title": "Numerical data",
    "section": "Visualizing univariate numerical data",
    "text": "Visualizing univariate numerical data\n\nTo visualize the distribution (i.e. behavior) of a single variable, we could create a dot plot where:\n\nEach case is plotted on a horizontal axis as a dot\nValues that appear multiple times in the dataset would have stacked dots\n\n\nPros and cons?\n\nIn the following, we have a dot plot of BMI rounded to the nearest integer."
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#examples",
    "href": "slides/slides-03-numerical-pt1.html#examples",
    "title": "Numerical data",
    "section": "Examples",
    "text": "Examples\n\nLet’s calculate the sample mean weight of a piece of candy in our bag. Let \\(x\\) be the weight of a candy.\n\n\nCalculate your \\(\\bar{x}\\)\n\nNote: we did not need individual values \\(x_{1}, x_{2},\\ldots\\) to calculate \\(\\bar{x}\\)!\n\nCan we obtain the population mean?\n\n\\(\\mu=\\)\n\n\n\n\n\nWhat is the average of the following values? \\(\\qquad 1, 4, 4\\)\nIf instead there were ten 1’s and twenty 4’s, would the average be the same?\nThus, we see that means depend on proportions!"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#condensing-information",
    "href": "slides/slides-03-numerical-pt1.html#condensing-information",
    "title": "Numerical data",
    "section": "Condensing information",
    "text": "Condensing information\n\nWe often care about variable’s distribution: the different values the variable can take on along with how often\nRather than provide someone with an entire dataset, it is more useful to provide quick “snapshot” information\nTwo pieces of quantitative information that describe a distribution:\n\nCenter\nSpread"
  },
  {
    "objectID": "coding_practice/coding-practice-04.-numerical-pt2.html",
    "href": "coding_practice/coding-practice-04.-numerical-pt2.html",
    "title": "Numerical data coding practice",
    "section": "",
    "text": "Change your name in the YAML.\nIn the following code chunk, load in the openintro package. Then run this code chunk. We need this package to once again work with the cherry data frame.\n\n\n\n\n\nIf we have a data frame (like cherry), we can access a specific variable’s data in the data frame by typing the code like the following: data_frame_name$variable_name. Note that the spelling of the variable name must match how it appears in the data frame!\n\nIn the code chunk below, obtain the values of the observed diameters of these trees using code. Then answer: what type of object is output from the code?\n\n\n\nAnswer:\n\nIn the code chunk below, write code to find the mean and median of the height of trees in the cherry data frame. Based on what you find, answer the following: do you believe the distribution of the height of cherry trees is skewed or symmetric? Why?\n\n\n\n\nAnswer:\n\nLet’s confirm your answer above by creating a rather ugly (but easy to obtain) histogram. The hist() function requires one input: a vector of numerical values to visualize. Plot a histogram of the heights of these trees.\n\n\n\n\n\nOptional: modify the plot above by specifying some of all of following extra inputs to the hist() function.\n\n\nmain: plot title (must be a string object)\nxlab: x-axis label (must be a string object)\ncol: color to fill the bars in with (must be a valid color specified as a string object)\n\nThis looks like hist(data, main = \"Title\", xlab = \"x-axis title\", col = \"some color\").\nOnce you’re finished, be sure to render and submit the outputted PDF file to the corresponding Gradescope assignment!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#announcements",
    "href": "slides/slides-04-numerical-pt2.html#announcements",
    "title": "Numerical data",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours change next week\nHomework 2 due date changed"
  },
  {
    "objectID": "live_code/live_code_notes.html",
    "href": "live_code/live_code_notes.html",
    "title": "STAT 201 Live code notes",
    "section": "",
    "text": "# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#changing-plot-theme",
    "href": "slides/slides-06-categorical-data.html#changing-plot-theme",
    "title": "Categorical data",
    "section": "Changing plot theme",
    "text": "Changing plot theme\n\n\nChange the background of plots by adding on any one of the following:\n\ntheme_bw(), theme_minimal(), theme_gray(), theme_void() and a few more (see all options by checking the help file for any one of these)\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = smoker, y = bmi)) +\n  geom_boxplot() +\n  theme_minimal()"
  },
  {
    "objectID": "schedule.html#code-copy",
    "href": "schedule.html#code-copy",
    "title": "Schedule",
    "section": "Code copy",
    "text": "Code copy"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#housekeeping",
    "href": "slides/slides-08-wrangle-prob.html#housekeeping",
    "title": "More wrangling + Probability",
    "section": "Housekeeping",
    "text": "Housekeeping"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#joining-data-frames",
    "href": "slides/slides-08-wrangle-prob.html#joining-data-frames",
    "title": "More wrangling + Probability",
    "section": "Joining data frames",
    "text": "Joining data frames\nAssume we have two data frame, x and y. There are some shared variables (i.e. columns) in the two. Suppose we want to combine them together.\n\nsomething_join(x, y)\n\n\nMutating joins:\n\nleft_join(): return all rows from x\nright_join(): return all rows from y\nfull_join(): return all rows from both x and y\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\n\nFiltering joins:\n\nsemi_join(): return all rows from x where there are matching values in y, keeping just columns from x\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#setup",
    "href": "slides/slides-08-wrangle-prob.html#setup",
    "title": "More wrangling + Probability",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\n\n\n\nx\n\n\n\n\n\n\nID\nx_val\n\n\n\n\n1\nx1\n\n\n2\nx2\n\n\n3\nx3\n\n\n\n\n\n\n\n\n\n\ny\n\n\n\n\n\n\nID\ny_val\n\n\n\n\n1\ny1\n\n\n2\ny2\n\n\n4\ny4"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#anti_join",
    "href": "slides/slides-08-wrangle-prob.html#anti_join",
    "title": "More wrangling + Probability",
    "section": "anti_join()",
    "text": "anti_join()\nReturns all rows from x without any match in y, and not add columns from y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nanti_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    3 \n    x3"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#left_join",
    "href": "slides/slides-08-wrangle-prob.html#left_join",
    "title": "More wrangling + Probability",
    "section": "left_join()",
    "text": "left_join()\nAdds columns to x from y, matching all rows in x\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nleft_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#right_join",
    "href": "slides/slides-08-wrangle-prob.html#right_join",
    "title": "More wrangling + Probability",
    "section": "right_join()",
    "text": "right_join()\nAdds columns to x from y, matching all rows in y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nright_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    4 \n    NA \n    y4"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#full_join",
    "href": "slides/slides-08-wrangle-prob.html#full_join",
    "title": "More wrangling + Probability",
    "section": "full_join()",
    "text": "full_join()\nAdds columns to x from y, matching all rows in x OR y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nfull_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA \n  \n  \n    4 \n    NA \n    y4"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#inner_join",
    "href": "slides/slides-08-wrangle-prob.html#inner_join",
    "title": "More wrangling + Probability",
    "section": "inner_join()",
    "text": "inner_join()\nAll rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\ninner_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#semi_join",
    "href": "slides/slides-08-wrangle-prob.html#semi_join",
    "title": "More wrangling + Probability",
    "section": "semi_join()",
    "text": "semi_join()\nReturns all rows from x with a match in y, but does not add columns from y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nsemi_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#inner_join-cont.",
    "href": "slides/slides-08-wrangle-prob.html#inner_join-cont.",
    "title": "More wrangling + Probability",
    "section": "inner_join() (cont.)",
    "text": "inner_join() (cont.)\nExample with multiple matches:\n\n\n\nx2\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n  \n    1 \n    new_x \n  \n\n\n\n\n\n\n\ny2\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n  \n    1 \n    new_y \n  \n\n\n\n\n\n\n\n\ninner_join(x2, y2, by = \"ID\")\n\n\n\nWarning in inner_join(x2, y2, by = \"ID\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    1 \n    x1 \n    new_y \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    1 \n    new_x \n    y1 \n  \n  \n    1 \n    new_x \n    new_y"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#joining-with-different-variable-names",
    "href": "slides/slides-08-wrangle-prob.html#joining-with-different-variable-names",
    "title": "More wrangling + Probability",
    "section": "Joining with different variable names",
    "text": "Joining with different variable names\nIf the variables in x and y have different names but we know they represent the same variable:\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny3\n\n\n\n\n\n \n  \n    ID_y \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nleft_join(x, y3, by =  c(\"ID\" = \"ID_y\"))\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#joining-on-multiple-variables",
    "href": "slides/slides-08-wrangle-prob.html#joining-on-multiple-variables",
    "title": "More wrangling + Probability",
    "section": "Joining on multiple variables",
    "text": "Joining on multiple variables\nCan specify more than one variable in the by argument. Will need to be a vector of characters."
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#section",
    "href": "slides/slides-08-wrangle-prob.html#section",
    "title": "More wrangling + Probability",
    "section": "",
    "text": "fishery harvest of countries for 2016, by capture and aquaculture\n\nlibrary(readr)\nfish_url <- \"https://raw.githubusercontent.com/math118-fall2022/website/refs/heads/master/docs/slides/lec-slides/data/fisheries.csv\"\ncountries_url <- \"https://raw.githubusercontent.com/math118-fall2022/website/refs/heads/master/docs/slides/lec-slides/data/continents.csv\"\nfisheries <- read_csv(fish_url)\n\nRows: 216 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): country\ndbl (3): capture, aquaculture, total\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinents <- read_csv(countries_url)\n\nRows: 245 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): country, continent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nkable(fisheries) |>\n  kable_styling(font_size = 20)\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    total \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    2200 \n  \n  \n    Albania \n    7886 \n    950 \n    8836 \n  \n  \n    Algeria \n    95000 \n    1361 \n    96361 \n  \n  \n    American Samoa \n    3047 \n    20 \n    3067 \n  \n  \n    Andorra \n    0 \n    0 \n    0 \n  \n  \n    Angola \n    486490 \n    655 \n    487145 \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n    3010 \n  \n  \n    Argentina \n    755226 \n    3673 \n    758899 \n  \n  \n    Armenia \n    3758 \n    16381 \n    20139 \n  \n  \n    Aruba \n    142 \n    0 \n    142 \n  \n  \n    Australia \n    174629 \n    96847 \n    271476 \n  \n  \n    Austria \n    350 \n    3483 \n    3833 \n  \n  \n    Azerbaijan \n    676 \n    640 \n    1316 \n  \n  \n    Bahamas \n    11625 \n    8 \n    11633 \n  \n  \n    Bahrain \n    15000 \n    6 \n    15006 \n  \n  \n    Bangladesh \n    1674770 \n    2203554 \n    3878324 \n  \n  \n    Barbados \n    1735 \n    26 \n    1761 \n  \n  \n    Belarus \n    686 \n    11199 \n    11885 \n  \n  \n    Belgium \n    26970 \n    44 \n    27014 \n  \n  \n    Belize \n    91432 \n    953 \n    92385 \n  \n  \n    Benin \n    49806 \n    3080 \n    52886 \n  \n  \n    Bermuda \n    410 \n    0 \n    410 \n  \n  \n    Bhutan \n    7 \n    150 \n    157 \n  \n  \n    Bolivia \n    7000 \n    3000 \n    10000 \n  \n  \n    Bosnia and Herzegovina \n    305 \n    4564 \n    4869 \n  \n  \n    Botswana \n    38 \n    15 \n    53 \n  \n  \n    Brazil \n    705000 \n    581230 \n    1286230 \n  \n  \n    British Virgin Islands \n    1200 \n    0 \n    1200 \n  \n  \n    Brunei \n    13292 \n    948 \n    14240 \n  \n  \n    Bulgaria \n    8614 \n    15762 \n    24376 \n  \n  \n    Burkina Faso \n    22070 \n    470 \n    22540 \n  \n  \n    Burundi \n    21805 \n    1330 \n    23135 \n  \n  \n    Cambodia \n    629950 \n    172500 \n    802450 \n  \n  \n    Cameroon \n    233190 \n    2315 \n    235505 \n  \n  \n    Canada \n    874727 \n    200765 \n    1075492 \n  \n  \n    Cape Verde \n    19900 \n    0 \n    19900 \n  \n  \n    Cayman Islands \n    125 \n    0 \n    125 \n  \n  \n    Central African Republic \n    29000 \n    190 \n    29190 \n  \n  \n    Chad \n    110000 \n    94 \n    110094 \n  \n  \n    Chile \n    1829238 \n    1050117 \n    2879355 \n  \n  \n    China \n    17800000 \n    63700000 \n    81500000 \n  \n  \n    Colombia \n    86344 \n    96970 \n    183314 \n  \n  \n    Comoros \n    16407 \n    0 \n    16407 \n  \n  \n    Costa Rica \n    14750 \n    22421 \n    37171 \n  \n  \n    Croatia \n    72312 \n    15805 \n    88117 \n  \n  \n    Cuba \n    23574 \n    29185 \n    52759 \n  \n  \n    Curaçao \n    35534 \n    0 \n    35534 \n  \n  \n    Cyprus \n    1507 \n    6625 \n    8132 \n  \n  \n    Czech Republic \n    3507 \n    20952 \n    24459 \n  \n  \n    Democratic Republic of the Congo \n    237372 \n    3161 \n    240533 \n  \n  \n    Denmark \n    670344 \n    36337 \n    706681 \n  \n  \n    Djibouti \n    2220 \n    0 \n    2220 \n  \n  \n    Dominica \n    770 \n    6 \n    776 \n  \n  \n    Dominican Republic \n    14640 \n    2285 \n    16925 \n  \n  \n    Ecuador \n    715495 \n    451090 \n    1166585 \n  \n  \n    Egypt \n    335614 \n    1370660 \n    1706274 \n  \n  \n    El Salvador \n    54084 \n    7956 \n    62040 \n  \n  \n    Equatorial Guinea \n    8000 \n    15 \n    8015 \n  \n  \n    Eritrea \n    4300 \n    0 \n    4300 \n  \n  \n    Estonia \n    75931 \n    868 \n    76799 \n  \n  \n    Eswatini \n    65 \n    100 \n    165 \n  \n  \n    Ethiopia \n    45500 \n    95 \n    45595 \n  \n  \n    Faroe Islands \n    568435 \n    83300 \n    651735 \n  \n  \n    Federated States of Micronesia \n    88397 \n    0 \n    88397 \n  \n  \n    Fiji \n    44663 \n    754 \n    45417 \n  \n  \n    Finland \n    192065 \n    14412 \n    206477 \n  \n  \n    France \n    561173 \n    166640 \n    727813 \n  \n  \n    France \n    90 \n    0 \n    90 \n  \n  \n    French Polynesia \n    13754 \n    1343 \n    15097 \n  \n  \n    Gabon \n    31000 \n    45 \n    31045 \n  \n  \n    Gambia \n    58261 \n    5 \n    58266 \n  \n  \n    Georgia \n    30078 \n    670 \n    30748 \n  \n  \n    Germany \n    271185 \n    41721 \n    312906 \n  \n  \n    Ghana \n    327457 \n    52480 \n    379937 \n  \n  \n    Gibraltar \n    1 \n    0 \n    1 \n  \n  \n    Greece \n    76362 \n    123410 \n    199772 \n  \n  \n    Greenland \n    273175 \n    0 \n    273175 \n  \n  \n    Grenada \n    2550 \n    0 \n    2550 \n  \n  \n    Guam \n    1391 \n    110 \n    1501 \n  \n  \n    Guatemala \n    19011 \n    26268 \n    45279 \n  \n  \n    Guinea \n    128000 \n    250 \n    128250 \n  \n  \n    Guinea-Bissau \n    6700 \n    0 \n    6700 \n  \n  \n    Guyana \n    42142 \n    337 \n    42479 \n  \n  \n    Haiti \n    16510 \n    1220 \n    17730 \n  \n  \n    Honduras \n    10600 \n    53100 \n    63700 \n  \n  \n    Hong Kong \n    142775 \n    4258 \n    147033 \n  \n  \n    Hungary \n    5048 \n    16248 \n    21296 \n  \n  \n    Iceland \n    1085176 \n    15129 \n    1100305 \n  \n  \n    India \n    5082332 \n    5703002 \n    10785334 \n  \n  \n    Indonesia \n    6584419 \n    16600000 \n    23184419 \n  \n  \n    Iran \n    695407 \n    398129 \n    1093536 \n  \n  \n    Iraq \n    28000 \n    28835 \n    56835 \n  \n  \n    Ireland \n    259845 \n    40244 \n    300089 \n  \n  \n    Isle of Man \n    7040 \n    0 \n    7040 \n  \n  \n    Israel \n    1758 \n    18914 \n    20672 \n  \n  \n    Italy \n    198130 \n    157109 \n    355239 \n  \n  \n    Ivory Coast \n    67500 \n    4701 \n    72201 \n  \n  \n    Jamaica \n    16800 \n    620 \n    17420 \n  \n  \n    Japan \n    3275263 \n    1067994 \n    4343257 \n  \n  \n    Jersey and Guernsey \n    2985 \n    1499 \n    4484 \n  \n  \n    Jordan \n    873 \n    885 \n    1758 \n  \n  \n    Kazakhstan \n    41335 \n    1878 \n    43213 \n  \n  \n    Kenya \n    171391 \n    15360 \n    186751 \n  \n  \n    Kiribati \n    172822 \n    3652 \n    176474 \n  \n  \n    Kuwait \n    5493 \n    196 \n    5689 \n  \n  \n    Kyrgyzstan \n    89 \n    1931 \n    2020 \n  \n  \n    Laos \n    70915 \n    109835 \n    180750 \n  \n  \n    Latvia \n    114806 \n    788 \n    115594 \n  \n  \n    Lebanon \n    4291 \n    1015 \n    5306 \n  \n  \n    Lesotho \n    52 \n    1050 \n    1102 \n  \n  \n    Liberia \n    14700 \n    40 \n    14740 \n  \n  \n    Libya \n    30002 \n    10 \n    30012 \n  \n  \n    Liechtenstein \n    0 \n    0 \n    0 \n  \n  \n    Lithuania \n    106945 \n    4393 \n    111338 \n  \n  \n    Luxembourg \n    0 \n    0 \n    0 \n  \n  \n    Macao \n    1500 \n    0 \n    1500 \n  \n  \n    Madagascar \n    142333 \n    25998 \n    168331 \n  \n  \n    Malawi \n    152852 \n    7646 \n    160498 \n  \n  \n    Malaysia \n    1584371 \n    407887 \n    1992258 \n  \n  \n    Maldives \n    129191 \n    0 \n    129191 \n  \n  \n    Mali \n    102486 \n    4194 \n    106680 \n  \n  \n    Malta \n    2420 \n    6073 \n    8493 \n  \n  \n    Marshall Islands \n    64795 \n    5 \n    64800 \n  \n  \n    Mauritania \n    609754 \n    0 \n    609754 \n  \n  \n    Mauritius \n    18062 \n    1021 \n    19083 \n  \n  \n    Mexico \n    1524467 \n    221328 \n    1745795 \n  \n  \n    Moldova \n    50 \n    16011 \n    16061 \n  \n  \n    Monaco \n    1 \n    0 \n    1 \n  \n  \n    Mongolia \n    15 \n    0 \n    15 \n  \n  \n    Montenegro \n    1595 \n    929 \n    2524 \n  \n  \n    Morocco \n    1454105 \n    1142 \n    1455247 \n  \n  \n    Mozambique \n    299591 \n    1180 \n    300771 \n  \n  \n    Myanmar \n    2072390 \n    1017644 \n    3090034 \n  \n  \n    Namibia \n    503878 \n    591 \n    504469 \n  \n  \n    Nauru \n    530 \n    0 \n    530 \n  \n  \n    Nepal \n    21500 \n    49043 \n    70543 \n  \n  \n    Netherlands \n    370274 \n    62940 \n    433214 \n  \n  \n    New Caledonia \n    3815 \n    1587 \n    5402 \n  \n  \n    New Zealand \n    424791 \n    109016 \n    533807 \n  \n  \n    Nicaragua \n    45500 \n    22530 \n    68030 \n  \n  \n    Niger \n    34592 \n    300 \n    34892 \n  \n  \n    Nigeria \n    734731 \n    306727 \n    1041458 \n  \n  \n    North Korea \n    209000 \n    554100 \n    763100 \n  \n  \n    North Macedonia \n    306 \n    986 \n    1292 \n  \n  \n    Northern Mariana Islands \n    950 \n    42 \n    992 \n  \n  \n    Norway \n    2203360 \n    1326216 \n    3529576 \n  \n  \n    Oman \n    279606 \n    103 \n    279709 \n  \n  \n    Pakistan \n    513156 \n    156430 \n    669586 \n  \n  \n    Palau \n    818 \n    23 \n    841 \n  \n  \n    Palestine \n    3306 \n    280 \n    3586 \n  \n  \n    Panama \n    144450 \n    8808 \n    153258 \n  \n  \n    Papua New Guinea \n    309245 \n    6200 \n    315445 \n  \n  \n    Paraguay \n    17000 \n    8500 \n    25500 \n  \n  \n    Peru \n    3811802 \n    100187 \n    3911989 \n  \n  \n    Philippines \n    2027992 \n    2200914 \n    4228906 \n  \n  \n    Poland \n    218115 \n    38300 \n    256415 \n  \n  \n    Portugal \n    186950 \n    9787 \n    196737 \n  \n  \n    Puerto Rico \n    1901 \n    20 \n    1921 \n  \n  \n    Qatar \n    14516 \n    10 \n    14526 \n  \n  \n    Republic of the Congo \n    86748 \n    177 \n    86925 \n  \n  \n    Romania \n    12728 \n    12574 \n    25302 \n  \n  \n    Russia \n    4773413 \n    173840 \n    4947253 \n  \n  \n    Rwanda \n    25013 \n    580 \n    25593 \n  \n  \n    Saint Kitts and Nevis \n    65734 \n    1 \n    65735 \n  \n  \n    Saint Lucia \n    2097 \n    32 \n    2129 \n  \n  \n    Saint Vincent and the Grenadines \n    23077 \n    0 \n    23077 \n  \n  \n    Samoa \n    8801 \n    10 \n    8811 \n  \n  \n    San Marino \n    0 \n    0 \n    0 \n  \n  \n    São Tomé and Príncipe \n    11750 \n    0 \n    11750 \n  \n  \n    Saudi Arabia \n    68082 \n    39920 \n    108002 \n  \n  \n    Senegal \n    474162 \n    2079 \n    476241 \n  \n  \n    Serbia \n    2067 \n    6878 \n    8945 \n  \n  \n    Seychelles \n    127128 \n    0 \n    127128 \n  \n  \n    Sierra Leone \n    202100 \n    75 \n    202175 \n  \n  \n    Singapore \n    1234 \n    6112 \n    7346 \n  \n  \n    Sint Maarten \n    253 \n    0 \n    253 \n  \n  \n    Slovakia \n    1866 \n    2169 \n    4035 \n  \n  \n    Slovenia \n    311 \n    1844 \n    2155 \n  \n  \n    Solomon Islands \n    66445 \n    10582 \n    77027 \n  \n  \n    Somalia \n    30000 \n    0 \n    30000 \n  \n  \n    South Africa \n    622070 \n    7994 \n    630064 \n  \n  \n    South Korea \n    1395951 \n    1859220 \n    3255171 \n  \n  \n    South Sudan \n    35000 \n    20 \n    35020 \n  \n  \n    Spain \n    915137 \n    283831 \n    1198968 \n  \n  \n    Sri Lanka \n    521637 \n    30974 \n    552611 \n  \n  \n    Sudan \n    33002 \n    4500 \n    37502 \n  \n  \n    Suriname \n    47013 \n    102 \n    47115 \n  \n  \n    Sweden \n    208783 \n    15747 \n    224530 \n  \n  \n    Switzerland \n    1851 \n    1733 \n    3584 \n  \n  \n    Syria \n    4500 \n    3500 \n    8000 \n  \n  \n    Tajikistan \n    1100 \n    450 \n    1550 \n  \n  \n    Tanzania \n    370966 \n    12547 \n    383513 \n  \n  \n    Thailand \n    1530583 \n    962571 \n    2493154 \n  \n  \n    Timor-Leste \n    3200 \n    1560 \n    4760 \n  \n  \n    Togo \n    31891 \n    98 \n    31989 \n  \n  \n    Tonga \n    1697 \n    3 \n    1700 \n  \n  \n    Trinidad and Tobago \n    13027 \n    11 \n    13038 \n  \n  \n    Tunisia \n    115064 \n    16165 \n    131229 \n  \n  \n    Turkey \n    335326 \n    250331 \n    585657 \n  \n  \n    Turkmenistan \n    15000 \n    30 \n    15030 \n  \n  \n    Turks and Caicos Islands \n    2780 \n    0 \n    2780 \n  \n  \n    Tuvalu \n    7684 \n    3 \n    7687 \n  \n  \n    Uganda \n    389244 \n    118051 \n    507295 \n  \n  \n    Ukraine \n    75743 \n    21425 \n    97168 \n  \n  \n    United Arab Emirates \n    73000 \n    1241 \n    74241 \n  \n  \n    United Kingdom \n    702405 \n    194492 \n    896897 \n  \n  \n    United States \n    4931017 \n    444369 \n    5375386 \n  \n  \n    Uruguay \n    51500 \n    70 \n    51570 \n  \n  \n    US Virgin Islands \n    551 \n    8 \n    559 \n  \n  \n    Uzbekistan \n    27267 \n    38055 \n    65322 \n  \n  \n    Vanuatu \n    44002 \n    16 \n    44018 \n  \n  \n    Venezuela \n    284175 \n    25998 \n    310173 \n  \n  \n    Vietnam \n    2785940 \n    3634531 \n    6420471 \n  \n  \n    Yemen \n    154450 \n    0 \n    154450 \n  \n  \n    Zambia \n    83918 \n    30285 \n    114203 \n  \n  \n    Zimbabwe \n    15711 \n    10085 \n    25796"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#section-1",
    "href": "slides/slides-08-wrangle-prob.html#section-1",
    "title": "More wrangling + Probability",
    "section": "",
    "text": "kable(continents) |>\n  kable_styling(font_size = 20)\n\n\n\n \n  \n    country \n    continent \n  \n \n\n  \n    Afghanistan \n    Asia \n  \n  \n    Åland Islands \n    Europe \n  \n  \n    Albania \n    Europe \n  \n  \n    Algeria \n    Africa \n  \n  \n    American Samoa \n    Oceania \n  \n  \n    Andorra \n    Europe \n  \n  \n    Angola \n    Africa \n  \n  \n    Anguilla \n    Americas \n  \n  \n    Antigua & Barbuda \n    Americas \n  \n  \n    Argentina \n    Americas \n  \n  \n    Armenia \n    Asia \n  \n  \n    Aruba \n    Americas \n  \n  \n    Australia \n    Oceania \n  \n  \n    Austria \n    Europe \n  \n  \n    Azerbaijan \n    Asia \n  \n  \n    Bahamas \n    Americas \n  \n  \n    Bahrain \n    Asia \n  \n  \n    Bangladesh \n    Asia \n  \n  \n    Barbados \n    Americas \n  \n  \n    Belarus \n    Europe \n  \n  \n    Belgium \n    Europe \n  \n  \n    Belize \n    Americas \n  \n  \n    Benin \n    Africa \n  \n  \n    Bermuda \n    Americas \n  \n  \n    Bhutan \n    Asia \n  \n  \n    Bolivia \n    Americas \n  \n  \n    Caribbean Netherlands \n    Americas \n  \n  \n    Bosnia & Herzegovina \n    Europe \n  \n  \n    Botswana \n    Africa \n  \n  \n    Brazil \n    Americas \n  \n  \n    Brunei \n    Asia \n  \n  \n    Bulgaria \n    Europe \n  \n  \n    Burkina Faso \n    Africa \n  \n  \n    Burundi \n    Africa \n  \n  \n    Cape Verde \n    Africa \n  \n  \n    Cambodia \n    Asia \n  \n  \n    Cameroon \n    Africa \n  \n  \n    Canada \n    Americas \n  \n  \n    Cayman Islands \n    Americas \n  \n  \n    Central African Republic \n    Africa \n  \n  \n    Chad \n    Africa \n  \n  \n    Chile \n    Americas \n  \n  \n    China \n    Asia \n  \n  \n    Christmas Island \n    Oceania \n  \n  \n    Colombia \n    Americas \n  \n  \n    Comoros \n    Africa \n  \n  \n    Congo - Brazzaville \n    Africa \n  \n  \n    Cook Islands \n    Oceania \n  \n  \n    Costa Rica \n    Americas \n  \n  \n    Côte d’Ivoire \n    Africa \n  \n  \n    Croatia \n    Europe \n  \n  \n    Cuba \n    Americas \n  \n  \n    Curaçao \n    Americas \n  \n  \n    Cyprus \n    Asia \n  \n  \n    Czechia \n    Europe \n  \n  \n    North Korea \n    Asia \n  \n  \n    Congo - Kinshasa \n    Africa \n  \n  \n    Denmark \n    Europe \n  \n  \n    Djibouti \n    Africa \n  \n  \n    Dominica \n    Americas \n  \n  \n    Dominican Republic \n    Americas \n  \n  \n    Ecuador \n    Americas \n  \n  \n    Egypt \n    Africa \n  \n  \n    El Salvador \n    Americas \n  \n  \n    Equatorial Guinea \n    Africa \n  \n  \n    Eritrea \n    Africa \n  \n  \n    Estonia \n    Europe \n  \n  \n    Ethiopia \n    Africa \n  \n  \n    Falkland Islands \n    Americas \n  \n  \n    Faroe Islands \n    Europe \n  \n  \n    Fiji \n    Oceania \n  \n  \n    Finland \n    Europe \n  \n  \n    France \n    Europe \n  \n  \n    French Guiana \n    Americas \n  \n  \n    French Polynesia \n    Oceania \n  \n  \n    Gabon \n    Africa \n  \n  \n    Gambia \n    Africa \n  \n  \n    Georgia \n    Asia \n  \n  \n    Germany \n    Europe \n  \n  \n    Ghana \n    Africa \n  \n  \n    Gibraltar \n    Europe \n  \n  \n    Greece \n    Europe \n  \n  \n    Greenland \n    Americas \n  \n  \n    Grenada \n    Americas \n  \n  \n    Guadeloupe \n    Americas \n  \n  \n    Guam \n    Oceania \n  \n  \n    Guatemala \n    Americas \n  \n  \n    Guernsey \n    Europe \n  \n  \n    Guinea \n    Africa \n  \n  \n    Guinea-Bissau \n    Africa \n  \n  \n    Guyana \n    Americas \n  \n  \n    Haiti \n    Americas \n  \n  \n    Vatican City \n    Europe \n  \n  \n    Honduras \n    Americas \n  \n  \n    Hong Kong SAR China \n    Asia \n  \n  \n    Hungary \n    Europe \n  \n  \n    Iceland \n    Europe \n  \n  \n    India \n    Asia \n  \n  \n    Indonesia \n    Asia \n  \n  \n    Iran \n    Asia \n  \n  \n    Iraq \n    Asia \n  \n  \n    Ireland \n    Europe \n  \n  \n    Isle of Man \n    Europe \n  \n  \n    Israel \n    Asia \n  \n  \n    Italy \n    Europe \n  \n  \n    Jamaica \n    Americas \n  \n  \n    Japan \n    Asia \n  \n  \n    Jersey \n    Europe \n  \n  \n    Jordan \n    Asia \n  \n  \n    Kazakhstan \n    Asia \n  \n  \n    Kenya \n    Africa \n  \n  \n    Kiribati \n    Oceania \n  \n  \n    Kuwait \n    Asia \n  \n  \n    Kyrgyzstan \n    Asia \n  \n  \n    Laos \n    Asia \n  \n  \n    Latvia \n    Europe \n  \n  \n    Lebanon \n    Asia \n  \n  \n    Lesotho \n    Africa \n  \n  \n    Liberia \n    Africa \n  \n  \n    Libya \n    Africa \n  \n  \n    Liechtenstein \n    Europe \n  \n  \n    Lithuania \n    Europe \n  \n  \n    Luxembourg \n    Europe \n  \n  \n    Macau SAR China \n    Asia \n  \n  \n    Madagascar \n    Africa \n  \n  \n    Malawi \n    Africa \n  \n  \n    Malaysia \n    Asia \n  \n  \n    Maldives \n    Asia \n  \n  \n    Mali \n    Africa \n  \n  \n    Malta \n    Europe \n  \n  \n    Marshall Islands \n    Oceania \n  \n  \n    Martinique \n    Americas \n  \n  \n    Mauritania \n    Africa \n  \n  \n    Mauritius \n    Africa \n  \n  \n    Mayotte \n    Africa \n  \n  \n    Mexico \n    Americas \n  \n  \n    Micronesia (Federated States of) \n    Oceania \n  \n  \n    Monaco \n    Europe \n  \n  \n    Mongolia \n    Asia \n  \n  \n    Montenegro \n    Europe \n  \n  \n    Montserrat \n    Americas \n  \n  \n    Morocco \n    Africa \n  \n  \n    Mozambique \n    Africa \n  \n  \n    Myanmar (Burma) \n    Asia \n  \n  \n    Namibia \n    Africa \n  \n  \n    Nauru \n    Oceania \n  \n  \n    Nepal \n    Asia \n  \n  \n    Netherlands \n    Europe \n  \n  \n    Netherlands Antilles \n    Americas \n  \n  \n    New Caledonia \n    Oceania \n  \n  \n    New Zealand \n    Oceania \n  \n  \n    Nicaragua \n    Americas \n  \n  \n    Niger \n    Africa \n  \n  \n    Nigeria \n    Africa \n  \n  \n    Niue \n    Oceania \n  \n  \n    Norfolk Island \n    Oceania \n  \n  \n    Northern Mariana Islands \n    Oceania \n  \n  \n    Norway \n    Europe \n  \n  \n    Oman \n    Asia \n  \n  \n    Pakistan \n    Asia \n  \n  \n    Palau \n    Oceania \n  \n  \n    Palestinian Territories \n    Asia \n  \n  \n    Panama \n    Americas \n  \n  \n    Papua New Guinea \n    Oceania \n  \n  \n    Paraguay \n    Americas \n  \n  \n    Peru \n    Americas \n  \n  \n    Philippines \n    Asia \n  \n  \n    Pitcairn Islands \n    Oceania \n  \n  \n    Poland \n    Europe \n  \n  \n    Portugal \n    Europe \n  \n  \n    Puerto Rico \n    Americas \n  \n  \n    Qatar \n    Asia \n  \n  \n    South Korea \n    Asia \n  \n  \n    Moldova \n    Europe \n  \n  \n    Réunion \n    Africa \n  \n  \n    Romania \n    Europe \n  \n  \n    Russia \n    Europe \n  \n  \n    Rwanda \n    Africa \n  \n  \n    St. Barthélemy \n    Americas \n  \n  \n    St. Helena \n    Africa \n  \n  \n    St. Kitts & Nevis \n    Americas \n  \n  \n    St. Lucia \n    Americas \n  \n  \n    Saint Martin (French part) \n    Americas \n  \n  \n    St. Pierre & Miquelon \n    Americas \n  \n  \n    St. Vincent & Grenadines \n    Americas \n  \n  \n    Samoa \n    Oceania \n  \n  \n    San Marino \n    Europe \n  \n  \n    São Tomé & Príncipe \n    Africa \n  \n  \n    Saudi Arabia \n    Asia \n  \n  \n    Senegal \n    Africa \n  \n  \n    Serbia \n    Europe \n  \n  \n    Seychelles \n    Africa \n  \n  \n    Sierra Leone \n    Africa \n  \n  \n    Singapore \n    Asia \n  \n  \n    Sint Maarten \n    Americas \n  \n  \n    Slovakia \n    Europe \n  \n  \n    Slovenia \n    Europe \n  \n  \n    Solomon Islands \n    Oceania \n  \n  \n    Somalia \n    Africa \n  \n  \n    Somaliland \n    Africa \n  \n  \n    South Africa \n    Africa \n  \n  \n    South Sudan \n    Africa \n  \n  \n    Spain \n    Europe \n  \n  \n    Sri Lanka \n    Asia \n  \n  \n    Sudan \n    Africa \n  \n  \n    Suriname \n    Americas \n  \n  \n    Svalbard & Jan Mayen \n    Europe \n  \n  \n    Swaziland \n    Africa \n  \n  \n    Sweden \n    Europe \n  \n  \n    Switzerland \n    Europe \n  \n  \n    Syria \n    Asia \n  \n  \n    Taiwan \n    Asia \n  \n  \n    Tajikistan \n    Asia \n  \n  \n    Thailand \n    Asia \n  \n  \n    Macedonia \n    Europe \n  \n  \n    Timor-Leste \n    Asia \n  \n  \n    Togo \n    Africa \n  \n  \n    Tokelau \n    Oceania \n  \n  \n    Tonga \n    Oceania \n  \n  \n    Trinidad & Tobago \n    Americas \n  \n  \n    Tunisia \n    Africa \n  \n  \n    Turkey \n    Asia \n  \n  \n    Turkmenistan \n    Asia \n  \n  \n    Turks & Caicos Islands \n    Americas \n  \n  \n    Tuvalu \n    Oceania \n  \n  \n    Uganda \n    Africa \n  \n  \n    Ukraine \n    Europe \n  \n  \n    United Arab Emirates \n    Asia \n  \n  \n    United Arab Republic \n    Asia \n  \n  \n    United Kingdom \n    Europe \n  \n  \n    Tanzania \n    Africa \n  \n  \n    United States \n    Americas \n  \n  \n    Uruguay \n    Americas \n  \n  \n    Uzbekistan \n    Asia \n  \n  \n    Vanuatu \n    Oceania \n  \n  \n    Venezuela \n    Americas \n  \n  \n    Vietnam \n    Asia \n  \n  \n    Republic of Vietnam \n    Asia \n  \n  \n    British Virgin Islands \n    Americas \n  \n  \n    U.S. Virgin Islands \n    Americas \n  \n  \n    Wallis & Futuna \n    Oceania \n  \n  \n    Western Sahara \n    Africa \n  \n  \n    Yemen \n    Asia \n  \n  \n    Zambia \n    Africa \n  \n  \n    Zimbabwe \n    Africa \n  \n\n\n\n\n\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#section-2",
    "href": "slides/slides-08-wrangle-prob.html#section-2",
    "title": "More wrangling + Probability",
    "section": "",
    "text": "left_join(fisheries, continents, by = \"country\") |>\n  kable() |>\n  kable_styling(font_size = 20)\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    total \n    continent \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    2200 \n    Asia \n  \n  \n    Albania \n    7886 \n    950 \n    8836 \n    Europe \n  \n  \n    Algeria \n    95000 \n    1361 \n    96361 \n    Africa \n  \n  \n    American Samoa \n    3047 \n    20 \n    3067 \n    Oceania \n  \n  \n    Andorra \n    0 \n    0 \n    0 \n    Europe \n  \n  \n    Angola \n    486490 \n    655 \n    487145 \n    Africa \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n    3010 \n    NA \n  \n  \n    Argentina \n    755226 \n    3673 \n    758899 \n    Americas \n  \n  \n    Armenia \n    3758 \n    16381 \n    20139 \n    Asia \n  \n  \n    Aruba \n    142 \n    0 \n    142 \n    Americas \n  \n  \n    Australia \n    174629 \n    96847 \n    271476 \n    Oceania \n  \n  \n    Austria \n    350 \n    3483 \n    3833 \n    Europe \n  \n  \n    Azerbaijan \n    676 \n    640 \n    1316 \n    Asia \n  \n  \n    Bahamas \n    11625 \n    8 \n    11633 \n    Americas \n  \n  \n    Bahrain \n    15000 \n    6 \n    15006 \n    Asia \n  \n  \n    Bangladesh \n    1674770 \n    2203554 \n    3878324 \n    Asia \n  \n  \n    Barbados \n    1735 \n    26 \n    1761 \n    Americas \n  \n  \n    Belarus \n    686 \n    11199 \n    11885 \n    Europe \n  \n  \n    Belgium \n    26970 \n    44 \n    27014 \n    Europe \n  \n  \n    Belize \n    91432 \n    953 \n    92385 \n    Americas \n  \n  \n    Benin \n    49806 \n    3080 \n    52886 \n    Africa \n  \n  \n    Bermuda \n    410 \n    0 \n    410 \n    Americas \n  \n  \n    Bhutan \n    7 \n    150 \n    157 \n    Asia \n  \n  \n    Bolivia \n    7000 \n    3000 \n    10000 \n    Americas \n  \n  \n    Bosnia and Herzegovina \n    305 \n    4564 \n    4869 \n    NA \n  \n  \n    Botswana \n    38 \n    15 \n    53 \n    Africa \n  \n  \n    Brazil \n    705000 \n    581230 \n    1286230 \n    Americas \n  \n  \n    British Virgin Islands \n    1200 \n    0 \n    1200 \n    Americas \n  \n  \n    Brunei \n    13292 \n    948 \n    14240 \n    Asia \n  \n  \n    Bulgaria \n    8614 \n    15762 \n    24376 \n    Europe \n  \n  \n    Burkina Faso \n    22070 \n    470 \n    22540 \n    Africa \n  \n  \n    Burundi \n    21805 \n    1330 \n    23135 \n    Africa \n  \n  \n    Cambodia \n    629950 \n    172500 \n    802450 \n    Asia \n  \n  \n    Cameroon \n    233190 \n    2315 \n    235505 \n    Africa \n  \n  \n    Canada \n    874727 \n    200765 \n    1075492 \n    Americas \n  \n  \n    Cape Verde \n    19900 \n    0 \n    19900 \n    Africa \n  \n  \n    Cayman Islands \n    125 \n    0 \n    125 \n    Americas \n  \n  \n    Central African Republic \n    29000 \n    190 \n    29190 \n    Africa \n  \n  \n    Chad \n    110000 \n    94 \n    110094 \n    Africa \n  \n  \n    Chile \n    1829238 \n    1050117 \n    2879355 \n    Americas \n  \n  \n    China \n    17800000 \n    63700000 \n    81500000 \n    Asia \n  \n  \n    Colombia \n    86344 \n    96970 \n    183314 \n    Americas \n  \n  \n    Comoros \n    16407 \n    0 \n    16407 \n    Africa \n  \n  \n    Costa Rica \n    14750 \n    22421 \n    37171 \n    Americas \n  \n  \n    Croatia \n    72312 \n    15805 \n    88117 \n    Europe \n  \n  \n    Cuba \n    23574 \n    29185 \n    52759 \n    Americas \n  \n  \n    Curaçao \n    35534 \n    0 \n    35534 \n    Americas \n  \n  \n    Cyprus \n    1507 \n    6625 \n    8132 \n    Asia \n  \n  \n    Czech Republic \n    3507 \n    20952 \n    24459 \n    NA \n  \n  \n    Democratic Republic of the Congo \n    237372 \n    3161 \n    240533 \n    NA \n  \n  \n    Denmark \n    670344 \n    36337 \n    706681 \n    Europe \n  \n  \n    Djibouti \n    2220 \n    0 \n    2220 \n    Africa \n  \n  \n    Dominica \n    770 \n    6 \n    776 \n    Americas \n  \n  \n    Dominican Republic \n    14640 \n    2285 \n    16925 \n    Americas \n  \n  \n    Ecuador \n    715495 \n    451090 \n    1166585 \n    Americas \n  \n  \n    Egypt \n    335614 \n    1370660 \n    1706274 \n    Africa \n  \n  \n    El Salvador \n    54084 \n    7956 \n    62040 \n    Americas \n  \n  \n    Equatorial Guinea \n    8000 \n    15 \n    8015 \n    Africa \n  \n  \n    Eritrea \n    4300 \n    0 \n    4300 \n    Africa \n  \n  \n    Estonia \n    75931 \n    868 \n    76799 \n    Europe \n  \n  \n    Eswatini \n    65 \n    100 \n    165 \n    NA \n  \n  \n    Ethiopia \n    45500 \n    95 \n    45595 \n    Africa \n  \n  \n    Faroe Islands \n    568435 \n    83300 \n    651735 \n    Europe \n  \n  \n    Federated States of Micronesia \n    88397 \n    0 \n    88397 \n    NA \n  \n  \n    Fiji \n    44663 \n    754 \n    45417 \n    Oceania \n  \n  \n    Finland \n    192065 \n    14412 \n    206477 \n    Europe \n  \n  \n    France \n    561173 \n    166640 \n    727813 \n    Europe \n  \n  \n    France \n    90 \n    0 \n    90 \n    Europe \n  \n  \n    French Polynesia \n    13754 \n    1343 \n    15097 \n    Oceania \n  \n  \n    Gabon \n    31000 \n    45 \n    31045 \n    Africa \n  \n  \n    Gambia \n    58261 \n    5 \n    58266 \n    Africa \n  \n  \n    Georgia \n    30078 \n    670 \n    30748 \n    Asia \n  \n  \n    Germany \n    271185 \n    41721 \n    312906 \n    Europe \n  \n  \n    Ghana \n    327457 \n    52480 \n    379937 \n    Africa \n  \n  \n    Gibraltar \n    1 \n    0 \n    1 \n    Europe \n  \n  \n    Greece \n    76362 \n    123410 \n    199772 \n    Europe \n  \n  \n    Greenland \n    273175 \n    0 \n    273175 \n    Americas \n  \n  \n    Grenada \n    2550 \n    0 \n    2550 \n    Americas \n  \n  \n    Guam \n    1391 \n    110 \n    1501 \n    Oceania \n  \n  \n    Guatemala \n    19011 \n    26268 \n    45279 \n    Americas \n  \n  \n    Guinea \n    128000 \n    250 \n    128250 \n    Africa \n  \n  \n    Guinea-Bissau \n    6700 \n    0 \n    6700 \n    Africa \n  \n  \n    Guyana \n    42142 \n    337 \n    42479 \n    Americas \n  \n  \n    Haiti \n    16510 \n    1220 \n    17730 \n    Americas \n  \n  \n    Honduras \n    10600 \n    53100 \n    63700 \n    Americas \n  \n  \n    Hong Kong \n    142775 \n    4258 \n    147033 \n    NA \n  \n  \n    Hungary \n    5048 \n    16248 \n    21296 \n    Europe \n  \n  \n    Iceland \n    1085176 \n    15129 \n    1100305 \n    Europe \n  \n  \n    India \n    5082332 \n    5703002 \n    10785334 \n    Asia \n  \n  \n    Indonesia \n    6584419 \n    16600000 \n    23184419 \n    Asia \n  \n  \n    Iran \n    695407 \n    398129 \n    1093536 \n    Asia \n  \n  \n    Iraq \n    28000 \n    28835 \n    56835 \n    Asia \n  \n  \n    Ireland \n    259845 \n    40244 \n    300089 \n    Europe \n  \n  \n    Isle of Man \n    7040 \n    0 \n    7040 \n    Europe \n  \n  \n    Israel \n    1758 \n    18914 \n    20672 \n    Asia \n  \n  \n    Italy \n    198130 \n    157109 \n    355239 \n    Europe \n  \n  \n    Ivory Coast \n    67500 \n    4701 \n    72201 \n    NA \n  \n  \n    Jamaica \n    16800 \n    620 \n    17420 \n    Americas \n  \n  \n    Japan \n    3275263 \n    1067994 \n    4343257 \n    Asia \n  \n  \n    Jersey and Guernsey \n    2985 \n    1499 \n    4484 \n    NA \n  \n  \n    Jordan \n    873 \n    885 \n    1758 \n    Asia \n  \n  \n    Kazakhstan \n    41335 \n    1878 \n    43213 \n    Asia \n  \n  \n    Kenya \n    171391 \n    15360 \n    186751 \n    Africa \n  \n  \n    Kiribati \n    172822 \n    3652 \n    176474 \n    Oceania \n  \n  \n    Kuwait \n    5493 \n    196 \n    5689 \n    Asia \n  \n  \n    Kyrgyzstan \n    89 \n    1931 \n    2020 \n    Asia \n  \n  \n    Laos \n    70915 \n    109835 \n    180750 \n    Asia \n  \n  \n    Latvia \n    114806 \n    788 \n    115594 \n    Europe \n  \n  \n    Lebanon \n    4291 \n    1015 \n    5306 \n    Asia \n  \n  \n    Lesotho \n    52 \n    1050 \n    1102 \n    Africa \n  \n  \n    Liberia \n    14700 \n    40 \n    14740 \n    Africa \n  \n  \n    Libya \n    30002 \n    10 \n    30012 \n    Africa \n  \n  \n    Liechtenstein \n    0 \n    0 \n    0 \n    Europe \n  \n  \n    Lithuania \n    106945 \n    4393 \n    111338 \n    Europe \n  \n  \n    Luxembourg \n    0 \n    0 \n    0 \n    Europe \n  \n  \n    Macao \n    1500 \n    0 \n    1500 \n    NA \n  \n  \n    Madagascar \n    142333 \n    25998 \n    168331 \n    Africa \n  \n  \n    Malawi \n    152852 \n    7646 \n    160498 \n    Africa \n  \n  \n    Malaysia \n    1584371 \n    407887 \n    1992258 \n    Asia \n  \n  \n    Maldives \n    129191 \n    0 \n    129191 \n    Asia \n  \n  \n    Mali \n    102486 \n    4194 \n    106680 \n    Africa \n  \n  \n    Malta \n    2420 \n    6073 \n    8493 \n    Europe \n  \n  \n    Marshall Islands \n    64795 \n    5 \n    64800 \n    Oceania \n  \n  \n    Mauritania \n    609754 \n    0 \n    609754 \n    Africa \n  \n  \n    Mauritius \n    18062 \n    1021 \n    19083 \n    Africa \n  \n  \n    Mexico \n    1524467 \n    221328 \n    1745795 \n    Americas \n  \n  \n    Moldova \n    50 \n    16011 \n    16061 \n    Europe \n  \n  \n    Monaco \n    1 \n    0 \n    1 \n    Europe \n  \n  \n    Mongolia \n    15 \n    0 \n    15 \n    Asia \n  \n  \n    Montenegro \n    1595 \n    929 \n    2524 \n    Europe \n  \n  \n    Morocco \n    1454105 \n    1142 \n    1455247 \n    Africa \n  \n  \n    Mozambique \n    299591 \n    1180 \n    300771 \n    Africa \n  \n  \n    Myanmar \n    2072390 \n    1017644 \n    3090034 \n    NA \n  \n  \n    Namibia \n    503878 \n    591 \n    504469 \n    Africa \n  \n  \n    Nauru \n    530 \n    0 \n    530 \n    Oceania \n  \n  \n    Nepal \n    21500 \n    49043 \n    70543 \n    Asia \n  \n  \n    Netherlands \n    370274 \n    62940 \n    433214 \n    Europe \n  \n  \n    New Caledonia \n    3815 \n    1587 \n    5402 \n    Oceania \n  \n  \n    New Zealand \n    424791 \n    109016 \n    533807 \n    Oceania \n  \n  \n    Nicaragua \n    45500 \n    22530 \n    68030 \n    Americas \n  \n  \n    Niger \n    34592 \n    300 \n    34892 \n    Africa \n  \n  \n    Nigeria \n    734731 \n    306727 \n    1041458 \n    Africa \n  \n  \n    North Korea \n    209000 \n    554100 \n    763100 \n    Asia \n  \n  \n    North Macedonia \n    306 \n    986 \n    1292 \n    NA \n  \n  \n    Northern Mariana Islands \n    950 \n    42 \n    992 \n    Oceania \n  \n  \n    Norway \n    2203360 \n    1326216 \n    3529576 \n    Europe \n  \n  \n    Oman \n    279606 \n    103 \n    279709 \n    Asia \n  \n  \n    Pakistan \n    513156 \n    156430 \n    669586 \n    Asia \n  \n  \n    Palau \n    818 \n    23 \n    841 \n    Oceania \n  \n  \n    Palestine \n    3306 \n    280 \n    3586 \n    NA \n  \n  \n    Panama \n    144450 \n    8808 \n    153258 \n    Americas \n  \n  \n    Papua New Guinea \n    309245 \n    6200 \n    315445 \n    Oceania \n  \n  \n    Paraguay \n    17000 \n    8500 \n    25500 \n    Americas \n  \n  \n    Peru \n    3811802 \n    100187 \n    3911989 \n    Americas \n  \n  \n    Philippines \n    2027992 \n    2200914 \n    4228906 \n    Asia \n  \n  \n    Poland \n    218115 \n    38300 \n    256415 \n    Europe \n  \n  \n    Portugal \n    186950 \n    9787 \n    196737 \n    Europe \n  \n  \n    Puerto Rico \n    1901 \n    20 \n    1921 \n    Americas \n  \n  \n    Qatar \n    14516 \n    10 \n    14526 \n    Asia \n  \n  \n    Republic of the Congo \n    86748 \n    177 \n    86925 \n    NA \n  \n  \n    Romania \n    12728 \n    12574 \n    25302 \n    Europe \n  \n  \n    Russia \n    4773413 \n    173840 \n    4947253 \n    Europe \n  \n  \n    Rwanda \n    25013 \n    580 \n    25593 \n    Africa \n  \n  \n    Saint Kitts and Nevis \n    65734 \n    1 \n    65735 \n    NA \n  \n  \n    Saint Lucia \n    2097 \n    32 \n    2129 \n    NA \n  \n  \n    Saint Vincent and the Grenadines \n    23077 \n    0 \n    23077 \n    NA \n  \n  \n    Samoa \n    8801 \n    10 \n    8811 \n    Oceania \n  \n  \n    San Marino \n    0 \n    0 \n    0 \n    Europe \n  \n  \n    São Tomé and Príncipe \n    11750 \n    0 \n    11750 \n    NA \n  \n  \n    Saudi Arabia \n    68082 \n    39920 \n    108002 \n    Asia \n  \n  \n    Senegal \n    474162 \n    2079 \n    476241 \n    Africa \n  \n  \n    Serbia \n    2067 \n    6878 \n    8945 \n    Europe \n  \n  \n    Seychelles \n    127128 \n    0 \n    127128 \n    Africa \n  \n  \n    Sierra Leone \n    202100 \n    75 \n    202175 \n    Africa \n  \n  \n    Singapore \n    1234 \n    6112 \n    7346 \n    Asia \n  \n  \n    Sint Maarten \n    253 \n    0 \n    253 \n    Americas \n  \n  \n    Slovakia \n    1866 \n    2169 \n    4035 \n    Europe \n  \n  \n    Slovenia \n    311 \n    1844 \n    2155 \n    Europe \n  \n  \n    Solomon Islands \n    66445 \n    10582 \n    77027 \n    Oceania \n  \n  \n    Somalia \n    30000 \n    0 \n    30000 \n    Africa \n  \n  \n    South Africa \n    622070 \n    7994 \n    630064 \n    Africa \n  \n  \n    South Korea \n    1395951 \n    1859220 \n    3255171 \n    Asia \n  \n  \n    South Sudan \n    35000 \n    20 \n    35020 \n    Africa \n  \n  \n    Spain \n    915137 \n    283831 \n    1198968 \n    Europe \n  \n  \n    Sri Lanka \n    521637 \n    30974 \n    552611 \n    Asia \n  \n  \n    Sudan \n    33002 \n    4500 \n    37502 \n    Africa \n  \n  \n    Suriname \n    47013 \n    102 \n    47115 \n    Americas \n  \n  \n    Sweden \n    208783 \n    15747 \n    224530 \n    Europe \n  \n  \n    Switzerland \n    1851 \n    1733 \n    3584 \n    Europe \n  \n  \n    Syria \n    4500 \n    3500 \n    8000 \n    Asia \n  \n  \n    Tajikistan \n    1100 \n    450 \n    1550 \n    Asia \n  \n  \n    Tanzania \n    370966 \n    12547 \n    383513 \n    Africa \n  \n  \n    Thailand \n    1530583 \n    962571 \n    2493154 \n    Asia \n  \n  \n    Timor-Leste \n    3200 \n    1560 \n    4760 \n    Asia \n  \n  \n    Togo \n    31891 \n    98 \n    31989 \n    Africa \n  \n  \n    Tonga \n    1697 \n    3 \n    1700 \n    Oceania \n  \n  \n    Trinidad and Tobago \n    13027 \n    11 \n    13038 \n    NA \n  \n  \n    Tunisia \n    115064 \n    16165 \n    131229 \n    Africa \n  \n  \n    Turkey \n    335326 \n    250331 \n    585657 \n    Asia \n  \n  \n    Turkmenistan \n    15000 \n    30 \n    15030 \n    Asia \n  \n  \n    Turks and Caicos Islands \n    2780 \n    0 \n    2780 \n    NA \n  \n  \n    Tuvalu \n    7684 \n    3 \n    7687 \n    Oceania \n  \n  \n    Uganda \n    389244 \n    118051 \n    507295 \n    Africa \n  \n  \n    Ukraine \n    75743 \n    21425 \n    97168 \n    Europe \n  \n  \n    United Arab Emirates \n    73000 \n    1241 \n    74241 \n    Asia \n  \n  \n    United Kingdom \n    702405 \n    194492 \n    896897 \n    Europe \n  \n  \n    United States \n    4931017 \n    444369 \n    5375386 \n    Americas \n  \n  \n    Uruguay \n    51500 \n    70 \n    51570 \n    Americas \n  \n  \n    US Virgin Islands \n    551 \n    8 \n    559 \n    NA \n  \n  \n    Uzbekistan \n    27267 \n    38055 \n    65322 \n    Asia \n  \n  \n    Vanuatu \n    44002 \n    16 \n    44018 \n    Oceania \n  \n  \n    Venezuela \n    284175 \n    25998 \n    310173 \n    Americas \n  \n  \n    Vietnam \n    2785940 \n    3634531 \n    6420471 \n    Asia \n  \n  \n    Yemen \n    154450 \n    0 \n    154450 \n    Asia \n  \n  \n    Zambia \n    83918 \n    30285 \n    114203 \n    Africa \n  \n  \n    Zimbabwe \n    15711 \n    10085 \n    25796 \n    Africa \n  \n\n\n\n\n# right_join(continents, fisheries, by = \"country\")"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#example",
    "href": "slides/slides-08-wrangle-prob.html#example",
    "title": "More wrangling + Probability",
    "section": "Example",
    "text": "Example\nWe have data on fishery harvests of countries from 2016:\n\n\n\n\nfisheries |>\n    slice(1:10)\n\n\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    total \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    2200 \n  \n  \n    Albania \n    7886 \n    950 \n    8836 \n  \n  \n    Algeria \n    95000 \n    1361 \n    96361 \n  \n  \n    American Samoa \n    3047 \n    20 \n    3067 \n  \n  \n    Andorra \n    0 \n    0 \n    0 \n  \n  \n    Angola \n    486490 \n    655 \n    487145 \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n    3010 \n  \n  \n    Argentina \n    755226 \n    3673 \n    758899 \n  \n  \n    Armenia \n    3758 \n    16381 \n    20139 \n  \n  \n    Aruba \n    142 \n    0 \n    142"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#bringing-in-continent",
    "href": "slides/slides-08-wrangle-prob.html#bringing-in-continent",
    "title": "More wrangling + Probability",
    "section": "Bringing in continent",
    "text": "Bringing in continent\nSuppose I would like to explore the data on a continent level. We don’t have continent in the current data frame, but we could join in the following data:\n\ncontinents |>\n  slice(1:5)\n\n\n\n\n\n \n  \n    country \n    continent \n  \n \n\n  \n    Afghanistan \n    Asia \n  \n  \n    Åland Islands \n    Europe \n  \n  \n    Albania \n    Europe \n  \n  \n    Algeria \n    Africa \n  \n  \n    American Samoa \n    Oceania \n  \n\n\n\n\n\n\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?"
  },
  {
    "objectID": "slides/slides-08-wrangle-prob.html#example-cont.",
    "href": "slides/slides-08-wrangle-prob.html#example-cont.",
    "title": "More wrangling + Probability",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nleft_join(fisheries, continents, by = \"country\") |>\n  slice(1:10)\n\n\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    total \n    continent \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    2200 \n    Asia \n  \n  \n    Albania \n    7886 \n    950 \n    8836 \n    Europe \n  \n  \n    Algeria \n    95000 \n    1361 \n    96361 \n    Africa \n  \n  \n    American Samoa \n    3047 \n    20 \n    3067 \n    Oceania \n  \n  \n    Andorra \n    0 \n    0 \n    0 \n    Europe \n  \n  \n    Angola \n    486490 \n    655 \n    487145 \n    Africa \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n    3010 \n    NA \n  \n  \n    Argentina \n    755226 \n    3673 \n    758899 \n    Americas \n  \n  \n    Armenia \n    3758 \n    16381 \n    20139 \n    Asia \n  \n  \n    Aruba \n    142 \n    0 \n    142 \n    Americas \n  \n\n\n\n\n\n\nNotice the NA\nCould also use the following piping code:\n\n\n\nfisheries |>\n  left_join(continents, by = \"country\")"
  },
  {
    "objectID": "slides/slides-08-joins.html#joining-data-frames",
    "href": "slides/slides-08-joins.html#joining-data-frames",
    "title": "Joining data frames",
    "section": "Joining data frames",
    "text": "Joining data frames\nAssume we have two data frame, x and y. There are some shared variables (i.e. columns) in the two. Suppose we want to combine them together into one single data frame.\n\n\nsomething_join(x, y)\n\n\n\nMutating joins:\n\nleft_join(): return all rows from x\nright_join(): return all rows from y\nfull_join(): return all rows from both x and y\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\n\nFiltering joins:\n\nsemi_join(): return all rows from x where there are matching values in y, keeping just columns from x\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x"
  },
  {
    "objectID": "slides/slides-08-joins.html#setup",
    "href": "slides/slides-08-joins.html#setup",
    "title": "Joining data frames",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\n\n\n\nx\n\n\n\n\n\n\nID\nx_val\n\n\n\n\n1\nx1\n\n\n2\nx2\n\n\n3\nx3\n\n\n\n\n\n\n\n\n\n\ny\n\n\n\n\n\n\nID\ny_val\n\n\n\n\n1\ny1\n\n\n2\ny2\n\n\n4\ny4"
  },
  {
    "objectID": "slides/slides-08-joins.html#left_join",
    "href": "slides/slides-08-joins.html#left_join",
    "title": "Joining data frames",
    "section": "left_join()",
    "text": "left_join()\nAdds columns to x from y, matching all rows in x\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nleft_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA"
  },
  {
    "objectID": "slides/slides-08-joins.html#right_join",
    "href": "slides/slides-08-joins.html#right_join",
    "title": "Joining data frames",
    "section": "right_join()",
    "text": "right_join()\nAdds columns to x from y, matching all rows in y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nright_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    4 \n    NA \n    y4"
  },
  {
    "objectID": "slides/slides-08-joins.html#full_join",
    "href": "slides/slides-08-joins.html#full_join",
    "title": "Joining data frames",
    "section": "full_join()",
    "text": "full_join()\nAdds columns to x from y, matching all rows in x OR y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nfull_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA \n  \n  \n    4 \n    NA \n    y4"
  },
  {
    "objectID": "slides/slides-08-joins.html#inner_join",
    "href": "slides/slides-08-joins.html#inner_join",
    "title": "Joining data frames",
    "section": "inner_join()",
    "text": "inner_join()\nAll rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\ninner_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2"
  },
  {
    "objectID": "slides/slides-08-joins.html#inner_join-cont.",
    "href": "slides/slides-08-joins.html#inner_join-cont.",
    "title": "Joining data frames",
    "section": "inner_join() (cont.)",
    "text": "inner_join() (cont.)\nExample with multiple matches:\n\n\n\nx2\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n  \n    1 \n    new_x \n  \n\n\n\n\n\n\n\ny2\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n  \n    1 \n    new_y \n  \n\n\n\n\n\n\n\n\ninner_join(x2, y2, by = \"ID\")\n\n\n\nWarning in inner_join(x2, y2, by = \"ID\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    1 \n    x1 \n    new_y \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    1 \n    new_x \n    y1 \n  \n  \n    1 \n    new_x \n    new_y"
  },
  {
    "objectID": "slides/slides-08-joins.html#semi_join",
    "href": "slides/slides-08-joins.html#semi_join",
    "title": "Joining data frames",
    "section": "semi_join()",
    "text": "semi_join()\nReturns all rows from x with a match in y, but does not add columns from y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nsemi_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2"
  },
  {
    "objectID": "slides/slides-08-joins.html#anti_join",
    "href": "slides/slides-08-joins.html#anti_join",
    "title": "Joining data frames",
    "section": "anti_join()",
    "text": "anti_join()\nReturns all rows from x without any match in y, and not add columns from y\n\n\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny\n\n\n\n\n\n \n  \n    ID \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\nanti_join(x, y, by = \"ID\")\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    3 \n    x3"
  },
  {
    "objectID": "slides/slides-08-joins.html#joining-with-different-variable-names",
    "href": "slides/slides-08-joins.html#joining-with-different-variable-names",
    "title": "Joining data frames",
    "section": "Joining with different variable names",
    "text": "Joining with different variable names\nIf the variables in x and y have different names but we know they represent the same variable:\n\n\n\nx\n\n\n\n\n\n \n  \n    ID \n    x_val \n  \n \n\n  \n    1 \n    x1 \n  \n  \n    2 \n    x2 \n  \n  \n    3 \n    x3 \n  \n\n\n\n\n\n\n\ny3\n\n\n\n\n\n \n  \n    ID_y \n    y_val \n  \n \n\n  \n    1 \n    y1 \n  \n  \n    2 \n    y2 \n  \n  \n    4 \n    y4 \n  \n\n\n\n\n\n\n\n\n\nleft_join(x, y3, by =  c(\"ID\" = \"ID_y\"))\n\n\n\n\n\n \n  \n    ID \n    x_val \n    y_val \n  \n \n\n  \n    1 \n    x1 \n    y1 \n  \n  \n    2 \n    x2 \n    y2 \n  \n  \n    3 \n    x3 \n    NA"
  },
  {
    "objectID": "slides/slides-08-joins.html#joining-on-multiple-variables",
    "href": "slides/slides-08-joins.html#joining-on-multiple-variables",
    "title": "Joining data frames",
    "section": "Joining on multiple variables",
    "text": "Joining on multiple variables\nCan specify more than one variable in the by argument. Will need to a vector of character objects.\n\n\n\nenrollment\n\n\n\n\n\n \n  \n    student_id \n    course \n    start_year \n  \n \n\n  \n    1 \n    STAT 310 \n    F22 \n  \n  \n    1 \n    MATH 223 \n    F22 \n  \n  \n    2 \n    STAT 310 \n    F23 \n  \n  \n    3 \n    STAT 201 \n    W24 \n  \n\n\n\n\n\n\n\npayment\n\n\n\n\n\n \n  \n    student_id \n    Course \n    status \n  \n \n\n  \n    1 \n    STAT 310 \n    paid \n  \n  \n    1 \n    MATH 223 \n    paid \n  \n  \n    2 \n    STAT 310 \n    unpaid \n  \n  \n    3 \n    STAT 201 \n    paid \n  \n\n\n\n\n\n\n\n\n\n# note, multiple join functions would work in this example!\ninner_join(enrollment, payment, by = c(\"student_id\", \"course\" = \"Course\"))\n\n\n\n\n\n \n  \n    student_id \n    course \n    start_year \n    status \n  \n \n\n  \n    1 \n    STAT 310 \n    F22 \n    paid \n  \n  \n    1 \n    MATH 223 \n    F22 \n    paid \n  \n  \n    2 \n    STAT 310 \n    F23 \n    unpaid \n  \n  \n    3 \n    STAT 201 \n    W24 \n    paid"
  },
  {
    "objectID": "slides/slides-08-joins.html#example",
    "href": "slides/slides-08-joins.html#example",
    "title": "Joining data frames",
    "section": "Example",
    "text": "Example\nWe have data on fishery harvests (in tons) by countries from 2016:\n\n\n\n\nfish |>\n    slice(1:9)\n\n\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n  \n  \n    Albania \n    7886 \n    950 \n  \n  \n    Algeria \n    95000 \n    1361 \n  \n  \n    American Samoa \n    3047 \n    20 \n  \n  \n    Andorra \n    0 \n    0 \n  \n  \n    Angola \n    486490 \n    655 \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n  \n  \n    Argentina \n    755226 \n    3673 \n  \n  \n    Armenia \n    3758 \n    16381"
  },
  {
    "objectID": "slides/slides-08-joins.html#bringing-in-continent",
    "href": "slides/slides-08-joins.html#bringing-in-continent",
    "title": "Joining data frames",
    "section": "Bringing in continent",
    "text": "Bringing in continent\nSuppose I would like to explore the data on a continent level. We don’t have continent in the current data frame, but we could join in the following data:\n\ncontinents |>\n  slice(1:5)\n\n\n\n\n\n \n  \n    country \n    continent \n  \n \n\n  \n    Afghanistan \n    Asia \n  \n  \n    Åland Islands \n    Europe \n  \n  \n    Albania \n    Europe \n  \n  \n    Algeria \n    Africa \n  \n  \n    American Samoa \n    Oceania \n  \n\n\n\n\n\n\n\nWe want to keep all rows and columns from fish and add a column for corresponding continents. Which join function should we use?\nWe want to keep all rows from fish for which we have a corresponding continent and add a column for corresponding continents. Which join function should we use?"
  },
  {
    "objectID": "slides/slides-08-joins.html#example-cont.",
    "href": "slides/slides-08-joins.html#example-cont.",
    "title": "Joining data frames",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\n\n\nleft_join(fish, continents, by = \"country\") |>\n  slice(1:9)\n\n\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    continent \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    Asia \n  \n  \n    Albania \n    7886 \n    950 \n    Europe \n  \n  \n    Algeria \n    95000 \n    1361 \n    Africa \n  \n  \n    American Samoa \n    3047 \n    20 \n    Oceania \n  \n  \n    Andorra \n    0 \n    0 \n    Europe \n  \n  \n    Angola \n    486490 \n    655 \n    Africa \n  \n  \n    Antigua and Barbuda \n    3000 \n    10 \n    NA \n  \n  \n    Argentina \n    755226 \n    3673 \n    Americas \n  \n  \n    Armenia \n    3758 \n    16381 \n    Asia \n  \n\n\n\n\n\n\nNotice the NA\n\n\n\n\ninner_join(fish, continents, by = \"country\") |>\n  slice(1:9)\n\n\n\n\n\n \n  \n    country \n    capture \n    aquaculture \n    continent \n  \n \n\n  \n    Afghanistan \n    1000 \n    1200 \n    Asia \n  \n  \n    Albania \n    7886 \n    950 \n    Europe \n  \n  \n    Algeria \n    95000 \n    1361 \n    Africa \n  \n  \n    American Samoa \n    3047 \n    20 \n    Oceania \n  \n  \n    Andorra \n    0 \n    0 \n    Europe \n  \n  \n    Angola \n    486490 \n    655 \n    Africa \n  \n  \n    Argentina \n    755226 \n    3673 \n    Americas \n  \n  \n    Armenia \n    3758 \n    16381 \n    Asia \n  \n  \n    Aruba \n    142 \n    0 \n    Americas \n  \n\n\n\n\n\n\n\n\n\nCould also use the following piping code:\n\n\n\nfish |>\n  left_join(continents, by = \"country\")"
  },
  {
    "objectID": "slides/slides-08-joins.html#live-code",
    "href": "slides/slides-08-joins.html#live-code",
    "title": "More wrangling + Probability",
    "section": "Live code",
    "text": "Live code"
  },
  {
    "objectID": "slides/slides-11-probability.html#key-terms",
    "href": "slides/slides-11-probability.html#key-terms",
    "title": "Probability basics",
    "section": "Key terms",
    "text": "Key terms\n\nRandom process: a situation in which a particular result, called an outcome, is random/not known ahead of time\n\nExamples: flipping a coin, rolling six-sided die, sports game, if a treatment is effective\n\nA sample space \\(S\\) is the set of all possible outcomes of the random process\n\n\nWhat are possible sample spaces for the above examples?\n\n\nAn event is a set of outcomes from a random process"
  },
  {
    "objectID": "slides/slides-11-probability.html#random-variable",
    "href": "slides/slides-11-probability.html#random-variable",
    "title": "Probability basics",
    "section": "Random variable",
    "text": "Random variable\n\nA random variable is a variable whose value is unknown and depends on random events\n\nOften denoted with a capital letter like \\(X\\) or \\(Y\\)\n\nThere are two types: discrete and continuous (just like in numeric variables)\n\nDiscrete: represents random process where sample space is “countable” (i.e. {1,2} or {1,2,3,4,…})\nContinuous: sample space is “uncountable” (i.e. can take on any value within a specified interval with infinite number of possible values)\n\nNOTE: we will focus on discrete random variables for now"
  },
  {
    "objectID": "slides/slides-11-probability.html#probability",
    "href": "slides/slides-11-probability.html#probability",
    "title": "Probability basics",
    "section": "Probability",
    "text": "Probability\n\nFor us, the probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times\n\nProbability is used to express the likelihood that some outcome or event will or will not occur\nThink of as a proportion\n\nLet \\(A\\) denote some outcome or event. We denote the probability of \\(A\\) occurring as \\(\\text{P}(A)\\) or \\(\\text{Pr}(A)\\).\nWhen the sample space \\(S\\) is discrete with a finite size, and all outcomes equally likely, then \\(\\text{Pr}(A) = \\frac{\\text{ number of outcomes favorable to } A}{\\text{ number of total outcomes possible} }\\)"
  },
  {
    "objectID": "slides/slides-11-probability.html#example",
    "href": "slides/slides-11-probability.html#example",
    "title": "Probability basics",
    "section": "Example",
    "text": "Example\nLet the random process rolling a fair, six-sided die one time. Let \\(X\\) be a random variable representing the value of the die.\n\nFor each of the following, determine the outcome(s) under consideration, along with the value of the probability itself:\n\n\\(\\text{Pr}(X = 1)\\)\n\\(\\text{Pr}(X = 1 \\text{ and } X = 2)\\)\n\\(\\text{Pr}(X \\text{ is even})\\)\n\n\n\nConvince ourselves that \\(X\\) is a RV. Recall: sample space is 1,..,6.\nPossible outcome is 1, and an event would be \\(X=1\\); the RV being 1.\nPossible event is 1 or 2."
  },
  {
    "objectID": "slides/slides-11-probability.html#operations-with-events",
    "href": "slides/slides-11-probability.html#operations-with-events",
    "title": "Probability basics",
    "section": "Operations with events",
    "text": "Operations with events\nLet \\(A\\) and \\(B\\) be two possible events.\n\nThe intersection of \\(A\\) and \\(B\\) is denoted as \\(A \\cap B\\), and is the set of outcomes that belong to both events \\(A\\) and \\(B\\)\nThe union of \\(A\\) and \\(B\\) is denoted as \\(A \\cup B\\), and is the set of outcomes that belong to \\(A\\) and/or \\(B\\)\n\n\nWhen we have only two or three events, Venn diagrams can be very useful for visualizing probabilities!"
  },
  {
    "objectID": "slides/slides-11-probability.html#disjoint-events",
    "href": "slides/slides-11-probability.html#disjoint-events",
    "title": "Probability basics",
    "section": "Disjoint events",
    "text": "Disjoint events\nTwo events are disjoint or mutually exclusive if they cannot simultaneously happen.\n\nThat is, if \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cap B) = ?\\)\n\nIf our random process is rolling a six-sided die one time, what are some examples of disjoint events?"
  },
  {
    "objectID": "slides/slides-11-probability.html#rules-of-probability",
    "href": "slides/slides-11-probability.html#rules-of-probability",
    "title": "Probability basics",
    "section": "Rules of probability",
    "text": "Rules of probability\nKolmogorov axioms\n\nThe probability of any event is non-negative real number\nThe probability of the entire sample space 1\nIf \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cup B) = \\text{Pr}(A) + \\text{Pr}(B)\\)\n\n\nThese axioms imply that all probabilities are between 0 and 1 inclusive, and lead to some important rules!"
  },
  {
    "objectID": "slides/slides-11-probability.html#addition-rule",
    "href": "slides/slides-11-probability.html#addition-rule",
    "title": "Probability basics",
    "section": "Addition rule",
    "text": "Addition rule\nLet \\(A\\) and \\(B\\) be two possible events. Then the addition rule states that the probability that at least one will occur is:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\nVenn diagram\nExample: in a standard deck of 52 cards, we have four suits (diamond, heart, club, spade) with 13 cards within each suit (1-10, Jack, Queen, King).\n\nSuppose we randomly draw one card from the shuffled deck.\nLet \\(A\\) be the event that the card is a spade.\nLet \\(B\\) be the event that the card is a face card (Jack, Queen or King).\nFind \\(P(A \\cup B)\\)."
  },
  {
    "objectID": "slides/slides-11-probability.html#complement",
    "href": "slides/slides-11-probability.html#complement",
    "title": "Probability basics",
    "section": "Complement",
    "text": "Complement\n\nThe complement of an event \\(A\\) is the set of all outcomes in \\(S\\) that are not in \\(A\\)\n\nDenoted as \\(A^c\\)\n\nContinuing the dice example, if \\(A\\) is the event that a 1 or 2 is rolled, what is \\(A^c\\)?\nComplement rule: \\(\\text{Pr}(A^c) = 1 - \\text{Pr}(A)\\)\n\nLet our random process be the sum of two dice. What is the probability that…\n\nthe sum of the dice is \\(not\\) 6?\nthe sum is at least 4?"
  },
  {
    "objectID": "slides/slides-11-probability.html#demorgans-laws",
    "href": "slides/slides-11-probability.html#demorgans-laws",
    "title": "Probability basics",
    "section": "DeMorgan’s Laws",
    "text": "DeMorgan’s Laws\nLet’s use Venn diagrams to try and determine formulas for the following:\n\nComplement of union: \\((A \\cup B)^c = \\ ?\\)\nComplement of intersection: \\((A \\cap B)^c = \\ ?\\)"
  },
  {
    "objectID": "slides/slides-11-probability.html#independence",
    "href": "slides/slides-11-probability.html#independence",
    "title": "Probability basics",
    "section": "Independence",
    "text": "Independence\n\nQualitatively, two processes are independent if knowing the outcome of one does not provide any information about the outcome of the other process\n\nExamples and non-examples?\n\nFormally: \\(A\\) and \\(B\\) are independent events if\\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\)"
  },
  {
    "objectID": "slides/slides-11-probability.html#probability-distributions",
    "href": "slides/slides-11-probability.html#probability-distributions",
    "title": "Probability basics",
    "section": "Probability distributions",
    "text": "Probability distributions\nWhen a random variable is discrete, it can be useful to discuss its probability distribution, which is a table of all (disjoint) outcomes and their associated probabilities.\n\n\nLet \\(X\\) be the sum of two fair, six-sided dice. What is the sample space associated with \\(S\\)?\nFill out the table below to display the probability distribution of \\(X\\):\n\n\n\n\n\n\n\\(X\\)\n2\n3\n4\n5\n6\n7\n\n\nProbability\n\n\n\n\n\n\n\n\n\\(X\\)\n8\n9\n10\n11\n12\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nWhy not include 1 or 13?"
  },
  {
    "objectID": "slides/slides-11-probability.html#probability-distributions-cont.",
    "href": "slides/slides-11-probability.html#probability-distributions-cont.",
    "title": "Probability basics",
    "section": "Probability distributions (cont.)",
    "text": "Probability distributions (cont.)\nThe probability distribution of a discrete random variable \\(X\\) must satisfy the following three rules:\n\nThe values \\(x\\) listed must be disjoint\nEach probability must be between 0 and 1 (inclusive)\nThe probabilities must sum to 1\n\n\nLet’s confirm that the distribution we found on the previous slide satisfies these rules!"
  },
  {
    "objectID": "slides/slides-11-probability.html#practice",
    "href": "slides/slides-11-probability.html#practice",
    "title": "Probability basics",
    "section": "Practice",
    "text": "Practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-08-joins.html#housekeeping",
    "href": "slides/slides-08-joins.html#housekeeping",
    "title": "Joining data frames",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nWrangling coding practice due tonight!\nOffice hours tomorrow 10am-12pm\nProblem Set 3 has large R component"
  },
  {
    "objectID": "slides/slides-08-joins.html#wrangle",
    "href": "slides/slides-08-joins.html#wrangle",
    "title": "Joining data frames",
    "section": "Wrangle",
    "text": "Wrangle\n\nfish |>\n  left_join(continents, by = \"country\") |>\n  group_by(continent) |> # get continent-level summary stats\n  summarise(mean_capture = mean(capture), sd_capture = sd(capture))\n\n# A tibble: 6 × 3\n  continent mean_capture sd_capture\n  <chr>            <dbl>      <dbl>\n1 Africa         180705.    266107.\n2 Americas       433235.   1038899.\n3 Asia          1036018.   2869652.\n4 Europe         317874.    797072.\n5 Oceania         74660.    121027.\n6 <NA>           134722.    448079."
  },
  {
    "objectID": "slides/slides-08-joins.html#visualize",
    "href": "slides/slides-08-joins.html#visualize",
    "title": "Joining data frames",
    "section": "Visualize",
    "text": "Visualize\n\nfish |>\n  na.omit() |> #remove any observations with any NAs\n  left_join(continents, by = \"country\") |>\n  ggplot(aes(x = continent, y = capture)) +\n  geom_boxplot(outliers = F) +\n  theme_bw() +\n  labs(caption = \"Excluding outliers\")"
  },
  {
    "objectID": "slides/slides-08-joins.html#visualize-cont.",
    "href": "slides/slides-08-joins.html#visualize-cont.",
    "title": "Joining data frames",
    "section": "Visualize (cont.)",
    "text": "Visualize (cont.)\n\nfish |>\n  mutate(log_capture = log(capture)) |>\n  left_join(continents, by = \"country\") |>\n  na.omit() |> #remove observations with any NAs\n  ggplot(aes(x = continent, y = capture)) +\n  geom_boxplot(outliers = F) +\n  theme_bw() +\n  labs(caption = \"Excluding outliers\", y = \"Log capture\")\n\n\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#joins",
    "href": "live_code/data_wrangling_pt2.html#joins",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Joins",
    "text": "Joins\nWe also have a dataset the provides the continent for a given country:\n\ncontinents_url <- \"https://raw.githubusercontent.com/math118-fall2022/website/refs/heads/master/docs/slides/lec-slides/data/continents.csv\"\ncontinents <- read_csv(continents_url)\n\nLet’s join the two data frames together.\n\nIf we want to keep all rows from fish for which we have a corresponding continent and add a column for the continents:\n\ninner_join(fish, continents, by = \"country\") |>\n  slice(1:9)\n\n# A tibble: 9 × 6\n  country        capture aquaculture  total total_mil continent\n  <chr>            <dbl>       <dbl>  <dbl>     <dbl> <chr>    \n1 Afghanistan       1000        1200   2200  0.0022   Asia     \n2 Albania           7886         950   8836  0.00884  Europe   \n3 Algeria          95000        1361  96361  0.0964   Africa   \n4 American Samoa    3047          20   3067  0.00307  Oceania  \n5 Andorra              0           0      0  0        Europe   \n6 Angola          486490         655 487145  0.487    Africa   \n7 Argentina       755226        3673 758899  0.759    Americas \n8 Armenia           3758       16381  20139  0.0201   Asia     \n9 Aruba              142           0    142  0.000142 Americas \n\n\nIf we want to keep all rows from fish and add a column for the corresponding continent:\n\nleft_join(fish, continents, by = \"country\") |>\n  slice(1:9)\n\n# A tibble: 9 × 6\n  country             capture aquaculture  total total_mil continent\n  <chr>                 <dbl>       <dbl>  <dbl>     <dbl> <chr>    \n1 Afghanistan            1000        1200   2200   0.0022  Asia     \n2 Albania                7886         950   8836   0.00884 Europe   \n3 Algeria               95000        1361  96361   0.0964  Africa   \n4 American Samoa         3047          20   3067   0.00307 Oceania  \n5 Andorra                   0           0      0   0       Europe   \n6 Angola               486490         655 487145   0.487   Africa   \n7 Antigua and Barbuda    3000          10   3010   0.00301 <NA>     \n8 Argentina            755226        3673 758899   0.759   Americas \n9 Armenia                3758       16381  20139   0.0201  Asia     \n\n# we could also use this piping code\nfish_joined <- fish |>\n  left_join(continents, by = \"country\")"
  },
  {
    "objectID": "slides/slides-08-joins.html",
    "href": "slides/slides-08-joins.html",
    "title": "Joining data frames",
    "section": "",
    "text": "Wrangling coding practice due tonight!\nOffice hours tomorrow 10am-12pm\nProblem Set 3 has large R component"
  },
  {
    "objectID": "slides/slides-08-joins.html#group_by",
    "href": "slides/slides-08-joins.html#group_by",
    "title": "Joining data frames",
    "section": "group_by()",
    "text": "group_by()\n\nfish |>\n  left_join(continents, by = \"country\") |>\n  group_by(continent) |> # get continent-level summary stats\n  summarise(mean_capture = mean(capture), sd_capture = sd(capture))\n\n# A tibble: 6 × 3\n  continent mean_capture sd_capture\n  <chr>            <dbl>      <dbl>\n1 Africa         180705.    266107.\n2 Americas       433235.   1038899.\n3 Asia          1036018.   2869652.\n4 Europe         317874.    797072.\n5 Oceania         74660.    121027.\n6 <NA>           134722.    448079."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#a-note-on-nas",
    "href": "live_code/data_wrangling_pt2.html#a-note-on-nas",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "A note on NAs",
    "text": "A note on NAs\nConsider the following data frame:\n\n\n\n\ndf\n\n  age score\n1   1    NA\n2   2     2\n3  NA     3\n\n\nna.omit() will remove ALL rows with any NA:\n\ndf |>\n  na.omit()\n\n  age score\n2   2     2\n\n\nIf we want to be more selective, we should combine filter() with is.na()\n\n# is.na() returns TRUE if the value is NA, and FALSE otherwise\n# the ! says \"not\"\ndf |>\n  filter(!is.na(age))\n\n  age score\n1   1    NA\n2   2     2"
  },
  {
    "objectID": "slides/slides-09-probability.html",
    "href": "slides/slides-09-probability.html",
    "title": "Probability basics",
    "section": "",
    "text": "Problem Set 3 due tonight"
  },
  {
    "objectID": "slides/slides-09-probability.html#key-terms",
    "href": "slides/slides-09-probability.html#key-terms",
    "title": "Probability basics",
    "section": "Key terms",
    "text": "Key terms\n\nRandom process: a situation in which a particular result, called an outcome, is random/not known ahead of time\n\nExamples: flipping a coin, rolling six-sided die, sports game, if a treatment is effective\n\nA sample space \\(S\\) is the set of all possible outcomes of the random process\n\n\nWhat are possible sample spaces for the above examples?\n\n\nAn event is a set of outcomes from a random process"
  },
  {
    "objectID": "slides/slides-09-probability.html#random-variable",
    "href": "slides/slides-09-probability.html#random-variable",
    "title": "Probability basics",
    "section": "Random variable",
    "text": "Random variable\n\nA random variable is a variable whose value is unknown and depends on random events\n\nOften denoted with a capital letter like \\(X\\) or \\(Y\\)\n\nThere are two types: discrete and continuous (just like in numeric variables)\n\nDiscrete: represents random process where sample space is “countable” (i.e. {1,2} or {1,2,3,4,…})\nContinuous: sample space is “uncountable” (i.e. can take on any value within a specified interval with infinite number of possible values)\n\nNOTE: we will focus on discrete random variables for now"
  },
  {
    "objectID": "slides/slides-09-probability.html#probability",
    "href": "slides/slides-09-probability.html#probability",
    "title": "Probability basics",
    "section": "Probability",
    "text": "Probability\n\nFor us, the probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times\n\nProbability is used to express the likelihood that some outcome or event will or will not occur\nThink of as a proportion\n\nLet \\(A\\) denote some outcome or event. We denote the probability of \\(A\\) occurring as \\(\\text{P}(A)\\) or \\(\\text{Pr}(A)\\).\nWhen the sample space \\(S\\) is discrete with a finite size, and all outcomes equally likely, then \\(\\text{Pr}(A) = \\frac{\\text{ number of outcomes favorable to } A}{\\text{ number of total outcomes possible} }\\)"
  },
  {
    "objectID": "slides/slides-09-probability.html#example",
    "href": "slides/slides-09-probability.html#example",
    "title": "Probability basics",
    "section": "Example",
    "text": "Example\nLet the random process rolling a fair, six-sided die one time. Let \\(X\\) be a random variable representing the value of the die.\n\nFor each of the following, determine the outcome(s) under consideration, along with the value of the probability itself:\n\n\\(\\text{Pr}(X = 1)\\)\n\\(\\text{Pr}(X = 1 \\text{ and } X = 2)\\)\n\\(\\text{Pr}(X \\text{ is even})\\)\n\n\n\nConvince ourselves that \\(X\\) is a RV. Recall: sample space is 1,..,6.\nPossible outcome is 1, and an event would be \\(X=1\\); the RV being 1.\nPossible event is 1 or 2."
  },
  {
    "objectID": "slides/slides-09-probability.html#operations-with-events",
    "href": "slides/slides-09-probability.html#operations-with-events",
    "title": "Probability basics",
    "section": "Operations with events",
    "text": "Operations with events\nLet \\(A\\) and \\(B\\) be two possible events.\n\nThe intersection of \\(A\\) and \\(B\\) is denoted as \\(A \\cap B\\), and is the set of outcomes that belong to both events \\(A\\) and \\(B\\)\nThe union of \\(A\\) and \\(B\\) is denoted as \\(A \\cup B\\), and is the set of outcomes that belong to \\(A\\) and/or \\(B\\)\n\n\nWhen we have only two or three events, Venn diagrams can be very useful for visualizing probabilities!"
  },
  {
    "objectID": "slides/slides-09-probability.html#disjoint-events",
    "href": "slides/slides-09-probability.html#disjoint-events",
    "title": "Probability basics",
    "section": "Disjoint events",
    "text": "Disjoint events\nTwo events are disjoint or mutually exclusive if they cannot simultaneously happen.\n\nThat is, if \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cap B) = ?\\)\n\nIf our random process is rolling a six-sided die one time, what are some examples of disjoint events?"
  },
  {
    "objectID": "slides/slides-09-probability.html#rules-of-probability",
    "href": "slides/slides-09-probability.html#rules-of-probability",
    "title": "Probability basics",
    "section": "Rules of probability",
    "text": "Rules of probability\nKolmogorov axioms\n\nThe probability of any event is non-negative real number\nThe probability of the entire sample space 1\nIf \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cup B) = \\text{Pr}(A) + \\text{Pr}(B)\\)\n\n\nThese axioms imply that all probabilities are between 0 and 1 inclusive, and lead to some important rules!"
  },
  {
    "objectID": "slides/slides-09-probability.html#addition-rule",
    "href": "slides/slides-09-probability.html#addition-rule",
    "title": "Probability basics",
    "section": "Addition rule",
    "text": "Addition rule\nLet \\(A\\) and \\(B\\) be two possible events. Then the addition rule states that the probability that at least one will occur is:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\nVenn diagram\nExample: in a standard deck of 52 cards, we have four suits (diamond, heart, club, spade) with 13 cards within each suit (1-10, Jack, Queen, King).\n\nSuppose we randomly draw one card from the shuffled deck.\nLet \\(A\\) be the event that the card is a spade.\nLet \\(B\\) be the event that the card is a face card (Jack, Queen or King).\nFind \\(P(A \\cup B)\\)."
  },
  {
    "objectID": "slides/slides-09-probability.html#complement",
    "href": "slides/slides-09-probability.html#complement",
    "title": "Probability basics",
    "section": "Complement",
    "text": "Complement\n\nThe complement of an event \\(A\\) is the set of all outcomes in \\(S\\) that are not in \\(A\\)\n\nDenoted as \\(A^c\\)\n\nContinuing the dice example, if \\(A\\) is the event that a 1 or 2 is rolled, what is \\(A^c\\)?\nComplement rule: \\(\\text{Pr}(A^c) = 1 - \\text{Pr}(A)\\)\n\nLet our random process be the sum of two dice. What is the probability that…\n\nthe sum of the dice is \\(not\\) 6?\nthe sum is at least 4?"
  },
  {
    "objectID": "slides/slides-09-probability.html#independence",
    "href": "slides/slides-09-probability.html#independence",
    "title": "Probability basics",
    "section": "Independence",
    "text": "Independence\n\nQualitatively, two processes are independent if knowing the outcome of one does not provide any information about the outcome of the other process\n\nExamples and non-examples?\n\nFormally: \\(A\\) and \\(B\\) are independent events if\\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\)"
  },
  {
    "objectID": "slides/slides-09-probability.html#probability-distributions",
    "href": "slides/slides-09-probability.html#probability-distributions",
    "title": "Probability basics",
    "section": "Probability distributions",
    "text": "Probability distributions\nWhen a random variable is discrete, it can be useful to discuss its probability distribution, which is a table of all (disjoint) outcomes and their associated probabilities.\n\n\nLet \\(X\\) be the sum of two fair, six-sided dice. What is the sample space associated with \\(S\\)?\nFill out the table below to display the probability distribution of \\(X\\):\n\n\n\n\n\n\n\\(X\\)\n2\n3\n4\n5\n6\n7\n\n\nProbability\n\n\n\n\n\n\n\n\n\\(X\\)\n8\n9\n10\n11\n12\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nWhy not include 1 or 13?"
  },
  {
    "objectID": "slides/slides-09-probability.html#probability-distributions-cont.",
    "href": "slides/slides-09-probability.html#probability-distributions-cont.",
    "title": "Probability basics",
    "section": "Probability distributions (cont.)",
    "text": "Probability distributions (cont.)\nThe probability distribution of a discrete random variable \\(X\\) must satisfy the following three rules:\n\nThe values \\(x\\) listed must be disjoint\nEach probability must be between 0 and 1 (inclusive)\nThe probabilities must sum to 1\n\n\nLet’s confirm that the distribution we found on the previous slide satisfies these rules!"
  },
  {
    "objectID": "slides/slides-09-probability.html#practice",
    "href": "slides/slides-09-probability.html#practice",
    "title": "Probability basics",
    "section": "Practice",
    "text": "Practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#recap",
    "href": "slides/slides-10-conditional-probability.html#recap",
    "title": "Conditional probability",
    "section": "Recap",
    "text": "Recap\n\nTwo events are disjoint/mutually exclusive if they do not have any overlapping outcomes\nAddition rule: \\(\\text{Pr}(A \\cup B) =\\)\nComplement rule: \\(\\text{Pr}(A^c) =\\)"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#probabilities-with-contingency-tables",
    "href": "slides/slides-10-conditional-probability.html#probabilities-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Probabilities with contingency tables",
    "text": "Probabilities with contingency tables\n\nAs we saw in the previous class, sometimes the probabilities of events are quite clear to calculate (e.g. dice rolls or drawing cards)\nBut oftentimes we have to use data to try and estimate probabilities\n\nWhy? Some probabilities are not known, and we use proportions from data as a proxy\n\nWhen we have two (or more) variables, we often want to understand the relationships between them (e.g. \\(A \\cap B\\))"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#practice",
    "href": "slides/slides-10-conditional-probability.html#practice",
    "title": "Conditional probability",
    "section": "Practice",
    "text": "Practice\n\nSource: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\n\nDefine events \\(A\\) = died and \\(B\\) = non-coffee drinker. Calculate/set-up the calculations for the following for a randomly selected person in the cohort:\n\n\\(\\text{P}(A)\\)\n\\(\\text{P}(A \\cap B)\\)\n\\(\\text{P}(A \\cup B^c)\\)"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#marginal-and-joint-probabilities",
    "href": "slides/slides-10-conditional-probability.html#marginal-and-joint-probabilities",
    "title": "Conditional probability",
    "section": "Marginal and joint probabilities",
    "text": "Marginal and joint probabilities\n\n\\(\\text{P}(A)\\) is an example of a marginal probability, which is a probability involving a single event\n\nFrom the contingency table, we use row totals or column totals and the overall total to obtain marginal probabilities\n\n\\(\\text{P}(A \\cap B)\\) is an example of a joint probability, which is a probability involving two or more events that have yet to occur\n\nFrom the contingency table, we use specific cells and the overall total to obtain joint probabilities"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#marginal-from-joint",
    "href": "slides/slides-10-conditional-probability.html#marginal-from-joint",
    "title": "Conditional probability",
    "section": "Marginal from joint",
    "text": "Marginal from joint\nWe can obtain the marginal probabilities from joint probabilities:\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\\[\\begin{align*}\n\\text{P}(B) &=\\text{P}(\\text{no coffee}) \\\\\n&= \\text{P}(\\text{no coffee} \\ \\cap \\text{ did not die}) + \\text{P}(\\text{no coffee} \\ \\cap \\text{ died})  \\\\\n&= \\text{P}(B \\cap A) + \\text{P}(B \\cap A^c) \\\\\n&= \\frac{5438}{69164 } + \\frac{1039}{69164} \\\\\n&= 0.0936\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#conditional-probability",
    "href": "slides/slides-10-conditional-probability.html#conditional-probability",
    "title": "Conditional probability",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nConditional probability: a probability that an event will occur given that another event has already occurred\n\nE.g. Given that it rained yesterday, what is the probability that it will rain today?\nIt is called “conditional” because we calculate a probability under a specific condition\n\n\n\n\\(\\text{Pr}(A | B)\\) : probability of \\(A\\) given \\(B\\)\n\nNot to be confused with the coding | which is “or”\nAppears to involve two events, but we assume that the event that is conditioned on (in this case \\(B\\)) has already happened\n\nWe can easily obtain conditional probabilities from contingency tables!"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#conditional-probability-with-contingency-tables",
    "href": "slides/slides-10-conditional-probability.html#conditional-probability-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Conditional probability with contingency tables",
    "text": "Conditional probability with contingency tables\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nFrom contingency table, we use specific cells and row or column totals to obtain conditional probabilities\n\n\n\nRecall events \\(A\\) = died and \\(B\\) = non-coffee drinker. Write \\(\\text{P}()\\) notation for the conditional probability of dying given that someone does not drink coffee, and then obtain this probability."
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#general-multiplication-rule",
    "href": "slides/slides-10-conditional-probability.html#general-multiplication-rule",
    "title": "Conditional probability",
    "section": "General multiplication rule",
    "text": "General multiplication rule\nConditional, joint, and marginal probabilities are related via the general multiplication rule:\n\n\\[\n\\text{P}(A \\cap B) =\n\\]\n\n\nLet’s see this in the coffee example!\nVery useful for finding probability that two events will happen in sequence.\n\nExample: A box has three tickets, colored red, orange, yellow. We will draw two tickets randomly one-at-a-time without replacement. What is the probability of drawing the red ticket first and then the orange ticket?"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#independence-and-conditional-probabilities",
    "href": "slides/slides-10-conditional-probability.html#independence-and-conditional-probabilities",
    "title": "Conditional probability",
    "section": "Independence and conditional probabilities",
    "text": "Independence and conditional probabilities\n\nRecall, events \\(A\\) and \\(B\\) are independent when what is true about their joint probability?\nUsing the general multiplication rule, what is another way to determine if events \\(A\\) and \\(B\\) are independent?\n\nWhy does this make sense “intuitively”?\n\n\nUsing this new test of independence, are dying and abstaining from coffee independent events?"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#conditional-probability-formula",
    "href": "slides/slides-10-conditional-probability.html#conditional-probability-formula",
    "title": "Conditional probability",
    "section": "Conditional probability formula",
    "text": "Conditional probability formula\nWe can re-arrange the general multiplication formula to obtain the following general formula for conditional probability. For any events \\(A\\) and \\(B\\):\n\n\\[\n\\text{P}(A| B) = \\frac{\\text{P}(A \\cap B)}{\\text{P}(B)}\n\\]\n\n\n\nCome up with a similar formula for \\(\\text{P}(B|A)\\)\n\n\nNote: complement rule holds for conditional probabilities if we condition on the same information: \\(\\text{P}(A|B) = 1 - \\text{P}(A^c | B)\\)"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#law-of-total-probability",
    "href": "slides/slides-10-conditional-probability.html#law-of-total-probability",
    "title": "Conditional probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nLet \\(A\\) be an event, then let \\(\\{B_{1},B_{2},\\ldots, B_{k}\\}\\) be a set of mutually exclusive events whose union comprises their entire sample space \\(S\\)\nThen Law of Total Probability (LoTP) says:\n\n\n\\[\n\\text{Pr}(A) = \\text{Pr}(A \\cap B_{1} ) + \\text{Pr}(A \\cap B_{2}) + \\ldots + \\text{Pr}(A \\cap B_{k})\n\\]\n\n\nBlob picture\nWe already did this in the coffee example! We said \\(\\text{P}(\\text{no coffee}) = \\text{P}(\\text{no coffee} \\ \\cap \\text{ did not die}) + \\text{P}(\\text{no coffee} \\ \\cap \\text{ died})\\)\n\nHere, the outcomes of “did not die” and “died” are the mutually exclusive events that comprise \\(S\\)"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#tree-diagram",
    "href": "slides/slides-10-conditional-probability.html#tree-diagram",
    "title": "Conditional probability",
    "section": "Tree diagram",
    "text": "Tree diagram\nTool to organize outcomes and probabilities around the structure of the data. Useful when outcomes occur sequentially, and outcomes are conditioned on predecessors. Let’s do an example:\n\nA class has a midterm and a final exam. 80% of students passed the midterm. Of those students who passed the midterm, 90% also passed the final. Of those student who did not pass the midterm, 15% passed on the final. You randomly pick up a final exam and notice the student passed. What is the probability that they passed the midterm?\n\nUsing \\(\\text{P}()\\) notation, what probability are we interested in? What probabilities do we need to calculate along the way?\n\nLet’s construct our tree!\n\nIn the tree diagram, where are the three types of probabilities appearing?"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#bayes-rule-1",
    "href": "slides/slides-10-conditional-probability.html#bayes-rule-1",
    "title": "Conditional probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\nAs we saw before, the two conditional probabilities \\(P(A|B)\\) and \\(P(B|A)\\) are not the same. But are they related in some way?\nBayes’ rule:\n\n\n\\[\n\\text{P}(A|B) = \\frac{P(B|A) P(A)}{P(B)}\n\\]\n\n\nWhy is this seemingly more complicated formula useful?"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#bayes-theorem-more-general",
    "href": "slides/slides-10-conditional-probability.html#bayes-theorem-more-general",
    "title": "Conditional probability",
    "section": "Bayes’ Theorem (more general)",
    "text": "Bayes’ Theorem (more general)\n\nSuppose we have a random process and have a defined event \\(A\\)\nFurther suppose we can break up the sample space into \\(k\\) disjoint/mutually exclusive outcomes or events \\(B_{1}, B_{2}, \\ldots, B_{k}\\)\nWithout loss of generality, suppose we want \\(\\text{P}(B_{1} | A)\\)\nBayes’ Theorem states:\n\\[\\begin{align*}\n\\text{P}(B_{1} |  A ) &= \\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A)}\\qquad \\qquad\\qquad \\qquad \\text{(Bayes' Rule)} \\\\\n&= \\frac{\\text{P}(A|B_{1})\\text{P}(B_{1})}{\\text{P}(A\\cap B_{1}) + \\text{P}(A \\cap B_{2}) + \\ldots + \\text{P}(A \\cap B_{k})} \\qquad \\qquad \\text{(LoTP)} \\\\\n&=\\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A|B_{1}) \\text{P}(B_{1}) + \\text{P}(A | B_{2}) \\text{P}(B_{2}) + \\ldots + \\text{P}(A | B_{k} ) \\text{P}(B_{k})}\n\\end{align*}\\]\n\n\nHow would this change if we wanted \\(P(A_{2} | B)\\) instead?\nWhy is this important? We want P(B_i | A), but sometimes we only have probabilities in the other order of conditioning!\n\n\nLet’s see how the tree diagram compares to the formula!"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html#example",
    "href": "slides/slides-10-conditional-probability.html#example",
    "title": "Conditional probability",
    "section": "Example",
    "text": "Example\n\nIn Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but this test is not perfect.\nIn about 11% of patients with breast cancer, the test gives a false negative: it indicates a woman does not have breast cancer when she does have breast cancer.\nIn about 7% of patients who do not have breast cancer, the test gives a false positive: it indicates these patients have breast cancer when they actually do not.\nIf we tested a random Canadian woman over 40 for breast cancer using a mammogram and the test came back positive, what is the probability that the patient actually has breast cancer?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#study-design",
    "href": "slides/slides-11-simpsons.html#study-design",
    "title": "Simpson’s paradox",
    "section": "Study design",
    "text": "Study design\n\nWhat are the differences between observational studies and experimental studies?\nWhat is a confounding variable?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#uc-berkeley-admissions",
    "href": "slides/slides-11-simpsons.html#uc-berkeley-admissions",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions",
    "text": "UC Berkeley admissions\nObservational study on sex bias based on Fall 1973 admissions data to the graduate program at the University of California, Berkeley\n\n\n\n\nAdmit\nDeny\nTotal\n\n\n\n\nMen\n3738\n4704\n8442\n\n\nWomen\n1494\n2827\n4321\n\n\nTotal\n5232\n7531\n12763\n\n\n\n\n\nWhat is the probability* of admission for a randomly selected applicant?\nWhat is the probability of admission among men? Among women?\nAre the probabilities you found marginal, joint, or conditional probabilities?\n\n\n\n\nSuppose we want to understand the relationship between gender and admission decision. What sort of visualization might be appropriate for representing this data?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#uc-berkeley-admissions-cont.",
    "href": "slides/slides-11-simpsons.html#uc-berkeley-admissions-cont.",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions (cont.)",
    "text": "UC Berkeley admissions (cont.)"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#dive-into-data",
    "href": "slides/slides-11-simpsons.html#dive-into-data",
    "title": "Simpson’s paradox",
    "section": "Dive into data",
    "text": "Dive into data\nWe have more nuanced data about the graduate admissions: we know the department that each person was applied to.\nWe will consider the six largest departments: A, B, C, D, E, F\n\nThe first six observations in the data frame are as follows:\n\n\n\n# head() gives us the first 6 rows\nhead(admissions)\n\n# A tibble: 6 × 3\n  Decision Gender Dept \n  <chr>    <chr>  <chr>\n1 Admit    Male   B    \n2 Reject   Female C    \n3 Admit    Male   C    \n4 Reject   Female C    \n5 Admit    Male   A    \n6 Reject   Male   F    \n\n\n\n\n\nWhat sort of EDA would be interesting/appropriate for these data?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#frequency-tables",
    "href": "slides/slides-11-simpsons.html#frequency-tables",
    "title": "Simpson’s paradox",
    "section": "Frequency tables",
    "text": "Frequency tables\nNumber of applicants by department:\n\n\nFemale applicants:\n\nadmissions |>\n  filter(Gender == \"Female\") |> \n  count(Dept)\n\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n108\n\n\nB\n25\n\n\nC\n593\n\n\nD\n375\n\n\nE\n393\n\n\nF\n341\n\n\n\n\n\n\nMale applicants:\n\nadmissions |>\n  filter(Gender == \"Male\") |> \n  count(Dept)\n\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n825\n\n\nB\n560\n\n\nC\n325\n\n\nD\n417\n\n\nE\n191\n\n\nF\n373\n\n\n\n\n\n\nBoth groups:\n\nadmissions |>\n  count(Dept, Gender)\n\n\n\n\n\n \n  \n    Dept \n    Gender \n    n \n  \n \n\n  \n    A \n    Female \n    108 \n  \n  \n    A \n    Male \n    825 \n  \n  \n    B \n    Female \n    25 \n  \n  \n    B \n    Male \n    560 \n  \n  \n    C \n    Female \n    593 \n  \n  \n    C \n    Male \n    325 \n  \n  \n    D \n    Female \n    375 \n  \n  \n    D \n    Male \n    417 \n  \n  \n    E \n    Female \n    393 \n  \n  \n    E \n    Male \n    191 \n  \n  \n    F \n    Female \n    341 \n  \n  \n    F \n    Male \n    373"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#more-detailed-frequency-tables",
    "href": "slides/slides-11-simpsons.html#more-detailed-frequency-tables",
    "title": "Simpson’s paradox",
    "section": "More-detailed frequency tables",
    "text": "More-detailed frequency tables\nNumber of applicants by department and admission status:\n\n\nFemale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    89 \n  \n  \n    A \n    Reject \n    19 \n  \n  \n    B \n    Admit \n    17 \n  \n  \n    B \n    Reject \n    8 \n  \n  \n    C \n    Admit \n    202 \n  \n  \n    C \n    Reject \n    391 \n  \n  \n    D \n    Admit \n    131 \n  \n  \n    D \n    Reject \n    244 \n  \n  \n    E \n    Admit \n    94 \n  \n  \n    E \n    Reject \n    299 \n  \n  \n    F \n    Admit \n    24 \n  \n  \n    F \n    Reject \n    317 \n  \n\n\n\n\n\n\nMale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    512 \n  \n  \n    A \n    Reject \n    313 \n  \n  \n    B \n    Admit \n    353 \n  \n  \n    B \n    Reject \n    207 \n  \n  \n    C \n    Admit \n    120 \n  \n  \n    C \n    Reject \n    205 \n  \n  \n    D \n    Admit \n    138 \n  \n  \n    D \n    Reject \n    279 \n  \n  \n    E \n    Admit \n    53 \n  \n  \n    E \n    Reject \n    138 \n  \n  \n    F \n    Admit \n    22 \n  \n  \n    F \n    Reject \n    351"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#visualize",
    "href": "slides/slides-11-simpsons.html#visualize",
    "title": "Simpson’s paradox",
    "section": "Visualize",
    "text": "Visualize\nCan visualize three categorical variables at once!"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#closer-look",
    "href": "slides/slides-11-simpsons.html#closer-look",
    "title": "Simpson’s paradox",
    "section": "Closer look",
    "text": "Closer look\nProbability of admission conditioning on gender and department:\n\n\n\n\n\n\n \n  \n    Dept \n    Gender \n    cond_prob_admit \n  \n \n\n  \n    A \n    Female \n    0.82 \n  \n  \n    A \n    Male \n    0.62 \n  \n  \n    B \n    Female \n    0.68 \n  \n  \n    B \n    Male \n    0.63 \n  \n  \n    C \n    Female \n    0.34 \n  \n  \n    C \n    Male \n    0.37 \n  \n  \n    D \n    Female \n    0.35 \n  \n  \n    D \n    Male \n    0.33 \n  \n  \n    E \n    Female \n    0.24 \n  \n  \n    E \n    Male \n    0.28 \n  \n  \n    F \n    Female \n    0.07 \n  \n  \n    F \n    Male \n    0.06 \n  \n\n\n\n\n\n\n\n\nAre all departments uniform in admission rates?\nDo admissions still seem biased against female applicants?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#whats-going-on",
    "href": "slides/slides-11-simpsons.html#whats-going-on",
    "title": "Simpson’s paradox",
    "section": "What’s going on?",
    "text": "What’s going on?\n\n\n\nBut wait… didn’t we start by noting that men were way more likely to be admitted than women?\nThe first two departments (A and B) are easy to get into\nThe following table shows for each gender, the proportion of applicants each department received.\n\n\n\n\n\n\n\n \n  \n    Gender \n    Dept \n    cond_prop \n  \n \n\n  \n    Female \n    A \n    0.059 \n  \n  \n    Female \n    B \n    0.014 \n  \n  \n    Female \n    C \n    0.323 \n  \n  \n    Female \n    D \n    0.204 \n  \n  \n    Female \n    E \n    0.214 \n  \n  \n    Female \n    F \n    0.186 \n  \n  \n    Male \n    A \n    0.307 \n  \n  \n    Male \n    B \n    0.208 \n  \n  \n    Male \n    C \n    0.121 \n  \n  \n    Male \n    D \n    0.155 \n  \n  \n    Male \n    E \n    0.071 \n  \n  \n    Male \n    F \n    0.139 \n  \n\n\n\n\n\n\n\n\nWhat do you notice?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#simpsons-paradox",
    "href": "slides/slides-11-simpsons.html#simpsons-paradox",
    "title": "Simpson’s paradox",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\nThe UC Berkeley admissions observational study is an example of Simpson’s paradox: when omitting one explanatory variable causes the measure/degree of association between another explanatory variable and a response variable to reverse or disappear\n\nIn other words, the inclusion/exclusion of a third variable in the analysis can change the apparent relationship between the other two variables\nWhat was the confounding variable in UC Berkeley study?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#filtering-for-multiple-levels",
    "href": "slides/slides-11-simpsons.html#filtering-for-multiple-levels",
    "title": "Simpson’s paradox",
    "section": "Filtering for multiple levels",
    "text": "Filtering for multiple levels\nSuppose I want to retain observations in the first three departments. We could do the following:\n\nadmissions |>\n  filter(Dept == \"A\" | Dept == \"B\" | Dept == \"C\")\n\nOr I could streamline using the %in% operator:\n\nadmissions |>\n  filter(Dept %in% c(\"A\", \"B\", \"C\"))\n\n\nThis reads: filter for observations where the Dept value is in the vector of options (A, B, C)"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#wrangling-for-probabilities",
    "href": "slides/slides-11-simpsons.html#wrangling-for-probabilities",
    "title": "Simpson’s paradox",
    "section": "Wrangling for probabilities",
    "text": "Wrangling for probabilities\n\n\nWhat is the probability that someone was admitted?\n\nadmissions |>\n  count(Decision) |>\n  mutate(prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 2 × 2\n  Decision  prob\n  <chr>    <dbl>\n1 Admit    0.388\n2 Reject   0.612\n\n\n\n\nWhat is the probability that someone was admitted, conditioned on gender?\n\nadmissions |>\n  count(Gender, Decision) |>\n  group_by(Gender) |>\n  mutate(cond_prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Decision cond_prob\n  <chr>  <chr>        <dbl>\n1 Female Admit        0.304\n2 Female Reject       0.696\n3 Male   Admit        0.445\n4 Male   Reject       0.555\n\n\n\n\nHow might I extend to also condition on Department?"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#more-complex-categorical-variables",
    "href": "slides/slides-11-simpsons.html#more-complex-categorical-variables",
    "title": "Simpson’s paradox",
    "section": "More complex categorical variables",
    "text": "More complex categorical variables\nSuppose I want to create a new variable called Dept2 that takes the values:\n\n“Group 1” if someone applied to Department A or B\n“Group 2” if someone applied to Department C or D\n“Group 3” if someone applied to Department E or F\n\n\n\n# option 1 (awful): nested if_else()\nadmissions |>\n  mutate(Dept2 = if_else(Dept %in% c(\"A\", \"B\"), \"Group 1\",\n                           if_else(Dept %in% c(\"C\", \"D\"), \"Group 2\",\n                                   \"Group 3\")))\n\n\n\n# A tibble: 5 × 4\n  Decision Gender Dept  Dept2  \n  <chr>    <chr>  <chr> <chr>  \n1 Reject   Female C     Group 2\n2 Admit    Male   A     Group 1\n3 Reject   Female E     Group 3\n4 Reject   Male   B     Group 1\n5 Reject   Female C     Group 2"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#case_when",
    "href": "slides/slides-11-simpsons.html#case_when",
    "title": "Simpson’s paradox",
    "section": "case_when()",
    "text": "case_when()\nWe will use the case_when() function which generalizes if_else(). We use the following notation: <logical condition> ~ <value of variable>. Different “ifs” are separated by commas, and the logical conditions are checked sequentially.\n\n\n\nadmissions |>\n  mutate(Dept2 = case_when(\n    Dept %in% c(\"A\", \"B\") ~ \"Group 1\",\n    Dept %in% c(\"C\", \"D\") ~ \"Group 2\",\n    Dept %in% c(\"E\", \"F\") ~ \"Group 3\",\n  )) \n\n\n\n# A tibble: 5 × 4\n  Decision Gender Dept  Dept2  \n  <chr>    <chr>  <chr> <chr>  \n1 Reject   Female C     Group 2\n2 Admit    Male   A     Group 1\n3 Reject   Female E     Group 3\n4 Reject   Male   B     Group 1\n5 Reject   Female C     Group 2\n\n\n\n\n# The following is also acceptable, but \n# relies on sequential ordering:\nadmissions |>\n  mutate(Dept2 = case_when(\n    Dept %in% c(\"A\", \"B\") ~ \"Group 1\",\n    Dept %in% c(\"C\", \"D\") ~ \"Group 2\",\n    T ~ \"Group 3\",\n  )) |>\n  sample_frac() \n\n\n\n# A tibble: 5 × 4\n  Decision Gender Dept  Dept2  \n  <chr>    <chr>  <chr> <chr>  \n1 Reject   Female C     Group 2\n2 Admit    Male   A     Group 1\n3 Reject   Female E     Group 3\n4 Reject   Male   B     Group 1\n5 Reject   Female C     Group 2"
  },
  {
    "objectID": "slides/slides-11-simpsons.html#prettier-tables-using-kable",
    "href": "slides/slides-11-simpsons.html#prettier-tables-using-kable",
    "title": "Simpson’s paradox",
    "section": "Prettier tables using kable()",
    "text": "Prettier tables using kable()\n\nWhen we finish wrangling, the output is always a data frame\n\nWhile this is so useful for coding, it’s not the most beautiful when rendering!\nHow can we make turn the data frame into a beautiful table?\n\nWe will need to first install the kableExtra library.\n\n\n\n\n\nlibrary(kableExtra)\n\nadmissions |>\n  count(Decision) |>\n  mutate(prob = n/sum(n)) |>\n  kable()\n\n\n\n\nDecision\nn\nprob\n\n\n\n\nAdmit\n1755\n0.3877596\n\n\nReject\n2771\n0.6122404\n\n\n\n\n\n\n\n\nCan specify number of digits:\n\n\n\nadmissions |>\n  count(Decision) |>\n  mutate(prob = n/sum(n)) |>\n  kable(digits = 3)\n\n\n\n\nDecision\nn\nprob\n\n\n\n\nAdmit\n1755\n0.388\n\n\nReject\n2771\n0.612"
  },
  {
    "objectID": "slides/slides-08-joins.html#removing-nas",
    "href": "slides/slides-08-joins.html#removing-nas",
    "title": "Joining data frames",
    "section": "Removing NAs",
    "text": "Removing NAs\n\nna.omit() will remove all observations with any NA, regardless of where the NA appears\nIf you want a more delicate touch and would like to remove observations with an NA for a given variable, we can use is.na()\n\nThis function takes in a variable as input, and outputs TRUE for each observation with an NA value in that variable, and FALSE otherwise\nUseful with the filter() function!\n\n\n\n\n\n\nfish |>\n  full_join(continents, by = \"country\") |>\n  mutate(prop_capture = capture / (capture + aquaculture)) |>\n  na.omit() |>\n  summarise(avg_prop = mean(prop_capture))\n\n# A tibble: 1 × 1\n  avg_prop\n     <dbl>\n1    0.780\n\n\n\n\nfish |>\n  full_join(continents, by = \"country\") |>\n  mutate(prop_capture = capture / (capture + aquaculture)) |>\n  filter(!is.na(prop_capture)) |>\n  summarise(avg_prop = mean(prop_capture))\n\n# A tibble: 1 × 1\n  avg_prop\n     <dbl>\n1    0.782\n\n\n\n\n\n\nNotice the difference!"
  },
  {
    "objectID": "slides/slides-10-conditional-probability.html",
    "href": "slides/slides-10-conditional-probability.html",
    "title": "Conditional probability",
    "section": "",
    "text": "Two events are disjoint/mutually exclusive if they do not have any overlapping outcomes\nAddition rule: \\(\\text{Pr}(A \\cup B) =\\)\nComplement rule: \\(\\text{Pr}(A^c) =\\)"
  },
  {
    "objectID": "coding_practice/coding-practice-11-group-case.html",
    "href": "coding_practice/coding-practice-11-group-case.html",
    "title": "Coding practice: grouping and case_when",
    "section": "",
    "text": "Change your name in the YAML and load in the packages necessary for wrangling and making beautiful tables.\n\n\n\n\nWe will once again work the the diamonds dataset.\n\nCreate a new data frame called diamonds2 that contains all the data in diamonds with an additional variable called price_ct which is the price of the diamond per carat.\n\nThen create a beautiful table (i.e. not data frame) that shows the average price per carat for each cut of diamond, arranged from highest to lowest.\n\n\n\n\nCreate a table that displays the proportion of diamonds whose price per carat of exceeds 8000 USD for each color of diamond. Your table should only display the color of the diamonds and the proportion that are greater than 8000 USD.\n\n\n\n\n\nTo your diamonds2 data frame, use case_when() to add variable called carat_cat that takes the values:\n\n\n“< 1” if the diamond is less than 1 carat\n“1-3” if the diamond is between 1 and 3 carats, inclusive\n“> 3” if the diamond is more than 3 carats\n\nThen using an appropriate plot type, visualize the distribution of price per carat for each of the categories you created. Make sure your plot has informative axis labels. What do you notice?\n\n\n\nAnswer:"
  },
  {
    "objectID": "homework/hw4_r.html",
    "href": "homework/hw4_r.html",
    "title": "STAT 201: Problem Set 4 (R)",
    "section": "",
    "text": "Today’s data comes from a study of conducted in Whickham, England. In this study, the researchers recorded each participant’s age, smoking status at the start of the study, and their health outcome 20 years later.\nThe data is in the mosaicData package. You may have to install the package first! Then run the following code:\n\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(mosaicData)\n\nWe will work with the Whickham data from the package. You should open its Help file and take a view of the data before proceeding. Note that the type “factor” can be though of as a categorical variable. Make sure you understand the data before proceeding!\n\nBefore looking at the data and using your intuition: What would you expect the relationship between smoking status and health outcome to be?\n\nAnswer:\n\nCreate an standardized bar plot that depicts the relationship between smoking status and health outcome. This about what the explanatory and response variables should be and how that affects your plot. Make sure you have informative labels and titles. Change the background of the plot to something besides the default, and also change the colors of the bars to be something besides the default (e.g. scale_fill_viridis_d() or scale_fill_brewer()).\n\n\n\n\n\nUsing wrangling code, calculate the conditional probabilities of death for each smoking status. Your resulting table should:\n\n\nOnly report only the probabilities for when outcome is Dead\nOnly retain the variables for smoke statu and the conditional probabilities in a meaningful order\nRender as a beautiful table, not a data frame\n\n\n\n\n\nDo your calculations and visualization from Exercises 2 and 3 align with your hypothesis from Exercise 1? Briefly explain why or why not.\n\nAnswer:\n\nUsing case_when(), create a new variable for future use called age_cat that takes the values as follows:\n\n\n“18-44”: if someone is less than or equal to 44 years old\n“45-64”: if someone is between 45 and 64 years old, inclusive\n“65+”: if someone is older than 64\n\nStore the resulting data frame into a new data frame called Whickham2\n\n\n\n\nRe-create your first visualization from Exercise 2, this time bringing in your new age_cat variable in an appropriate way. Make sure you have informative labels and titles, and use the same color choice you as in Exercise 2.\n\n\n\n\n\nElaborate on your table from Exercise 3 above by breaking it down by age category. Your resulting table should:\n\n\nOnly report only the probabilities for when outcome is Dead\nOnly retain the variables for smoke status, the conditional probabilities, and age category in a meaningful order\nPresent the results such that multiple rows with the same age categories appear in consecutive order in the table\nRender as a beautiful table, not a data frame\n\n\n\n\n\nCompare the two visualizations and the two summary tables. What changed, and what might explain the change?\n\nAnswer:\nWhen finished, render one more time and submit the PDF to Gradescope!"
  },
  {
    "objectID": "midterms/midterm1_practice.html",
    "href": "midterms/midterm1_practice.html",
    "title": "STAT 201: Practice Midterm",
    "section": "",
    "text": "TYPE THE HONOR CODE PLEDGE BELOW\nLoad your packages necessary for wrangling code, plotting, and creating beautiful tables:\nThe data containing the records of gun violence incidents are found in gun_violence. The data are obtained from Kaggle, and have been slightly modified. The variable definitions are as follows:\nWe will also be using data about state populations The data are found in the census. These data come from the U.S. Census. The definition of variables in this file are as follows:\nLastly, we have information about the number of gun laws in each state in 2017. These are found in laws, with variables as follows:"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-1",
    "href": "midterms/midterm1_practice.html#question-1",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 1",
    "text": "Question 1\nIn which five cities or counties did the most incidents occur? What are the probabilities that a randomly selected incident in our dataset occurred in each of these cities/counties? Answer this by creating some beautiful tables, and and interpret what you find in a sentence.\n\n\n\nAnswer:"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-2",
    "href": "midterms/midterm1_practice.html#question-2",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 2",
    "text": "Question 2\nWhile there are a variety of definitions of mass shootings, one definition is “any incidents in which four or more people were shot, whether injured or killed”. Based on this definition, create a beautiful table that displays the top six incidents that meet this definition of mass shooting in descending order of number of people shot. Only display the date, state, city or county, and number of people."
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-3",
    "href": "midterms/midterm1_practice.html#question-3",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 3",
    "text": "Question 3\nLet’s examine which days of the year are most common for gun violence. Display a table of the top three days of the year with highest number of total incidents, displayed in descending order. Comment on what you notice.\n\n\n\nAnswer:"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-4",
    "href": "midterms/midterm1_practice.html#question-4",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 4",
    "text": "Question 4\nCreate a data frame called state_incidents where each row is an observation of a state and its total number of incidents in a given year. For the years 2014-2017, which three states had the lowest average number of incidents? Which three states had the highest average number of incidents?\n\n\n\nAnswer:"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-5",
    "href": "midterms/midterm1_practice.html#question-5",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 5",
    "text": "Question 5\nCombine the three datasets into one and save the result into a new dataframe called state_incidents2. After this step, you should have 6 variables in state_incidents2."
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-6",
    "href": "midterms/midterm1_practice.html#question-6",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 6",
    "text": "Question 6\nCreate a new variable called rate that is equal to the number of gun violence incidents per 100000 people in a given year. This is calculated as taking the number of incidents divided by number of residents, multiplied by 100000. Save this into the same data frame state_incidents2. Then answer the following question:\nFor the years 2014-2017, which three states had the lowest average rate of incidents? Which three states had the highest average rate of incidents? Comment on how your findings here compare to your findings from Exercise 4.\n\n\n\nAnswer:"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-7",
    "href": "midterms/midterm1_practice.html#question-7",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 7",
    "text": "Question 7\nCreate groupings for the state populations for easy visualization. Add a new variable called pop_class that groups the states into the following categories. Don’t forget to store your results.\n- \"Extra-small\" = populations less than 1.5 million residents\n- \"Small\" = population of at least 1.5 million, but less than 5 million residents\n- \"Medium\" = population of at least 5 million, but less than 10 million residents\n- \"Large\" = population of least 10 million residents"
  },
  {
    "objectID": "midterms/midterm1_practice.html#question-8",
    "href": "midterms/midterm1_practice.html#question-8",
    "title": "STAT 201: Practice Midterm",
    "section": "Question 8",
    "text": "Question 8\nCreate a visualization that displays the distribution of the rate of gun violence incidents for each year and by the population class. Describe any trends you notice."
  },
  {
    "objectID": "midterms/midterm1_practice1.html",
    "href": "midterms/midterm1_practice1.html",
    "title": "STAT 201: Midterm 1 Practice 1",
    "section": "",
    "text": "In the following code chunk, load your libraries for wrangling, plotting, and making pretty tables. Then run the code chunk:\nWe have data from over 1000 wines in the dataset wine_ratings. Each case in the dataset represents one bottle of wine. The wines included in the dataset are wines that were tasted and reviewed.\nRun the following code to load in the data and take a look at it before continuing!"
  },
  {
    "objectID": "midterms/midterm1_practice1.html#exercise-5",
    "href": "midterms/midterm1_practice1.html#exercise-5",
    "title": "STAT 201: Midterm 1 Practice 1",
    "section": "Exercise 5",
    "text": "Exercise 5\nAmong all wines in the original dataset that have at least 25 reviews and information about prices, determine which type of wine grape seems to be the worst value. In your answer, briefly describe your methods/reasoning and identify the wine variety.\n\n\n\nAnswer:"
  },
  {
    "objectID": "midterms/midterm1_practice2.html",
    "href": "midterms/midterm1_practice2.html",
    "title": "Midterm 1 Practice 2",
    "section": "",
    "text": "In many cities, there is a bike-share system where people can rent bicycles by the hour. People can use the bikes by either registering as members and purchasing a pass at a discounted rate, or by being a casual rider and paying per trip. We have data from Washington D.C.’s bike-share system from June-August 2012. The data are loaded in and stored as bikes. Each case is one rental. The variables are as follows:\n\nmonth: month (6 = June, 7 = July, 8 = August)\nday: day of the month (1-30)\nhour: hour (0, 6-23, where 0 = 12:00am, 6 = 6:00am, …, 23 = 11:00pm)\nday_week: day of the week\ntype: whether the renter was a member or a non-member (“registered” or “casual”)\n\n\nTo the code chunk below, add libraries necessary for data wrangling, plotting, and making pretty tables.\n\n\n\n\n\nModify the bikes data frame to include a variable that represents the time of day where:\n\nRentals from 6:00-8:00am are “early morning”\nRentals from 9:00am-12:00pm are “late morning”\nRentals from 1:00pm-4:00pm are “afternoon”\nRentals from 5:00pm-8:00pm are “early evening”\nRentals at any other time are “evening”\n\n\n\n\n\n\nFor rentals in 2011, do the time of day and the type of renter appear associated? Create an appropriate, well-labeled visualization and interpret it to answer the question.\n\n\n\n\nAnswer:\n\nCreate a beautiful table that displays the proportion of rentals by registered users for each day of the week, displayed in order of highest to lowest. Your table should only retain the day of the week and the proportion of registered users. What do you notice?\n\n\n\n\nAnswer:\n\nCreate a beautiful summary table that displays the mean and standard deviation of daily number of bike rentals in June 2012.\n\n\n\n\n\nRe-create the graph seen on the rendered version."
  },
  {
    "objectID": "midterms/midterm1_practice2_render.html",
    "href": "midterms/midterm1_practice2_render.html",
    "title": "STAT 201: Midterm 1 Practice 2",
    "section": "",
    "text": "A Pell Grant is a need-based federal grant for undergraduate students paying for college. Students are automatically considered for a Pell Grant award when they submit a FAFSA.\nEach case in the dataset pell represents the Pell Grant award to a given school in a given year.\n\nstate: state/territory shortcode\naward: total award amount in USD\nrecipient: total number of recipients\nname: name of college/university\nsession: meeting ID\nyear: year\n\nWe also have a dataset called states that provide information on the states and territories of the US. The variables are:\n\nNAME: name of the state/territory\nAbbreviation: state/territory shortcode\nType: political devision (“state” or “territory”)\n\nRun the following code chunk to load in the two datasets:\n\n\n\n\nExercise 1\nLet’s clean and wrangle the data a bit.\n\nRemove any case where at least one of the following is true:\n\nThe school is missing information about the award amount\nThe school had less than 1 student receiving a Pell Grant\nThe school receive an award of 0 dollars but had more than 0 students recieve a Pell grant\n\nCreate a new variable called award_pp that represents the award amount per person for each school\nCreate a new variable called decade that takes the value:\n\n“1990s” if the award was granted in the 1990s\n“2000s” if the award was granted in the 2000s\n“2010s” if the award was granted in the 2010s\n\n\nStore your cleaned and wrangled data frame back into pell.\n\n\n\n\n\nExercise 2\nMake a visualization the shows the distribution of the award amount per person for each decade. Have informative labels and titles. Interpret what you see.\n\n\n\nAnswer:\n\n\nExercise 3\nNow let’s bring in the information about states vs territories. Combine the two datasets into a single dataset called pell2 that retains all observations about pell grants awards for which we also have information about the type of political division (i.e. state or territory).\n\n\n\n\n\nExercise 4\nFor awards made in 2015, create a beautiful table that displays the mean and standard deviation of the award per person for each of the two political divisions. Then answer the question: did the two political divisions differ in the Pell grant awarded?\n\n\n\nAnswer:\n\n\nExercise 5\nDisplay a beautiful table of the five U.S. states that received the largest statewide average award per person in the 2010s.\n\n\n\n\n\nExercise 6\nRe-create the following plot:"
  },
  {
    "objectID": "slides/slides-12-ethics.html#what-is-ethics-why-discuss",
    "href": "slides/slides-12-ethics.html#what-is-ethics-why-discuss",
    "title": "Data ethics",
    "section": "What is ethics? Why discuss?",
    "text": "What is ethics? Why discuss?\n\nPhilosopher Socrates is quoted as saying that “the most important thing is not life, but the good life”1\n\nQuestions of ethics attempt to answer the question: What is a life worth living?\n\nEthics involves human choice, and goes beyond “intent”\nEthics enters politically, personally, and professionally\n\nProfessional ethics describes the standard of behavior expected of workplace professional (depends on the field)\n\nQuestions of technological and data ethics are emerging due to speed at which these fields are growing\n\nTechnology increasingly affects how and how successfully humans are seeking the “good life”\n\n\nPlato, Crito"
  },
  {
    "objectID": "slides/slides-12-ethics.html#ethical-benefits-of-data-practices",
    "href": "slides/slides-12-ethics.html#ethical-benefits-of-data-practices",
    "title": "Data ethics",
    "section": "Ethical benefits of data practices?",
    "text": "Ethical benefits of data practices?\n\nData does have benefits for society! What are some?\n\n\nIncreasing human understanding of our world\nCan lead to more efficient use of resources\nPredictive accuracy and personalization"
  },
  {
    "objectID": "slides/slides-12-ethics.html#ethically-significant-harms-of-data-practices",
    "href": "slides/slides-12-ethics.html#ethically-significant-harms-of-data-practices",
    "title": "Data ethics",
    "section": "Ethically significant harms of data practices?",
    "text": "Ethically significant harms of data practices?\n\nData does have harms for society! What are some?\n\n\nHarms to privacy and security, lack of consent\nHarms to fairness and justice\n\nAvoidable errors and inaccuracies, biases that arise from falsehood, sampling errors, and discriminatory practices\n\nHarms to transparency and autonomy\n\n“Black box”, “deep learning” algorithms\nProprietary software\n\nMany harms are implicit (which makes them hard to mitigate!)"
  },
  {
    "objectID": "slides/slides-12-ethics.html#ethics-in-technology-and-data",
    "href": "slides/slides-12-ethics.html#ethics-in-technology-and-data",
    "title": "Data ethics",
    "section": "Ethics in technology and data",
    "text": "Ethics in technology and data\n\nTechnologies are not ethically “neutral”–they are built and informed by humans, and so they naturally reflect the values and biases that humans have\n\nHave you heard of the term “big data”? If so, what does it mean to you?\n\n“Big data” is more than just the explosive growth of large datasets!\n\nIt involves the ways/techniques that these large datasets are stored, processed, and analyzed\nHumans enter at these steps!"
  },
  {
    "objectID": "slides/slides-12-ethics.html#what-can-you-do",
    "href": "slides/slides-12-ethics.html#what-can-you-do",
    "title": "Data ethics",
    "section": "What can you do?",
    "text": "What can you do?\n\nWith this class, you should learn to make visualizations and tables that are factual and not intended to deceive your audience\n\nYou can and should tell stories with your visualizations, but you should not purposefully hide or distort important aspects of the data (e.g. outliers, omit confounders, only display results that confirm your hypothesis)\n\nDon’t lie with statistics!\nMake all your work reproducible, and open-source (i.e. public)"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-1-stand-your-ground",
    "href": "slides/slides-12-ethics.html#example-1-stand-your-ground",
    "title": "Data ethics",
    "section": "Example 1: stand your ground",
    "text": "Example 1: stand your ground\n\nIn 2005, the Florida legislature passed a controversial “Stand Your Ground” law\n\nThe law allowed for a broader class of scenarios where the use of deadly force by citizens could be justified\nProponents of the law thought it would reduce crime\nOpponents worried it would increase the amount of lethal force"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-2-covid-19-reporting",
    "href": "slides/slides-12-ethics.html#example-2-covid-19-reporting",
    "title": "Data ethics",
    "section": "Example 2: COVID-19 reporting",
    "text": "Example 2: COVID-19 reporting\nIn May 2020, the state of Georgia published the following graphical display of COVID-19 cases:\n\n\n\n\n\nWhat is the story the figure is trying to tell?\nIs it factually correct?\nIs it deceptive?"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-3-health-care-recommendation",
    "href": "slides/slides-12-ethics.html#example-3-health-care-recommendation",
    "title": "Data ethics",
    "section": "Example 3: health care recommendation",
    "text": "Example 3: health care recommendation\n\nGoal: identify patients for “high-risk care management” programs that seek to improve the care of patients with complex health needs by providing additional resources\n\nSuch programs are considered effective at improving outcomes and satisfaction while reducing costs\nBut these programs are themselves costly -> want to identify patients who have the highest “medical need”\n\nAlgorithm’s designers used previous patients’ health care spending as a proxy for medical need\nAssigned patients a “risk score”, where higher risk meant more complex needs and therefore priority\n\nPatients with highest risk scores automatically qualified for program\nPatients with lower (but still high) risk scores were interviewed for potential candidacy"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-3-health-care-cont.",
    "href": "slides/slides-12-ethics.html#example-3-health-care-cont.",
    "title": "Data ethics",
    "section": "Example 3: health care (cont.)",
    "text": "Example 3: health care (cont.)\n\n\n\nInterpret the plot1.\nWhat do you notice happened?\n\n\n\n\n\n\n\n\n\nObermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S. (2019)."
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-3-health-care-cont.-1",
    "href": "slides/slides-12-ethics.html#example-3-health-care-cont.-1",
    "title": "Data ethics",
    "section": "Example 3: health care (cont.)",
    "text": "Example 3: health care (cont.)\n\nDiscuss what’s going on in these two new plots. Then use them to explain the results of the algorithm.\n\n\n\n\n\n\n\n\n\nEven though black patients tend to have more severe medical conditions, algorithm is built to predict health care costs rather than illness"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-4-propublica-analysis4",
    "href": "slides/slides-12-ethics.html#example-4-propublica-analysis4",
    "title": "Data ethics",
    "section": "Example 4: ProPublica analysis1",
    "text": "Example 4: ProPublica analysis1\nFamous case study of algorithmic bias!\n\nFor more than 7,000 people arrested in Broward County, Florida in 2013 and 2014, “risk scores” were assigned via an algorithm that were used to predict the likelihood of the person committing a future crime\n\nIntention of algorithm’s designers: higher risk scores should accurately predict if someone will be charged with a future crime\n\nTo determine accuracy of the risk scores, these people were tracked over the next two years to see if they were charged with new crimes\n\nhttps://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-4-propublica-cont.",
    "href": "slides/slides-12-ethics.html#example-4-propublica-cont.",
    "title": "Data ethics",
    "section": "Example 4: ProPublica (cont.)",
    "text": "Example 4: ProPublica (cont.)\nDistribution of risk scores:\n\n\n\n\n\n\n\n\nLets’s now see how the algorithms performed"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-4-propublica-cont.-1",
    "href": "slides/slides-12-ethics.html#example-4-propublica-cont.-1",
    "title": "Data ethics",
    "section": "Example 4: ProPublica (cont.)",
    "text": "Example 4: ProPublica (cont.)\n\nOnly 20% of those predicted to commit violent crimes actually did\nAlgorithm had higher accuracy (61%) when full range of crimes taken into account (e.g. misdemeanors)\n\n\n\n\n\nBlack defendants were more likely to be falsely flagged as “higher”/future criminals, and at almost twice the rate as White defendants\nWhite defendants mislabeled as “low risk” more often than black defendants\n\nAre risk scores inherently bad?"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-5-race-prediction",
    "href": "slides/slides-12-ethics.html#example-5-race-prediction",
    "title": "Data ethics",
    "section": "Example 5: race prediction",
    "text": "Example 5: race prediction\nImai and Khanna (2016) built a racial prediction algorithm using a Bayes classifier trained on voter registration records from Florida and the U.S. Census Bureau’s name list.\n\nTheir algorithm takes in a list of last names (and optionally their home address) and returns predicted probabilities for a person’s race.\nIn addition to the publishing the paper detailing the methodology, the authors published the software for the classifier on GitHub under an open-source license."
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-5-race-prediction-cont.",
    "href": "slides/slides-12-ethics.html#example-5-race-prediction-cont.",
    "title": "Data ethics",
    "section": "Example 5: race prediction (cont.)",
    "text": "Example 5: race prediction (cont.)\n\nlibrary(tidyverse)\nlibrary(wru) # uses 2020 census data by default\nnames <- data.frame(surname =  c(\"Tang\", \"Lyford\", \"Peterson\", \"Flores\", \"Malcolm\"))\npredict_race(voter.file = names, surname.only = TRUE) %>% \n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth) |>\n  kable(digits = 3)\n\n\n\n\nsurname\npred.whi\npred.bla\npred.his\npred.asi\npred.oth\n\n\n\n\nTang\n0.018\n0.004\n0.011\n0.932\n0.035\n\n\nLyford\n0.927\n0.001\n0.025\n0.013\n0.034\n\n\nPeterson\n0.803\n0.103\n0.029\n0.009\n0.056\n\n\nFlores\n0.039\n0.004\n0.919\n0.025\n0.013\n\n\nMalcolm\n0.613\n0.302\n0.026\n0.006\n0.054\n\n\n\n\n\n\n\nWhat might this algorithm be useful for? What are some questions you have about it? Is it ethical to use this software? Does your answer change depending on the intended use? Does it matter that the software is open-source?"
  },
  {
    "objectID": "slides/slides-12-ethics.html#ethical-benefits-and-harms-of-data",
    "href": "slides/slides-12-ethics.html#ethical-benefits-and-harms-of-data",
    "title": "Data ethics",
    "section": "Ethical benefits and harms of data?",
    "text": "Ethical benefits and harms of data?\n\n\n\nData does have benefits for society! What are some?\n\n\nIncreasing human understanding of our world\nCan lead to more efficient use of resources\nPredictive accuracy and personalization\n\n\n\nData does have harms for society! What are some?\n\n\nHarms to privacy and security, lack of consent\nHarms to fairness and justice\n\nBiases arise from falsehood, sampling errors, and discriminatory practices\n\nHarms to transparency and autonomy\n\n“Black box”/“deep learning” algorithms, proprietary software\n\nMany harms are implicit (which makes them hard to mitigate!)"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-1-stand-your-ground-cont.",
    "href": "slides/slides-12-ethics.html#example-1-stand-your-ground-cont.",
    "title": "Data ethics",
    "section": "Example 1: stand your ground (cont.)",
    "text": "Example 1: stand your ground (cont.)\nNine years later, in 2014, Reuters published a graphic similar to the one below1:\n\n\n\n\n\nWhat is the story the figure is trying to tell?\nIs it factually correct?\nIs it deceptive?\n\n\n\nhttps://mdsr-book.github.io/mdsr2e/ch-ethics.html#ethics-intro"
  },
  {
    "objectID": "slides/slides-12-ethics.html#data-viz-worst-practices",
    "href": "slides/slides-12-ethics.html#data-viz-worst-practices",
    "title": "Data ethics",
    "section": "Data viz worst practices",
    "text": "Data viz worst practices\nDon’t do the following:\n\nUse misleading scales\nCherry-pick the data/only visualize specific data points\nHave ambiguous legends/labels\nUse colors that convey a bias\nFail to explain your methods"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-4-compas-and-propublica-analysis4",
    "href": "slides/slides-12-ethics.html#example-4-compas-and-propublica-analysis4",
    "title": "Data ethics",
    "section": "Example 4: COMPAS and ProPublica analysis1",
    "text": "Example 4: COMPAS and ProPublica analysis1\nFamous case study of algorithmic bias!\n\nFor more than 7,000 people arrested in Broward County, Florida in 2013 and 2014, “risk scores” were assigned via an algorithm that were used to predict the likelihood of the person committing a future crime\n\nIntention of algorithm’s designers: higher risk scores should accurately predict if someone will be charged with a future crime\n\nTo determine accuracy of the risk scores, these people were tracked over the next two years to see if they were charged with new crimes\n\nWho might want such risk scores? How might they be used?\n\n\nhttps://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-5-facial-criminal-prediction",
    "href": "slides/slides-12-ethics.html#example-5-facial-criminal-prediction",
    "title": "Data ethics",
    "section": "Example 5: facial criminal prediction",
    "text": "Example 5: facial criminal prediction\nActivity borrowed from Prof. Chodrow in CS department.\n\nIn 2016, researchers Xiaolin Wu and Xi Zhang published a paper detailing an algorithm that predicted whether an individual is likely to commit a crime in the future, based only on a picture of their face\n\nAccording to the paper, their algorithm was “very accurate” (details beyond this course)\n\n\nRead Section 2 of the paper and answer the following questions:\n\nHow were the data obtained?\nWhat would be the “explanatory” and “response variables”? Are the values of the response variables directly observed, or inferred?"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-5-facial-criminal-prediction-cont.",
    "href": "slides/slides-12-ethics.html#example-5-facial-criminal-prediction-cont.",
    "title": "Data ethics",
    "section": "Example 5: facial criminal prediction (cont.)",
    "text": "Example 5: facial criminal prediction (cont.)\n\n\nNow look to Figure 1 from the paper. What do you notice? What questions might you have?\n\nThe authors’ algorithm identified certain features of the face that were highly predictive of criminality, including\n\nthe curvature of upper lip\nthe distance between two eye inner corners\nthe angle enclosed by rays from the nose tip to the two corners of the mouth\n\n\nOne possible explanation is that these features are expressions of genetic markers that are also associated with criminality. Can you suggest another possible explanation?"
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-6-race-prediction",
    "href": "slides/slides-12-ethics.html#example-6-race-prediction",
    "title": "Data ethics",
    "section": "Example 6: race prediction",
    "text": "Example 6: race prediction\nImai and Khanna (2016) built a racial prediction algorithm using a Bayes classifier trained on voter registration records from Florida and the U.S. Census Bureau’s name list.\n\nTheir algorithm takes in a list of last names (and optionally their home address) and returns predicted probabilities for a person’s race.\nIn addition to the publishing the paper detailing the methodology, the authors published the software for the classifier on GitHub under an open-source license."
  },
  {
    "objectID": "slides/slides-12-ethics.html#example-6-race-prediction-cont.",
    "href": "slides/slides-12-ethics.html#example-6-race-prediction-cont.",
    "title": "Data ethics",
    "section": "Example 6: race prediction (cont.)",
    "text": "Example 6: race prediction (cont.)\n\nlibrary(tidyverse)\nlibrary(wru) # uses 2020 census data by default\nnames <- data.frame(surname =  c(\"Tang\", \"Lyford\", \"Peterson\", \"Flores\", \"Malcolm\"))\npredict_race(voter.file = names, surname.only = TRUE) %>% \n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth) |>\n  kable(digits = 3)\n\n\n\n\nsurname\npred.whi\npred.bla\npred.his\npred.asi\npred.oth\n\n\n\n\nTang\n0.018\n0.004\n0.011\n0.932\n0.035\n\n\nLyford\n0.927\n0.001\n0.025\n0.013\n0.034\n\n\nPeterson\n0.803\n0.103\n0.029\n0.009\n0.056\n\n\nFlores\n0.039\n0.004\n0.919\n0.025\n0.013\n\n\nMalcolm\n0.613\n0.302\n0.026\n0.006\n0.054\n\n\n\n\n\n\n\nWhat might this algorithm be useful for? What are some questions you have about it? Is it ethical to use this software? Does your answer change depending on the intended use? Does it matter that the software is open-source?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#activity",
    "href": "slides/slides-13-samp-dist.html#activity",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Activity",
    "text": "Activity\nWhile you’re coming into the room, please take 1 card. Then:\n\nOn the unlined side, write down “yes” if you drink coffee regularly, and “no” otherwise\nOn the lined side, write down the average number of hours of sleep you get per night\nThen bring these to Prof. Tang"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#where-we-are-going",
    "href": "slides/slides-13-samp-dist.html#where-we-are-going",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Where we are going",
    "text": "Where we are going\nWe are shifting focus from EDA and beginning to enter the world of statistical inference and modeling!\n\nWant to answer questions about a population, but must rely on a sample\nCollect data from sample –> calculate statistics\nWhat can we say about the statistics?\nData are random! So how sure are we about our conclusions?\n\n\nStatistics starts here!"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#inference",
    "href": "slides/slides-13-samp-dist.html#inference",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Inference",
    "text": "Inference\nStatistical inference is the process of using sample data to make conclusions about the underlying population the sample came from\n\nEstimation: using the sample to estimate a plausible values for the unknown parameter\nTesting: evaluating whether our observed sample provides evidence for or against some claim about the population"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#research-questions-involving-estimation",
    "href": "slides/slides-13-samp-dist.html#research-questions-involving-estimation",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Research questions involving estimation",
    "text": "Research questions involving estimation\n\nExamples:\n\nWhat proportion of Middlebury students drink coffee regularly?\nWhat is the average number of hours of sleep Middlebury students get a night?\n\nQuestions here are about a population parameter\n\nIf we have a census, we can answer the question immediately.\nIf we only have a sample, we have to do our best to answer the question using our data \\(x_{1}, x_{2},\\ldots, x_{n}\\)"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#activity-1",
    "href": "slides/slides-13-samp-dist.html#activity-1",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Activity",
    "text": "Activity\n\n\nWhat proportion of Middlebury STAT 201A students drink coffee regularly?\n\nTarget population:\nSampling method:\nPopulation parameter:\nAre we able to compute the value of the parameter, or do we need to calculate a statistic?\n\n\nWhat proportion of Middlebury students drink coffee regularly?\n\nTarget population:\nSampling method:\nPopulation parameter:\nAre we able to compute the value of the parameter, or do we need to calculate a statistic?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#point-estimate",
    "href": "slides/slides-13-samp-dist.html#point-estimate",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Point estimate",
    "text": "Point estimate\n\nSample proportion \\(\\hat{p}\\) is a very sensible estimate for true proportion \\(p\\)\n\\(\\hat{p}\\) is an example of a point estimate: a single number used to estimate a true but unknown population parameter\n\ni.e. a point estimate is a statistic with a specific purpose\nOther examples include sample mean \\(\\bar{x}\\) for true mean \\(\\mu\\), and \\(s\\) for \\(\\sigma\\)\n\n\nWhat might be a desirable characteristic of a “good” point estimate?\n\n\nDo we expect that the sample statistic will equal the population parameter? (e.g. how likely is it that \\(\\bar{x} = \\mu\\) or \\(\\hat{p} = p\\) exactly?) Why or why not?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#variability-of-statistic",
    "href": "slides/slides-13-samp-dist.html#variability-of-statistic",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Variability of statistic",
    "text": "Variability of statistic\n\nTwo datasets collected under identical sampling procedures will almost always differ due to variability in the sample.\n\nAs a result, values of the point estimate/sample statistic that we calculate from the different samples will also exhibit variability\n\nThus, there exists the notion of a sampling distribution of the statistic: how the statistic behaves under repeated random samples obtained via the same sampling procedure\n\nThe variability associated with the sampling distribution of the statistic is called the standard error\n\nNote: “error” \\(\\neq\\) bad\n\nThis is in contrast to the standard deviation, which describes variability in the individual data points and not the statistic"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#different-distributions",
    "href": "slides/slides-13-samp-dist.html#different-distributions",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Different distributions",
    "text": "Different distributions\n\nPopulation distribution: distribution of the variable of interest for everyone in the population\n\nHas associated variability \\(\\sigma\\)\n\nSample distribution: distribution of the data from a single sample\n\nHas associated variability \\(s\\)\n\nSampling distribution: distribution of sample statistics calculated from the data obtained from multiple samples\n\nHas associated variability standard error \\((SE)\\)"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#recall-candy-activity",
    "href": "slides/slides-13-samp-dist.html#recall-candy-activity",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Recall candy activity",
    "text": "Recall candy activity\nAt the beginning of the semester, I passed around a bag of candy and everyone took out 5 pieces at random, and measured the average weight.\n\n\nWhat was the parameter of interest? What sample statistic did you calculate?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histogram visualizes your sample mean weights.\nDoes this histogram visualize the population distribution, the sample distribution, or the sampling distribution of a statistic?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#candy-activity-cont.",
    "href": "slides/slides-13-samp-dist.html#candy-activity-cont.",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Candy activity (cont.)",
    "text": "Candy activity (cont.)\n\n\nEach one of the values in the histogram is a sample mean \\(\\bar{x}\\) (i.e. a sample statistic)\nThus, the histogram visualizes the sampling distribution of the sample mean\n\nThe mean of these sample means is 7.49 grams, with \\(SE=\\) 1.34"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#how-to-answer-the-research-question",
    "href": "slides/slides-13-samp-dist.html#how-to-answer-the-research-question",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "How to answer the research question?",
    "text": "How to answer the research question?\nRemember, our questions of interest are about a population. The following options list ways to answer the question. For each, what are the pros/cons?\n\n\nUsing the population\nUsing a single sample (i.e. the sample distribution)\nUsing several samples (i.e. the sampling distribution)\n\n\n\nThus, for answering estimation questions, we should aim to access a sampling distribution (we did this with the candy activity!)"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#how-to-obtain-a-sampling-distribution",
    "href": "slides/slides-13-samp-dist.html#how-to-obtain-a-sampling-distribution",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "How to obtain a sampling distribution?",
    "text": "How to obtain a sampling distribution?\n\nSometimes, we assume that the population/data have a very specific behavior, and this allows us to exactly define the sampling distribution\n\nWill see this in a couple of weeks\n\nIf we don’t want to make assumptions, then we rely on sampling\n\nCan we obtain multiple samples cheaply and quickly?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#procedure",
    "href": "slides/slides-13-samp-dist.html#procedure",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Procedure",
    "text": "Procedure\n\nAssume we have a single sample \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\ldots, x_{n})\\) from the population. Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\boldsymbol{x}\\). Call this set of \\(b\\)-th re-sampled data \\(\\boldsymbol{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\boldsymbol{x}^{*}_{b}\\)\n\n\n\n\nAt the end of this procedure, we will have a bootstrap distribution of resample or bootstrap statistics.\n\nThis bootstrap distribution approximates the sampling distribution!\n\n\n\n\n\nIn the candy activity, I claim that we did not perform bootstrapping. Why not?"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#demonstration",
    "href": "slides/slides-13-samp-dist.html#demonstration",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Demonstration",
    "text": "Demonstration\n\nActivity cont.\nLive code demonstration"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#why-resample-with-replacement",
    "href": "slides/slides-13-samp-dist.html#why-resample-with-replacement",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Why resample with replacement?",
    "text": "Why resample with replacement?\n\nWe want to understand the sampling error of the sampling distribution!\n\nWhat would the bootstrap samples \\(\\boldsymbol{x}^*_b\\) look like if we sampled without replacement?\n\n\nSampling without replacement -> zero variation in the resampled statistics\n\nResampling with replacement will give us “new” datasets that are similar to original sample distribution but not exactly the same!\n\nIdeally, the variation in the bootstrapped statistics is similar to the true standard error of the sample statistics"
  },
  {
    "objectID": "slides/slides-13-samp-dist.html#remarks",
    "href": "slides/slides-13-samp-dist.html#remarks",
    "title": "Sampling distribution and Introduction to Bootstrap",
    "section": "Remarks",
    "text": "Remarks\n\n\nRelies on having a representative original sample!\n\n\nResampling from initial sample should be roughly equivalent to sampling directly from the population\n\nRequires computational tools!\n\nWe need \\(B\\) to be large enough to accurately capture variability. \\(B=5000\\) or \\(B=10000\\) sufficient in this class\nMore complex problems will require larger \\(B\\)\n\nBootstrapping can fail!\nBootstrapping is not a solution to small sample sizes!!"
  },
  {
    "objectID": "datafest.html",
    "href": "datafest.html",
    "title": "DataFest",
    "section": "",
    "text": ".qmd TEMPLATE HERE!!!!\ndatafest"
  },
  {
    "objectID": "datafest.html#brief-description",
    "href": "datafest.html#brief-description",
    "title": "DataFest",
    "section": "Brief description",
    "text": "Brief description\nOver the weekend of April 4-6, you will work with a completely new-to-you dataset to answer some research question(s) of interest! More details on the Middlebury DataFest website!\nIn small groups, you will work to answer the research question(s) of interest using methods we’ve thus far learned in the class.\nBecause of the extra time-commitment of DataFest, the problem set associated with Week 7 will be light or maybe combined into a problem set with Week 8!"
  },
  {
    "objectID": "datafest.html#requirements",
    "href": "datafest.html#requirements",
    "title": "DataFest",
    "section": "Requirements",
    "text": "Requirements\n\nGroup creation\nYou will work in groups of 2-3 people.\nBy the due date listed in the table above, you should either:\n\nform a group of three on your own and then e-mail Prof. Tang your decision, cc-ing everyone in the group\nform a group of two and then e-mail Prof. Tang your decision, cc-ing the other person in the group.\n\nYour group of two may be randomly paired with another person\n\ne-mail Prof. Tang if you don’t have a preference and/or want to meet new people and would like to be randomly placed in a group\n\nWhile not binding, you should view the people you work with on DataFest as people who you might like to work on the final project with.\nOnce all groups have been formed, Prof. Tang will confirm them and we will register for DataFest as a class on Monday 3/31.\n\n\nDataFest participation\n\nYou must attend the DataFest opening ceremony on Friday 4/4 at 6:00pm in the Q-Center. At the ceremony you will learn about the data and the research questions\nIn addition to the opening ceremony, it is my expectation that your group works for at least 3 hours on the project over the course of the weekend.\n\nYour whole group need not work together at the same time, but I highly encourage it all the same!\nYour are certainly welcome to work more than 3 hours!\n\nThere will be plenty of mentors on-site to help you will bugs. Prof. Tang will specifically be there at times TBD.\nYou will be asked to sign-up to present your finalized product to a panel of judges on Sunday 4/6 somewhere between 11am-1pm. Your entire group should attend the presentations (more details below).\n\n\n\nReport\nYou will be asked to create and submit a well-written report (in the form a rendered .qmd) that answers some or all of the research question(s) using a mix of both of the following methods:\n\nCompelling visualizations and summary tables, and\nSimulation-based inference techniques\n\nYour report should include:\n\nA brief introduction that includes the research question(s) you plan on answering.\nFor each research question of interest:\n\nDetails of cleaning/wrangling of the data you performed to answer the question\nA description of the methods you used to answer the question\nThe actual result+interpretation in context (e.g. a visualization, confidence interval, conduct hypothesis test)\n\nA brief conclusion about what you might do differently or things that were particularly challenging\nA brief description of each person’s contribution.\n\nYou report should be submitted to Canvas. One per group!"
  },
  {
    "objectID": "datafest.html#grading",
    "href": "datafest.html#grading",
    "title": "DataFest",
    "section": "Grading",
    "text": "Grading\nThis is meant to be a fun and low-stakes assignment that assess your ability to clearly convey a statistical analysis. The report will be graded as follows:\n\n\n\n\n\n\n\n\nWhat\nDetails\nPoints\n\n\n\n\nIntroduction\nIncludes a brief paragraph introducing any and all data used in the analysis. Also clearly states the research question(s) you plan on answering.\n1.5\n\n\nData cleaning + wrangling description\nClearly explains how the data were manipulated for the analyses that are subsequently performed, and why you manipulated the data in such a way. This should be at a level of detail where someone could reproduce your cleaning without seeing your actual code.\n3\n\n\nMethodology\nDescribes methods used to answer the research question(s) and gives adequate justification for why the method is appropriate.\n3\n\n\nVisualization/table + Interpretation\nCompelling and rich. Do not settle for a simple univariate visualization or a frequency table.\nInterprets the visualization with enough detail that someone who is unfamiliar with the data can understand it.\n3\n\n\nInference technique + interpretation\nCorrectly applies the inference techniques that were described in the methods.\n\nInterprets the results in the context of the research question.\n4\n\n\nConclusion\nIncludes a brief concluding paragraph about what could be done differently.\n1.5\n\n\nWriting style\nClear writing with very few grammatical errors.\n2\n\n\nReproducibility\nCode is as reproducible as possible. This includes setting seeds and not “hard-coding” values.\n2\n\n\nTotal\n\n20\n\n\n\nThese 20 points will be divided by 4 and then incorporated into the your individual final project score. The final project will be out of 125 points. So a 0 on the DataFest project means you could obtain at most 120/125 \\(\\approx 96\\%\\) on the final project. Once again, I emphasize that this project is low stakes but good practice for the final project!\n\nExtra credit opportunity\nYour project need not only use the methods/functions we’ve learned in this class. Depending on the question/data you work with, you may need or want to teach yourself something new. Groups that successfully teach themselves and/or implement at least one of the following will be eligible for some extra credit points that will count towards Midterm 1. The list is not exhaustive:\n\nWrangling dates and times using lubridate\nWrangling text data using tidytext\nVisualizing maps/spatial data using geom_sf\nCreate ggplot()s that use at least two different data frames and geom_xx() functions\nCreate an innovative, multivariate visualization that we have not seen as a class\n\nWhile there will be mentors at DataFest who can help you, you should take the responsibility of using the internet to learn about some of these methods. Prof. Tang reserves that right to ask clarification questions about any and all code that is in your report."
  },
  {
    "objectID": "datafest.html#key-dates",
    "href": "datafest.html#key-dates",
    "title": "DataFest",
    "section": "Key dates",
    "text": "Key dates\n\n\n\nDeliverable\nWhat/where\nDate\n\n\n\n\nGroup formation\nEmail Prof. Tang (one per group)\nThursday 3/27 at 11:59pm\n\n\nRegister for DataFest\nDataFest website, “Register” tab (each person must do so)\nMonday 3/31 in class\n\n\nDataFest opening ceremony\nQ-Center (MBH 202)\nFriday 4/4 at 6:00pm\n\n\nWork on DataFest project\nQ-Center (MBH 202)\nAnytime from opening ceremony-Sunday 4/6 11:00am\n\n\nSubmit deliverable\nRendered .qmd report submitted to Canvas (one per group!)\nSunday 4/6 11:00am\n\n\nProject presentations (optional)\nQ-Center (MBH 202)\nSunday 4/6 11:00am-12:00pm or 12:00pm-1:00pm"
  },
  {
    "objectID": "live_code/bootstrap_dist_live.html",
    "href": "live_code/bootstrap_dist_live.html",
    "title": "Bootstrap distribution",
    "section": "",
    "text": "library(tidyverse)\nx <- c(\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\")\nn <- length(x)\nB <- 1000\nboot_props <- rep(NA, B)\nfor(b in 1:B){\n  x_b <- sample(x, size = n, replace = TRUE)\n  boot_props[b] <- sum(x_b == \"yes\")/n\n}\n\ndata.frame(props = boot_props) |>\n  ggplot(aes(x = props)) +\n  geom_histogram(bins = 10)"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#housekeeping",
    "href": "slides/slides-14-bootstrap_ci.html#housekeeping",
    "title": "Bootstrap Confidence Intervals",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nDataFest groups!"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#recap",
    "href": "slides/slides-14-bootstrap_ci.html#recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Recap",
    "text": "Recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nRecall research question from last class: what proportion of STAT 201A students drink coffee regularly?\nSince I actually can take a census, I do have access to true sampling distribution of the sample proportion\n\nI will repeatedly take SRS (i.e. without replacement) of \\(n=10\\) values from the population (call this \\(\\vec{x}\\)) and calculate \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#bootstrap-recap",
    "href": "slides/slides-14-bootstrap_ci.html#bootstrap-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap recap",
    "text": "Bootstrap recap\nIf instead I could not repeatedly sample from population, we could obtain bootstrap distribution as an approximation of the sampling distribution of the statistic!\nProcedure:\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\boldsymbol{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\boldsymbol{x}\\). Call this set of resampled data \\(\\boldsymbol{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\boldsymbol{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "href": "slides/slides-14-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution from activity",
    "text": "Bootstrap distribution from activity\n\n\n\nIn our original sample of \\(n = 10\\), we had \\(\\hat{p} = 0.2\\). We have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that our bootstrap distribution isn’t a great approximation (maybe \\(n = 10\\) did not yield a representative sample)"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#comparison",
    "href": "slides/slides-14-bootstrap_ci.html#comparison",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparison",
    "text": "Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur bootstrap distribution isn’t a great approximation (maybe \\(n = 10\\) did not yield a representative sample)\nWhat do we do with the bootstrap distribution?"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#answering-estimation-question",
    "href": "slides/slides-14-bootstrap_ci.html#answering-estimation-question",
    "title": "Bootstrap Confidence Intervals",
    "section": "Answering estimation question",
    "text": "Answering estimation question\n\nGreat…but what do we do with the bootstrap distribution?\nRecall our research question: What proportion of STAT 201A drink coffee regularly?\n\nCould respond using our single point estimate: \\(\\hat{p} = 0.35\\)\nBut due to variability, we recognize that the point estimate will rarely (if ever) equal population parameter\n\nRather than report a single number, why not report a range of values?\n\n\nThis is possible only if we have a sampling distribution to work with!!"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#confidence-intervals",
    "href": "slides/slides-14-bootstrap_ci.html#confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nAnalogy: would you rather go fishing with a single pole or a large net?\n\nA range of values gives us a better chance at capturing the true value\n\nA confidence interval provides such a range of plausible values for the parameter (more rigorous definition coming soon)\n\n“Interval”: specify a lower bound and an upper bound\nConfidence intervals are not unique! Depending on the method you use, you might get different intervals"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#bootstrap-percentile-interval",
    "href": "slides/slides-14-bootstrap_ci.html#bootstrap-percentile-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap percentile interval",
    "text": "Bootstrap percentile interval\n\nThe \\(\\gamma \\times 100\\)% bootstrap percentile interval is obtained by finding the bounds of the middle \\(\\gamma \\times 100\\)% of the bootstrap distribution\nCalled “percentile interval” because the bounds are the \\((1-\\gamma)/2\\times100\\) and \\((1+\\gamma)/2\\times 100\\) percentiles of the bootstrap distribution\n\n\n\nIf \\(\\gamma = 0.90\\), then the bounds would be at which percentiles?\n\n\n\nFor our purposes, “bootstrap confidence interval” will be equivalent to “bootstrap percentile interval”\nquantile() function in R gives us easy way to obtain percentiles: quantile(x, p) gives us \\(p\\)-th percentile of x"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "href": "slides/slides-14-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Obtaining bootstrap confidence interval",
    "text": "Obtaining bootstrap confidence interval\n\n\nOur 90% confidence interval for \\(p\\): (0, 0.4)"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#interpreting-a-confidence-interval",
    "href": "slides/slides-14-bootstrap_ci.html#interpreting-a-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval",
    "text": "Interpreting a confidence interval\n\nOur 90% bootstrap CI for \\(p\\): (0, 0.4). Does this mean there is a 90% chance/probability that the true proportion lies in the interval?\n\n\nAnswer: NO\n\n\nRemember: bootstrap distribution is based on our original sample\n\nIf we started with a different original sample \\(\\boldsymbol{x}\\), then our estimated 90% confidence interval would also be different\n\n\nWhat a confidence interval (CI) represents: if we take many independent repeated samples from this population using the same method and calculate a \\(\\gamma \\times 100\\) % CI for the parameter in the exact same way, then in theory, \\(\\gamma \\times 100\\) % of these intervals should capture/contain the parameter\n\n\n\\(\\gamma\\) represents the long-run proportion of CIs that theoretically contain the true parameter\nHowever, we never know if any particular interval(s) actually do!"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "href": "slides/slides-14-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval (cont.)",
    "text": "Interpreting a confidence interval (cont.)\n\nCorrect interpretation (generic) of our interval \\((a,b)\\): We are \\(\\gamma \\times 100\\) % confident that the population parameter is between \\(a\\) and \\(b\\).\n\n\nInterpret our bootstrap CI in context\n\n\nAgain: why is this interpretation incorrect? “There is a 90% chance/probability that the true parameter value lies in the interval.”"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#remarks",
    "href": "slides/slides-14-bootstrap_ci.html#remarks",
    "title": "Bootstrap Confidence Intervals",
    "section": "Remarks",
    "text": "Remarks\n\n\nWhat is a virtue of a “good” confidence interval?\n\n\nHow do you expect the interval to change as the original sample size \\(n\\) changes?\nHow do you expect the interval to change as level of confidence \\(\\gamma\\) changes?\n\nOnce again, a good interval relies on a representative original sample!"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#comparing-confidence-intervals",
    "href": "slides/slides-14-bootstrap_ci.html#comparing-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nComparing changes in 90% bootstrap CI for sample sizes \\(n = 5, 10, \\text{ and } 17\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0, 0.8)\n\n\nn = 10\n(0, 0.4)\n\n\nn = 17\n(0.18, 0.53)\n\n\n\n\n\n\nWhat do you notice about the bootstrap distributions and CIs as \\(n\\) increases?"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#live-code-your-turn",
    "href": "slides/slides-14-bootstrap_ci.html#live-code-your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Live code + your turn!",
    "text": "Live code + your turn!\n\nLive code:\n\ncoding your own for loop\nin-line code\nsetting a seed\n\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#visualizing-bootstrap-confidence-interval",
    "href": "slides/slides-14-bootstrap_ci.html#visualizing-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Visualizing bootstrap confidence interval",
    "text": "Visualizing bootstrap confidence interval\n\n\nOur 90% bootstrap CI for \\(p\\): (0, 0.4)"
  },
  {
    "objectID": "slides/slides-14-bootstrap_ci.html#samplint-distribution-recap",
    "href": "slides/slides-14-bootstrap_ci.html#samplint-distribution-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Samplint distribution recap",
    "text": "Samplint distribution recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nRecall research question from last class: what proportion of STAT 201A students drink coffee regularly?\n\n\n\n\nSince I took a census, I actually do have access to true sampling distribution of the sample proportion!\nI will repeatedly take SRS (i.e. without replacement) of \\(n=10\\) values from the population and calculate \\(\\hat{p}\\)"
  },
  {
    "objectID": "coding_practice/coding-practice-14-bootstrap.html",
    "href": "coding_practice/coding-practice-14-bootstrap.html",
    "title": "Bootstrap confidence intervals",
    "section": "",
    "text": "We will work with the average hours of sleep our class reported. Run the following code chunk to load the data:\n\nlibrary(tidyverse)\nlibrary(readr)\nsleep <- read_csv(\"https://raw.githubusercontent.com/midd-stat201-spring2025/midd-stat201-spring2025.github.io/refs/heads/main/data/coffee_sleep.csv\")\n\nWe will intialize a pseudo-random-number-generator using the set.seed() function. You can choose any whole number to input as the parameter to this function. For example, I used the seed of 201. If I have the exact same seed and code as you, then we will produce the same random results.\n\nset.seed(201)\n\n\nWe will first take an original sample of size 10.\nCreate a variable that represents and stores the target sample size. Then, take a random sample of size 10 of average sleep hours from our population. Store your sample into a variable called x.\n\n\n# create a variable for sample size\n\n# obtain and store our sample\n\n\nThen, we will take 5000 bootstrap iterations. Store this value as a variable B for reproducibility.\nThen obtain a bootstrap distribution of the sample means using your original sample. Remember to store the bootstrap statistics somewhere! Please use a meaningful variable name. It may be useful to look at and modify the live code from previous class (on website). Your code shouldn’t print out/show us any output.\n\n\n# store number of bootstrap iterations\n\n\nUse the quantile() function to obtain the bounds for a 80%, 90%, and 99% bootstrap confidence interval, respectively. Store these bounds as variables with different (but meaningful) variable names (you should have 6 variables total).\n\nYour code shouldn’t print out/show us any output.\n\n# 80%\n\n# 90%\n\n# 99%\n\n\nIn the space provided below, report the three confidence intervals in the format of (lower, upper) using in-line code.\n\nIn-line code allows us to be reproducible. Remember, the format is: r where after the space within the back-ticks you type the appropriate R code.\n80% CI:\n90%: CI:\n99% CI:\n\nHow do the confidence interval widths change as the level of confidence increases?\n\nAnswer:\n\nInterpret one of your confidence intervals in context. Use in-line code in your answer.\n\nAnswer:"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html",
    "href": "slides/slides-14-bootstrap-ci.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "DataFest groups!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#samplint-distribution-recap",
    "href": "slides/slides-14-bootstrap-ci.html#samplint-distribution-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Samplint distribution recap",
    "text": "Samplint distribution recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nRecall research question from last class: what proportion of STAT 201A students drink coffee regularly?\n\n\n\n\nSince I took a census, I actually do have access to true sampling distribution of the sample proportion!\nI will repeatedly take SRS (i.e. without replacement) of \\(n=10\\) values from the population and calculate \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#bootstrap-recap",
    "href": "slides/slides-14-bootstrap-ci.html#bootstrap-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap recap",
    "text": "Bootstrap recap\nIf instead I could not repeatedly sample from population, we could obtain bootstrap distribution as an approximation of the sampling distribution of the statistic!\nProcedure:\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\boldsymbol{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\boldsymbol{x}\\). Call this set of resampled data \\(\\boldsymbol{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\boldsymbol{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#bootstrap-distribution-from-activity",
    "href": "slides/slides-14-bootstrap-ci.html#bootstrap-distribution-from-activity",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution from activity",
    "text": "Bootstrap distribution from activity\n\n\n\nIn our original sample of \\(n = 10\\), we had \\(\\hat{p} = 0.2\\). We have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that our bootstrap distribution isn’t a great approximation (maybe \\(n = 10\\) did not yield a representative sample)"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#answering-estimation-question",
    "href": "slides/slides-14-bootstrap-ci.html#answering-estimation-question",
    "title": "Bootstrap Confidence Intervals",
    "section": "Answering estimation question",
    "text": "Answering estimation question\n\nGreat…but what do we do with the bootstrap distribution?\nRecall our research question: What proportion of STAT 201A drink coffee regularly?\n\nCould respond using our single point estimate: \\(\\hat{p} = 0.2\\)\nBut due to variability, we recognize that the point estimate will rarely (if ever) equal population parameter\n\nRather than report a single number, why not report a range of values?\n\n\nThis is possible only if we have a sampling distribution to work with!!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#confidence-intervals",
    "href": "slides/slides-14-bootstrap-ci.html#confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nAnalogy: would you rather go fishing with a single pole or a large net?\n\nA range of values gives us a better chance at capturing the true value\n\nA confidence interval provides such a range of plausible values for the parameter (more rigorous definition coming soon)\n\n“Interval”: specify a lower bound and an upper bound\nConfidence intervals are not unique! Depending on the method you use, you might get different intervals"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#bootstrap-percentile-interval",
    "href": "slides/slides-14-bootstrap-ci.html#bootstrap-percentile-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap percentile interval",
    "text": "Bootstrap percentile interval\n\nThe \\(\\gamma \\times 100\\)% bootstrap percentile interval is obtained by finding the bounds of the middle \\(\\gamma \\times 100\\)% of the bootstrap distribution\nCalled “percentile interval” because the bounds are the \\((1-\\gamma)/2\\times100\\) and \\((1+\\gamma)/2\\times 100\\) percentiles of the bootstrap distribution\n\n\n\nIf \\(\\gamma = 0.90\\), then the bounds would be at which percentiles?\n\n\n\nFor our purposes, “bootstrap confidence interval” will be equivalent to “bootstrap percentile interval”\nquantile() function in R gives us easy way to obtain percentiles: quantile(x, p) gives us \\(p\\)-th percentile of x"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#visualizing-bootstrap-confidence-interval",
    "href": "slides/slides-14-bootstrap-ci.html#visualizing-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Visualizing bootstrap confidence interval",
    "text": "Visualizing bootstrap confidence interval\n\n\nOur 90% bootstrap CI for \\(p\\): (0, 0.4)"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#interpreting-a-confidence-interval",
    "href": "slides/slides-14-bootstrap-ci.html#interpreting-a-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval",
    "text": "Interpreting a confidence interval\n\nOur 90% bootstrap CI for \\(p\\): (0, 0.4). Does this mean there is a 90% chance/probability that the true proportion lies in the interval?\n\n\nAnswer: NO\n\n\nRemember: bootstrap distribution is based on our original sample\n\nIf we started with a different original sample \\(\\boldsymbol{x}\\), then our estimated 90% confidence interval would also be different\n\n\nWhat a confidence interval (CI) represents: if we take many independent repeated samples from this population using the same method and calculate a \\(\\gamma \\times 100\\) % CI for the parameter in the exact same way, then in theory, \\(\\gamma \\times 100\\) % of these intervals should capture/contain the parameter\n\n\n\\(\\gamma\\) represents the long-run proportion of CIs that theoretically contain the true parameter\nHowever, we never know if any particular interval(s) actually do!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#interpreting-a-confidence-interval-cont.",
    "href": "slides/slides-14-bootstrap-ci.html#interpreting-a-confidence-interval-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval (cont.)",
    "text": "Interpreting a confidence interval (cont.)\n\nCorrect interpretation (generic) of our interval \\((a,b)\\): We are \\(\\gamma \\times 100\\) % confident that the population parameter is between \\(a\\) and \\(b\\).\n\n\nInterpret our bootstrap CI in context\n\n\nAgain: why is this interpretation incorrect? “There is a 90% chance/probability that the true parameter value lies in the interval.”"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#remarks",
    "href": "slides/slides-14-bootstrap-ci.html#remarks",
    "title": "Bootstrap Confidence Intervals",
    "section": "Remarks",
    "text": "Remarks\n\n\nWhat is a virtue of a “good” confidence interval?\n\n\nHow do you expect the interval to change as the original sample size \\(n\\) changes?\nHow do you expect the interval to change as level of confidence \\(\\gamma\\) changes?\n\nOnce again, a good interval relies on a representative original sample!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#comparing-confidence-intervals",
    "href": "slides/slides-14-bootstrap-ci.html#comparing-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nComparing changes in 90% bootstrap CI for sample sizes \\(n = 5, 10, \\text{ and } 17\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0, 0.8)\n\n\nn = 10\n(0, 0.4)\n\n\nn = 17\n(0.18, 0.53)\n\n\n\n\n\n\nWhat do you notice about the bootstrap distributions and CIs as \\(n\\) increases?"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#live-code-your-turn",
    "href": "slides/slides-14-bootstrap-ci.html#live-code-your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Live code + your turn!",
    "text": "Live code + your turn!\n\nLive code:\n\nin-line code\nsetting a seed\n\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#housekeeping",
    "href": "slides/slides-14-bootstrap-ci.html#housekeeping",
    "title": "Bootstrap Confidence Intervals",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nDataFest groups!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#live-code-coding-practice",
    "href": "slides/slides-14-bootstrap-ci.html#live-code-coding-practice",
    "title": "Bootstrap Confidence Intervals",
    "section": "Live code + Coding practice!",
    "text": "Live code + Coding practice!\n\nLive code:\n\nin-line code\nsetting a seed\n\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "slides/slides-14-bootstrap-ci.html#sampling-distribution-recap",
    "href": "slides/slides-14-bootstrap-ci.html#sampling-distribution-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Sampling distribution recap",
    "text": "Sampling distribution recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nRecall research question from last class: what proportion of STAT 201A students drink coffee regularly?\n\n\n\n\nSince I took a census, I actually do have access to true sampling distribution of the sample proportion!\nI will repeatedly take SRS (i.e. without replacement) of \\(n=10\\) values from the population and calculate \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html",
    "href": "slides/slides-15-intro-testing.html",
    "title": "Introduction to Hypothesis Testing",
    "section": "",
    "text": "Office hours change this week\nMid-semester feedback survey results"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#testing",
    "href": "slides/slides-15-intro-testing.html#testing",
    "title": "Introduction to Hypothesis Testing",
    "section": "Testing",
    "text": "Testing\nWe are now entering into second branch of inference-related tasks: testing.\n\nWe have some “claim”/question about the target population, and we use sampled data to provide evidence for or against the claim\n\nEspecially important in medicine\n\nWe will use the hypothesis testing framework to formalize the process of making decisions about research claims.\n\nBecause the claim is about target population, we will almost always formulate claims in terms of population parameters\nThen we use sampled data to provide the evidence for/against"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#step-1-define-hypotheses",
    "href": "slides/slides-15-intro-testing.html#step-1-define-hypotheses",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 1: Define hypotheses",
    "text": "Step 1: Define hypotheses\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\nWe define hypotheses to translate our research question/claim into statistical notation\nWe always define two hypotheses in context: a null hypothesis and an alternative hypothesis\nNull hypothesis \\(H_{0}\\): hypothesis that represents “business as usual”/status quo/nothing unusual or noteworthy\nAlternative hypothesis \\(H_{A}\\): claim the researchers want to demonstrate\n\n\nIt will not always be obvious what the hypotheses should be, but you will develop intuition for this over time!"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#defining-hypotheses-in-context",
    "href": "slides/slides-15-intro-testing.html#defining-hypotheses-in-context",
    "title": "Introduction to Hypothesis Testing",
    "section": "Defining hypotheses in context",
    "text": "Defining hypotheses in context\nResearch question: do the minority of Middlebury students drink coffee regularly?\n\n\nTry to write down our null and alternative hypotheses in statistical notation! This includes defining parameters!\n\n\nDefine \\(p\\) as the true proportion of Middlebury students who drink coffee regularly\n\\(H_{0}:\\ p = 0.5\\) versus \\(H_{A}:\\ p < 0.5\\)"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#step-2-collect-and-summarize-data",
    "href": "slides/slides-15-intro-testing.html#step-2-collect-and-summarize-data",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 2: Collect and summarize data",
    "text": "Step 2: Collect and summarize data\n\n\n\nOur sample is the convenience sample I took of our class: 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, where 1 = “yes” and 0 = “no”.\n\nPoint estimate: \\(\\hat{p}_{obs} = 0.35\\)\n\nAre we prepared to answer our research question based on this evidence?\n\nNO! Due to variability, we should ask: do the data provide convincing evidence that the minority of Middlebury students drink coffee regularly?"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "href": "slides/slides-15-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 3: Determine if we have “convincing evidence”",
    "text": "Step 3: Determine if we have “convincing evidence”\n“Convincing evidence” for us means that it would be highly unlikely to observe the data we did (or data even more extreme) if \\(H_{0}\\) were true!\n\nWe will calculate a p-value: the probability of observing data as or more extreme than we did, assuming \\(H_{0}\\) true\n\nNote: p in “p-value” is not the same as parameter \\(p\\)!\nThis is a conditional probability: we condition on \\(H_{0}\\) true\n\nHighly unlikely is vague and needs to defined by the researcher, ideally before seeing data.\n\nIf we want to provide a yes/no answer to the research question, we need some threshold to compare the p-value to. This is called a significance level \\(\\alpha\\)\nCommon choices are \\(\\alpha = 0.05\\), \\(\\alpha = 0.01\\) (more on this later)!\n\nFor our example, we will choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#how-to-obtain-p-value",
    "href": "slides/slides-15-intro-testing.html#how-to-obtain-p-value",
    "title": "Introduction to Hypothesis Testing",
    "section": "How to obtain p-value?",
    "text": "How to obtain p-value?\n\nHow to obtain this probability?\nNeed access to a distribution that corresponds to a world where \\(H_{0}\\) is true (i.e. the null distribution)\n\nOption 1: if we have assumptions about how our data behave, we can obtain this distribution using theory/math (next week)\nOption 2: if we don’t want to make assumptions, why not simulate?\n\nWe will call this option “simulating under \\(H_{0}\\)”\n\n\n\nThis is the step that requires the most “work”, and what exactly you do will depend on the the type of data and the research question/claim you have"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "href": "slides/slides-15-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nWe have to simulate our data under the assumption that \\(H_{0}\\) is true (recall \\(H_0\\): \\(p = 0.5\\))\nImagine a big bag filled with many slips of pink and purple slips of paper\n\nPink = coffee-drinkers\nPurple = non-coffee-drinkers\n\n\n\n\nTo simulate under \\(H_{0}\\), what proportion of the slips in the bag should be pink vs purple?\n\n\n\nTo simulate under \\(H_{0}: p = 0.50\\), half of the slips should be pink!"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "href": "slides/slides-15-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nTo simulate under \\(H_{0}\\), we replicate our original sample, this time sampling from this “null world” bag of paper slips\n\nRepeatedly take samples from this null distribution using original sample size \\(n =\\) 20\nFor each sample, calculate the simulated proportion of pink slips\n\nLive code?\n\n\n\nset.seed(2)\nB <- 5000 \nn <- length(x)\nnull_props <- rep(NA, B)\nfor(b in 1:B){\n  null_samp <- sample(x = c(\"pink\", \"purple\"), \n                      size = n,\n                      replace = T,\n                      prob = c(0.5, 0.5)) \n  null_props[b] <- sum(null_samp == \"pink\")/n\n}"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#null-distribution-of-statistic",
    "href": "slides/slides-15-intro-testing.html#null-distribution-of-statistic",
    "title": "Introduction to Hypothesis Testing",
    "section": "Null distribution of statistic",
    "text": "Null distribution of statistic\nWe can visualize the distribution of \\(\\hat{p}\\) assuming \\(H_{0}\\) true:\n\n\nThis is called the null distribution of the sample statistic, which is the distribution of the statistic \\(\\hat{p}\\) assuming \\(H_{0}\\) is true\n\nWhere is this null distribution of \\(\\hat{p}\\) centered? Why does that “make sense”?"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#comparing-null-to-observed",
    "href": "slides/slides-15-intro-testing.html#comparing-null-to-observed",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comparing null to observed",
    "text": "Comparing null to observed\nLet’s return to our original goal of Step 3! We need to find the p-value: the probability of observing data as or more extreme as ours, assuming \\(H_{0}\\) were true.\n\nOur observed point estimate was \\(\\hat{p}_{obs} =\\) 0.35\n\\(H_{0}\\): \\(p = 0.5\\) and \\(H_{A}\\): \\(p < 0.5\\)\n\n\n\n\n\nWhat does “as or more extreme” mean in this context?\nHow can we use the null distribution to obtain this probability?"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#obtain-p-value-step-3-cont.",
    "href": "slides/slides-15-intro-testing.html#obtain-p-value-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Obtain p-value (step 3 cont.)",
    "text": "Obtain p-value (step 3 cont.)\nWe can directly estimate the p-value using our null distribution and our observed \\(\\hat{p}\\)!\n\n\nOut of 5000 replications, we saw 643 instances of \\(\\hat{p} \\leq \\hat{p}_{obs}\\)\np-value is \\(\\frac{ 643}{5000} \\approx\\) 0.13"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "href": "slides/slides-15-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 4: Interpret p-value and make decision",
    "text": "Step 4: Interpret p-value and make decision\n\nInterpret the p-value 0.1286 in context\n\n\nAssuming \\(H_{0}\\) true, the probability of observing a sample proportion as or more extreme as our 0.35 is approximately 0.13\n\n\nMake a decision about research claim/question by comparing p-value to significance level \\(\\alpha\\)\n\nIf p-value \\(< \\alpha\\), we reject \\(H_{0}\\) (it was highly unlikely to observe our data given \\(H_{0}\\) and our selected threshold)\nIf p-value \\(\\geq \\alpha\\), we fail to reject \\(H_{0}\\) (not have enough evidence against the null)\n\n\nNote: we never “accept \\(H_{A}\\)”!\n\n\n\nSince our p value is greater than \\(\\alpha = 0.05\\), we fail to reject \\(H_{0}\\). The data do not provide sufficient evidence to suggest that the minority of Middlebury students drink coffee regularly."
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#summary-of-testing-framework",
    "href": "slides/slides-15-intro-testing.html#summary-of-testing-framework",
    "title": "Introduction to Hypothesis Testing",
    "section": "Summary of testing framework",
    "text": "Summary of testing framework\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain the null distribution of the statistic and use it to obtain/estimate p-value\n\nWe did this using by simulating\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#errors-in-decision",
    "href": "slides/slides-15-intro-testing.html#errors-in-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\nIn Step 4, we make a decision but it could be wrong! (Unfortunately, we will never know)\nWe always fall into one of the following four scenarios:\n\n\n\n\n\n\n\n\n\n\nIdentify which cells are good scenarios, and which are bad"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#errors-in-decision-1",
    "href": "slides/slides-15-intro-testing.html#errors-in-decision-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\n\n\nWhat kind of error could we have made in our example?\n\nIt is important to weight the consequences of making each type of error!\n\nWe have some control in this - how? Through \\(\\alpha\\)!"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#comprehension-questions",
    "href": "slides/slides-15-intro-testing.html#comprehension-questions",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat are the similarities/differences between the bootstrap distribution of a sample statistic and the simulated null distribution?\nDo you understand what a p-value represents, and how we obtain it from the null distribution?\nWhat role does \\(\\alpha\\) play? Why is it important to set \\(\\alpha\\) early on?"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#housekeeping",
    "href": "slides/slides-15-intro-testing.html#housekeeping",
    "title": "Introduction to Hypothesis Testing",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nDataFest groups!"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#hypothesis-testing-framework",
    "href": "slides/slides-15-intro-testing.html#hypothesis-testing-framework",
    "title": "Introduction to Hypothesis Testing",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\nFour stages (we will step through each one):\n\nDefine your hypotheses\nCollect data, set a significance level\nDetermine strength of evidence (null distribution, p-value)\nMake decision and conclusion in context"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses",
    "href": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses",
    "title": "Introduction to Hypothesis Testing",
    "section": "Practice in defining hypotheses",
    "text": "Practice in defining hypotheses\n\nFor each of the following, determine whether it represents a null hypothesis claim or an alternative hypothesis claim:\n\n\nKing cheetahs on average run the same speed as standard spotted cheetahs.\nFor a particular student, the probability of correctly answer a 5-option multiple choice test is larger than 0.2 (i.e. better than guessing)\nThe probability of getting in a car accident is the same if using a cell phone then if not using a cell phone.\nThe number of hours that grade-school children spend doing homework predicts their future success on standardized tests."
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-1",
    "href": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Practice in defining hypotheses",
    "text": "Practice in defining hypotheses\nFor each of the following, determine whether it represents a null hypothesis claim or an alternative hypothesis claim:\n\nKing cheetahs on average run the same speed as standard spotted cheetahs.\n\nNull!\n\nFor a particular student, the probability of correctly answer a 5-option multiple choice test is larger than 0.2 (i.e. better than guessing)\n\nAlternative!\n\nThe probability of getting in a car accident is the same if using a cell phone then if not using a cell phone.\n\nNull!\n\nThe number of hours that grade-school children spend doing homework predicts their future success on standardized tests.\n\nAlternative!"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-2",
    "href": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-2",
    "title": "Introduction to Hypothesis Testing",
    "section": "Practice in defining hypotheses",
    "text": "Practice in defining hypotheses\n\nWrite out the null and alternative hypotheses in words and also in statistical notation for the following situations:\n\n\nNew York is known as “the city that never sleeps’’. A random sample of 25 New Yorkers were asked how much they sleep they get per night. Do these data providing convincing evidence that New Yorkers on average sleep less than 8 hours per night?\nA study suggests that 25% of 25 year-olds have gotten married. You believe that this is incorrect and decide to conduct your own analysis."
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-3",
    "href": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-3",
    "title": "Introduction to Hypothesis Testing",
    "section": "Practice in defining hypotheses",
    "text": "Practice in defining hypotheses\nNew York is known as “the city that never sleeps’’. A random sample of 25 New Yorkers were asked how much they sleep they get per night. Does these data providing convincing evidence that New Yorkers on average sleep less than 8 hours per night?\n\nWords\n\n\\(H_0\\): New Yorkers sleep an average of 8 hours per night\n\\(H_{A}:\\) New Yorkers sleep an average of less than 8 hours per night\n\nNotation: let \\(\\mu\\) be the average hours of sleep of New Yorkers\n\n\\(H_{0}: \\mu = 8\\)\n\\(H_{A}: \\mu < 8\\)"
  },
  {
    "objectID": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-4",
    "href": "slides/slides-15-intro-testing.html#practice-in-defining-hypotheses-4",
    "title": "Introduction to Hypothesis Testing",
    "section": "Practice in defining hypotheses",
    "text": "Practice in defining hypotheses\nA study suggests that 25% of 25 year-olds in the US have gotten married. You believe that this is incorrect and decide to conduct your own analysis.\n\nWords\n\n\\(H_0\\): the proportion of 25 year-olds in the US who are married is 0.25\n\\(H_{A}:\\) the proportion of 25 year-olds in the US who are married is not 0.25\n\nNotation: let \\(p\\) be the proportion of 25 year-olds in the US who are married\n\n\\(H_{0}: p = 0.25\\)\n\\(H_{A}: p \\neq 0.25\\)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#housekeeping",
    "href": "slides/slides-16-randomization.html#housekeeping",
    "title": "Hypothesis Testing via Randomization",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours change this week"
  },
  {
    "objectID": "slides/slides-16-randomization.html#where-were-going-today",
    "href": "slides/slides-16-randomization.html#where-were-going-today",
    "title": "Hypothesis Testing via Randomization",
    "section": "Where we’re going today",
    "text": "Where we’re going today\n\nWe will see another kinds of hypotheses for different types of research questions\nHypothesis testing framework is the same, but will change how we obtain null distribution\nTry to see the big picture"
  },
  {
    "objectID": "slides/slides-16-randomization.html#running-example-sex-discrimination-study",
    "href": "slides/slides-16-randomization.html#running-example-sex-discrimination-study",
    "title": "Hypothesis Testing via Randomization",
    "section": "Running example: sex discrimination study",
    "text": "Running example: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nEach given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#defining-hypotheses",
    "href": "slides/slides-16-randomization.html#defining-hypotheses",
    "title": "Hypothesis Testing via Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\n\nWhat is/are the variables(s) here? What types of variables are they?\n\nWe need to construct hypotheses where \\(H_{0}\\) is “status quo” and \\(H_{A}\\) is the claim researchers have\n\\(H_{0}\\): the variables sex and decision are independent.\n\ni.e. any observed difference in promotion rates is due to variability\n\n\\(H_{A}\\): the variables sex and decision are not independent, and equally-qualified female personnel are less likely to be promoted than male personnel"
  },
  {
    "objectID": "slides/slides-16-randomization.html#data",
    "href": "slides/slides-16-randomization.html#data",
    "title": "Hypothesis Testing via Randomization",
    "section": "Data",
    "text": "Data\nFor each of the 48 supervisors, the following were recorded:\n\nThe sex of the candidate in the file (male/female)\nThe decision (promote/not promote)\n\n\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\n\n\nWhat evidence do we have? What summary statistic(s) would be useful for answering the research question?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#data-cont.",
    "href": "slides/slides-16-randomization.html#data-cont.",
    "title": "Hypothesis Testing via Randomization",
    "section": "Data (cont.)",
    "text": "Data (cont.)\nConditional probability of getting promoted by sex:\n\n\n\n# look at data\ndiscrimination |>\n  slice(1:4)\n\n     sex    decision\n1   male     promote\n2 female not promote\n3   male     promote\n4 female     promote\n\n\n\n\ndiscrimination |>\n  count(sex, decision) |>\n  group_by(sex) |>\n  mutate(cond_prob = n/sum(n)) |>\n  filter(decision == \"promote\") |>\n  select(-n)\n\n\n\n\n\n\n\n\nsex\ndecision\ncond_prob\n\n\n\n\nfemale\npromote\n0.583\n\n\nmale\npromote\n0.875\n\n\n\n\n\n\nIs the observed difference \\(\\hat{p}_{f,obs} - \\hat{p}_{m,obs} =\\) -0.2916667 convincing evidence? We need to examine variability in the data, assuming \\(H_{0}\\) true.\nLet’s set \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#simulate-under-null",
    "href": "slides/slides-16-randomization.html#simulate-under-null",
    "title": "Hypothesis Testing via Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nSimulating under \\(H_{0}\\) means operating in a hypothetical word where sex and decision are independent.\n\nThis means that knowing the sex of the candidate should have no bearing on the decision to promote or not\n\nWe will perform a simulation called a randomization test:\n\nRandomly pair up decision and sex outcome pairs\nRandomly assigning a decision to each person would be equivalent to a world in which the bankers’ decision had been independent of candidate’s sex (i.e. if \\(H_{0}\\) true)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#randomization-test",
    "href": "slides/slides-16-randomization.html#randomization-test",
    "title": "Hypothesis Testing via Randomization",
    "section": "Randomization test",
    "text": "Randomization test\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nWrite down “promote” on 35 cards and “not promote” on 13 cards. Repeat the following:\n\nThoroughly shuffle these 48 cards.\nDeal out a stack of 24 cards to represent males, and the remaining 24 cards to represent females\n\nThis is how we simulate under \\(H_{0}\\)\n\nCalculate the proportion of “promote” cards in each stack, \\(\\hat{p}_{f, sim}\\) and \\(\\hat{p}_{m, sim}\\)\nCalculate and record the difference \\(\\hat{p}_{f,sim} - \\hat{p}_{m,sim}\\) (order of difference doesn’t matter so long as you are consistent)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#randomization-test-activity",
    "href": "slides/slides-16-randomization.html#randomization-test-activity",
    "title": "Hypothesis Testing via Randomization",
    "section": "Randomization test (activity)",
    "text": "Randomization test (activity)\nTry it!"
  },
  {
    "objectID": "slides/slides-16-randomization.html#randomization-test-code",
    "href": "slides/slides-16-randomization.html#randomization-test-code",
    "title": "Hypothesis Testing via Randomization",
    "section": "Randomization test (code)",
    "text": "Randomization test (code)\n\nset.seed(100)\nn <- nrow(discrimination)\nn_f <- sum(discrimination$sex == \"female\")\nn_m <- sum(discrimination$sex == \"male\")\ndecisions <- discrimination$decision\nB <- 1000\ndiff_props_null <- rep(NA, B)\nfor(b in 1:B){\n  shuffled <- sample(decisions, n)\n  rand_f <- shuffled[1:n_f]\n  rand_m <- shuffled[-c(1:n_f)]\n  \n  p_f_sim <-  mean(rand_f == \"promote\")\n  p_m_sim <-mean(rand_m == \"promote\")\n  \n  diff_props_null[b] <- p_f_sim - p_m_sim\n}\n\n\n\nWhere should the null distribution be centered?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#null-distribution",
    "href": "slides/slides-16-randomization.html#null-distribution",
    "title": "Hypothesis Testing via Randomization",
    "section": "Null distribution",
    "text": "Null distribution"
  },
  {
    "objectID": "slides/slides-16-randomization.html#obtain-p-value",
    "href": "slides/slides-16-randomization.html#obtain-p-value",
    "title": "Hypothesis Testing via Randomization",
    "section": "Obtain p-value",
    "text": "Obtain p-value\nRecall, the observed difference in our data was \\(\\hat{p}_{f,obs} - \\hat{p}_{m,obs} =\\) -0.2916667.\n\np-value is probability of observing data as or more extreme than our original data, given \\(H_{0}\\) true.\n\nWhere does “as or more extreme” correspond to on our plot?\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut of 1000 simulations under \\(H_{0}\\), 28 resulted in a difference in promotion rates as or more extreme than our observed\nSo the p-value is approximately 0.028"
  },
  {
    "objectID": "slides/slides-16-randomization.html#making-decision-and-conclusion",
    "href": "slides/slides-16-randomization.html#making-decision-and-conclusion",
    "title": "Hypothesis Testing via Randomization",
    "section": "Making decision and conclusion",
    "text": "Making decision and conclusion\nOur research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\\(H_{0}\\): sex and decision are independent\n\\(H_{A}\\): sex and decision are not independent and equally-qualified female personnel are less likely to get promoted than male personnel by male supervisors\n\\(\\alpha = 0.05\\)\n\n\n\nInterpret our p-value in context.\nMake a decision and conclusion in response to the research question."
  },
  {
    "objectID": "slides/slides-16-randomization.html#making-decision-and-conclusion-answer",
    "href": "slides/slides-16-randomization.html#making-decision-and-conclusion-answer",
    "title": "Hypothesis Testing via Randomization",
    "section": "Making decision and conclusion (answer)",
    "text": "Making decision and conclusion (answer)\n\np-value interpretation: Assuming that sex and decision are independent, the probability of observing a difference in promotion rates as or more extreme as -0.2916667 is 0.028.\nDecision: Because the observed p-value of 0.028 is less than our significant level 0.05, we reject \\(H_{0}\\).\nConclusion: The data provide strong evidence of sex discrimination against female candidates by the male supervisors.\n\nWhat kind of error could we have made?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#running-example-cpr",
    "href": "slides/slides-16-randomization.html#running-example-cpr",
    "title": "Hypothesis Testing via Randomization",
    "section": "Running example: CPR",
    "text": "Running example: CPR\n\nAn experiment was conducted, consisting of two treatments on 90 patients who underwent CPR for a heart attack and subsequently went to the hospital. Each patient was randomly assigned to either:\n\ntreatment group: received a blood thinner\ncontrol group: did not receive a blood thinner\n\nFor each patient, the outcome recorded was whether they survived for at least 24 hours.\n\nWhat is/are the variables(s) here? What types of variables are they?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#defining-hypotheses-1",
    "href": "slides/slides-16-randomization.html#defining-hypotheses-1",
    "title": "Hypothesis Testing via Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\nThe researchers are interested in learning if the blood thinner treatment was effective for patients who undergo CPR after a heart attack?\n\n\\(H_{0}:\\) the blood thinner treatment was not effective\n\\(H_{A}:\\) the blood thinner treatment was effective\n\n\n\nTry to write down the hypotheses using statistical notation.\n\n\n\nLet \\(p_{T}\\) and \\(p_{C}\\) denote the proportion of patients who survive when receiving the thinner (Treatment) and when not receiving the treatment (Control), respectively\n\n\n\n\nOption 1\n\n\\(H_{0}\\): \\(p_{T} = p_{C}\\)\n\\(H_{A}\\): \\(p_{T} > p_{C}\\)\n\n\n\n\nOption 2 (preferred)\n\n\\(H_{0}\\): \\(p_{T} - p_{C} = 0\\)\n\\(H_{A}\\): \\(p_{T} - p_{C}> 0\\)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#collect-data",
    "href": "slides/slides-16-randomization.html#collect-data",
    "title": "Hypothesis Testing via Randomization",
    "section": "Collect data",
    "text": "Collect data\nUsing the data, obtain the observed difference in sample proportions.\n\n\n\ncpr |>\n  slice(1:3)\n\n\n\n# A tibble: 3 × 2\n  group     outcome \n  <fct>     <fct>   \n1 treatment died    \n2 control   died    \n3 control   survived\n\n\n\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\n\n\n\n\n\nWhat evidence do we have? What summary statistic(s) would be useful for answering the research question?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#simulate-under-null-1",
    "href": "slides/slides-16-randomization.html#simulate-under-null-1",
    "title": "Hypothesis Testing via Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nWe will once again perform a randomization test to try and simulate the difference in proportions under \\(H_{0}\\)\n\nUnder \\(H_{0}\\), treatment group is no better than control group, so let’s simulate assuming that outcome and treatment are independent\n\n\n\n\nTry filling out worksheet!\n\n\n\nWrite down died on 65 cards, and survived on 25 cards. Then repeat several times:\n\nShuffle cards well\nDeal out 50 to be Control group, and remaining 40 to be Treatment group\nCalculate proportions of survival \\(\\hat{p}_{C, sim}\\) and \\(\\hat{p}_{T, sim}\\)\nObtain and record the simulated difference \\(\\hat{p}_{T, sim} - \\hat{p}_{C, sim}\\)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#simulate-under-null-code",
    "href": "slides/slides-16-randomization.html#simulate-under-null-code",
    "title": "Hypothesis Testing via Randomization",
    "section": "Simulate under null (code)",
    "text": "Simulate under null (code)\nLive code or look here:\n\nset.seed(310)\nn_t <- sum(cpr$group == \"treatment\")\nn_c <- sum(cpr$group == \"control\")\ncards <- cpr$outcome\nB <- 1000\ndiff_props_null <- rep(NA , B)\nfor(b in 1:B){\n  shuffled <- sample(cards)\n  treat_sim <- shuffled[1:n_t]\n  control_sim <- shuffled[-c(1:n_t)]\n  \n  p_t_sim <- mean(treat_sim == \"survived\")\n  p_c_sim <- mean(control_sim == \"survived\")\n  \n  diff_props_null[b] <- p_t_sim - p_c_sim\n}\n\n\n\nWhere should our null distribution be centered at?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#visualizing-null-distribution",
    "href": "slides/slides-16-randomization.html#visualizing-null-distribution",
    "title": "Hypothesis Testing via Randomization",
    "section": "Visualizing null distribution",
    "text": "Visualizing null distribution\n\n\nHow would we obtain the p-value in this problem?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#calculate-p-value",
    "href": "slides/slides-16-randomization.html#calculate-p-value",
    "title": "Hypothesis Testing via Randomization",
    "section": "Calculate p-value",
    "text": "Calculate p-value\n\n\n\n\n\n\n\n\n\nWe simulated 148 out of 1000 simulations where the difference in proportions under \\(H_{0}\\) was as or more extreme than our observed difference of 0.13\nSo p-value is approximately 0.148"
  },
  {
    "objectID": "slides/slides-16-randomization.html#interpret-and-make-conclusion",
    "href": "slides/slides-16-randomization.html#interpret-and-make-conclusion",
    "title": "Hypothesis Testing via Randomization",
    "section": "Interpret and make conclusion",
    "text": "Interpret and make conclusion\nThe researchers are interested in learning if the blood thinner treatment was effective.\nOur p-value is 0.148.\n\n\nMake a decision and conclusion about the research question in context. What type of error could we have made?\n\n\n\nDecision: because our p-value of 0.148 is greater than \\(\\alpha = 0.05\\), we fail to reject \\(H_{0}\\)\nConclusion: the data do not provide convincing evidence that the blood thinner treatment improves survival rates among patients who undergo CPR.\nPossible error: Type 2"
  },
  {
    "objectID": "slides/slides-16-randomization.html#comprehension-questions",
    "href": "slides/slides-16-randomization.html#comprehension-questions",
    "title": "Hypothesis Testing via Randomization",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat were the similarities and differences between:\n\nhypothesis test for independence\nhypothesis test for two proportions\n\nHow do the randomization tests today differ from the test for one proportion that we learned last class?"
  },
  {
    "objectID": "slides/slides-16-randomization.html#summarise-data",
    "href": "slides/slides-16-randomization.html#summarise-data",
    "title": "Hypothesis Testing via Randomization",
    "section": "Summarise data",
    "text": "Summarise data\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\n\n\n# pull() takes a column from data frame and turns into vector\np_hat_c <- cpr |>\n  filter(group == \"control\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull(p) \np_hat_t <- cpr |>\n  filter(group == \"treatment\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull()\nobs_diff <- p_hat_t - p_hat_c\n\n\n\n\n\\(\\hat{p}_{C, obs} = \\frac{11}{50} = 0.22\\)\n\\(\\hat{p}_{T,obs} = \\frac{14}{40} = 0.35\\)\nObserved difference: \\(\\hat{p}_{T,obs} - \\hat{p}_{C,obs} = 0.13\\)\n\n\n\n\nIs this “convincing evidence” that blood thinner usage after CPR is effective?\nSet \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-16-randomization.html#running-example-cpr-openintro",
    "href": "slides/slides-16-randomization.html#running-example-cpr-openintro",
    "title": "Hypothesis Testing via Randomization",
    "section": "Running example: CPR (openintro)",
    "text": "Running example: CPR (openintro)\n\nAn experiment was conducted, consisting of two treatments on 90 patients who underwent CPR for a heart attack and subsequently went to the hospital. Each patient was randomly assigned to either:\n\ntreatment group: received a blood thinner\ncontrol group: did not receive a blood thinner\n\nFor each patient, the outcome recorded was whether they survived for at least 24 hours.\n\nWhat is/are the variables(s) here? What types of variables are they?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html",
    "href": "slides/slides-17-single-mean.html",
    "title": "Hypothesis testing for a mean",
    "section": "",
    "text": "Office hours tomorrow: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#recap",
    "href": "slides/slides-17-single-mean.html#recap",
    "title": "Hypothesis testing for a mean",
    "section": "Recap",
    "text": "Recap\n\nWe have seen how to perform hypothesis tests for questions involving the following:\n\nA single proportion (coffee consumption)\nIndependence of two categorical variables (banker sex discrimination)\n\nThink of as one population\n\nDifference in two proportions (blood thinner)\n\nThink of as two populations\n\n\nWe are now going to see another hypothesis test, this time for numerical data"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#running-example-form-hypotheses",
    "href": "slides/slides-17-single-mean.html#running-example-form-hypotheses",
    "title": "Hypothesis testing for a mean",
    "section": "Running example + form hypotheses",
    "text": "Running example + form hypotheses\nWe will use the duke_forest dataset provided in openintro. It provides data on some houses that were sold in the Duke Forest neighborhood of Durham, NC in November 2020.\n\n\n\n\nBefore we look at the data, we should form our hypotheses. Suppose I am interested in learning if the average price of houses in Duke Forest is $500,000 or not.\n\nWhat might our hypotheses be?\n\n\n\\(H_{0}\\): \\(\\mu =\\) 5 versus \\(H_{A}\\): \\(\\mu\\neq\\) 5, where \\(\\mu\\) is the true average housing price in Duke Forest in November 2020 (in $100,000)\nTerminology: I will refer to \\(\\mu_{0} =\\) 5 as my “null hypothesized value”. (i.e. the specific value of \\(\\mu\\) in \\(H_{0}\\))"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#collect-data",
    "href": "slides/slides-17-single-mean.html#collect-data",
    "title": "Hypothesis testing for a mean",
    "section": "Collect data",
    "text": "Collect data\n\n\n\n\nThe observed/sample mean housing price is $55.99k from a sample of 98 houses.\n\nNow we must determine if we have “convincing evidence”! Choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#simulating-null-distribution",
    "href": "slides/slides-17-single-mean.html#simulating-null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Simulating null distribution",
    "text": "Simulating null distribution\nTo simulate from the null distribution, we need to operate in a world where \\(H_{0}\\) is true\n\nSo, I need to repeatedly simulate data sets of size 98 where the true mean is 5, without changing anything else\nIf I don’t want to make any assumptions about how the data behave, how might I do that?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#bootstrap-to-the-rescue",
    "href": "slides/slides-17-single-mean.html#bootstrap-to-the-rescue",
    "title": "Hypothesis testing for a mean",
    "section": "Bootstrap to the rescue",
    "text": "Bootstrap to the rescue\n\nHow would I obtain a bootstrap distribution of the sample mean price of houses?\n\n\n\n\n\nRemind ourselves: Where should the bootstrap distribution be centered?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#bootstrap-to-null-distribution",
    "href": "slides/slides-17-single-mean.html#bootstrap-to-null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Bootstrap to null distribution",
    "text": "Bootstrap to null distribution\n\n\n\n\n\n\n\n\n\nThis is not the null distribution! The null distribution should be centered at \\(\\mu_{0} = 5\\)\nHowever, the null distribution should have the same variability in \\(\\bar{x}\\) as the bootstrap distribution.\n\n\n\n\nSo to get the null distribution, why not just shift the bootstrap distribution to be centered where we want it to be?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#shifting-to-the-bootstrap-distribution",
    "href": "slides/slides-17-single-mean.html#shifting-to-the-bootstrap-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Shifting to the bootstrap distribution",
    "text": "Shifting to the bootstrap distribution\n\nIn this example, bootstrap distribution is centered at \\(\\bar{x} = 5.599\\)\nIn order to center this distribution at \\(\\mu_{0} = 5\\), just subtract \\(5.599 - 5 = 0.599\\) from every single bootstrapped mean\n\nThis will give us a simulated distribution for \\(\\bar{x}\\) centered at \\(\\mu_{0} = 5\\), which is exactly the null distribution!\n\nWe call this “shifting the bootstrap distribution”, because we simply shift where the bootstrap distribution is centered\n\n\n\n\n\n# how much to shift by, where xbar is sample mean housing prices\nshift <- xbar - mu0\n# shift my vector of bootstrapped sample means\nnull_dist <- boot_means - shift"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#null-distribution",
    "href": "slides/slides-17-single-mean.html#null-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Null distribution",
    "text": "Null distribution\n\n\n\nNotice where the distributions are centered. Also note: graphs aren’t exactly identical due to binning of histogram."
  },
  {
    "objectID": "slides/slides-17-single-mean.html#obtain-the-p-value",
    "href": "slides/slides-17-single-mean.html#obtain-the-p-value",
    "title": "Hypothesis testing for a mean",
    "section": "Obtain the p-value",
    "text": "Obtain the p-value\n\\(H_{0}\\): \\(\\mu = 5\\) versus \\(H_{A}\\): \\(\\mu \\neq 5\\)\nOur observed sample mean housing price is 5.599.\n\n\nWhat does it mean to be “as or more extreme” now?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#two-sided-alternative-hypothesis",
    "href": "slides/slides-17-single-mean.html#two-sided-alternative-hypothesis",
    "title": "Hypothesis testing for a mean",
    "section": "Two-sided alternative hypothesis",
    "text": "Two-sided alternative hypothesis\n\nThis is the first time we’ve seen a two-sided hypothesis as a class\nSince the alternative is “double sided”, we can be extreme in both the positive and negative direction!"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#obtain-the-p-value-cont.",
    "href": "slides/slides-17-single-mean.html#obtain-the-p-value-cont.",
    "title": "Hypothesis testing for a mean",
    "section": "Obtain the p-value (cont.)",
    "text": "Obtain the p-value (cont.)\nLet \\(shift\\) represent the amount we shifted the distribution by:\n\\[shift = 5.599 - 5 = 0.599\\]\nSimulated means as or more extreme than \\(\\mu_{0} + shift\\) or \\(\\mu_{0} - shift\\) will contribute:\n\n\n\n\n\n\n\n\n\nsum( (null_dist >= mu0 + shift) | (null_dist <= mu0 - shift))/B\n\n[1] 0.0098"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#make-decision-and-conclusion",
    "href": "slides/slides-17-single-mean.html#make-decision-and-conclusion",
    "title": "Hypothesis testing for a mean",
    "section": "Make decision and conclusion",
    "text": "Make decision and conclusion\n\nMake a decision and conclusion in the context of the research question.\n\n\nSince our p-value of 0.0098 is less than the significance level of 0.05, we reject \\(H_{0}\\). We have convincing evidence to suggest that the true average housing price of homes in Duke Forest in 2020 was not $500k."
  },
  {
    "objectID": "slides/slides-17-single-mean.html#comprehension-questions",
    "href": "slides/slides-17-single-mean.html#comprehension-questions",
    "title": "Hypothesis testing for a mean",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhy did we shift the bootstrap distribution?\nHow do we estimate the p-value in the case of a two-sided alternative hypothesis?"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#housekeeping",
    "href": "slides/slides-17-single-mean.html#housekeeping",
    "title": "Hypothesis testing for a mean",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nDataFest tomorrow! See you there!"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#collect-and-summarise-data",
    "href": "slides/slides-17-single-mean.html#collect-and-summarise-data",
    "title": "Hypothesis testing for a mean",
    "section": "Collect and summarise data",
    "text": "Collect and summarise data\n\n\n\n\nThe observed/sample mean housing price is \\(\\bar{x}_{obs} =\\) 5.599 from a sample of 98 houses.\n\nNow we must determine if we have “convincing evidence”! Choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-17-single-mean.html#shifting-the-bootstrap-distribution",
    "href": "slides/slides-17-single-mean.html#shifting-the-bootstrap-distribution",
    "title": "Hypothesis testing for a mean",
    "section": "Shifting the bootstrap distribution",
    "text": "Shifting the bootstrap distribution\n\nIn this example, bootstrap distribution is centered at \\(\\bar{x}_{obs} = 5.599\\)\nIn order to center this distribution at \\(\\mu_{0} = 5\\), just subtract \\(5.599 - 5 = 0.599\\) from every single bootstrapped mean\n\nThis will give us a simulated distribution for \\(\\bar{x}\\) centered at \\(\\mu_{0} = 5\\), which is exactly the null distribution!\n\nWe call this “shifting the bootstrap distribution”, because we simply shift where the bootstrap distribution is centered\n\n\n\n\n\nmu0 <- 5\n\n# xbar holds observed sample mean\nshift <- xbar - mu0\n\n# boot_means is a vector holding B bootstrapped sample means\nnull_dist <- boot_means - shift"
  },
  {
    "objectID": "live_code/diff_props_cpr.html",
    "href": "live_code/diff_props_cpr.html",
    "title": "Code for CPR example",
    "section": "",
    "text": "library(openintro)\nlibrary(tidyverse)\n\n# summarise data\n## option 1: harder to remember\nprops <- cpr |>\n  group_by(group) |>\n  summarise(prop = mean(outcome == \"survived\")) |>\n  pull(prop)\n\ndiff_prop_obs <- props[2] - props[1]\n\n## option 2: more code, but clearer\np_c_obs <- cpr |>\n  group_by(group) |>\n  summarise(prop = mean(outcome == \"survived\")) |>\n  filter(group == \"control\") |>\n  pull(prop)\n\np_t_obs <- cpr |>\n  group_by(group) |>\n  summarise(prop = mean(outcome == \"survived\")) |>\n  filter(group == \"treatment\") |>\n  pull(prop)\ndiff_prop_obs <- p_t_obs - p_c_obs\n\n### step 3: simulate null\nset.seed(310)\nn_t <- sum(cpr$group == \"treatment\")\nn_c <- sum(cpr$group == \"control\")\ncards <- cpr$outcome\nB <- 1000\ndiff_props_null <- rep(NA , B)\nfor(b in 1:B){\n  shuffled <- sample(cards)\n  treat_sim <- shuffled[1:n_t]\n  control_sim <- shuffled[-c(1:n_t)]\n  \n  p_t_sim <- mean(treat_sim == \"survived\")\n  p_c_sim <- mean(control_sim == \"survived\")\n  \n  diff_props_null[b] <- p_t_sim - p_c_sim\n}\n\n# p-value: we want \"greater than\" direction\np_val <- mean(diff_props_null >= diff_prop_obs)"
  },
  {
    "objectID": "live_code/ht_single_mean_duke.html",
    "href": "live_code/ht_single_mean_duke.html",
    "title": "Simulation test for a single mean",
    "section": "",
    "text": "library(readr)\nlibrary(tidyverse)\n# change the following file path accordingly\nduke_forest <- read_csv(\"~/Desktop/STAT 201/duke_forest.csv\")\n\n\nprices <- duke_forest |>\n  pull(price)\n\nprices <- prices / 100000\n\nxbar <- mean(prices)\nn <- length(prices)\n\n# bootstrap distribution of sample means (5000 iterations)\nset.seed(5)\nB <- 5000\nboot_means <- rep(NA, B)\nfor(b in 1:B){\n  boot_samp <- sample(prices, n, replace = T)\n  boot_means[b] <- mean(boot_samp)\n}\n\nmu0 <- 5\nshift <- xbar - mu0\nnull_dist <- boot_means - shift\n\np_val <- mean(null_dist >= xbar | null_dist <= (mu0 - shift)) \n\nP-value of 0.009"
  },
  {
    "objectID": "datafest_template.html",
    "href": "datafest_template.html",
    "title": "DataFest",
    "section": "",
    "text": "# add extra packages as necessary\nlibrary(tidyverse)\nlibrary(readr)\n\n# load data"
  },
  {
    "objectID": "datafest_template.html#introduction",
    "href": "datafest_template.html#introduction",
    "title": "DataFest",
    "section": "Introduction",
    "text": "Introduction\nWrite your introduction here! Make sure to very clearly state the research question(s) you’re trying to answer."
  },
  {
    "objectID": "datafest_template.html#data-cleaningwrangling",
    "href": "datafest_template.html#data-cleaningwrangling",
    "title": "DataFest",
    "section": "Data cleaning/wrangling",
    "text": "Data cleaning/wrangling\nDiscuss at a high-level the wrangling you needed to do to get your data into a position to implement your methods below. (This might be one of the last parts of the report you right).\n\n# any code you might need to do macro-level wrangling"
  },
  {
    "objectID": "datafest_template.html#methods",
    "href": "datafest_template.html#methods",
    "title": "DataFest",
    "section": "Methods",
    "text": "Methods\nBrief description of methods used to answer your research question(s), along with justification for why your methods is/are appropriate. Remember, we need at least one visualization and one simulation-based inference method!\nThere shouldn’t any code in this section because you are just describing your methods."
  },
  {
    "objectID": "datafest_template.html#results-with-interpretation",
    "href": "datafest_template.html#results-with-interpretation",
    "title": "DataFest",
    "section": "Results with interpretation",
    "text": "Results with interpretation\nImplement your methods described above. This section is mostly code, with just some text for interpretation in context."
  },
  {
    "objectID": "datafest_template.html#conclusion",
    "href": "datafest_template.html#conclusion",
    "title": "DataFest",
    "section": "Conclusion",
    "text": "Conclusion\nBrief conclusion about what you would do differently/wish you had!"
  },
  {
    "objectID": "datafest_template.html#acknowledgements",
    "href": "datafest_template.html#acknowledgements",
    "title": "DataFest",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nPlease briefly describe each team member’s contribution to the project!"
  },
  {
    "objectID": "slides/slides-19-clt.html#recap",
    "href": "slides/slides-19-clt.html#recap",
    "title": "Central Limit Theorem",
    "section": "Recap",
    "text": "Recap\n\n\n\n\nNormal distribution: symmetric, bell-shaped curve that is described by mean \\(\\mu\\) and standard deviation \\(\\sigma\\)\n\nCommon model used to describe behavior of continuous variables\n\nUse area under the Normal curve to obtain probabilities\n68-95-99.7 rule\nz-score standardizes observations to allow for easier comparison: \\(z = \\frac{x- \\mu}{\\sigma}\\)\n\nIf the data are known to be Normal, then the z-scores are \\(N(0,1)\\)"
  },
  {
    "objectID": "slides/slides-19-clt.html#warm-up",
    "href": "slides/slides-19-clt.html#warm-up",
    "title": "Central Limit Theorem",
    "section": "Warm-up",
    "text": "Warm-up\n\nLet \\(Z \\sim N(0,1)\\). If the 10th percentile of \\(Z\\) is -1.28, what is the 90th percentile?\nLet \\(X \\sim N(0,2)\\). If the 10th percentile of \\(X\\) is -2.56, what is the 90th percentile? Or can you not say without code?\nLet \\(Y \\sim N(2,1)\\). If the 10th percentile of \\(Y\\) is 0.72, what is the 90th percentile? Or can you not say without code?"
  },
  {
    "objectID": "slides/slides-19-clt.html#where-were-going",
    "href": "slides/slides-19-clt.html#where-were-going",
    "title": "Central Limit Theorem",
    "section": "Where we’re going",
    "text": "Where we’re going\n\nWe are going to learn one of the BIGGEST theorems in Statistics\nUses the Normal distribution, and will be immensely helpful for inference tasks of confidence intervals and hypothesis testing"
  },
  {
    "objectID": "slides/slides-19-clt.html#central-limit-theorem-clt",
    "href": "slides/slides-19-clt.html#central-limit-theorem-clt",
    "title": "Central Limit Theorem",
    "section": "Central Limit Theorem (CLT)",
    "text": "Central Limit Theorem (CLT)\n\nAssume that you have a sufficiently large sample of \\(n\\) independent values \\(x_{1},\\ldots, x_{n}\\) from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nThen the distribution of sample means is approximately Normal:\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\n\nThat is, the sampling distribution of the sample mean is approximately normal with mean \\(\\mu\\) and standard error \\(\\sigma/\\sqrt{n}\\)"
  },
  {
    "objectID": "slides/slides-19-clt.html#clt-assumptions",
    "href": "slides/slides-19-clt.html#clt-assumptions",
    "title": "Central Limit Theorem",
    "section": "CLT assumptions",
    "text": "CLT assumptions\n\nIndependent samples:\n\nUsually achieved by random sampling\n\nNormality condition:\n\nIf the data \\(x_{1},\\ldots, x_{n}\\) are known to be Normal and independent, then the distribution of \\(\\bar{X}\\) is exactly Normal\nIf data are not known to be Normal, then check:\n\nIf \\(n\\) is small \\((n < 30)\\): if there are no clear outliers, we assume data are approximately normal\nIf \\(n\\) is larger \\((30 \\leq n < ?)\\): if there are no particularly extreme outliers, we assume data are approximately normal\n\n\n\n\n\nIf any of these aren’t met, then we cannot use CLT"
  },
  {
    "objectID": "slides/slides-19-clt.html#normality-condition",
    "href": "slides/slides-19-clt.html#normality-condition",
    "title": "Central Limit Theorem",
    "section": "Normality condition",
    "text": "Normality condition\n\nDo you believe the normality condition is satisfied in the following two samples?\n\n\n\n\n\n\nSample 1: small \\(n < 30\\). But histogram and boxplot reveals no clear outliers, so I would say normality condition is met.\nSample 2: larger \\(n \\geq 30\\). Even though \\(n\\) is larger, there is a particularly extreme outlier, so I would say normality condition is not met."
  },
  {
    "objectID": "slides/slides-19-clt.html#activity",
    "href": "slides/slides-19-clt.html#activity",
    "title": "Central Limit Theorem",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "slides/slides-19-clt.html#height-example",
    "href": "slides/slides-19-clt.html#height-example",
    "title": "Central Limit Theorem",
    "section": "Height example",
    "text": "Height example\n\n\n\nThe average height of all NBA players in the 2008-9 season is 79.21 inches, with a population standard deviation of 3.57 inches. We randomly sampled 20 of these players and recorded their heights, as shown below.\n\n\n\nWhat is the sampling distribution of the sample mean heights? Do we know it exactly?"
  },
  {
    "objectID": "slides/slides-19-clt.html#height-example-solution",
    "href": "slides/slides-19-clt.html#height-example-solution",
    "title": "Central Limit Theorem",
    "section": "Height example: solution",
    "text": "Height example: solution\nWe don’t know if the data are Normal. But:\n\nIndependence? Yes: we have independent samples!\nNormality condition? Yes: even though we have small sample size, the histogram of the data looks approximately Normal (no clear outliers).\n\n\nSo CLT applies! By CLT: \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(79.21, \\frac{3.57}{\\sqrt{20}}\\right)\\)\n\n\n\n\nIf data instead looked like the following, I would say normality condition is violated:"
  },
  {
    "objectID": "slides/slides-19-clt.html#bank-example",
    "href": "slides/slides-19-clt.html#bank-example",
    "title": "Central Limit Theorem",
    "section": "Bank example",
    "text": "Bank example\nCustomers are standing in line at a bank.\n\nLet \\(X_{i}\\) represent the service time for customer \\(i\\).\nSuppose that the average service time for all customers is 5 minutes, with a standard deviation of 6 minutes.\n\n\n\nAssume that a bank currently has 36 customers in it, and all customers are independent of each other. What is the probability that the average service time of all these customers is less than 4 minutes?"
  },
  {
    "objectID": "slides/slides-19-clt.html#bank-example-solution",
    "href": "slides/slides-19-clt.html#bank-example-solution",
    "title": "Central Limit Theorem",
    "section": "Bank example: solution",
    "text": "Bank example: solution\n\nWe want \\(\\text{Pr}(\\bar{X} < 4)\\)\nConditions for CLT met: independence (random sample) and sufficiently large sample size \\((n=36)\\).\n\nSo by CLT, \\(\\bar{X} \\overset{\\cdot}{\\sim}N(5, \\frac{6}{\\sqrt{36}}) = N(5, 1)\\)\n\nUsing 68-95-99.7 rule, probability that the average service time of all these customers is less than 4 minutes is about \\(1 - (0.34 + 0.5) = 0.16\\)\n\npnorm(4, 5, 1) = 0.159"
  },
  {
    "objectID": "slides/slides-19-clt.html#proportion-as-a-mean",
    "href": "slides/slides-19-clt.html#proportion-as-a-mean",
    "title": "Central Limit Theorem",
    "section": "Proportion as a mean",
    "text": "Proportion as a mean\nRemember \\(\\hat{p}\\) is a sample mean! So the CLT applies to proportions as well!\n\\[\n\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i} \\qquad \\qquad x_{i} =\\{0, 1\\}\n\\]\n\nTypically, \\(x_{i} = 1\\) is read as “success” and \\(x_{i} = 0\\) as “failure”, so \\(p\\) is the population-level probability of success"
  },
  {
    "objectID": "slides/slides-19-clt.html#clt-for-proportions",
    "href": "slides/slides-19-clt.html#clt-for-proportions",
    "title": "Central Limit Theorem",
    "section": "CLT for proportions",
    "text": "CLT for proportions\nCLT for sample proportions: if we have \\(n\\) independent binary observations with \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\), then:\n\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\n\nWhat do the conditions \\(np \\geq 10\\) and \\(n(1-p)\\geq 10\\) mean?\n\nFor this reason, this is called the “success-failure” condition for CLT for proportions"
  },
  {
    "objectID": "slides/slides-19-clt.html#mms-example",
    "href": "slides/slides-19-clt.html#mms-example",
    "title": "Central Limit Theorem",
    "section": "M&M’s example",
    "text": "M&M’s example\nMars, Inc. is the company that makes M&M’s. In 2008, Mars changed their color distribution to have 13% red candies.\n\n\nLet \\(\\hat{p}\\) represent the proportion of red M&M’s in a random sample of \\(n\\) M&M’s. What is the sampling distribution of \\(\\hat{p}\\) if we take a random sample of sizes:\n\n\\(n = 100\\), vs.\n\\(n = 10\\)"
  },
  {
    "objectID": "slides/slides-19-clt.html#mms-example-solution",
    "href": "slides/slides-19-clt.html#mms-example-solution",
    "title": "Central Limit Theorem",
    "section": "M&M’s example: solution",
    "text": "M&M’s example: solution\n\nIndependence? Yes, due to the random sample.\nSuccess-failure? Depends…\n\n\n\n\nIf \\(n= 100\\):\n\n\\(np = 100(0.13) = 13 \\geq 10\\)\n\\(n(1-p) = 100(0.87) = 87 \\geq 10\\)\n\nSo CLT applies!\n\n\n\\[\n\\begin{align*}\n\\hat{p} &\\overset{\\cdot}{\\sim} N\\left(0.13, \\sqrt{\\frac{0.13(1-0.13)}{100}}\\right) \\\\\n&= N(0.13, 0.034 )\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-19-clt.html#mms-example-cont.",
    "href": "slides/slides-19-clt.html#mms-example-cont.",
    "title": "Central Limit Theorem",
    "section": "M&M’s example (cont.)",
    "text": "M&M’s example (cont.)\nThe following histograms display sampling distributions for \\(\\hat{p}\\) = proportion of red candies in random samples of size \\(n = \\{10, 50, 100, 200\\}\\):"
  },
  {
    "objectID": "slides/slides-19-clt.html#why-is-clt-so-important",
    "href": "slides/slides-19-clt.html#why-is-clt-so-important",
    "title": "Central Limit Theorem",
    "section": "Why is CLT so important?",
    "text": "Why is CLT so important?\n\nAllows statisticians safely assume that the mean’s sampling distribution is approximately Normal. The Normal distribution has nice properties and is easy to work with.\nCan be applied to both continuous and discrete numeric data!\nDoes not depend on the underlying distribution of the data.\n\n\nFor many of these reasons, we can use the CLT for inference!\nNOTE: we might not know what \\(\\mu\\) or \\(p\\) actually are, but CLT tells us that the sampling distributions of \\(\\bar{X}\\) and \\(\\hat{p}\\) are centered at their theoretical values!"
  },
  {
    "objectID": "slides/slides-19-clt.html#mathematical-cis",
    "href": "slides/slides-19-clt.html#mathematical-cis",
    "title": "Central Limit Theorem",
    "section": "Mathematical CIs",
    "text": "Mathematical CIs\n\nThe CLT gives us the sampling distribution of a sample mean “for free” (assuming conditions are met)\nFormula for a (symmetric) \\(\\gamma \\times 100\\%\\) confidence interval:\n\\[\n\\text{point estimate} \\pm \\underbrace{\\text{critical value} \\times \\text{SE}}_{\\text{Margin of Error}}\n\\]\n\npoint estimate: the “best guess” statistic from our observed data (e.g. \\(\\hat{p}_{obs}\\) and \\(\\bar{x}_{obs}\\))\nSE: standard error of the statistic\ncritical value: percentile that guarantees the \\(\\gamma\\times 100\\). This will vary depending on your data/assumptions"
  },
  {
    "objectID": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion",
    "href": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion",
    "title": "Central Limit Theorem",
    "section": "Towards a CI for a single proportion",
    "text": "Towards a CI for a single proportion\nSuppose that I have a sample of \\(n\\) binary values. Using the sample, I want a \\(\\gamma \\times 100\\%\\) confidence interval for the probability of success \\(p\\).\n\nIf assumptions of CLT for sample proportions hold, then we know\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\n\nHow do we know if success-failure condition holds without knowing \\(p\\)?\n\n\nLet’s use our best guess: \\(\\hat{p}_{obs}\\)\nSuccess-failure condition for confidence intervals: \\(n\\hat{p}_{obs}\\) and \\(n(1-\\hat{p}_{obs})\\) both \\(\\geq 10\\)"
  },
  {
    "objectID": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion-cont.",
    "href": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion-cont.",
    "title": "Central Limit Theorem",
    "section": "Towards a CI for a single proportion (cont.)",
    "text": "Towards a CI for a single proportion (cont.)\nWe can use/manipulate the CLT result to obtain a confidence interval for \\(p\\)!\n\nPoint estimate: \\(\\hat{p}_{obs}\\)\nStandard error: \\(SE = \\sqrt{\\frac{p(1-p)}{n}}\\)\n\nBut we still don’t have \\(p\\)!\nInstead, use the following approximation for CI:\n\n\n\n\\[\\widehat{\\text{SE}} \\approx \\sqrt{\\frac{\\hat{p}_{obs}(1-\\hat{p}_{obs})}{n}}\\]"
  },
  {
    "objectID": "slides/slides-19-clt.html#ci-for-single-proportion",
    "href": "slides/slides-19-clt.html#ci-for-single-proportion",
    "title": "Central Limit Theorem",
    "section": "CI for single proportion",
    "text": "CI for single proportion\nSo the formula for a (symmetric) \\(\\gamma\\times 100\\%\\) CI for \\(p\\) is:\n\n\\[\n\\hat{p}_{obs} \\pm z_{(1+\\gamma)/2}^{*}\\times \\sqrt{\\frac{\\hat{p}_{obs}(1-\\hat{p}_{obs})}{n}}\n\\]where the critical value \\(z^{*}_{(1+\\gamma)/2}\\) is obtained from \\(N(0,1)\\) distribution.\n\n\nNOTE: we could have obtained the CI directly from the sampling distribution of \\(\\hat{p}\\). However, the critical value of \\(z_{(1+\\gamma)/2}^{*}\\sim N(0,1)\\) is very general. Does not depend on the specific data you have!"
  },
  {
    "objectID": "slides/slides-19-clt.html#example",
    "href": "slides/slides-19-clt.html#example",
    "title": "Central Limit Theorem",
    "section": "Example",
    "text": "Example\nA poll of 100 randomly sampled registered voters in a town was conducted, asking voters if they support legalized marijuana. It was found that 60% of respondents were in support.\n\nWhat is the population parameter? What is the point estimate/statistic?\n\n\nFind a (symmetric) 90% confidence interval for the true proportion of town residents in favor of legalized marijuana.\n\n\n\nConditions met?\n\n\nIndependence: random sample\nSuccess-failure condition: \\(n\\hat{p}_{obs} =100(0.6) = 60 \\geq 10\\) and \\(n(1-\\hat{p}_{obs}) = 100(0.4) = 40 \\geq 10\\)\n\nBecause conditions for CLT are met, we can proceed."
  },
  {
    "objectID": "slides/slides-19-clt.html#example-cont.",
    "href": "slides/slides-19-clt.html#example-cont.",
    "title": "Central Limit Theorem",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nFind 90% CI for proportion of town residents in favor of legalized marijuana.\n\n\nGathering components for CI:\n\n\nPoint estimate: \\(\\hat{p}_{obs}\\) = 0.6\nStandard error: \\(\\widehat{SE} = \\sqrt{\\frac{0.6(0.4)}{100}} \\approx 0.049\\)\n\nCritical value: what percentiles do we want?\n\n\n\\(z_{0.95}^{*} =\\) qnorm(0.95, mean = 0, sd = 1) \\(\\approx 1.645\\)\n\n\n\nSo our 90% confidence interval for \\(p\\) is:\n\\[\n\\hat{p}_{obs} \\pm z^{*}_{0.95} \\widehat{SE} = 0.6 \\pm 1.645(0.049) = (0.519, 0.681)\n\\]\n\n\n\nInterpret the confidence interval in context!"
  },
  {
    "objectID": "slides/slides-19-clt.html#comprehension-questions",
    "href": "slides/slides-19-clt.html#comprehension-questions",
    "title": "Central Limit Theorem",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat is the main takeaway of the CLT?\nWhat are the assumptions of the CLT?\nWhat is the Normal approximation for CLT?\nHow do we construct a \\(\\gamma \\times 100\\%\\) confidence interval using a mathematical model?"
  },
  {
    "objectID": "slides/slides-19-clt.html#clt-for-sample-proportions",
    "href": "slides/slides-19-clt.html#clt-for-sample-proportions",
    "title": "Central Limit Theorem",
    "section": "CLT for sample proportions",
    "text": "CLT for sample proportions\nSuppose we have some true population proportion \\(p\\). If we take a sample of size \\(n\\) from the population, then the CLT tells us that sampling distribution of \\(\\hat{p}\\) is approximately Normal if we have:\n\nIndependence\n“Success-failure” condition: \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\)\n\n\nIf these two conditions hold, then by CLT:\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\n\n\nWhy is the condition called “success-failure”?\nAre you comfortable with using a Normal distribution to approximate the sampling distribution of \\(\\hat{p}\\)?"
  },
  {
    "objectID": "slides/slides-19-clt.html#flow-chart",
    "href": "slides/slides-19-clt.html#flow-chart",
    "title": "Central Limit Theorem",
    "section": "Flow chart",
    "text": "Flow chart\n\nLet’s make a flow chart!\nNOTE: we might not know what \\(\\mu\\) or \\(p\\) actually are, but CLT tells us that the sampling distributions of \\(\\bar{X}\\) and \\(\\hat{p}\\) are centered at their theoretical values!"
  },
  {
    "objectID": "slides/slides-19-clt.html#mms-example-solution-cont.",
    "href": "slides/slides-19-clt.html#mms-example-solution-cont.",
    "title": "Central Limit Theorem",
    "section": "M&M’s example: solution (cont.)",
    "text": "M&M’s example: solution (cont.)\n\nIf \\(n = 10\\):\n\n\\(np = 10(0.13) = 1.3 < 10\\)\n\nSuccess-failure condition not met. Cannot use CLT.\n\n\n\n\nIf we incorrectly applied CLT, we might think \\[\\begin{align*}\n\\hat{p} &\\overset{\\cdot}{\\sim} N\\left(0.13, \\sqrt{\\frac{0.13(1-0.13)}{10}}\\right) \\\\\n&=  N(0.13, 0.106 )\n\\end{align*}\\]\nWhat does this distribution look like?\n\n\n\n\nWhy is this scary??"
  },
  {
    "objectID": "slides/slides-19-clt.html#clt-again",
    "href": "slides/slides-19-clt.html#clt-again",
    "title": "Central Limit Theorem",
    "section": "CLT again",
    "text": "CLT again\nLet’s see it again: If the assumptions of independence and Normality condition apply, then\n\\[\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}} \\right)\\] where \\(\\mu\\) and \\(\\sigma\\) are the population mean and standard deviation, and \\(\\bar{X}\\) is the sample mean obtained from a sample of size \\(n\\).\n\n\nWhat does the \\(\\frac{\\sigma}{\\sqrt{n}}\\) represent?\nFor fixed \\(\\sigma\\), how does the sampling distribution change as \\(n\\) increases?"
  },
  {
    "objectID": "slides/slides-19-clt.html#compare-sampling-distribution-to-population-and-one-sample",
    "href": "slides/slides-19-clt.html#compare-sampling-distribution-to-population-and-one-sample",
    "title": "Central Limit Theorem",
    "section": "Compare sampling distribution to population and one sample",
    "text": "Compare sampling distribution to population and one sample\nNote: the y-axis is density (how likely each value of height is from the given distribution).\n\n\nWhat do you notice about how the three distributions compare? Are some distributions very similar? Are some very different? Why do you think this is?"
  },
  {
    "objectID": "slides/slides-19-clt.html#the-three-different-dists.",
    "href": "slides/slides-19-clt.html#the-three-different-dists.",
    "title": "Central Limit Theorem",
    "section": "The three different dists.",
    "text": "The three different dists.\nNote: \\(y\\)-axis is density (how likely each \\(x\\) value is from the given distribution).\n\n\nWhat do you notice about how the three distributions compare? Are some distributions very similar? Are some very different? Why do you think this is?"
  },
  {
    "objectID": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion-cont.-1",
    "href": "slides/slides-19-clt.html#towards-a-ci-for-a-single-proportion-cont.-1",
    "title": "Central Limit Theorem",
    "section": "Towards a CI for a single proportion (cont.)",
    "text": "Towards a CI for a single proportion (cont.)\n\nCritical value: to obtain the middle \\(\\gamma \\times 100\\%\\), use the \\(\\frac{1-\\gamma}{2}\\) and \\(\\frac{1+\\gamma}{2}\\) percentiles of the \\(N(0,1)\\) distribution\n\n\\(z_{(1-\\gamma)/2}^{*}\\) (lower bound) and \\(z_{(1+\\gamma)/2}^{*}\\) (upper bound)\nNote: \\(z_{(1+\\gamma)/2}^{*} = - z_{(1-\\gamma)/2}^{*}\\)"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#housekeeping",
    "href": "slides/slides-20-ht-prop.html#housekeeping",
    "title": "Test for single proportion with CLT",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours today 2:30-3:30pm!\nProject proposals due Wednesday"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#recap",
    "href": "slides/slides-20-ht-prop.html#recap",
    "title": "Test for single proportion with CLT",
    "section": "Recap",
    "text": "Recap\n\nCLT -> sampling distribution for sample means -> confidence intervals for populations means\nNow we’re returning to hypothesis testing!\n\nTwo sets of hypotheses (competing claims)\nCollect data, calculate a statistic from the observed data, set significance level\nObtain p-value from the null distribution\n\np-value: probability of observing data as or more extreme as our own, assuming \\(H_{0}\\) true\n\nMake a decision"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#hypothesis-testing-using-mathematical-model",
    "href": "slides/slides-20-ht-prop.html#hypothesis-testing-using-mathematical-model",
    "title": "Test for single proportion with CLT",
    "section": "Hypothesis testing using mathematical model",
    "text": "Hypothesis testing using mathematical model\n\nWe learned how to conduct hypothesis tests (HTs) using simulation to obtain null distribution\nBut we can also use CLT to obtain null distribution!\nSo the only step that will “look different” is #3: how we obtain our null distribution and p-value\n\nLooks different depending on type of data\n\nMake a conclusion in terms of \\(H_{A}\\)"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#steps-1-and-2-dont-change",
    "href": "slides/slides-20-ht-prop.html#steps-1-and-2-dont-change",
    "title": "Test for single proportion with CLT",
    "section": "Steps 1 and 2 don’t change",
    "text": "Steps 1 and 2 don’t change\nWant to conduct a hypothesis test about a population proportion.\n\nDefine hypotheses\n\n\\(H_{0}: p = p_{0}\\)\n\\(H_{A}: p \\neq p_{0}\\) (or \\(H_{A}: p > p_{0}\\) or \\(H_{A}: p < p_{0}\\))\nRemember, \\(p_{0}\\) is our “null hypothesized value”\n\n\n\n\nCollect data, set significance level\n\nObtain observed sample proportion \\(\\hat{p}_{obs}\\)\nSet \\(\\alpha\\) significance level"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#null-distribution-and-p-value",
    "href": "slides/slides-20-ht-prop.html#null-distribution-and-p-value",
    "title": "Test for single proportion with CLT",
    "section": "3. Null distribution and p-value",
    "text": "3. Null distribution and p-value\nRecall CLT for sample proportion: if we have \\(n\\) independent binary observations that satisfy the success-failure condition, then\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}} \\right)\n\\]\n\nThis is the sampling distribution of \\(\\hat{p}\\)\nBut we want the null distribution of \\(\\hat{p}\\): the sampling distribution under \\(H_{0}\\)\nWe should operate in a world where \\(H_{0}\\) is true\n\n\n\nWhat does this mean?\n\n\n\nSo to use CLT for null distribution, we must satisfy:\n\nIndependence\n\nSuccess-failure condition under \\(H_{0}\\): \\(np_{0} \\geq 10\\) and \\(n(1-p_{0}) \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#null-distribution-and-p-value-cont.",
    "href": "slides/slides-20-ht-prop.html#null-distribution-and-p-value-cont.",
    "title": "Test for single proportion with CLT",
    "section": "3. Null distribution and p-value (cont.)",
    "text": "3. Null distribution and p-value (cont.)\nIf CLT holds and \\(H_{0}\\) is true, then our null distribution is:\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p_{0}, \\sqrt{\\frac{p_{0} (1-p_{0})}{n}} \\right)\n\\]\n\nWe can standardize the null distribution by taking z-score:\n\n\n\\[\nZ = \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#test-statistic",
    "href": "slides/slides-20-ht-prop.html#test-statistic",
    "title": "Test for single proportion with CLT",
    "section": "Test statistic",
    "text": "Test statistic\n\np-value requires us to compare our observed data to the null distribution\nWe calculate a test statistic: a quantity that assesses how consistent our sampled data are with \\(H_{0}\\)\n\nOur test statistic is always of the form:\n\n\n\\[\\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}_{0}}\\] where \\(\\text{SE}_{0}\\) represents the standard error under \\(H_{0}\\)\n\n\nFor this specific test, our test statistic is the \\(z\\)-score of \\(\\hat{p}_{obs}\\):\n\n\n\\[z =\\frac{\\hat{p}_{\\text{obs}} - p_{0}}{\\sqrt{\\frac{p_{0} (1-p_{0})}{n}}}\\]\n\n\nBecause null distribution is Normal, this z-score follows \\(N(0,1)\\) distribution!"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#obtain-p-value",
    "href": "slides/slides-20-ht-prop.html#obtain-p-value",
    "title": "Test for single proportion with CLT",
    "section": "Obtain p-value",
    "text": "Obtain p-value\n\nIf \\(|z|\\) large, then that usually means observed value is extremely unusual for \\(H_{0}\\), which is convincing evidence against \\(H_{0}\\)\np-value is then \\(\\text{Pr}(Z \\geq z)\\) or \\(\\text{Pr}(Z \\leq z)\\) (or both), depending on \\(H_{A}\\)\n\nEasily obtained using pnorm()\n\nStep 4: doesn’t change!"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test",
    "href": "slides/slides-20-ht-prop.html#example-taste-test",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test",
    "text": "Example: taste test\nSome people claim that they can tell the difference between a diet soda and a regular soda in the first sip. A researcher wanted to test this claim using a hypothesis test at the 0.05 significance level.\n\nHe randomly sampled 80 people.\nHe then filled 80 plain white cups with soda, half diet and half regular through random assignment, and asked each person to take one sip from their cup and identify the soda as diet or regular.\n53 participants correctly identified the soda.\n\n\nLet \\(p\\) be the proportion of people who correctly identify soda type.\n\n\n\nTry defining \\(H_{0}\\) and \\(H_{A}\\)."
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test-cont.",
    "href": "slides/slides-20-ht-prop.html#example-taste-test-cont.",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\nDefine hypotheses\n\n\\(H_{0}\\): \\(p = 0.5\\) (random guessing)\n\\(H_{A}\\): \\(p > 0.5\\) (better than random guessing)\nNote: \\(p_{0} = 0.5\\) is our null hypothesized value!\n\nCollect data\n\n\\(\\hat{p}_{\\text{obs}} = \\frac{53}{80} = 0.6625\\)\n\n\n\nNote: significance level already determined to be 0.05"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test-cont.-1",
    "href": "slides/slides-20-ht-prop.html#example-taste-test-cont.-1",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\nObtain null distribution and p-value\n\n\nCheck conditions for inference satisfied\n\n\nIndependence: random sample\nsuccess-failure: \\(np_{0} = 80(0.5) = 40 \\geq 10\\) and \\(n(1-p_{0}) = 40 \\geq 10\\)\n\nBecause conditions for CLT are met, we can obtain the null distribution using CLT.\n\n\n\nNull distribution\n\n\n\\[\\hat{p} \\overset{\\cdot}{\\sim} N\\left(0.5, \\sqrt{\\frac{0.5(1-0.5)}{80}} = 0.056 \\right)\\]"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test-cont.-2",
    "href": "slides/slides-20-ht-prop.html#example-taste-test-cont.-2",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\n\nTest statistic:\n\n\n\\[z = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} = \\frac{0.6625 - 0.5}{0.056} = 2.90\\]\n\nThis means that if \\(H_{0}\\) true, our observed \\(\\hat{p}_{obs}\\) is 2.90 SDs above the mean\n\nDoes this seem like “convincing evidence”?"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-mms",
    "href": "slides/slides-20-ht-prop.html#example-mms",
    "title": "Test for single proportion with CLT",
    "section": "Example: M&M’s",
    "text": "Example: M&M’s\nM&M’s reported that 14% of its candies are yellow. We are interested in testing this claim. In a random sample of 100 M&M’s, 9 were found to be yellow. Conduct a hypothesis test via CLT at the \\(0.10\\) level.\n\n\n\n\nWrite out null and alternative hypotheses in statistical notation (don’t forget to define quantities)\nSummarise data and set \\(\\alpha\\)\nVerify conditions for CLT are met\n\n\n\n\n\\(H_{0}: p = 0.14\\) vs \\(H_{A}: p \\neq 0.14\\), where \\(p =\\) true proportion of yellow M&M’s\n\\(\\hat{p}_{obs} = \\frac{9}{100} = 0.09\\)\n\\(\\alpha = 0.10\\)\nIndependence? Yes, via random sample\nSuccess-failure: Yes: \\(np_{0} = 100(0.14) = 14 \\geq 10\\) and \\(n(1-p_{0}) = 86 \\geq 10\\)\n\n\n\n\n\nBecause conditions for CLT are met, we can obtain the null distribution using CLT."
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-mms-cont.",
    "href": "slides/slides-20-ht-prop.html#example-mms-cont.",
    "title": "Test for single proportion with CLT",
    "section": "Example: M&M’s (cont.)",
    "text": "Example: M&M’s (cont.)\n\n\nObtain null distribution and obtain observed test statistic\n\n\n\nBy CLT, our null distribution is \\(\\hat{p} \\overset{\\cdot}{\\sim} N\\left(0.14, \\sqrt{\\frac{0.14(1-0.14)}{100}} = 0.035 \\right)\\)\n\n\nTest statistic:\n\\[z = \\frac{\\hat{p}_{obs} - p_{0}}{\\text{SE}_{0}} = \\frac{0.09 - 0.14}{0.035} = -1.43\\]"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-mms-cont.-1",
    "href": "slides/slides-20-ht-prop.html#example-mms-cont.-1",
    "title": "Test for single proportion with CLT",
    "section": "Example: M&M’s (cont.)",
    "text": "Example: M&M’s (cont.)\n\n\nObtain p-value. First draw a picture, then write out in \\(\\text{Pr}()\\) notation and in code what we want to find.\n\n\n\n\n\n\n\n\n\n\n\n\nSince \\(H_{A}\\) is two-sided, we want \\[\\begin{align*}\n    &\\text{Pr}(Z \\leq -1.43 \\cup Z \\geq 1.43) \\\\\n    &= \\text{Pr}(Z \\leq -1.43) + \\text{Pr}(Z \\geq 1.43)  \\\\\n    &= 2\\times \\text{Pr}(Z \\leq -1.43) \\\\\n    \\end{align*}\\]\n\n\n2 * pnorm(-1.43, 0, 1)\n\n[1] 0.152717\n\n2 * (1-pnorm(1.43, 0, 1))\n\n[1] 0.152717"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#null-distribution-via-clt",
    "href": "slides/slides-20-ht-prop.html#null-distribution-via-clt",
    "title": "Test for single proportion with CLT",
    "section": "Null distribution via CLT",
    "text": "Null distribution via CLT\nRecall CLT for sample proportion: if we have \\(n\\) independent binary observations that satisfy the success-failure condition, then\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}} \\right)\n\\]\n\nThis is the sampling distribution of \\(\\hat{p}\\)\nBut we want the null distribution of \\(\\hat{p}\\): the sampling distribution under \\(H_{0}\\)\nWe should operate in a world where \\(H_{0}\\) is true\nSo to use CLT for null distribution, we must satisfy:\n\nIndependence\n\nSuccess-failure condition under \\(H_{0}\\): \\(np_{0} \\geq 10\\) and \\(n(1-p_{0}) \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#null-distribution-via-clt-cont.",
    "href": "slides/slides-20-ht-prop.html#null-distribution-via-clt-cont.",
    "title": "Test for single proportion with CLT",
    "section": "Null distribution via CLT (cont.)",
    "text": "Null distribution via CLT (cont.)\nIf succes-failure and independence conditions are met and \\(H_{0}\\) is true, then CLT tells us our null distribution is:\n\\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p_{0}, \\sqrt{\\frac{p_{0} (1-p_{0})}{n}} \\right)\n\\]\n\nThis is how the sample proportion would behave assuming \\(H_{0}\\) is true!\nWe will use this to see how crazy our \\(\\hat{p}_{obs}\\) is"
  },
  {
    "objectID": "slides/handout-20-ht-prop.html",
    "href": "slides/handout-20-ht-prop.html",
    "title": "Hypothesis test for single proportion via CLT",
    "section": "",
    "text": "Soda taste test example\nSome people claim they can tell the difference between a diet soda and a regular soda in the first sip. A researcher wanted to test this claim using a hypothesis test at the 0.05 significance level.\n\nHe randomly sampled 80 people who claimed they can tell the difference.\nHe then filled 80 plain white cups with soda, half diet and half regular through random assignment, and asked each person to take one sip from their cup and identify the soda as diet or regular.\n53 participants correctly identified the soda.\n\nLet \\(p\\) be the proportion of people who correctly identify soda type among people who think they can tell the difference.\n\nStep 1\n\\(H_{0}:\\)\n\\(H_{A}:\\)\n\n\nStep 2\nCalculate useful summary information and set \\(\\alpha\\)\n\n\nStep 3\nFind null distribution of \\(\\hat{p}\\) via CLT.\n\nCheck conditions:\n\nBecause conditions for CLT are __________, we _______ obtain the null distribution using CLT.\n\nObtain null distribution of \\(\\hat{p}\\):\n\nTo find p-value:\n\nCalculate our observed test statistic:\n\\[\n= \\frac{\\text{point est.} - \\text{null value}}{\\text{SE}_{0}}\n\\]\n\n\nCalculate p-value\n\nDraw a picture of a Normal distribution, and shade in the correct area\nWrite R code that corresponds to the probability of interest\n\n\n\n\nStep 4\nDecision:\nConclusion:\n\n\n\nM&Ms example\nM&M’s reported that 14% of its candies are yellow. We are interested in testing this claim. In a random sample of 100 M&M’s, 9 were found to be yellow. Conduct a hypothesis test via CLT at the \\(0.10\\) level.\n\nStep 1\n\n\n\nStep 2\n\n\n\nStep 3\nVerify conditions for CLT-based hypothesis test are met:\n\n\n\n\n\n\nBecause conditions for CLT are _________, we _______ obtain the null distribution using CLT.\n\nNull distribution: \n\nTo find p-value:\n\nCalculate our observed test statistic\n\n\nCalculate p-value\n\nDraw a picture of a Normal distribution, and shade in the correct area\nWrite probability statement and R code that corresponds to the probability of interest\n\n\n\n\nStep 4\nDecision:\nConclusion:"
  },
  {
    "objectID": "slides/slides-19-clt.html",
    "href": "slides/slides-19-clt.html",
    "title": "Central Limit Theorem",
    "section": "",
    "text": "Normal distribution: symmetric, bell-shaped curve that is described by mean \\(\\mu\\) and standard deviation \\(\\sigma\\)\n\nCommon model used to describe behavior of continuous variables\n\nUse area under the Normal curve to obtain probabilities\n68-95-99.7 rule\nz-score standardizes observations to allow for easier comparison: \\(z = \\frac{x- \\mu}{\\sigma}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html",
    "href": "slides/slides-21-ci-mean.html",
    "title": "CIs and HTs for a single mean",
    "section": "",
    "text": "Central Limit Theorem: if we have a sufficiently large sample of \\(n\\) independent observations from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\)\nWhen considering the special case of sample proportions, if success-failure condition is met, we have \\(\\hat{p} \\overset{\\cdot}{\\sim} N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\\)\nTo obtain a \\(\\gamma\\times 100\\%\\) CI for a mean, we use\n\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\n\nWe needed to replace the standard error with an estimate"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#checking-normality",
    "href": "slides/slides-21-ci-mean.html#checking-normality",
    "title": "CIs and HTs for a single mean",
    "section": "Checking normality",
    "text": "Checking normality\n\nRemember, CLT requires a sufficiently large sample size \\(n\\) or assumption of Normality of the underlying data.\nNo perfect way to check Normality, but rule of thumb:\n\nIf \\(n < 30\\) small: check that there are no clear outliers\nIf \\(n \\geq 30\\) large: check that there are no particularly extreme outliers"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#ci-for-a-single-mean-known-variance",
    "href": "slides/slides-21-ci-mean.html#ci-for-a-single-mean-known-variance",
    "title": "CIs and HTs for a single mean",
    "section": "CI for a single mean (known variance)",
    "text": "CI for a single mean (known variance)\nSuppose we want a \\(\\gamma\\times 100\\%\\) CI for population mean \\(\\mu\\).\n\nIf CLT holds, then we know\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\nSo our \\(\\gamma \\times 100\\%\\) CI for \\(\\mu\\) is:\n\\[\n\\text{point estimate} \\pm \\underbrace{\\text{critical value} \\times \\text{SE}}_{\\text{Margin of Error}} = \\bar{x}_{obs} \\pm z_{(1+\\gamma)/2}^* \\times \\frac{\\sigma}{\\sqrt{n}}\n\\]"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-age-at-marriage",
    "href": "slides/slides-21-ci-mean.html#example-age-at-marriage",
    "title": "CIs and HTs for a single mean",
    "section": "Example: age at marriage",
    "text": "Example: age at marriage\n\n\n\nIn 2006-2010, the CDC conducted a thorough survey asking US women their age at first marriage. Suppose it is known that the standard deviation of the ages at first marriage is 5 years. Suppose we randomly sample 25 US women and ask them their age at first marriage (plotted below). Their average age at marriage was 23.32.\n\n\n\n\n\n\n\n\nWhat is/are the population parameter(s)? What is the statistic?\n\n\n\nWe will obtain an 80% confidence interval for the mean age of US women at first marriage.\n\n\n\nAre conditions of CLT met?\nIf so, what does CLT tell us?"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-age-at-marriage-cont.",
    "href": "slides/slides-21-ci-mean.html#example-age-at-marriage-cont.",
    "title": "CIs and HTs for a single mean",
    "section": "Example: age at marriage (cont.)",
    "text": "Example: age at marriage (cont.)\n\nObtain an 80% confidence interval for the mean age of US women at first marriage.\n\n\nBecause we have a random sample (independence) and there are no outliers in the data (normality condition), we can proceed with CLT!\n\n\n\n\n\n\\[\\bar{X} \\overset{\\cdot}{\\sim}N\\left(\\mu, \\frac{5}{\\sqrt{25}}\\right) = N(\\mu, 1)\\]\n\n\n\nConstruct your confidence interval and interpret!\n\n\n\nPoint estimate: \\(\\bar{x}_{obs} = 23.32\\)\nStandard error: \\(\\text{SE} = 1\\)\nCritical value: \\(z_{0.9}^{*} =\\) qnorm(0.9, 0, 1) \\(= 1.28\\)\n\n\nSo our 80% confidence interval is \\(23.32 \\pm 1.28 \\times 1 = (22.04, 24.6)\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#utility-of-this-model",
    "href": "slides/slides-21-ci-mean.html#utility-of-this-model",
    "title": "CIs and HTs for a single mean",
    "section": "Utility of this model",
    "text": "Utility of this model\n\nThe previous formula for the confidence interval for \\(\\mu\\) relies on knowing \\(\\sigma\\)\nBut wait…\n\nWant to construct a CI for \\(\\mu\\) because we don’t know its value\nIf we don’t know \\(\\mu\\), it seems highly unlikely that we would know \\(\\sigma\\)!\n\nSo in practice, we will have to estimate standard error for \\(\\bar{X}\\):\n\n\n\\[\n    \\widehat{\\text{SE}} = \\frac{s}{\\sqrt{n}}\n\\]\nwhere \\(s\\) is the observed sample standard deviation\n\n\nRecall we did something similar for CI for \\(p\\), where we replaced \\(p\\) with \\(\\hat{p}_{obs}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#variance-issue",
    "href": "slides/slides-21-ci-mean.html#variance-issue",
    "title": "CIs and HTs for a single mean",
    "section": "Variance issue",
    "text": "Variance issue\n\nEstimating variance is extremely difficult when \\(n\\) is small, and still not great for large \\(n\\)\n\nThus, replacing \\(\\sigma\\) with \\(s\\) invalidates CLT\n\nSo if \\(\\sigma\\) is unknown, we cannot use the Normal approximation to model \\(\\bar{X}\\) for inferential tasks\nInstead, we will use a new distribution for inference calculations, called the \\(t\\)-distribution"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#t-distribution",
    "href": "slides/slides-21-ci-mean.html#t-distribution",
    "title": "CIs and HTs for a single mean",
    "section": "\\(t\\)-distribution",
    "text": "\\(t\\)-distribution\n\nThe \\(t\\)-distribution is symmetric and bell-curved (like the Normal distribution)\nHas “thicker tails” than the Normal distribution (the tails decay more slowly)\n\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-distribution is always centered at 0\nOne parameter: degrees of freedom (df) defines exact shape of the \\(t\\)\n\nDenoted \\(t_{df}\\) (e.g. \\(t_{1}\\) or \\(t_{20}\\))\n\n\n\n\n\nAs \\(df\\) increases, \\(t\\) resembles the \\(N(0,1)\\). When \\(df \\geq 30\\), the \\(t_{df}\\) is nearly identical to \\(N(0,1)\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#working-with-t-distribution",
    "href": "slides/slides-21-ci-mean.html#working-with-t-distribution",
    "title": "CIs and HTs for a single mean",
    "section": "Working with \\(t\\) distribution",
    "text": "Working with \\(t\\) distribution\n\n\n\nLet’s draw pictures for the following:\n\nWhat proportion of the \\(t_{2}\\)-distribution falls below -1.5?\nWhat value of the \\(t_{2}\\)-distribution has \\(70\\%\\) area lying below it?"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#t-distribution-in-r",
    "href": "slides/slides-21-ci-mean.html#t-distribution-in-r",
    "title": "CIs and HTs for a single mean",
    "section": "\\(t\\) distribution in R",
    "text": "\\(t\\) distribution in R\n\npnorm(x, mean, sd) and qnorm(%, mean, sd) used to find probabilities and percentiles for the Normal distribution\nAnalogous functions for \\(t\\)-distribution: pt(x, df) and qt(%, df)\n\n\n\n\n\n\n\n\n\n\n\npt(-1.5,df =2) = 0.1361966\n\n\n\n\n\n\n\n\n\n\nqt(0.7, df =2) = 0.6172134"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#ci-for-a-single-mean-unknown-variance",
    "href": "slides/slides-21-ci-mean.html#ci-for-a-single-mean-unknown-variance",
    "title": "CIs and HTs for a single mean",
    "section": "CI for a single mean (unknown variance)",
    "text": "CI for a single mean (unknown variance)\n\nStill require independent observations and the Normality condition for CLT\nGeneral formula for \\(\\gamma \\times 100\\%\\) CI is the same, but we simply change what goes into the margin of error.\n\n\n\\[\n\\text{point estimate} \\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} = \\bar{x}_{obs} \\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s}{\\sqrt{n}}\n\\]\n\n\n\\(df = n-1\\) (always for this CI)\ncritical value \\(t^*_{df, (1+\\gamma)/2}\\) = \\((1+\\gamma)/2\\) percentile of the \\(t_{df}\\) distribution"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-age-at-marriage-cont.-1",
    "href": "slides/slides-21-ci-mean.html#example-age-at-marriage-cont.-1",
    "title": "CIs and HTs for a single mean",
    "section": "Example: age at marriage (cont.)",
    "text": "Example: age at marriage (cont.)\nLet’s return to the age at marriage example. Once again, obtain an 80% CI for the average age of first marriage for US women, but now suppose we don’t know \\(\\sigma\\).\n\nIn our sample of \\(n = 25\\) women, we observed a sample mean of \\(23.32\\) years and a sample standard deviation of \\(s = 4.03\\) years.\n\n\n\n\n\nPoint estimate: \\(\\bar{x}_{obs} = 23.32\\)\nStandard error: \\(\\widehat{\\text{SE}} = \\frac{s}{\\sqrt{n}}= \\frac{4.03}{\\sqrt{25}} = 0.806\\)\nCritical value:\n\n\\(df = n-1 = 24\\)\n\\(t_{24, 0.9}^*\\) = qt(0.9, df =24) = 1.32\n\n\n\nSo our 80% confidence interval for \\(\\mu\\) is:\n\\[\n23.32 \\pm 1.32 \\times 0.806 = (22.26, 24.38)\n\\]"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#comparing-cis",
    "href": "slides/slides-21-ci-mean.html#comparing-cis",
    "title": "CIs and HTs for a single mean",
    "section": "Comparing CIs",
    "text": "Comparing CIs\n\n\nKnown variance:\n80% CI: (22.04, 24.6)\n\nUnknown variance:\n80% CI: (22.26, 24.38)\n\n\n\n\nHow do the two intervals compare?\n\nInterpretation of CI does not change even if we use a different model!"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#examples",
    "href": "slides/slides-21-ci-mean.html#examples",
    "title": "CIs and HTs for a single mean",
    "section": "Examples",
    "text": "Examples\nAssume that all conditions necessary for inference are satisfied.\n\n\n\nqnorm(0.90) = 1.28\nqnorm(0.95) = 1.64\nqnorm(0.975) = 1.96\n\n\n\nqt(0.90, df = 35) = 1.31\nqt(0.95, df = 35) = 1.69\nqt(0.975, df = 35) = 2.03\n\n\n\nqt(0.90, df = 36) = 1.31\nqt(0.95, df = 36) = 1.69\nqt(0.975, df = 36) = 2.03\n\n\n\n\n\nA 90% confidence interval for a population mean \\(\\mu\\) is given as \\((18.985, 21.015)\\). The interval was obtained based on a SRS for 36 observations. Calculate the sample mean and sample standard deviation.\nThe standard deviation for students at particular Ivy League college is 250 points. Two students, Raina and Luke, want to estimate the average SAT score of students at this college. They want their margin of error to be no more than 25 points.\n\nRaina wants to use a 90% confidence level. How large a sample does Raina need to collect?\nLuke wants to use a 95% confidence level. Without calculations, determine whether Luke’s sample should be larger or smaller than Raina’s. Explain your reasoning.\nCalculate the minimum sample size for Luke."
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#paired-data",
    "href": "slides/slides-21-ci-mean.html#paired-data",
    "title": "CIs and HTs for a single mean",
    "section": "Paired data",
    "text": "Paired data\nSuppose we have two sets of observations/data \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\ldots x_{n})\\) and \\(\\boldsymbol{y} = (y_{1}, y_{2}, \\ldots, y_{n})\\)\n\nThe data are considered paired data if each \\(x_{i}\\) corresponds to exactly one \\(y_{i}\\)\nExample: your score on the midterm and your score on the final\nWhen analyzing paired data, we are typically interested in the difference in outcomes of each pair of observations"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#paired-differences",
    "href": "slides/slides-21-ci-mean.html#paired-differences",
    "title": "CIs and HTs for a single mean",
    "section": "Paired differences",
    "text": "Paired differences\n\nLet \\(d_{i} = y_{i} - x_{i}\\) for each \\(i = 1,\\ldots, n\\) be the observed differences\nThe \\(d_{i}\\) come from larger population with true mean difference \\(\\mu_{d}\\) and standard deviation of differences \\(\\sigma_{d}\\)\nThe sample mean difference and sample standard deviation of the differences are\n\n\n\\[\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_{i} \\qquad \\qquad s_{d} = \\frac{1}{n-1}\\sum_{i=1}^{n} (d_{i} - \\bar{d})^2 \\]"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#clt-for-mean-difference-in-pairs",
    "href": "slides/slides-21-ci-mean.html#clt-for-mean-difference-in-pairs",
    "title": "CIs and HTs for a single mean",
    "section": "CLT for mean difference in pairs",
    "text": "CLT for mean difference in pairs\n\nSuppose the \\(n\\) observational units are independent and the distribution of the differences is approximately normal. Then CLT says:\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\nWe are usually interested in performing inference for \\(\\mu_{d}\\) when both \\(\\mu_{d}\\) and \\(\\sigma_{d}\\) unknown\nOur formula for \\(\\gamma\\times 100\\%\\) CI for \\(\\mu_{d}\\) is analogous to the formula for one mean when \\(\\sigma\\) unknown:\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{d} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s_{d}}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-zinc",
    "href": "slides/slides-21-ci-mean.html#example-zinc",
    "title": "CIs and HTs for a single mean",
    "section": "Example: zinc",
    "text": "Example: zinc\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Let’s answer this using a 95% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n  bottom surface\n1  0.430   0.415\n2  0.266   0.238\n3  0.567   0.390\n4  0.531   0.410\n5  0.707   0.605\n6  0.716   0.609\n\n\n\nAre the data paired? Does CLT apply?"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-zinc-cont.",
    "href": "slides/slides-21-ci-mean.html#example-zinc-cont.",
    "title": "CIs and HTs for a single mean",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\n\npoint estimate: \\(\\bar{d} = 0.0804\\)\nSE \\(\\approx\\) \\(\\frac{s_{d}}{\\sqrt{n}} = \\frac{0.052}{\\sqrt{10}} = 0.016\\)\n\ncritical value: what code would you write?\n\n\n\\(df = n-1 = 9\\)\n\\(t_{9, 0.975}^{*} =\\) qt(0.975,9) \\(= 2.26\\)\n\n\n\n\n\nSo our 95% confidence interval is:\n\\[0.0804 \\pm 2.26(0.016) = (0.044, 0.117)\\]\n\n\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Explain."
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#difference-of-two-means",
    "href": "slides/slides-21-ci-mean.html#difference-of-two-means",
    "title": "CIs and HTs for a single mean",
    "section": "Difference of two means",
    "text": "Difference of two means\nNow consider two populations under the condition that the data/populations are not paired.\nWe might be interested in learning about whether or not the means of each population are equal (think about the voice jitter homework problem)!\n\nLet \\(\\mu_{1}\\) and \\(\\mu_{2}\\) represent the population means for the two populations 1 and 2\nSamples of size \\(n_{1}\\) and \\(n_{2}\\) from each population, respectively\nWe might think it reasonable to use \\(\\bar{x}_{1} - \\bar{x}_{2}\\) as a point estimate for \\(\\mu_{1} - \\mu_{2}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#conditions-for-inference",
    "href": "slides/slides-21-ci-mean.html#conditions-for-inference",
    "title": "CIs and HTs for a single mean",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nNow that we have two populations, conditions for CLT and use of the \\(t\\)-distribution for inference will look slightly different:\n\nIndependence (extended): need data within and between the two groups\n\ne.g.the two data sets come from independent random samples or from a randomized experiment\n\nNormality: we need to check for approximate normality for both groups separately"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#ci-for-difference-in-two-means",
    "href": "slides/slides-21-ci-mean.html#ci-for-difference-in-two-means",
    "title": "CIs and HTs for a single mean",
    "section": "CI for difference in two means",
    "text": "CI for difference in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nPoint estimate\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\text{SE} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-voice-shimmer",
    "href": "slides/slides-21-ci-mean.html#example-voice-shimmer",
    "title": "CIs and HTs for a single mean",
    "section": "Example: voice shimmer",
    "text": "Example: voice shimmer\nLet’s consider the voice shimmer of PD vs non-PD patients from last week’s homework.\n\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: people with Parkinson’s Disease\nPopulation 2: people without Parkinson’s Disease\n\n\nResearch question: are average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-voice-shimmer-cont.",
    "href": "slides/slides-21-ci-mean.html#example-voice-shimmer-cont.",
    "title": "CIs and HTs for a single mean",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\nAre average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\n\n\n\n\n\n\nstatus\nn\nxbar\ns\n\n\n\n\nHealthy\n48\n0.163\n0.058\n\n\nPD\n147\n0.321\n0.208\n\n\n\n\n\n\n\n\n\n\nDo assumptions for CLT hold?\n\n\nIndependence: random sample!\nNormality condition: \\(n \\geq 30\\) in both groups with no particularly extreme outliers\n\n\n\nSet-up/find the following:\n\n\nPoint estimate\nStandard error\nCode for critical value"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-voice-shimmer-cont.-1",
    "href": "slides/slides-21-ci-mean.html#example-voice-shimmer-cont.-1",
    "title": "CIs and HTs for a single mean",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\n\n\n\nPoint estimate: \\(\\bar{x}_{\\text{PD}} - \\bar{x}_{\\text{H}} = 0.32 - 0.16 = 0.158\\)\nSE \\(\\approx \\sqrt{\\frac{s_{\\text{PD}}^2}{n_{\\text{PD}}} + \\frac{s_{\\text{H}}^2}{n_{\\text{H}}}} = \\sqrt{\\frac{0.21^2}{147} + \\frac{0.06^2}{48}} = 0.019\\)\nCritical value:\n\n\\(df = \\min\\{n_{\\text{PD}} -1, n_{\\text{H}} -1 \\} = \\min\\{147 - 1, 48- 1\\} = 47\\)\nWant \\(0.975\\)-th percentile of \\(t_{47}\\) distribution: qt(0.975, df =47) = 2.01\n\n\n\n\nPutting everything together, our 95% CI for \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\) is: \\[\n0.158 \\pm 2.01 \\times 0.019 = (0.12, 0.196)\n\\]\n\nInterpret this CI in context. Note: direction of difference matters!\nAre average voice shimmers different between people with and without Parkinson’s? Briefly explain why or why not."
  },
  {
    "objectID": "slides/slides-19-clt.html#housekeeping",
    "href": "slides/slides-19-clt.html#housekeeping",
    "title": "Central Limit Theorem",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nFinal project groups!\nNo office hours this Friday, but make-up hours Thursday 2:30-3:30pm"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#clt-recap",
    "href": "slides/slides-20-ht-prop.html#clt-recap",
    "title": "Test for single proportion with CLT",
    "section": "CLT recap",
    "text": "CLT recap\nStart off with a sample of size \\(n\\). Assuming independent observations,\n\n\n\nCLT for sample means\nAssume population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). If normality condition met: \\[\n\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right) \\quad \\text{or} \\quad \\bar{X} \\overset{\\cdot}{\\sim}  N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\n\n\nNormality condition\n\nExactly normal\nNot normal and \\(n < 30\\): no outliers\nNot normal and \\(n \\geq 30\\): no particularly extreme outliers\n\n\n\n\nCLT for sample proportions\nAssume population proportion \\(p\\). If success-failure condition met: \\[\n\\hat{p} \\overset{\\cdot}{\\sim} N\\left (p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\n\nSuccess-failure condition: \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#hypothesis-testing-recap",
    "href": "slides/slides-20-ht-prop.html#hypothesis-testing-recap",
    "title": "Test for single proportion with CLT",
    "section": "Hypothesis testing recap",
    "text": "Hypothesis testing recap\n\nNow we’re returning to hypothesis testing!\n\nTwo sets of hypotheses (competing claims)\nCollect data, calculate a statistic from the observed data, set significance level\nObtain p-value from the null distribution\n\np-value: probability of observing data as or more extreme as our own, assuming \\(H_{0}\\) true\n\nMake a decision"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test-cont.-3",
    "href": "slides/slides-20-ht-prop.html#example-taste-test-cont.-3",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\n\nCalculate p-value (i.e. draw picture, set-up the calculation, and/or write code)\n\n\n\n\n\n\n\n\n\n\n\\[\n\\text{p-value} = \\text{Pr}(Z \\geq z) = \\text{Pr}(Z \\geq 2.90)\n\\]\n\n1 - pnorm(2.90, 0, 1)\n\n[1] 0.001865813"
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-taste-test-cont.-4",
    "href": "slides/slides-20-ht-prop.html#example-taste-test-cont.-4",
    "title": "Test for single proportion with CLT",
    "section": "Example: taste test (cont.)",
    "text": "Example: taste test (cont.)\n\n\nDecision and conclusion\n\n\nSince our p-value of 0.0019 is less than our significance level of 0.05, we reject \\(H_{0}\\).\nThe data provide strong evidence that the rate of correctly identifying a soda for these people is better than random guessing."
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#example-mms-cont.-2",
    "href": "slides/slides-20-ht-prop.html#example-mms-cont.-2",
    "title": "Test for single proportion with CLT",
    "section": "Example: M&M’s (cont.)",
    "text": "Example: M&M’s (cont.)\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value of 0.153 is greater than our significance level of 0.10, we fail to reject \\(H_{0}\\).\nThe data do not provide strong enough evidence to suggest that the true proportion of yellow M&Ms is different from 14%."
  },
  {
    "objectID": "slides/slides-20-ht-prop.html#comprehension-questions",
    "href": "slides/slides-20-ht-prop.html#comprehension-questions",
    "title": "Test for single proportion with CLT",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhy/how do the CLT conditions and/or statements change when obtaining:\n\nSampling distribution of \\(\\hat{p}\\)\nNull distribution of \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#recap",
    "href": "slides/slides-21-ci-mean.html#recap",
    "title": "CIs and HTs for a single mean",
    "section": "Recap",
    "text": "Recap\n\n\n\n\nCLT: if we have a sufficiently large sample of \\(n\\) independent observations from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\)\nTo obtain a \\(\\gamma\\times 100\\%\\) CI via CLT, we use\n\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\n\nWe may need to replace the standard error with an estimate \\(\\widehat{SE}\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#remarks",
    "href": "slides/slides-21-ci-mean.html#remarks",
    "title": "CIs and HTs for a single mean",
    "section": "Remarks",
    "text": "Remarks\n\nInterpretation of CI does not change even if we use a different model!\n\nIf you have access to both \\(\\sigma\\) and \\(s\\), would should you use?\n\n\nYou should use \\(\\sigma\\)!"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#hypothesis-test-recap",
    "href": "slides/slides-21-ci-mean.html#hypothesis-test-recap",
    "title": "CIs and HTs for a single mean",
    "section": "Hypothesis test recap",
    "text": "Hypothesis test recap\n\nSet hypotheses\nCollect and summarise data, set \\(\\alpha\\)\nObtain null distribution and p-value\n\nFor CLT-based method, obtain test statistic\n\nDecision and conclusion"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#hypotheses-and-null-distribution",
    "href": "slides/slides-21-ci-mean.html#hypotheses-and-null-distribution",
    "title": "CIs and HTs for a single mean",
    "section": "Hypotheses and null distribution",
    "text": "Hypotheses and null distribution\nWant to conduct a hypothesis test for the mean \\(\\mu\\) of a population.\n\nHypotheses: \\(H_0: \\mu= \\mu_{0}\\) versus \\(H_{A}: \\mu \\neq \\mu_{0} \\ (\\text{or } \\mu > \\mu_{0} \\text{ or } \\mu < \\mu_{0})\\)\nVerify conditions for CLT\n\nIndependence\nApproximate normality or large sample size\n\nThen from population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), we have \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\)\n\nWhat does the (approximate) null distribution for \\(\\bar{X}\\) look like?\n\n\n\n\\[\n\\bar{X} \\overset{\\cdot}{\\sim}  N\\left(\\boldsymbol{\\mu_{0}}, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#z-test-and-t-test-statistics",
    "href": "slides/slides-21-ci-mean.html#z-test-and-t-test-statistics",
    "title": "CIs and HTs for a single mean",
    "section": "z-test and t-test statistics",
    "text": "z-test and t-test statistics\nOur test statistic is always of the form:\n\\[\n\\frac{\\text{observed} - \\text{null}}{\\text{SE}} \\qquad \\text{ or } \\qquad \\frac{\\text{observed} - \\text{null}}{\\widehat{\\text{SE}}}\n\\]\n\n\n\nIf \\(\\sigma\\) known and CLT met, we perform a z-test where our test-statistic is:\n\n\n\\[z = \\frac{\\bar{x}_{obs} - \\mu_{0}}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)\\]\nand we obtain our p-value using pnorm()\n\n\n\nIf \\(\\sigma\\) unknown and CLT met, we perform a t-test by estimating \\(\\sigma\\) with \\(s\\). Our test statistic is:\n\n\n\\[\nt = \\frac{\\bar{x}_{obs} - \\mu_{0}}{\\frac{s}{\\sqrt{n}}} \\sim t_{df} \\qquad df = n-1\n\\]\nand we obtain our p-value using pt()\n\n\n\n\nEverything else proceeds as usual!"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-salinity",
    "href": "slides/slides-21-ci-mean.html#example-salinity",
    "title": "CIs and HTs for a single mean",
    "section": "Example: salinity",
    "text": "Example: salinity\nThe salinity level in a body of water is important for ecosystem function.\n\n\n\nWe have 30 salinity level measurements (ppt) collected from a random sample of water masses in the Bimini Lagoon, Bahamas.\n\n\nWe want to test if the average salinity level in Bimini Lagoon is different from 38 ppm at the \\(\\alpha = 0.05\\) level."
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-salinity-cont.",
    "href": "slides/slides-21-ci-mean.html#example-salinity-cont.",
    "title": "CIs and HTs for a single mean",
    "section": "Example: salinity (cont.)",
    "text": "Example: salinity (cont.)\n\n\nSet hypotheses (define parameters as necessary).\n\n\nLet \\(\\mu\\) be the average salinity level in Bimini Lagoon in ppt.\n\\(H_{0}: \\mu = 38\\) versus \\(H_{A}: \\mu \\neq 38\\)\n\nCollect summary information, set \\(\\alpha\\).\n\n\n\n\n\n\\(\\bar{x}_{obs} = 38.6\\)\n\\(s = 1.29\\)\n\\(n = 30\\)\n\\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-salinity-cont.-1",
    "href": "slides/slides-21-ci-mean.html#example-salinity-cont.-1",
    "title": "CIs and HTs for a single mean",
    "section": "Example: salinity (cont.)",
    "text": "Example: salinity (cont.)\n\n\n\n\n\nObtain null distribution, test statistic, and p-value\n\nCheck conditions for CLT\nIf conditions met, obtain null distribution and test-statistic, and determine distribution of test-statistic\n\n\n\n\nConditions:\n\nIndependence: random sample\nApproximate normality: \\(n = 30\\), but no clear outliers\n\nSo by CLT, null dist. is \\(\\bar{X} \\overset{\\cdot}{\\sim} N\\left(38, \\frac{\\sigma}{\\sqrt{30}}\\right)\\)\nSince we don’t know \\(\\sigma\\), we perform a \\(t\\)-test and obtain the following test-statistic:\n\n\\(t = \\frac{\\bar{x}_{obs} - \\mu_{0}}{\\widehat{SE}} = \\frac{38.6 - 38}{1.29 / \\sqrt{30}} = 2.543\\)\nThis test-statistic follows a \\(t_{29}\\) distribution"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-salinity-cont.-2",
    "href": "slides/slides-21-ci-mean.html#example-salinity-cont.-2",
    "title": "CIs and HTs for a single mean",
    "section": "Example: salinity (cont.)",
    "text": "Example: salinity (cont.)\n\n\nUse test-statistic to obtain p-value (draw picture and/or write code using appropriate distribution)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWant \\(P(T \\geq 2.54) + P(T \\leq 2.54)\\) because \\(H_{A}\\) is two-sided!\n\np_val <- 2 * (1 - pt(t, df = n-1))\np_val\n\n[1] 0.01658569"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#example-salinity-cont.-3",
    "href": "slides/slides-21-ci-mean.html#example-salinity-cont.-3",
    "title": "CIs and HTs for a single mean",
    "section": "Example: salinity (cont.)",
    "text": "Example: salinity (cont.)\n\nDecision and conclusion\n\n\nSince our p-value 0.017 is less than 0.05, we reject \\(H_{0}\\).\nThe data do provide sufficient evidence to suggest that the average salinity level in Bimini Lagoon is different from 38 ppt.\n\n\nLet’s code it up together!"
  },
  {
    "objectID": "live_code/ht_single_mean_clt.html",
    "href": "live_code/ht_single_mean_clt.html",
    "title": "Hypothesis test for single mean (CLT)",
    "section": "",
    "text": "Data salinity come from openintro.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n# visualize and get a feel for the data (important for CLT conditions)\nx <- salinity$salinity_ppt\nn <- length(x)\nggplot(salinity, aes(x = salinity_ppt)) +\n  geom_histogram(bins = 10)\n\n\n\n# create test statistic\nxbar <- mean(x)\ns <- sd(x)\nmu0 <- 38\nse <- s / sqrt(n)\nt <- (xbar - mu0)/se\nt\n\n[1] 2.543329\n\n# obtain p-value\ndf <- n-1\n# option 1\np_val <- 2 * (1 - pt(t, df))\np_val\n\n[1] 0.01657298\n\n# option 2: works no matter if t is positive or negative\np_val <- 2 * (1 - pt(abs(t), df))\np_val\n\n[1] 0.01657298"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#paired-data",
    "href": "slides/slides-21-ht-diff-means.html#paired-data",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Paired data",
    "text": "Paired data\nSuppose we have two sets of observations/data \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\ldots x_{n})\\) and \\(\\boldsymbol{y} = (y_{1}, y_{2}, \\ldots, y_{n})\\)\n\nThe data are considered paired data if each \\(x_{i}\\) corresponds to exactly one \\(y_{i}\\)\nExample: your score on the midterm and your score on the final\nWhen analyzing paired data, we are typically interested in the difference in outcomes of each pair of observations"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#paired-differences",
    "href": "slides/slides-21-ht-diff-means.html#paired-differences",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Paired differences",
    "text": "Paired differences\n\nLet \\(d_{i} = y_{i} - x_{i}\\) for each \\(i = 1,\\ldots, n\\) be the observed differences\nThe \\(d_{i}\\) come from larger population with true mean difference \\(\\mu_{d}\\) and standard deviation of differences \\(\\sigma_{d}\\)\nThe sample mean difference and sample standard deviation of the differences are\n\n\n\\[\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_{i} \\qquad \\qquad s_{d} = \\frac{1}{n-1}\\sum_{i=1}^{n} (d_{i} - \\bar{d})^2 \\]"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#clt-for-mean-difference-in-pairs",
    "href": "slides/slides-21-ht-diff-means.html#clt-for-mean-difference-in-pairs",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "CLT for mean difference in pairs",
    "text": "CLT for mean difference in pairs\n\nSuppose the \\(n\\) observational units are independent and the distribution of the differences is approximately normal. Then CLT says:\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\nWe are usually interested in performing inference for \\(\\mu_{d}\\) when both \\(\\mu_{d}\\) and \\(\\sigma_{d}\\) unknown\nOur formula for \\(\\gamma\\times 100\\%\\) CI for \\(\\mu_{d}\\) is analogous to the formula for one mean when \\(\\sigma\\) unknown:\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{d} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s_{d}}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-zinc",
    "href": "slides/slides-21-ht-diff-means.html#example-zinc",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: zinc",
    "text": "Example: zinc\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Let’s answer this using a 95% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n  bottom surface\n1  0.430   0.415\n2  0.266   0.238\n3  0.567   0.390\n4  0.531   0.410\n5  0.707   0.605\n6  0.716   0.609\n\n\n\nAre the data paired? Does CLT apply?"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#difference-of-two-means",
    "href": "slides/slides-21-ht-diff-means.html#difference-of-two-means",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Difference of two means",
    "text": "Difference of two means\nNow consider two populations under the condition that the data/populations are not paired.\nWe might be interested in learning about whether or not the means of each population are equal (think about the voice jitter homework problem)!\n\nLet \\(\\mu_{1}\\) and \\(\\mu_{2}\\) represent the population means for the two populations 1 and 2\nSamples of size \\(n_{1}\\) and \\(n_{2}\\) from each population, respectively\nWe might think it reasonable to use \\(\\bar{x}_{1} - \\bar{x}_{2}\\) as a point estimate for \\(\\mu_{1} - \\mu_{2}\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#conditions-for-inference",
    "href": "slides/slides-21-ht-diff-means.html#conditions-for-inference",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nNow that we have two populations, conditions for CLT and use of the \\(t\\)-distribution for inference will look slightly different:\n\nIndependence (extended): need data within and between the two groups\n\ne.g.the two data sets come from independent random samples or from a randomized experiment\n\nNormality: we need to check for approximate normality for both groups separately"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#ci-for-difference-in-two-means",
    "href": "slides/slides-21-ht-diff-means.html#ci-for-difference-in-two-means",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "CI for difference in two means",
    "text": "CI for difference in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\n\nPoint estimate\n\n\n\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\ncritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\text{SE} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-c02-concentrations",
    "href": "slides/slides-21-ht-diff-means.html#example-c02-concentrations",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: C02 concentrations",
    "text": "Example: C02 concentrations\n\nThe Mauna Loa Observatory in Hawaii of monitors atmospheric solar, atmospheric, and meteorological parameters\nContinuous measurements of atmospheric carbon dioxide (C02) began in March 1958\nWe have data on annual atmospheric C02 concentrations from 2000-2015.\nWe will conduct a hypothesis test to see if the average atmospheric C02 levels (ppm) from 2000-2015 is different from 350 ppm.\n\n\n\nRows: 66 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): year, mean, unc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-voice-shimmer",
    "href": "slides/slides-21-ht-diff-means.html#example-voice-shimmer",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: voice shimmer",
    "text": "Example: voice shimmer\nLet’s consider the voice shimmer of PD vs non-PD patients from last week’s homework.\n\n\nRows: 195 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): clip, status\ndbl (4): jitter, shimmer, hnr, avg.f.q\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: people with Parkinson’s Disease\nPopulation 2: people without Parkinson’s Disease\n\n\nResearch question: are average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\)"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-voice-shimmer-cont.",
    "href": "slides/slides-21-ht-diff-means.html#example-voice-shimmer-cont.",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\nAre average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\n\n\n\n\n\n\nstatus\nn\nxbar\ns\n\n\n\n\nHealthy\n48\n0.163\n0.058\n\n\nPD\n147\n0.321\n0.208\n\n\n\n\n\n\n\n\n\n\nDo assumptions for CLT hold?\n\n\nIndependence: random sample!\nNormality condition: \\(n \\geq 30\\) in both groups with no particularly extreme outliers\n\n\n\nSet-up/find the following:\n\n\nPoint estimate\nStandard error\nCode for critical value"
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-voice-shimmer-cont.-1",
    "href": "slides/slides-21-ht-diff-means.html#example-voice-shimmer-cont.-1",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\n\n\n\nPoint estimate: \\(\\bar{x}_{\\text{PD}} - \\bar{x}_{\\text{H}} = 0.32 - 0.16 = 0.158\\)\nSE \\(\\approx \\sqrt{\\frac{s_{\\text{PD}}^2}{n_{\\text{PD}}} + \\frac{s_{\\text{H}}^2}{n_{\\text{H}}}} = \\sqrt{\\frac{0.21^2}{147} + \\frac{0.06^2}{48}} = 0.019\\)\nCritical value:\n\n\\(df = \\min\\{n_{\\text{PD}} -1, n_{\\text{H}} -1 \\} = \\min\\{147 - 1, 48- 1\\} = 47\\)\nWant \\(0.975\\)-th percentile of \\(t_{47}\\) distribution: qt(0.975, df =47) = 2.01\n\n\n\n\nPutting everything together, our 95% CI for \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\) is: \\[\n0.158 \\pm 2.01 \\times 0.019 = (0.12, 0.196)\n\\]\n\nInterpret this CI in context. Note: direction of difference matters!\nAre average voice shimmers different between people with and without Parkinson’s? Briefly explain why or why not."
  },
  {
    "objectID": "slides/slides-21-ht-diff-means.html#example-zinc-cont.-2",
    "href": "slides/slides-21-ht-diff-means.html#example-zinc-cont.-2",
    "title": "Hypothesis testing with CLT (cont.)",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\\[t = \\frac{\\bar{d}_{obs} - \\mu_{0}}{s_{d}/\\sqrt{n}} = \\frac{0.0804 - 0}{0.052/\\sqrt{10}} = 4.889  \\sim t_{9}\\]\n\n\nSo our p-value is \\(\\text{Pr}(T \\geq t) = \\text{Pr}(T \\geq 4.889) = 1 - \\texttt{pt(4.889, 9)} = 0\\)\nWe reject \\(H_{0}\\)! The data provide convincing evidence that zinc concentrations of bottom well water is greater than those of surface water."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html",
    "href": "slides/slides-22-ht-ci-diffs.html",
    "title": "HTs and CIs for differences",
    "section": "",
    "text": "Project proposals due tonight!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#recap",
    "href": "slides/slides-22-ht-ci-diffs.html#recap",
    "title": "HTs and CIs for differences",
    "section": "Recap",
    "text": "Recap\n\nTest and CI for a single mean\n\nIf we know \\(\\sigma\\), use standard Normal distribution\nIf we don’t know \\(\\sigma\\) and only have access to \\(s\\), use \\(t\\) distribution"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#paired-data",
    "href": "slides/slides-22-ht-ci-diffs.html#paired-data",
    "title": "HTs and CIs for differences",
    "section": "Paired data",
    "text": "Paired data\nSuppose we have two sets of observations/data \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\ldots x_{n})\\) and \\(\\boldsymbol{y} = (y_{1}, y_{2}, \\ldots, y_{n})\\)\n\nThe data are considered paired data if each \\(x_{i}\\) corresponds to exactly one \\(y_{i}\\)\nExample: your score on the midterm and your score on the final\nWhen analyzing paired data, we are typically interested in the difference in outcomes of each pair of observations"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#paired-differences",
    "href": "slides/slides-22-ht-ci-diffs.html#paired-differences",
    "title": "HTs and CIs for differences",
    "section": "Paired differences",
    "text": "Paired differences\n\nLet \\(d_{i} = y_{i} - x_{i}\\) for each \\(i = 1,\\ldots, n\\) be the observed differences\nThe \\(d_{i}\\) come from larger population with true mean difference \\(\\mu_{d}\\) and standard deviation of differences \\(\\sigma_{d}\\)\nThe sample mean difference and sample standard deviation of the differences are\n\n\n\\[\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_{i} \\qquad \\qquad s_{d} = \\frac{1}{n-1}\\sum_{i=1}^{n} (d_{i} - \\bar{d})^2 \\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#clt-for-mean-difference-in-pairs",
    "href": "slides/slides-22-ht-ci-diffs.html#clt-for-mean-difference-in-pairs",
    "title": "HTs and CIs for differences",
    "section": "CLT for mean difference in pairs",
    "text": "CLT for mean difference in pairs\n\nSuppose the \\(n\\) observational units are independent and the distribution of the differences is approximately normal. Then CLT says:\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\nWe are usually interested in performing inference for \\(\\mu_{d}\\) when both \\(\\mu_{d}\\) and \\(\\sigma_{d}\\) unknown\nOur formula for \\(\\gamma\\times 100\\%\\) CI for \\(\\mu_{d}\\) is analogous to the formula for one mean when \\(\\sigma\\) unknown:\n\n\n\\[\n\\begin{align*}\n\\text{point estimate} &\\pm t^*_{df, (1+\\gamma)/2} \\times \\widehat{\\text{SE}} \\\\\n\\bar{d} &\\pm t_{df, (1+\\gamma)/2}^* \\times \\frac{s_{d}}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-zinc",
    "href": "slides/slides-22-ht-ci-diffs.html#example-zinc",
    "title": "HTs and CIs for differences",
    "section": "Example: zinc",
    "text": "Example: zinc\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Let’s answer this using a 95% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n  bottom surface\n1  0.430   0.415\n2  0.266   0.238\n3  0.567   0.390\n4  0.531   0.410\n5  0.707   0.605\n6  0.716   0.609\n\n\n\nAre the data paired? Does CLT apply?"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.",
    "title": "HTs and CIs for differences",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\nFind the test-statistic"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#difference-of-two-means",
    "href": "slides/slides-22-ht-ci-diffs.html#difference-of-two-means",
    "title": "HTs and CIs for differences",
    "section": "Difference of two means",
    "text": "Difference of two means\nNow consider two populations under the condition that the data/populations are not paired.\nWe might be interested in learning about whether or not the means of each population are equal (think about the voice jitter homework problem)!\n\nLet \\(\\mu_{1}\\) and \\(\\mu_{2}\\) represent the population means for the two populations 1 and 2\nSamples of size \\(n_{1}\\) and \\(n_{2}\\) from each population, respectively\nWe might think it reasonable to use \\(\\bar{x}_{1} - \\bar{x}_{2}\\) as a point estimate for \\(\\mu_{1} - \\mu_{2}\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#conditions-for-inference",
    "href": "slides/slides-22-ht-ci-diffs.html#conditions-for-inference",
    "title": "HTs and CIs for differences",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nNow that we have two populations, conditions for CLT and use of the \\(t\\)-distribution for inference will look slightly different:\n\nIndependence (extended): need data within and between the two groups\n\ne.g.the two data sets come from independent random samples or from a randomized experiment\n\nNormality: we need to check for approximate normality for both groups separately"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ci-for-difference-in-two-means",
    "href": "slides/slides-22-ht-ci-diffs.html#ci-for-difference-in-two-means",
    "title": "HTs and CIs for differences",
    "section": "CI for difference in two means",
    "text": "CI for difference in two means\nIf the conditions hold, then our usual formula for \\(\\gamma \\times 100\\%\\) CI still holds:\n\\[\n\\text{point estimate} \\pm \\text{critical value} \\times \\text{SE}\n\\]\nPoint estimate: \\(\\bar{x}_{1,obs} - \\bar{x}_{2,obs}\\)\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) known:\n\n\n\\(\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}\\)\nCritical value: \\(z_{(1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(N(0,1)\\)\n\n\n\n\nIf \\(\\sigma_{1}\\) and \\(\\sigma_{2}\\) unknown:\n\n\n\\(\\widehat{\\text{SE}} \\approx \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}\\)\ncritical value: \\(t_{df, (1+\\gamma)/2}^*\\)\n\n\\((1+\\gamma)/2\\) percentile of \\(t_{df}\\)\n\\(df = \\min\\{n_{1} -1, n_{2} - 1\\}\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-c02-concentrations",
    "href": "slides/slides-22-ht-ci-diffs.html#example-c02-concentrations",
    "title": "HTs and CIs for differences",
    "section": "Example: C02 concentrations",
    "text": "Example: C02 concentrations\n\nThe Mauna Loa Observatory in Hawaii of monitors atmospheric solar, atmospheric, and meteorological parameters\nContinuous measurements of atmospheric carbon dioxide (C02) began in March 1958\nWe have data on annual atmospheric C02 concentrations from 2000-2015.\nWe will conduct a hypothesis test to see if the average atmospheric C02 levels (ppm) from 2000-2015 is different from 350 ppm."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer",
    "href": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer",
    "title": "HTs and CIs for differences",
    "section": "Example: voice shimmer",
    "text": "Example: voice shimmer\nLet’s consider the voice shimmer of PD vs non-PD patients from last week’s homework.\n\n\n\n\nConvince yourself that this data isn’t paired!\n\n\nPopulation 1: people with Parkinson’s Disease\nPopulation 2: people without Parkinson’s Disease\n\n\nResearch question: are average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\nWe care about the difference in means \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer-cont.",
    "title": "HTs and CIs for differences",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\nAre average voice shimmers different between people with and without Parkinson’s? Create a 95% confidence interval to answer this question.\n\n\n\n\n\n\n\n\nDo assumptions for CLT hold?\n\n\nIndependence: random sample!\nNormality condition: \\(n \\geq 30\\) in both groups with no particularly extreme outliers\n\n\n\nSet-up/find the following:\n\n\nPoint estimate\nStandard error\nCode for critical value"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#example-voice-shimmer-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Example: voice shimmer (cont.)",
    "text": "Example: voice shimmer (cont.)\n\n\n\n\nPoint estimate: \\(\\bar{x}_{\\text{PD}} - \\bar{x}_{\\text{H}} = 385.02 - 353.12 = 31.9\\)\nSE \\(\\approx \\sqrt{\\frac{s_{\\text{PD}}^2}{n_{\\text{PD}}} + \\frac{s_{\\text{H}}^2}{n_{\\text{H}}}} = \\sqrt{\\frac{9.9^2}{16} + \\frac{9^2}{20}} = 3.19\\)\nCritical value:\n\n\\(df = \\min\\{n_{\\text{PD}} -1, n_{\\text{H}} -1 \\} = \\min\\{16 - 1, 20- 1\\} = 15\\)\nWant \\(0.975\\)-th percentile of \\(t_{15}\\) distribution: qt(0.975, df =15) = 2.13\n\n\n\n\nPutting everything together, our 95% CI for \\(\\mu_{\\text{PD}} - \\mu_{\\text{H}}\\) is: \\[\n31.9 \\pm 2.13 \\times 3.19 = (25.105, 38.695)\n\\]\n\nInterpret this CI in context. Note: direction of difference matters!\nAre average voice shimmers different between people with and without Parkinson’s? Briefly explain why or why not."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#paired-data-recap",
    "href": "slides/slides-22-ht-ci-diffs.html#paired-data-recap",
    "title": "HTs and CIs for differences",
    "section": "Paired data (recap)",
    "text": "Paired data (recap)\n\nRecall paired data: we have two set of data \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) where each \\(x_{i}\\) has a corresponding to one \\(y_{i}\\)\n\nCan obtain differences \\(d_{i} = y_{i} - x_{i}\\)\nWe are interested in the true mean difference \\(\\mu_{d}\\)\n\nRecall: if observational units are independent and the differences are approximately Normal, then CLT gives us:\n\n\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_{d}, \\frac{\\sigma_{d}}{\\sqrt{n}}\\right)\n\\]\n\n\nWe don’t typically know \\(\\sigma_{d}\\), so replace with sample \\(s_{d}\\) (and then use \\(t\\) distribution)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\nHypotheses: \\(H_0: \\mu_{d} = \\mu_{0}\\) versus \\(H_{A}: \\mu_{d} \\neq \\mu_0\\) (or \\(>\\) or \\(<\\) )\nObtain summary statistics \\(\\bar{d}_{obs}\\) and \\(s_{d}\\)\n\nCheck if CLT holds. If so, what is our null distribution?\n\n\n\n\\[\n\\bar{d} \\overset{\\cdot}{\\sim} N\\left(\\mu_0, \\frac{\\sigma_{d}}{\\sqrt{n}} \\right)\n\\]\n\n\n\nBecause we don’t know \\(\\sigma_{d}\\), our test statistic here is:\n\n\n\n\\[\nt = \\frac{\\bar{d}_{obs} - \\mu_0}{\\frac{s_{d}}{\\sqrt{n}}} \\sim t_{df}\n\\]\nwhere \\(df = n-1\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-zinc-revisited",
    "href": "slides/slides-22-ht-ci-diffs.html#example-zinc-revisited",
    "title": "HTs and CIs for differences",
    "section": "Example: zinc (revisited)",
    "text": "Example: zinc (revisited)\n\n\n\nData consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:\n\nDo the data suggest that the true average concentration in the bottom water is greater than that of surface water? Let’s now answer this using a hypothesis test at the 0.05 level.\n\n\n\nDefine parameters and hypotheses\n\n\nLet \\(\\mu_{d}\\) be the true mean difference between zinc concentrations (bottom-surface)\n\\(H_{0}: \\mu_{d} = 0\\) versus \\(H_{A}: \\mu_{d} > 0\\)\n\nLast week, we saw conditions for CLT were satisfied"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\\[t = \\frac{\\bar{d}_{obs} - \\mu_{0}}{s_{d}/\\sqrt{n}} = \\frac{0.0804 - 0}{0.052/\\sqrt{10}} = 4.889  \\sim t_{9}\\]\n\n\nSo our p-value is \\(\\text{Pr}(T \\geq t) = \\text{Pr}(T \\geq 4.889) = 1 - \\texttt{pt(4.889, 9)} = 0\\)\nWe reject \\(H_{0}\\)! The data provide convincing evidence that zinc concentrations of bottom well water is greater than those of surface water."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.-2",
    "href": "slides/slides-22-ht-ci-diffs.html#example-zinc-cont.-2",
    "title": "HTs and CIs for differences",
    "section": "Example: zinc (cont.)",
    "text": "Example: zinc (cont.)\n\n\n\nzinc <- zinc |>\n  mutate(d = bottom - surface)\nd_bar <- mean(zinc$d)\nd_bar\n\n[1] 0.0804\n\ns_d <- sd(zinc$d)\ns_d\n\n[1] 0.05227321\n\n\n\n\n\n\n\npoint estimate: \\(\\bar{d} = 0.0804\\)\nSE \\(\\approx\\) \\(\\frac{s_{d}}{\\sqrt{n}} = \\frac{0.052}{\\sqrt{10}} = 0.016\\)\n\ncritical value: what code would you write?\n\n\n\\(df = n-1 = 9\\)\n\\(t_{9, 0.975}^{*} =\\) qt(0.975,9) \\(= 2.26\\)\n\n\n\n\n\nSo our 95% confidence interval is:\n\\[0.0804 \\pm 2.26(0.016) = (0.044, 0.117)\\]\n\n\n\nDo the data suggest that the true average concentration in the bottom water is different than that of surface water? Explain."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#sampling-distribution-for-difference-in-means",
    "href": "slides/slides-22-ht-ci-diffs.html#sampling-distribution-for-difference-in-means",
    "title": "HTs and CIs for differences",
    "section": "Sampling distribution for difference in means",
    "text": "Sampling distribution for difference in means\n\nTwo populations, interest in \\(\\mu_{1} - \\mu_{2}\\) (or other order)\nSamples of size \\(n_{1}\\) and \\(n_{2}\\)\nIf CLT holds, we learned sampling distribution of difference in sample means is:\n\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(\\mu_{1} - \\mu_{2}, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\]\n\n\nWhen we don’t know the population standard deviations, we replace the \\(\\sigma\\) with \\(s\\) and use a \\(t\\) distribution\nSame thing will happen for hypothesis test!\n\n\nSame conditions for inference: independence (extended) and approximate normality/large sample size (extended)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-1",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-1",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test",
    "text": "Hypothesis test\nHypotheses \\(H_{0}: \\mu_{1} = \\mu_{2}\\) versus \\(H_{A}: \\mu_{1} \\neq \\mu_{2}\\) (or \\(>\\) or \\(<\\))\n\nIf CLT holds, our null distribution for the difference in sample means is:\n\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(0, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}} }\\right)\n\\]\n\n\n\nIn practice, use \\(s_{1}\\) and \\(s_{2}\\). So our test-statistic is…\n\n\n\n\\[\nt= \\frac{\\text{point est} - \\text{null value} }{\\widehat{\\text{SE}}_{0}} = \\frac{(\\bar{x}_{1} - \\bar{x}_{2}) - 0}{\\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}} \\sim t_{df}\n\\]\nwhere \\(df = \\min(n_{1}-1, n_{2}-1)\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#activity",
    "href": "slides/slides-22-ht-ci-diffs.html#activity",
    "title": "HTs and CIs for differences",
    "section": "Activity",
    "text": "Activity\nMunchkins!"
  },
  {
    "objectID": "slides/slides-21-ci-mean.html#housekeeping",
    "href": "slides/slides-21-ci-mean.html#housekeeping",
    "title": "CIs and HTs for a single mean",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nDessert social today! 3-4:30pm in WNS 105!\nModified office hours today: 1:30-2:30pm instead of 2-3pm\nHomework 7 due tonight\nProject proposals due Wednesday night"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#housekeeping",
    "href": "slides/slides-22-ht-ci-diffs.html#housekeeping",
    "title": "HTs and CIs for differences",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nProject proposals due tonight!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#difference-of-two-proportions",
    "href": "slides/slides-22-ht-ci-diffs.html#difference-of-two-proportions",
    "title": "HTs and CIs for differences",
    "section": "Difference of two proportions",
    "text": "Difference of two proportions\nSuppose we have two populations 1 and 2, and want to either estimate the value of or conduct a test for the difference in population proportions: \\(p_{1} - p_{2}\\)\n\nWe have samples of size \\(n_{1}\\) and \\(n_{2}\\) from each population\nReasonable point estimate: \\(\\hat{p}_{1, obs} - \\hat{p}_{2,obs}\\)\nWe will obtain the sampling distribution of the difference of two sample proportions\nNow that we have two populations, conditions for CLT will look slightly different!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#sampling-dist.-of-difference-of-two-proportions",
    "href": "slides/slides-22-ht-ci-diffs.html#sampling-dist.-of-difference-of-two-proportions",
    "title": "HTs and CIs for differences",
    "section": "Sampling dist. of difference of two proportions",
    "text": "Sampling dist. of difference of two proportions\n\nIn order to use CLT approximation, we have to ensure conditions are met:\n\nIndependence (extended): data are independent within and between groups\nSuccess-failure (extended): success-failure conditions holds for both groups\n\n\\(n_{1} p_{1} \\geq 10\\), \\(n_{1} (1-p_{1}) \\geq 10\\), \\(n_{2} p_{2} \\geq 10\\), and \\(n_{2} (1-p_{2}) \\geq 10\\)\n\n\nIf above hold, then:\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}} \\right)\n\\]\nwhere \\(p_{1}\\) and \\(p_{2}\\) are the population proportions"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#confidence-interval-for-difference-in-proportions",
    "href": "slides/slides-22-ht-ci-diffs.html#confidence-interval-for-difference-in-proportions",
    "title": "HTs and CIs for differences",
    "section": "Confidence interval for difference in proportions",
    "text": "Confidence interval for difference in proportions\nIf we want to obtain a \\(\\gamma\\times 100\\%\\) CI for \\(p_{1} - p_{2}\\), that means we don’t know the value of \\(p_{1} - p_{2}\\)!\n\nLike in the case of the CI for a single proportion, we will use our observed proportions to check success-failure\n\nSuccess-failure condition for CI for difference in proportions:\n\n\n\\(n_{1} \\hat{p}_{1,obs} \\geq 10\\) and \\(n_{1} (1-\\hat{p}_{1,obs}) \\geq 10\\)\n\\(n_{2} \\hat{p}_{2,obs} \\geq 10\\) and \\(n_{2} (1-\\hat{p}_{2,obs}) \\geq 10\\)\n\nThen our formula for the CI is the same as before:\n\n\n\\[\n\\begin{align*}\n&\\text{point. est} \\pm \\text{critical val.}\\times \\widehat{\\text{SE}} = \\\\\n&(\\hat{p}_{1,obs} - \\hat{p}_{2,obs}) \\pm z^{*}_{(1+\\gamma)/2} \\sqrt{\\frac{\\hat{p}_{1,obs} (1-\\hat{p}_{1,obs})}{n_{1}} + \\frac{\\hat{p}_{2,obs} (1-\\hat{p}_{2,obs})}{n_{2}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling",
    "text": "Example: offshore drilling\nA survey asked 827 randomly sampled registered voters in California: Do you support or oppose drilling for oil and natural gas off the Coast of California? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    258 \n    334 \n    592 \n  \n\n\n\n\n\n\nLet’s obtain a 95% CI via the CLT for the difference in the proportion of college and non-college Californians who support offshore drilling."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nObtain observed proportions and pooled proportion.\n\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    258 \n    334 \n    592 \n  \n\n\n\n\n\n\n\\(\\hat{p}_{nc, obs}= \\frac{154}{334}= 0.461\\)\n\\(\\hat{p}_{c, obs}= \\frac{132}{258}=0.512\\)\n\\(\\hat{p}_{pooled} =\\frac{154 + 132}{334 + 258} = \\frac{286}{592} = 0.483\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nCheck conditions for inference are satisfied.\n\n\nIndependence (extended): random sample probably gives independence within and across groups\nSuccess-failure (extended):\n\n\\(n_{1} \\hat{p}_{pooled} = 334 \\times 0.483 = 161.32 \\geq 10\\)\n\\(n_{1} (1 - \\hat{p}_{pooled}) = 334 \\times (1 - 0.483) = 172.68 \\geq 10\\)\n\\(n_{2} \\hat{p}_{pooled} = 258 \\times 0.483 = 124.61 \\geq 10\\)\n\\(n_{2} (1 - \\hat{p}_{pooled}) = 258 \\times (1 - 0.483) = 133.39 \\geq 10\\)\n\nSince conditions are met, we can proceed with CLT-based test!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-for-difference-in-proportions",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-for-difference-in-proportions",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test for difference in proportions",
    "text": "Hypothesis test for difference in proportions\nHypothesis tests for difference in proportions in this class will take the form:\n\n\\[\n\\begin{align*}\nH_{0}: p_{1} - p_{2}  &= 0 \\\\\nH_{A}: \\ p_{1} - p_{2}  &\\neq 0\\\\\n\\text{ or }\\ &<   \\\\\n\\text{ or }\\ &>\n\\end{align*}\n\\]\n\n\nFor success-failure condition for difference in two proportions, we don’t have null-hypothesized values for \\(p_{1}\\) or \\(p_{2}\\).\nSo how do we check the condition??"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#pooled-proportion",
    "href": "slides/slides-22-ht-ci-diffs.html#pooled-proportion",
    "title": "HTs and CIs for differences",
    "section": "Pooled proportion",
    "text": "Pooled proportion\n\nSince \\(H_{0}: p_{1} = p_{2}\\), then under the null \\(\\hat{p}_{1,obs}\\) and \\(\\hat{p}_{2,obs}\\) come from the same population\nSo under this null, we use a special proportion called the pooled proportion:\n\n\n\\[\n\\hat{p}_{pooled} = \\frac{\\text{total # of successes from both samples}}{\\text{combined sample size}}\n\\]\n\n\nThis is the best estimate of both \\(p_{1}\\) and \\(p_{2}\\) if \\(H_{0}: p_{1} = p_{2}\\) is true!\n\n\n\n\nFor this reason, use \\(\\hat{p}_{pooled}\\) to verify success-failure conditions for HT for difference of proportions:\n\n\\(n_{1} \\hat{p}_{pooled} \\geq 10\\) and \\(n_{1} (1-\\hat{p}_{pooled}) \\geq 10\\)\n\\(n_{2} \\hat{p}_{pooled} \\geq 10\\) and \\(n_{2} (1-\\hat{p}_{pooled}) \\geq 10\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-cont.",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\n\nObtain null distribution\n\nIf conditions satisfied, then we know the sampling distribution of \\(\\hat{p}_{1} - \\hat{p}_{2}\\)\nTo obtain the null distribution we assume \\(H_{0}: p_{1} - p_{2} = 0\\) is true and we \\(\\hat{p}_{pooled}\\) to estimate \\(p_{1}\\) and \\(p_{2}\\) to approximate standard error under the null:\n\n\n\n\\[\n\\begin{align*}\n\\hat{p}_{1} - \\hat{p}_{2} &\\overset{\\cdot}{\\sim} N\\left(p_{1} - p_{2}, \\sqrt{\\frac{p_{1} (1-p_{1})}{n_{1}} + \\frac{p_{2} (1-p_{2})}{n_{2}}}  \\right) \\qquad \\text{(CLT)} \\\\ &\\overset{\\cdot}{\\sim} N\\big(0, \\underbrace{\\sqrt{\\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{1}} + \\frac{\\hat{p}_{pooled}(1 - \\hat{p}_{pooled})}{n_{2}}}}_{\\widehat{\\text{SE}}_{0}} \\big) \\qquad (H_{0})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test (cont.)",
    "text": "Hypothesis test (cont.)\nObtain test-statistic:\n\\[\nz = \\frac{\\text{point estimate} - \\text{null value}}{\\text{SE}} \\approx \\frac{(\\hat{p}_{1,obs} - \\hat{p}_{2,obs}) - 0}{\\widehat{\\text{SE}}_{0}}\n\\]\n\nTo obtain p-value, we want \\(\\text{Pr}(Z \\geq z)\\) and/or \\(\\text{Pr}(Z \\leq z)\\) where \\(Z \\sim N(0,1)\\)\n\nObtain using pnorm(z, 0, 1)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-1",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-1",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling",
    "text": "Example: offshore drilling\nA survey asked 827 randomly sampled registered voters in California: Do you support or oppose drilling for oil and natural gas off the Coast of California? Or do you not know enough to say? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    do_not_know \n    131 \n    104 \n    235 \n  \n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    389 \n    438 \n    827 \n  \n\n\n\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-2",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-2",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{1} - \\hat{p}_{2}\\).\n\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.483(1 - 0.483)}{334} + \\frac{0.483(1 - 0.483)}{258}} = 0.041 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{1, obs}- \\hat{p}_{2, obs}) - 0}{\\widehat{\\text{SE}}_{0}} = \\frac{(0.461 - 0.512) - 0}{0.041} = -1.244\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-3",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-3",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nDraw picture and write code for p-value\n\n\n\n\n\n\n\n\n\n\n\n\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z)\\)\n2 * pnorm(-1.244, 0, 1) = 0.2134996\n\n\n\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater than 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-4",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-4",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\nConditions for inference:\n\nIndependence: random sample\nSuccess-failure:\n\n\\(n_{nc} \\hat{p}_{pooled} = 389 \\times 0.346 = 134.59 \\geq 10\\)\n\\(n_{nc} (1 - \\hat{p}_{pooled}) = 389 \\times (1 - 0.346) = 254.41 \\geq 10\\)\n\\(n_{c} \\hat{p}_{pooled} = 438 \\times 0.346 = 151.55 \\geq 10\\)\n\\(n_{c} (1 - \\hat{p}_{pooled}) = 438 \\times (1 - 0.346) = 286.45 \\geq 10\\)\n\n\nSince conditions are met, we can proceed"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-5",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-5",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{nc} - \\hat{p}_{c}\\)\n\n\n\n\\[\n\\hat{p}_{nc} - \\hat{p}_{c} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.346(1 - 0.346)}{389} + \\frac{0.346(1 - 0.346)}{438}} = 0.033 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{nc, obs}- \\hat{p}_{c, obs}) - 0}{\\text{SE}_{0}} = \\frac{(0.339 - 0.352) - 0}{0.033} = -0.394\n\\]\n\n\n\nDraw picture and write code for p-value"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-6",
    "href": "slides/slides-22-ht-ci-diffs.html#example-offshore-drilling-cont.-6",
    "title": "HTs and CIs for differences",
    "section": "Example: offshore drilling (cont.)",
    "text": "Example: offshore drilling (cont.)\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z) = 2 \\times \\text{Pr}(Z \\geq 0.394)\\)\n2 * (1 - pnorm(0.394)) = 0.694\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater the 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ci-example-offshore-drilling",
    "href": "slides/slides-22-ht-ci-diffs.html#ci-example-offshore-drilling",
    "title": "HTs and CIs for differences",
    "section": "CI example: offshore drilling",
    "text": "CI example: offshore drilling\nA survey asked 827 randomly sampled registered voters in California: Do you support or oppose drilling for oil and natural gas off the Coast of California? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    258 \n    334 \n    592 \n  \n\n\n\n\n\n\nLet’s obtain a 95% CI via the CLT for the difference in the proportion of college and non-college Californians who support offshore drilling."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ci-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#ci-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "CI example (cont.)",
    "text": "CI example (cont.)\nLet population 1 be college attendees, and population 2 be non-college attendees.\n\nCheck conditions for CLT.\n\nIndependence (extended)? Randomly sampled means we probably have independence within each group and across the two groups.\nSuccess-failure (extended)?\n\n\\(n_{1}\\hat{p}_{1,obs} = 154 \\geq 10\\)\n\\(n_{1}(1-\\hat{p}_{1,obs}) = 180 \\geq 10\\)\n\\(n_{2}\\hat{p}_{2,obs} = 132 \\geq 10\\)\n\\(n_{2}(1-\\hat{p}_{2,obs}) = 126 \\geq 10\\)\n\n\nSince both conditions are met, we can proceed with the CLT."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ci-example-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#ci-example-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "CI example (cont.)",
    "text": "CI example (cont.)\nCollect the components of CI:\n\n\n\n\nPoint estimate\n\n\nCritical value (code)\n\n\n\\(\\text{SE}\\) or \\(\\widehat{\\text{SE}}\\)\n\n\n\n\n\\(\\hat{p}_{1,obs} - \\hat{p}_{2,obs} = 0.461 - 0.512 = -0.051\\)\n\\(z^{*}_{0.975} =\\) qnorm(0.975, 0, 1) \\(\\approx 1.96\\)\n\\(\\widehat{\\text{SE}} = \\sqrt{\\frac{0.461(1 - 0.461)}{334} + \\frac{0.512(1 - 0.512)}{258}} = 0.041\\)\n\n\n\n\nSo putting it all together, our 95% CI is:\n\\[\n-0.051 \\pm 1.96 \\times 0.041 = (-0.131, 0.029)\n\\]\n\nInterpret!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ht-example-offshore-drilling-again",
    "href": "slides/slides-22-ht-ci-diffs.html#ht-example-offshore-drilling-again",
    "title": "HTs and CIs for differences",
    "section": "HT example: offshore drilling (again)",
    "text": "HT example: offshore drilling (again)\nUsing the same data as before, let’s answer the following question:\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#ht-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#ht-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "HT example (cont.)",
    "text": "HT example (cont.)\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?\n\n\n\nDefine parameters and hypotheses\n\n\nLet \\(p_{1}\\) be the proportion of registered voters from California who are college-graduates who support off-shore drilling\nLet \\(p_{2}\\) be the proportion be of registered voters from California who are not college-graduates who support off-shore drilling\n\\(H_{0}: p_{1} - p_{2} = 0\\) and \\(H_{A}: p_{1} - p_{2} \\neq 0\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-offshore-drilling",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-offshore-drilling",
    "title": "HTs and CIs for differences",
    "section": "Diff. props CI example: offshore drilling",
    "text": "Diff. props CI example: offshore drilling\nA survey asked 592 randomly sampled registered voters in California: Do you support or oppose drilling for oil and natural gas off the Coast of California? We have the following distribution of responses separated by whether the respondent graduated from college:\n\n\n\n\n \n  \n    position \n    no \n    yes \n    total \n  \n \n\n  \n    oppose \n    126 \n    180 \n    306 \n  \n  \n    support \n    132 \n    154 \n    286 \n  \n  \n    total \n    258 \n    334 \n    592 \n  \n\n\n\n\n\n\nLet’s obtain a 95% CI via the CLT for the difference in the proportion of college and non-college Californians who support offshore drilling."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "Diff. props CI example (cont.)",
    "text": "Diff. props CI example (cont.)\nLet population 1 be college attendees, and population 2 be non-college attendees. We want a 95% CI for \\(p_{1} - p_{2}\\), where \\(p_{i}\\) is the proportion of population \\(i\\) who support offshore drilling.\n\n\n\n\nObtain useful statistics\n\n\n\\(n_{1} = 334\\), \\(n_{2} = 258\\)\n\\(\\hat{p}_{1, obs} = \\frac{154}{334} = 0.461\\)\n\\(\\hat{p}_{2, obs} = \\frac{132}{258} = 0.512\\)\n\n\n\n\n\nCheck conditions for CLT.\n\n\nIndependence (extended)? Randomly sampled\nSuccess-failure (extended)?\n\n\\(n_{1}\\hat{p}_{1,obs} = 154 \\geq 10\\)\n\\(n_{1}(1-\\hat{p}_{1,obs}) = 180 \\geq 10\\)\n\\(n_{2}\\hat{p}_{2,obs} = 132 \\geq 10\\)\n\\(n_{2}(1-\\hat{p}_{2,obs}) = 126 \\geq 10\\)\n\n\n\n\n\n\nSince both conditions are met, we can proceed with the CLT."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ci-example-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Diff. props CI example (cont.)",
    "text": "Diff. props CI example (cont.)\nCollect the components of CI:\n\n\n\n\nPoint estimate\n\n\nCritical value (code)\n\n\n\\(\\text{SE}\\) or \\(\\widehat{\\text{SE}}\\)\n\n\n\n\n\\(\\hat{p}_{1,obs} - \\hat{p}_{2,obs} = 0.461 - 0.512 = -0.051\\)\n\\(z^{*}_{0.975} =\\) qnorm(0.975, 0, 1) \\(\\approx 1.96\\)\n\\(\\widehat{\\text{SE}} = \\sqrt{\\frac{0.461(1 - 0.461)}{334} + \\frac{0.512(1 - 0.512)}{258}} = 0.041\\)\n\n\n\n\nSo putting it all together, our 95% CI is:\n\\[\n-0.051 \\pm 1.96 \\times 0.041 = (-0.131, 0.029)\n\\]\n\nInterpret!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-offshore-drilling-again",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-offshore-drilling-again",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example: offshore drilling (again)",
    "text": "Diff. props HT example: offshore drilling (again)\nUsing the same data as before, let’s answer the following question:\n\n\n\n\nDo the data provide strong evidence at the 0.05 level that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates?\n\n\nLet \\(p_{1}\\) and \\(p_{2}\\) be defined as before.\n\nDefine hypotheses\n\n\n\\(H_{0}: p_{1} - p_{2} = 0\\) and \\(H_{A}: p_{1} - p_{2} \\neq 0\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example (cont.)",
    "text": "Diff. props HT example (cont.)\n\nObtain pooled proportion, and use it to check conditions for CLT.\n\n\n\\(\\hat{p}_{pooled} =\\frac{154 + 132}{334 + 258} = \\frac{286}{592} = 0.483\\)\nConditions\n\nIndependence (extended): random sample\nSuccess-failure (extended):\n\n\\(n_{1} \\hat{p}_{pooled} = 334 \\times 0.483 = 161.32 \\geq 10\\)\n\\(n_{1} (1 - \\hat{p}_{pooled}) = 334 \\times (1 - 0.483) = 172.68 \\geq 10\\)\n\\(n_{2} \\hat{p}_{pooled} = 258 \\times 0.483 = 124.61 \\geq 10\\)\n\\(n_{2} (1 - \\hat{p}_{pooled}) = 258 \\times (1 - 0.483) = 133.39 \\geq 10\\)\n\n\nSince conditions are met, we can proceed with CLT-based test!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example (cont.)",
    "text": "Diff. props HT example (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{1} - \\hat{p}_{2}\\).\n\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.483(1 - 0.483)}{334} + \\frac{0.483(1 - 0.483)}{258}} = 0.041 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{1, obs}- \\hat{p}_{2, obs}) - 0}{\\widehat{\\text{SE}}_{0}} = \\frac{(0.461 - 0.512) - 0}{0.041} = -1.244\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-2",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-2",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example (cont.)",
    "text": "Diff. props HT example (cont.)\n\nDraw picture and write code for p-value\n\n\n\n\n\n\n\n\n\n\n\n\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z)\\)\n2 * pnorm(-1.244, 0, 1) = 0.2134996\n\n\n\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater than 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-3",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-3",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example (cont.)",
    "text": "Diff. props HT example (cont.)\n\n\nFind the null distribution for \\(\\hat{p}_{1} - \\hat{p}_{2}\\).\n\n\n\n\\[\n\\hat{p}_{1} - \\hat{p}_{2} \\overset{\\cdot}{\\sim}N\\left(0, \\sqrt{\\frac{0.483(1 - 0.483)}{334} + \\frac{0.483(1 - 0.483)}{258}} = 0.041 \\right)\n\\]\n\n\n\nSet up calculation for test statistic\n\n\n\n\\[\n    z =\\frac{( \\hat{p}_{1, obs}- \\hat{p}_{2, obs}) - 0}{\\widehat{\\text{SE}}_{0}} = \\frac{(0.461 - 0.512) - 0}{0.041} = -1.244\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-4",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-props-ht-example-cont.-4",
    "title": "HTs and CIs for differences",
    "section": "Diff. props HT example (cont.)",
    "text": "Diff. props HT example (cont.)\n\nDraw picture and write code for p-value\n\n\n\n\n\n\n\n\n\n\n\n\np-value calculation:\n\n\\(\\text{Pr}(Z \\leq z) + \\text{Pr}(Z \\geq -z)\\)\n2 * pnorm(-1.244, 0, 1) = 0.2134996\n\n\n\n\n\n\nMake a decision and conclusion in context.\n\n\n\nSince our p-value is greater than 0.05, we fail to reject \\(H_{0}\\). The data do not provide strong evidence of a difference between the proportions of college graduates and non-college graduates who support off-shore drilling among California voters."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#difference-in-two-means-1",
    "href": "slides/slides-22-ht-ci-diffs.html#difference-in-two-means-1",
    "title": "HTs and CIs for differences",
    "section": "Difference in two means",
    "text": "Difference in two means\nWe still have two populations, but the variable of interest is quantitative (i.e. not binary).\nWe are interested in learning about the difference in the means of each population.\n\nLet \\(\\mu_{1}\\) and \\(\\mu_{2}\\) represent the population means for the two populations 1 and 2\nSamples of size \\(n_{1}\\) and \\(n_{2}\\) from each population, respectively\nConditions for CLT\n\nIndependence (extended): need data within and between the two groups\n\ne.g.the two data sets come from independent random samples or from a randomized experiment\n\nNormality: we need to check for approximate normality for both groups separately"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-c02-concentrations",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-c02-concentrations",
    "title": "HTs and CIs for differences",
    "section": "Diff. means CI example: C02 concentrations",
    "text": "Diff. means CI example: C02 concentrations\n\nThe Mauna Loa Observatory in Hawaii of monitors atmospheric solar, atmospheric, and meteorological parameters\nWe have data on annual atmospheric CO2 concentrations from 1980-2015.\n\nWe will obtain a 90% confidence interval for the difference between the average atmospheric C02 levels (ppm) from years 2000-2015 and years 1980-1999.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup\nn\nxbar\ns\n\n\n\n\n1980-1999\n20\n353.12\n9.0\n\n\n2000-2015\n16\n385.02\n9.9"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "Diff. means CI example (cont.)",
    "text": "Diff. means CI example (cont.)\n\nDefine parameters.\n\n\nLet \\(\\mu_{1}\\) be the average CO2 levels from 2000-2015 and \\(\\mu_{2}\\) the average CO2 levels from 1980-1999.\nWant to obtain a 90% CI for \\(\\mu_{1} - \\mu_{2}\\)\n\nNote: could also do \\(\\mu_{2} - \\mu_{1}\\) (interpretation just changes slightly)\n\n\n\n\nCheck conditions for CLT.\n\n\n\nIndependence (extended): most likely violated because CO2 levels are probably dependent across time. BUT let’s proceed with caution anyway.\nNormality: \\(n_{1} = 16 < 30\\) and \\(n_{2} = 20 < 30\\). But since histograms don’t reveal outliers, Normality condition appears met."
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.-1",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.-1",
    "title": "HTs and CIs for differences",
    "section": "Diff. means CI example (cont.)",
    "text": "Diff. means CI example (cont.)\n\nCollect components for CI:\n\n\n\n\nPoint estimate\nCritical value (code)\n\\(\\text{SE}\\) or \\(\\widehat{\\text{SE}}\\)\n\n\n\n\\(\\bar{x}_{1,obs} - \\bar{x}_{2,obs} = 385.02 - 353.12 = 31.9\\)\nSince we don’t know \\(\\sigma_{1}\\) nor \\(\\sigma_{2}\\), need to use \\(t\\)-distribution\n\nDegrees of freedom = \\(\\min\\{16 - 1, 20 -1\\} = 15\\)\n\\(t^*_{0.95}\\) = qt(0.95, df = 15) = 1.75\n\n\\(\\widehat{\\text{SE}} = \\sqrt{\\frac{9.9^2}{16} + \\frac{9^2}{20}} = 3.19\\)\n\n\n\n\n\nPut it all together:\n\n\n\n\\[\n\\text{point est.} \\pm \\text{crit. val}\\times \\text{SE} = 31.9 \\pm 1.75 \\times 3.19 = (26.3175, 37.4825)\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.-2",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ci-example-cont.-2",
    "title": "HTs and CIs for differences",
    "section": "Diff. means CI example (cont.)",
    "text": "Diff. means CI example (cont.)\n\nInterpret our CI of (26.3175, 37.4825) in context!"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#clt-for-difference-in-two-sample-means",
    "href": "slides/slides-22-ht-ci-diffs.html#clt-for-difference-in-two-sample-means",
    "title": "HTs and CIs for differences",
    "section": "CLT for difference in two sample means",
    "text": "CLT for difference in two sample means\nIf CLT conditions met, the distribution of difference in sample means is:\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(\\mu_{1} - \\mu_{2}, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\] where \\(n_{1}\\) and \\(n_{2}\\) are the sample sizes.\n\n\nRemember, we often do not know \\(\\sigma_{1}\\) nor \\(\\sigma_{2}\\)\nIn practice, will have to estimate with \\(s_{1}\\) and \\(s_{2}\\) and use the \\(t\\)-distribution"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-for-difference-in-means",
    "href": "slides/slides-22-ht-ci-diffs.html#hypothesis-test-for-difference-in-means",
    "title": "HTs and CIs for differences",
    "section": "Hypothesis test for difference in means",
    "text": "Hypothesis test for difference in means\nNow suppose we’re interested in testing for the difference between \\(\\mu_{1}\\) and \\(\\mu_{2}\\).\n\n\\(H_{0}: \\mu_{1} - \\mu_{2} = 0\\) versus \\(H_{A}: \\mu_{1} - \\mu_{2} \\neq 0\\) (or \\(<\\) or \\(>\\))\nSame conditions as in CI are necessary for CLT-based inference!\n\nIndependence (extended)\nNormality condition for both groups\n\nIf CLT met, then under \\(H_{0}\\), the null distribution is\n\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(0, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#null-distribution-for-difference-in-means",
    "href": "slides/slides-22-ht-ci-diffs.html#null-distribution-for-difference-in-means",
    "title": "HTs and CIs for differences",
    "section": "Null distribution for difference in means",
    "text": "Null distribution for difference in means\nIf CLT met, we saw:\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(\\mu_{1} - \\mu_{2}, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\]\n\nSo under \\(H_{0}\\), the null distribution is\n\n\\[\n\\bar{X}_{1} - \\bar{X}_{2} \\overset{\\cdot}{\\sim} N\\left(0, \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}} \\right)\n\\]"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#test-statistic-for-difference-in-means",
    "href": "slides/slides-22-ht-ci-diffs.html#test-statistic-for-difference-in-means",
    "title": "HTs and CIs for differences",
    "section": "Test statistic for difference in means",
    "text": "Test statistic for difference in means\nTest-statistic is of form:\n\\[\n\\frac{\\text{point est.} - \\text{null value}}{\\text{SE}_{0}}\n\\]\n\n\nIf \\(\\sigma_{1}, \\sigma_{2}\\) known, our test-statistic is:\n\\[\nz = \\frac{(\\bar{x}_{1,obs} - \\bar{x}_{2,obs}) - 0}{ \\sqrt{\\frac{\\sigma_{1}^2}{n_{1}} + \\frac{\\sigma_{2}^2}{n_{2}}}} \\sim N(0,1)\n\\]\n\nIf \\(\\sigma_{1}, \\sigma_{2}\\) unknown, our test-statistic is\n\n\n\\[\nt = \\frac{(\\bar{x}_{1,obs} - \\bar{x}_{2,obs}) - 0}{ \\sqrt{\\frac{s_{1}^2}{n_{1}} + \\frac{s_{2}^2}{n_{2}}}} \\sim t_{df}\n\\]\n\\(df = \\min\\{n_{1}-1, n_{2}-1 \\}\\)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ht-example-co2",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ht-example-co2",
    "title": "HTs and CIs for differences",
    "section": "Diff. means HT example: CO2",
    "text": "Diff. means HT example: CO2\nNow let’s test if the mean CO2 level in 2000-2015 was greater than that mean CO2 level in 1980-1999 at the \\(0.05\\) level using CLT.\n\n\\(H_{0}: \\mu_{1} - \\mu_{2} = 0\\) versus \\(H_{A}: \\mu_{1} > \\mu_{2}\\), where \\(\\mu_{1}\\) and \\(\\mu_{2}\\) were defined previously\nLet \\(\\alpha = 0.05\\)\nConditions for CLT are same as before (proceed with caution)"
  },
  {
    "objectID": "slides/slides-22-ht-ci-diffs.html#diff.-means-ht-example-cont.",
    "href": "slides/slides-22-ht-ci-diffs.html#diff.-means-ht-example-cont.",
    "title": "HTs and CIs for differences",
    "section": "Diff. means HT example (cont.)",
    "text": "Diff. means HT example (cont.)\n\n\n\nObtain test-statistic and p-value.\n\n\nFind the value of the test-statistic and its distribution\n\n\n\n\\[\nt = \\frac{(385.02 - 353.12)- 0}{3.19} = 10 \\sim t_{15}\n\\]\n\n\n\nWrite code for p-value (optionally draw picture)\n\np-value = 1- pt(10, df = 15) = 2.4984491^{-8} (tiny!)"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#housekeeping",
    "href": "slides/slides-23-chi-square.html#housekeeping",
    "title": "Chi-squared test",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nProject proposals due tonight!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#recall-probability",
    "href": "slides/slides-23-chi-square.html#recall-probability",
    "title": "Chi-squared test",
    "section": "Recall probability",
    "text": "Recall probability\n\nHow might we test these hypotheses?\nRecall from Probability lecture: if events \\(A\\) and \\(B\\) are independent, then \\(P(A \\cap B) = P(A) P(B)\\).\n\nWe will use this idea to obtain “expected counts” in each cell under a world where we assume the two variables are independent."
  },
  {
    "objectID": "slides/slides-23-chi-square.html#coffee-death-example",
    "href": "slides/slides-23-chi-square.html#coffee-death-example",
    "title": "Chi-squared test",
    "section": "Coffee-death example",
    "text": "Coffee-death example\n\n\n\nUnder independence\n\n\n\n\n\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n\\(\\text{expected}= \\frac{6477 \\times 60084}{69164} = 5626.69\\)\n\n6477\n\n\nDrinks coffee occasionally\n\n\n34152\n\n\nDrinks coffee regularly\n\n\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nGive example from table (assuming independence)\n\\[\n\\text{P}(\\text{does not drink coffee} \\cap \\text{die not die}) = \\text{P}(\\text{does not drink coffee}) \\times \\text{Pr}(\\text{die not die})\n\\]\nSo the expected count is this probability times sample size \\(n\\):\nIn general, assuming independence, the number of counts in cell \\((i,j)\\) should be\n\\[\n\\text{Expected Count in row i, column j} = E_{ij} = \\frac{(\\text{Row } i \\text{ total}) \\times (\\text{Column } j \\text{ total})}{\\text{Overall total}}\n\\]\n\nFill out rest of table!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#table-of-expected-counts",
    "href": "slides/slides-23-chi-square.html#table-of-expected-counts",
    "title": "Chi-squared test",
    "section": "Table of expected counts",
    "text": "Table of expected counts\n\n\n\n\n\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nNo coffee\n\\(E_{11}= \\frac{6477 \\times 60084}{69164} = 5626.69\\)\n\n6477\n\n\nOccasional coffee\n\n\n34152\n\n\nRegular coffee\n\n\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nIn general, the expected counts in cell of row \\(i\\) and column \\(j\\) (denoted \\(E_{ij}\\)) is:\n\\[\nE_{ij} = \\frac{(\\text{row } i \\text{ total}) \\times (\\text{column } j \\text{ total})}{\\text{Overall total}}\n\\]\n\nFill out rest of table!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#towards-a-test-statistic",
    "href": "slides/slides-23-chi-square.html#towards-a-test-statistic",
    "title": "Chi-squared test",
    "section": "Towards a test statistic",
    "text": "Towards a test statistic\nRemember, a test statistic is a quantity that compares our data to null world.\n\nSo let’s compare our observed counts to what we would expect under \\(H_{0}\\).\nLet \\(O_{ij}\\) represent the observed count in row \\(i\\) and column \\(j\\)\nWe might consider the following as a test statistic: \\[\\sum_{i,j} (O_{ij} - E_{ij}) \\qquad \\text{ (summing over all } i,j)\\]\n\nWhy might we not like this?"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#our-test-statistic",
    "href": "slides/slides-23-chi-square.html#our-test-statistic",
    "title": "Chi-squared test",
    "section": "Our test statistic",
    "text": "Our test statistic\nWe will consider the ratio of how far the observed counts are from the expected counts, as compared to the expected count\n\\[\n\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n\\]\n\nThis is called the Chi-squared test statistic\n\nLet’s calculate the value of \\(\\chi^2\\) for our data!\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\chi^2 &= \\frac{(5438 - 5626.7 )^2}{5626.7} + \\frac{(1039 - 850.3 )^2}{850.3} + \\ldots + \\frac{(3601 - 3746.1)^2}{3746.1} \\\\\n&= 6.33 + 41.88 + 0.06 + 0.42 + 0.85 + 5.62 \\\\\n&= 55.16\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#understanding-the-test-statistic",
    "href": "slides/slides-23-chi-square.html#understanding-the-test-statistic",
    "title": "Chi-squared test",
    "section": "Understanding the test statistic",
    "text": "Understanding the test statistic\n\n\nDiscuss with someone next to you:\n\nWhat are the bounds of \\(\\chi^2\\)?\nWould higher or lower values of \\(\\chi^2\\) provide convincing evidence against \\(H_{0}\\)? Why?\n\n\nThe sampling distribution of this statistic is clearly not Normal. Why?\nIf you take STAT 311, you will learn that the null distribution of the \\(\\chi^2\\) test statistic is the \\(\\chi_{df}^2\\) distribution (sorry for terminology)"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#chi-squared-distribution",
    "href": "slides/slides-23-chi-square.html#chi-squared-distribution",
    "title": "Chi-squared test",
    "section": "Chi-squared distribution",
    "text": "Chi-squared distribution"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#towards-a-test-statistic-cont.",
    "href": "slides/slides-23-chi-square.html#towards-a-test-statistic-cont.",
    "title": "Chi-squared test",
    "section": "Towards a test statistic (cont.)",
    "text": "Towards a test statistic (cont.)\n\nLet’s try to fix this issue using the following: \\[\\sum_{i,j} (O_{ij} - E_{ij})^2\\]\n\nThis is better, but not perfect because the magnitude of the quantity may be overly influenced by:\n\nHighly-represented cells\nThe number of levels \\(I\\) and \\(J\\)"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#null-distribution-for-this-test",
    "href": "slides/slides-23-chi-square.html#null-distribution-for-this-test",
    "title": "Chi-squared test",
    "section": "Null distribution for this test",
    "text": "Null distribution for this test\nWhen \\(H_{0}\\) true, the test statistic \\(\\chi^2 \\sim \\chi_{df}^2\\) where the degrees of freedom is calculated as \\(df = (I- 1)\\times(J-1)\\)\n\ni.e. \\(df = (\\text{number of rows} - 1)\\times(\\text{number of columns} - 1)\\)\n\nWhat are the degrees of freedom in our data?\n\n\n\\(df = (3-1) \\times (2-1) = 2\\)"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#p-value",
    "href": "slides/slides-23-chi-square.html#p-value",
    "title": "Chi-squared test",
    "section": "p-value",
    "text": "p-value"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#null-distribution-and-p-value",
    "href": "slides/slides-23-chi-square.html#null-distribution-and-p-value",
    "title": "Chi-squared test",
    "section": "Null distribution and p-value",
    "text": "Null distribution and p-value\nWhen \\(H_{0}\\) true, the test statistic \\(\\chi^2 \\sim \\chi_{df}^2\\) where \\(df = (I- 1)\\times(J-1)\\)\n\nThat is, \\(df = (\\text{number of rows} - 1)\\times(\\text{number of columns} - 1)\\)\n\nWhat are the degrees of freedom in our data?\n\n\n\\(df = (3-1) \\times (2-1) = 2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBecause the distribution is positive, p-value for this test is always calculated as the probability we are \\(\\geq\\) the observed test statistic\nUse pchisq(x, df) function:\n\n\n\n1 - pchisq(55.15, df = 2)\n\n[1] 1.057598e-12"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#conditions-for-the-test",
    "href": "slides/slides-23-chi-square.html#conditions-for-the-test",
    "title": "Chi-squared test",
    "section": "Conditions for the test",
    "text": "Conditions for the test\n\nEven though this isn’t a CLT-based result, we are still using a mathematical model (i.e. the \\(\\chi^2\\) distribution)\nAs a result, we have some conditions that must be met in order to use this test:\n\nIndependent observations (i.e. random sample)\nLarge samples: \\(E_{ij} \\geq 5\\) for each \\((i,j)\\) cell\n\nIn our data, the study was a random sample and we definitely had \\(E_{ij} \\geq 5\\), so we could indeed perform the Chi-squared test!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#conditions-for-the-chi-squared-test",
    "href": "slides/slides-23-chi-square.html#conditions-for-the-chi-squared-test",
    "title": "Chi-squared test",
    "section": "Conditions for the chi-squared test",
    "text": "Conditions for the chi-squared test\n\nEven though this isn’t a CLT-based result, we are still using a mathematical model (i.e. the \\(\\chi^2\\) distribution)\nAs a result, we have some conditions that must be met in order to use this test:\n\nIndependent observations (i.e. random sample)\nLarge samples: \\(E_{ij} \\geq 5\\) for each \\((i,j)\\) cell\n\nIn our data, the study was a random sample and we definitely had \\(E_{ij} \\geq 5\\), so we could indeed perform the Chi-squared test!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#coffee-death-data",
    "href": "slides/slides-23-chi-square.html#coffee-death-data",
    "title": "Chi-squared test",
    "section": "Coffee-death data",
    "text": "Coffee-death data\nRecall our data from earlier in the semester:\n\nSource: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nNo coffee\n5438\n1039\n6477\n\n\nOccasional coffee\n29712\n4440\n34152\n\n\nRegular coffee\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\n\\(H_{0}:\\) coffee consumption and mortality are independent\n\\(H_{A}\\): coffee consumption and mortality are associated\nNote, \\(I = 3\\) rows and \\(J = 2\\) columns"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#what-is-null-world",
    "href": "slides/slides-23-chi-square.html#what-is-null-world",
    "title": "Chi-squared test",
    "section": "What is null world?",
    "text": "What is null world?\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nNo coffee\n\n\n6477\n\n\nOccasional coffee\n\n\n34152\n\n\nRegular coffee\n\n\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nAssuming independence:\n\\[\n\\begin{align*}\n\\text{P}(\\text{no coffee} \\cap \\text{die not die}) &= \\text{P}(\\text{no coffee}) \\times \\text{P}(\\text{die not die}) \\\\\n&= \\left( \\frac{6477}{69164} \\right)\\times \\left( \\frac{60084}{69164} \\right)\n\\end{align*}\n\\]\n\n\nSo the expected count of this cell is the the sample size times this probability:\n\\[\n\\text{expected count} = 69164 \\times \\left( \\frac{6477}{69164} \\right)\\times \\left( \\frac{60084}{69164} \\right) = \\frac{6477 \\times 60084}{69164}\n\\]"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#table-of-expected-counts-1",
    "href": "slides/slides-23-chi-square.html#table-of-expected-counts-1",
    "title": "Chi-squared test",
    "section": "Table of expected counts",
    "text": "Table of expected counts\n\n\n\n\n\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nNo coffee\n\\(E_{11} = \\frac{6477 \\times 60084}{69164} = 5626.7\\)\n\\(E_{12} = 850.3\\)\n6477\n\n\nOccasional coffee\n\\(E_{21} =2.96685\\times 10^{4}\\)\n\\(E_{22} = 4483.5\\)\n34152\n\n\nRegular coffee\n\\(E_{31} = 2.47889\\times 10^{4}\\)\n\\(E_{32} = 3746.1\\)\n28535\n\n\nTotal\n60084\n9080\n69164"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#example-2",
    "href": "slides/slides-23-chi-square.html#example-2",
    "title": "Chi-squared test",
    "section": "Example 2",
    "text": "Example 2"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#a-new-test",
    "href": "slides/slides-23-chi-square.html#a-new-test",
    "title": "Chi-squared test",
    "section": "A new test",
    "text": "A new test\n\nSuppose we have two categorical variables:\n\nVariable 1 has \\(I\\) levels\nVariable 2 has \\(J\\) levels\n\nWe are interested in learning if the two variables are associated or not!\n\n\\(H_{0}\\): the two variables are independent (put into context)\n\\(H_{A}\\): the two variables are associated (put into context)\n\nNote! We are not interested in a mean/proportion, so CLT will not be helpful here!\nWe will build this hypothesis test backwards."
  },
  {
    "objectID": "slides/slides-23-chi-square.html#example-2-exploding-termites",
    "href": "slides/slides-23-chi-square.html#example-2-exploding-termites",
    "title": "Chi-squared test",
    "section": "Example 2: exploding termites!",
    "text": "Example 2: exploding termites!\n\nData come from this study!\nIn some termite species, worker termites assume a large share of defense\nThis often involves self-sacrifice (i.e. bursting)\nIn the species Neocapritermes taracua, workers fall into one of two categories based on coloring: “blue workers” and “white workers”\n\nThe blue coloring comes from a pair of crystal-like structures in the body\nIn defensive mode, both types of workers will burst and emit a toxic fluid\nBlue termites are thought to be more toxic than white termites"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#experiment",
    "href": "slides/slides-23-chi-square.html#experiment",
    "title": "Chi-squared test",
    "section": "Experiment",
    "text": "Experiment\n\nSome scientists wanted to learn about the toxicity of the termites and how they relate to the crystals.\nDesigned an experiment where another species of termite (Labiotermes labralis) was exposed to a drop of the bursting liquid obtained from one of four sources\n\nObserved survival status after 60 minutes\n\n\n\n\n\nFour types of burst liquid (treatment):\n\nBlue workers\nWhite workers\nBlue workers with crystals removed\nWhite workers with crystals added\n\n\n\n\nSurvival of (Labiotermes labralis) (response):\n\nUnharmed\nParalyzed\nDead"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#data-cont.",
    "href": "slides/slides-23-chi-square.html#data-cont.",
    "title": "Chi-squared test",
    "section": "Data (cont.)",
    "text": "Data (cont.)\nWe have the following data:\n\n\n\n\n\n\n\n\n\n\n\nUnharmed\nParalyzed\nDead\nTotal\n\n\n\n\nBlue workers\n3\n11\n26\n40\n\n\nWhite workers\n31\n4\n5\n40\n\n\nBlue workers (crystals removed)\n26\n8\n7\n41\n\n\nWhite workers (crystals added)\n17\n5\n18\n40\n\n\nTotal\n77\n28\n56\n161\n\n\n\n\nLet’s perform a \\(\\chi^2\\) test at the 0.05-level to see if bursting liquid source is associated with toxicity!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#conduct-test",
    "href": "slides/slides-23-chi-square.html#conduct-test",
    "title": "Chi-squared test",
    "section": "Conduct test",
    "text": "Conduct test\n\nDefine hypotheses\nCheck conditions for inference.\n\n\n\\(H_{0}\\): the bursting liquid source and toxicity of the liquid are independent\n\\(H_{A}\\): the bursting liquid source and toxicity of the liquid are associated"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#conditions",
    "href": "slides/slides-23-chi-square.html#conditions",
    "title": "Chi-squared test",
    "section": "Conditions",
    "text": "Conditions\nTable of expected counts:\n\n\n\n\nUnharmed\nParalyzed\nDead\nTotal\n\n\n\n\nBlue\n19.13\n6.96\n13.91\n40\n\n\nWhite\n19.13\n6.96\n13.91\n40\n\n\nBlue (w/o crystals)\n19.61\n7.13\n14.26\n41\n\n\nWhite (w/ crystals)\n19.13\n6.96\n13.91\n40\n\n\nTotal\n77\n28\n56\n161\n\n\n\nSince all expected counts \\(\\geq 5\\) and it’s reasonable to believe independence across termite survival, conditions are met!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html#finish-test",
    "href": "slides/slides-23-chi-square.html#finish-test",
    "title": "Chi-squared test",
    "section": "Finish test",
    "text": "Finish test\n\nObtain (or set-up the calculation) test-statistic, the distribution of the test statistic, and write-code to obtain p-value.\n\n\nValue of test statistic:\n\\[\n  \\begin{align*}\n  \\chi^2 &= \\frac{(3-19.13)^2}{19.13} + \\frac{(11-6.96)^2}{6.96} + \\frac{(26-13.91)^2}{13.91} + \\ldots + \\frac{(18-13.91)^2}{13.91} \\\\\n  &= 48.66\n  \\end{align*}\n  \\]\nDistribution of test statistic: \\(\\chi^2_{6}\\)\np-value: \\(P(\\chi^2 \\geq 48.66)\\)\n\n1 - pchisq(48.66, df = 6)\n\n[1] 8.720311e-09\n\n\n\n\n\nDecision and conclusion!"
  },
  {
    "objectID": "slides/slides-23-chi-square.html",
    "href": "slides/slides-23-chi-square.html",
    "title": "Chi-squared test",
    "section": "",
    "text": "Thank you for submitting project proposals! Will give feedback ASAP. Stay tuned if you need revisions."
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#housekeeping",
    "href": "slides/slides-24-slr-intro.html#housekeeping",
    "title": "Introduction to Simple Linear Regression",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nHomework 8 due tonight!\nProject proposal feedback"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#fitting-a-line-to-data",
    "href": "slides/slides-24-slr-intro.html#fitting-a-line-to-data",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting a line to data",
    "text": "Fitting a line to data\n\nHopefully we are all familiar with the equation of a line: \\(y = mx + b\\)\n\nIntercept \\(b\\) and slope \\(m\\) determine specific line\nThis function is deterministic: as long as we know \\(x\\), we know value of \\(y\\) exactly\n\nSimple linear regression: statistical method where the relationship between variables \\(x\\) and \\(y\\) is modeled as a line + error:\n\n\n\\[\ny = \\underbrace{\\beta_{0} \\ +\\ \\beta_{1} x}_{\\text{line}} \\ + \\underbrace{\\epsilon}_{\\text{error}}\n\\]"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#linear-regression-model",
    "href": "slides/slides-24-slr-intro.html#linear-regression-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nRemember, our linear regression model is:\n\\[\ny = \\beta_{0} + \\beta_{1}x + \\epsilon\n\\]\n\nWhile not wrong, it can be good practice to be specific about an observation \\(i\\):\n\\[\ny_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i}, \\qquad i = 1,\\ldots, n\n\\]\n\n\nHere, we are stating that each observation \\(i\\) has a specific:\n\nexplanatory variable value \\(x_{i}\\)\nresponse variable value \\(y_{i}\\)\nerror/randomness \\(\\epsilon_{i}\\)\n\nIn SLR, we further assume that the errors \\(\\epsilon_{i}\\) are independent and Normally distributed"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#linear-relationship",
    "href": "slides/slides-24-slr-intro.html#linear-relationship",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear relationship",
    "text": "Linear relationship\nSuppose we have the following data:\n\n\nObservations won’t fall exactly on a line, but do fall around a straight line, so maybe a linear relationship makes sense!"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#fitted-values",
    "href": "slides/slides-24-slr-intro.html#fitted-values",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values",
    "text": "Fitted values\nSuppose we have some specific estimates \\(b_0\\) and \\(b_{1}\\). We could approximate the linear relationship using these values as:\n\\[\n\\hat{y} = b_{0} + b_{1} x\n\\]\n\nThe hat on \\(y\\) signifies an estimate: \\(\\hat{y}\\) is the estimated/fitted value of \\(y\\) given these specific values of \\(x\\), \\(b_{0}\\) and \\(b_{1}\\)\n\nCan obtain a estimate \\(\\hat{y}\\) for every observed response \\(y\\)\n\nNote that the fitted value is obtained without the error"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#fitted-values-cont.",
    "href": "slides/slides-24-slr-intro.html#fitted-values-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitted values (cont.)",
    "text": "Fitted values (cont.)\n\n\nSuppose our estimated line is the yellow one: \\(\\hat{y} = 1.11 + 0.41 x\\)\nThe fitted value \\(\\hat{y}_{i}\\) for \\(y_{i}\\) lies on the line; the above plot shows three specific examples"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#residual",
    "href": "slides/slides-24-slr-intro.html#residual",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual",
    "text": "Residual\nResiduals (denoted as \\(e\\)) are the remaining variation in the data after fitting a model.\n\\[\n\\text{observed response} = \\text{fit} + \\text{residual}\n\\]\n\nFor each observation \\(i\\), we obtain the residual \\(e_{i}\\) via:\n\n\n\\[y_{i} = \\hat{y}_{i} + e_{i} \\Rightarrow e_{i} =  y_{i} - \\hat{y}_{i}\\]\n\n\nResidual = difference between observed and expected\nIn the plot, the residual is indicated by the vertical dashed line\n\n\nWhat is the ideal value for a residual? What does a positive/negative residual indicate?"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#residual-cont.",
    "href": "slides/slides-24-slr-intro.html#residual-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual (cont.)",
    "text": "Residual (cont.)\n\n\nResidual values for the three highlighted observations:\n\n\n\n\n \n  \n    x \n    y \n    y_hat \n    residual \n  \n \n\n  \n    -2.991 \n    2.481 \n    -0.130 \n    2.611 \n  \n  \n    -1.005 \n    -1.302 \n    0.691 \n    -1.994 \n  \n  \n    3.990 \n    3.929 \n    2.757 \n    1.172"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#residual-plot",
    "href": "slides/slides-24-slr-intro.html#residual-plot",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot",
    "text": "Residual plot\n\nResiduals are very helpful in evaluating how well a model fits a set of data\nResidual plot: original \\(x\\) values plotted against corresponding residuals on \\(y\\)-axis"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#residual-plot-cont.",
    "href": "slides/slides-24-slr-intro.html#residual-plot-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual plot (cont.)",
    "text": "Residual plot (cont.)\nResidual plots can be useful for identifying characteristics/patterns that remain in the data even after fitting a model.\n\n\nJust because you fit a model to data, does not mean the model is a good fit!\n\n\n\n\n\n\n\n\n\nCan you identify any patterns remaining in the residuals?"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#describing-linear-relationships",
    "href": "slides/slides-24-slr-intro.html#describing-linear-relationships",
    "title": "Introduction to Simple Linear Regression",
    "section": "Describing linear relationships",
    "text": "Describing linear relationships\nDifferent data may exhibit different strength of linear relationships:\n\n\nCan we quantify the strength of the linear relationship?"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#correlation",
    "href": "slides/slides-24-slr-intro.html#correlation",
    "title": "Introduction to Simple Linear Regression",
    "section": "Correlation",
    "text": "Correlation\n\nCorrelation is describes the strength of a linear relationship between two variables\n\nThe observed sample correlation is denoted by \\(R\\)\nFormula (not important): \\(R = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left(\\frac{x_{i} - \\bar{x}}{s_x} \\right)\\left(\\frac{y_{i} - \\bar{y}}{s_y} \\right)\\)\n\n\n\n\n\nAlways takes a value between -1 and 1\n\n-1 = perfectly linear and negative\n1 = perfectly linear and positive\n0 = no linear relationship\n\nNonlinear trends, even when strong, sometimes produce correlations that do not reflect the strength of the relationship"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#different-lines",
    "href": "slides/slides-24-slr-intro.html#different-lines",
    "title": "Introduction to Simple Linear Regression",
    "section": "Different lines",
    "text": "Different lines\nThe following display the same set of 50 observations.\n\n\n\n\n\n\n\n\n\nWhich line would you say fits the data the best?\n\n\n\n\nThere are infinitely many choices of \\((b_{0}, b_{1})\\) that could be used to create a line\nWe want the BEST choice (i.e. the one that gives us the “line of best fit”)\n\n\nHow to define “best”?"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#line-of-best-fit",
    "href": "slides/slides-24-slr-intro.html#line-of-best-fit",
    "title": "Introduction to Simple Linear Regression",
    "section": "Line of best fit",
    "text": "Line of best fit\nOne way to define a “best” is to choose the specific values of \\((b_{0}, b_{1})\\) that minimize the total residuals across all \\(n\\) data points. Results in following possible criterion:\n\nLeast absolute criterion: minimize sum of residual magnitudes:\n\n\n\\[\n|e_{1} | + |e_{2}| + \\ldots + |e_{n}|\n\\]\n\n\n\nLeast squares criterion: minimize sum of squared residuals:\n\n\n\n\\[\ne_{1}^2 + e_{2}^2 +\\ldots + e_{n}^2\n\\]\n\n\nThe choice of \\((b_{0}, b_{1})\\) that satisfy least squares criterion yields the least squares line, and will be our criterion for “best”\nOn previous slide, yellow line is the least squares line, whereas pink line is the least absolute line"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#linear-regression-model-1",
    "href": "slides/slides-24-slr-intro.html#linear-regression-model-1",
    "title": "Introduction to Simple Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nRemember, our linear regression model is:\n\\[\ny = \\beta_{0} + \\beta_{1}x + \\epsilon\n\\]\n\nWhile not wrong, it can be good practice to be specific about an observation \\(i\\):\n\\[\ny_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon_{i}, \\qquad i = 1,\\ldots, n\n\\]\n\n\nHere, we are stating that each observation \\(i\\) has a specific:\n\nexplanatory variable value \\(x_{i}\\)\nresponse variable value \\(y_{i}\\)\nerror/randomness \\(\\epsilon_{i}\\)"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#conditions-for-the-least-squares-line-line",
    "href": "slides/slides-24-slr-intro.html#conditions-for-the-least-squares-line-line",
    "title": "Introduction to Simple Linear Regression",
    "section": "Conditions for the least squares line (LINE)",
    "text": "Conditions for the least squares line (LINE)\nLike when using CLT, we should check some conditions before saying a linear regression model is appropriate!\n\nAssume for now that \\(x\\) is continuous numerical.\n\n\nLinearity: data should show a linear trend between \\(x\\) and \\(y\\)\nIndependence: the observations \\(i\\) are independent of each other\n\ne.g. random sample\nNon-example: time-series data\n\nNormality/nearly normal residuals: the residuals should appear approximately Normal\n\nPossible violations: outliers, influential points (more on this later)\n\nEqual variability: variability of points around the least squares line remains roughly constant"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#running-example",
    "href": "slides/slides-24-slr-intro.html#running-example",
    "title": "Introduction to Simple Linear Regression",
    "section": "Running example",
    "text": "Running example\nWe will see how to check for these four LINE conditions using the cherry data from openintro.\n\n\n\n\n\n\n\ndiam\nvolume\n\n\n\n\n8.3\n10.3\n\n\n8.6\n10.3\n\n\n8.8\n10.2\n\n\n10.5\n16.4\n\n\n10.7\n18.8\n\n\n\n\n\n\n\nExplanatory variable \\(x\\): diam\nResponse variable \\(y\\): volume\n\n\n\n\nOur candidate linear regression model is as follows\n\\[\n\\text{volume} = \\beta_{0} + \\beta_{1} \\text{diameter} +\\epsilon\n\\]"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#linearity",
    "href": "slides/slides-24-slr-intro.html#linearity",
    "title": "Introduction to Simple Linear Regression",
    "section": "1. Linearity",
    "text": "1. Linearity\nAssess before fitting the linear regression model by making a scatterplot of \\(x\\) vs. \\(y\\):\n\n\nDoes there appear to be a linear relationship between diameter and volume?\n\nI would say yes"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#independence",
    "href": "slides/slides-24-slr-intro.html#independence",
    "title": "Introduction to Simple Linear Regression",
    "section": "2. Independence",
    "text": "2. Independence\nAssess before fitting the linear regression model by understanding how your data were sampled.\n\nThe cherry data do not explicitly say that the trees were randomly sampled, but it might be a reasonable assumption\n\n\nAn example where independence is violated:\n\n\n\n\n\n\n\n\nHere, the data are a time series, where observation at time point \\(i\\) depends on the observation at time \\(i-1\\).\n\nSuccessive/consecutive observations are highly correlated"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#fitting-the-model",
    "href": "slides/slides-24-slr-intro.html#fitting-the-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Fitting the model",
    "text": "Fitting the model\n\n\n\nBecause the first two conditions are met, we can go ahead and fit the linear regression model (i.e. estimate the values of the coefficients)\n\nAfter fitting the model, we get the following estimates: \\(b_{0}= -36.94\\) and \\(b_{1} = 5.07\\). So our fitted model is:\n\n\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nRemember: the “hat” denotes an estimated/fitted value!\n\n\n\nWe will soon see how \\(b_{0}\\) and \\(b_{1}\\) are calculated and how to interpret them\nThe next two checks can only occur after fitting the model."
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#nearly-normal-residuals",
    "href": "slides/slides-24-slr-intro.html#nearly-normal-residuals",
    "title": "Introduction to Simple Linear Regression",
    "section": "3. Nearly normal residuals",
    "text": "3. Nearly normal residuals\nAssess after fitting the model by making histogram of residuals and checking for approximate Normality.\n\nRemember, residuals are \\(e_{i} = y_{i} - \\hat{y}_{i}\\)\n\n\n\n\n\ncherry |>\n  mutate(volume_hat = -36.94 + 5.07*diam) |>\n  mutate(residual = volume - volume_hat) \n\n\n\n\n\n \n  \n    diam \n    volume \n    volume_hat \n    residual \n  \n \n\n  \n    8.3 \n    10.3 \n    5.141 \n    -5.159 \n  \n  \n    8.6 \n    10.3 \n    6.662 \n    -3.638 \n  \n  \n    8.8 \n    10.2 \n    7.676 \n    -2.524 \n  \n  \n    10.5 \n    16.4 \n    16.295 \n    -0.105 \n  \n  \n    10.7 \n    18.8 \n    17.309 \n    -1.491 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo the residuals appear approximately Normal?\n\nI think so!"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#equal-variance",
    "href": "slides/slides-24-slr-intro.html#equal-variance",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance",
    "text": "4. Equal variance\nAssess after fitting the model by examining a residual plot and looking for patterns.\n\n\nA good residual plot:\n\n\n\n\n\n\nA bad residual plot:\n\n\n\n\n\n\n\nWe usually add a horizontal line at 0."
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#equal-variance-cont.",
    "href": "slides/slides-24-slr-intro.html#equal-variance-cont.",
    "title": "Introduction to Simple Linear Regression",
    "section": "4. Equal variance (cont.)",
    "text": "4. Equal variance (cont.)\nLet’s examine the residual plot of our fitted model for the cherry data:\n\n\n\nDo we think equal variance is met?\n\n\nI would say there is a definite pattern in the residuals, so equal variance condition is not met.\nSome of the variability in the errors appear related to diameter"
  },
  {
    "objectID": "slides/slides-24-slr-intro.html#simple-linear-regression-model",
    "href": "slides/slides-24-slr-intro.html#simple-linear-regression-model",
    "title": "Introduction to Simple Linear Regression",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\nWe have two variables:\n\n\\(y\\) is response variable. Must be continuous numerical.\n\\(x\\) is explanatory variable, also called the predictor variable\n\nCan be numerical or categorical\n\n\n\\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the model parameters (intercept and slope)\n\nEstimated using the data, with point estimates \\(b_{0}\\) and \\(b_{1}\\)\n\n\\(\\epsilon\\) (epsilon) represents the error\n\nAccounts for variability: we do not expect all data to fall perfectly on the line!\nSometimes we drop the \\(\\epsilon\\) term for convenience"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html",
    "href": "slides/slides-25-slr-interpretation.html",
    "title": "SLR coefficient estimates",
    "section": "",
    "text": "No TA hours tonight\nWill discuss details of Midterm 2 next week!\nRevisions for proposals due Saturday 11:59pm"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#parameter-estimates",
    "href": "slides/slides-25-slr-interpretation.html#parameter-estimates",
    "title": "SLR coefficient estimates",
    "section": "Parameter estimates",
    "text": "Parameter estimates\n\nLike in previous topics, we have to estimate the parameters using data\nWe want to estimate \\(\\beta_{0}\\) and \\(\\beta_{1}\\) using the \\((x_{i}, y_{i})\\)\n\nIn practice, we let software do this for us\n\nHowever, we can derive the least-squares estimates using properties of the least-squares line"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#estimating-slope-and-intercept",
    "href": "slides/slides-25-slr-interpretation.html#estimating-slope-and-intercept",
    "title": "SLR coefficient estimates",
    "section": "Estimating slope and intercept",
    "text": "Estimating slope and intercept\n\n\nFirst obtain \\(b_{1}\\):\n\n\\[\nb_{1} =\\frac{s_{y}}{s_{x}} R\n\\]\nwhere:\n\n\n\\(s_{x}\\) and \\(s_{y}\\) are the sample standard deviations of the explanatory and response variables\n\\(R\\) is the sample correlation between \\(x\\) and \\(y\\)\n\n\n\nThen obtain \\(b_{0}\\):\n\n\\[b_{0} = \\bar{y} - b_{1} \\bar{x}\\] where\n\n\n\\(\\bar{y}\\) is the sample mean of the response variable\n\\(\\bar{x}\\) is the sample mean of the explanatory variable\n\n\n\n\n\n\nTake STAT 0211 or 0311 to see where these formulas come from!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#fitting-cherry-model-by-hand",
    "href": "slides/slides-25-slr-interpretation.html#fitting-cherry-model-by-hand",
    "title": "SLR coefficient estimates",
    "section": "Fitting cherry model (by hand)",
    "text": "Fitting cherry model (by hand)\n\n\n\nVerify estimates \\(b_{0} = -36.94\\) and \\(b_{1} = 5.07\\) from our model for the cherry data:\n\n\n\ncherry |>\n  pivot_longer(cols = c(diam, volume), \n               names_to = \"variable\", \n               values_to = \"val\") |>\n  select(-height) |>\n  group_by(variable) |>\n  summarise(mean = mean(val), s = sd(val))  \n\n\n\n\n\n \n  \n    variable \n    mean \n    s \n  \n \n\n  \n    diam \n    13.248 \n    3.138 \n  \n  \n    volume \n    30.171 \n    16.438 \n  \n\n\n\n\n\n\n\nR <- cor(cherry$diam, cherry$volume)\nR\n\n[1] 0.9671194\n\n\n\nWhat does this value of \\(R\\) tell us?\n\n\n\n\n\n\n\n\n\n\nSet-up the calculations:\n\n\\(b_{1} = \\frac{s_{y}}{s_{x}} R\\)\n\\(b_{0} = \\bar{y} -b_{1} \\bar{x}\\)\n\n\n\n\n\n\\(b_{1} = \\frac{16.438}{3.138} \\times 0.967 = 5.07\\)\n\\(b_{0} = 30.171 - 5.07 \\times 13.248 = -36.94\\)\nLet’s find out what these numbers really mean!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#intercept-interpretation",
    "href": "slides/slides-25-slr-interpretation.html#intercept-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Intercept interpretation",
    "text": "Intercept interpretation\n\n\n\nTo interpret the estimate of the intercept \\(b_{0}\\), simply plug in \\(x= 0\\):\n\\[\n\\begin{align*}\n\\hat{y} &= b_{0} + b_{1} x \\\\\n&= b_{0} + b_{1}(0) \\\\\n&= b_{0}\n\\end{align*}\n\\]\n\n\n\nSo, the intercept describes the estimated/expected value of the response variable \\(y\\) if \\(x=0\\)\n\nBe sure to interpret in context!\n\n\n\n\n\n\nInterpret the intercept in our elmhurst model\n\nFor a family with an income of $0, the expected gift aid would be $24.319 (in $1000s), or simply $24319\n\n\n\n\nThe intercept’s interpretation only makes sense when a value of \\(x=0\\) is plausible!\n\nThis is typically not the case/relevant in many applications (though it is here!)"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#intercept-in-cherry-model",
    "href": "slides/slides-25-slr-interpretation.html#intercept-in-cherry-model",
    "title": "SLR coefficient estimates",
    "section": "Intercept in cherry model",
    "text": "Intercept in cherry model\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nInterpretation of intercept in context: for a tree with a diameter of 0 inches, the expected volume would be -36.94 cubic feet\n\nThis interpretation is mathematically correct, but practically speaking is useless\n\nThe intercept’s interpretation only makes sense when a value of \\(x=0\\) for the explanatory variable is plausible!\n\nThis is typically not the case/relevant in many applications\nTrees with 0 diameter are not able to sampled"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#slope-interpretation",
    "href": "slides/slides-25-slr-interpretation.html#slope-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Slope interpretation",
    "text": "Slope interpretation\n\nLet \\(\\hat{y}_{1}\\) be the estimated response for a given value of \\(x\\), so \\(\\hat{y}_{1} = b_{0} + b_{1} x\\)\nLet \\(\\hat{y}_{2}\\) be the estimated response for \\(x +1\\):\n\n\n\n\n\\[\n\\begin{align*}\n\\hat{y}_{2} &= b_{0} + b_{1} (x + 1)  \\\\\n&= \\color{orange}{b_{0} + b_{1}x}  + b_{1} \\\\\n&= \\color{orange}{\\hat{y}_{1}} + b_{1} \\Rightarrow \\\\\nb_{1} &= \\hat{y}_{2} - \\hat{y}_{1}\n\\end{align*}\n\\]\n\n\n\nInterpretation of estimated slope \\(b_{1}\\): for a 1 unit increase in the explanatory variable \\(x\\), we expect the response variable \\(y\\) to change by \\(b_{1}\\) units\n\n\n\n\n\nInterpret in context the estimated slope coefficient in the elmhurst model\n\nFor every $1000 increase in a family’s income, we expect that the gift aid the student receives will decrease by about $43"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#slope-in-cherry-model",
    "href": "slides/slides-25-slr-interpretation.html#slope-in-cherry-model",
    "title": "SLR coefficient estimates",
    "section": "Slope in cherry model",
    "text": "Slope in cherry model\n\\[\n\\widehat{\\text{volume}} = -36.94 + 5.07 \\times \\text{diameter}\n\\]\n\nInterpretation in context: for every 1 inch increase in diameter, we expect that volume of cherry trees to increase by 5.07 cubic feet"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-elmhurst",
    "href": "slides/slides-25-slr-interpretation.html#example-elmhurst",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst",
    "text": "Example: elmhurst\nThe elmhurst dataset from openintro provides a random sample of 50 students’ gift aid for students at Elmhurst College.\n\nWe will examine the relationship between the family income of the student and the gift aid that student received (in $1000s)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrite down the linear regression model.\n\n\n\\[\\text{gift aid} = \\beta_{0} + \\beta_{1} \\text{income} + \\epsilon\\]\n\n\n\n\nAre the first two conditions of LINE satisfied?"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-elmhurst-cont.",
    "href": "slides/slides-25-slr-interpretation.html#example-elmhurst-cont.",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst (cont.)",
    "text": "Example: elmhurst (cont.)\n\n\n\n\n\nWe run the model in R, and the output looks something like this:\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    24.319 \n    1.291 \n    18.831 \n    0 \n  \n  \n    family_income \n    -0.043 \n    0.011 \n    -3.985 \n    0 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe values in the estimate column are our \\(b_{0}\\) and \\(b_{1}\\):\n\n\n\\(b_{0} =\\) ? and \\(b_{1} =\\) ?\nWhat do you think the second column is?\n\n\n\nWrite out our fitted model in context"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-elmhurst-model",
    "href": "slides/slides-25-slr-interpretation.html#example-elmhurst-model",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst model",
    "text": "Example: elmhurst model\n\\[\n\\widehat{\\text{gift aid}} = 24.319  -0.043 \\times \\text{family_income}\n\\]\n\nBefore we interpret the coefficients, we should verify that the linear model is appropriate for the data!\n\n\n\n\n\n\n\n\nDo you believe the last two conditions of LINE are satisfied?"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-elmhurst-interpretation",
    "href": "slides/slides-25-slr-interpretation.html#example-elmhurst-interpretation",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst interpretation",
    "text": "Example: elmhurst interpretation\n\\[\n\\widehat{\\text{aid}} = 24.319 + -0.043 \\times \\text{family_income}\n\\]\n\n\n\n\nInterpret the slope in context\nInterpret the intercept in context\nIs the meaning of the intercept relevant?\n\n\n\n\nSlope: for every $1000 increase in family income, we expect that the student’s gift aid will decrease by $43.\nIntercept: for a student whose family income is $0, we expect that average amount of aid they will receive is $2.4319^{4}\nSince a family could have an income of $0, the intercept does seem relevant"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#words-of-caution",
    "href": "slides/slides-25-slr-interpretation.html#words-of-caution",
    "title": "SLR coefficient estimates",
    "section": "Words of caution",
    "text": "Words of caution\n\nThe estimates from the fitted model will always be imperfect\n\nThe linear equation is good at capturing trends, no individual outcome will be perfectly predicted\n\nDo not try to use the model for \\(x\\) values beyond the range of the observed \\(x\\)!\n\nThe true relationship between \\(x\\) and \\(y\\) is almost always much more complex than our simple line\nWe do not know how the relationship behaves outside our limited window"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#extrapolation",
    "href": "slides/slides-25-slr-interpretation.html#extrapolation",
    "title": "SLR coefficient estimates",
    "section": "Extrapolation",
    "text": "Extrapolation\nSuppose we would like to use our fitted model to estimate the expected gift aid for someone whose family income is $1,000,000:\n\n\nFind the estimated gift aid (careful with units)\n\n\n\\(\\widehat{\\text{gift aid}} = 24.319 + -0.043 \\times 1000 = -18.681\\)\nThis is ridiculous!\n\nThis is an example of extrapolation: using the model to estimate values outside the scope of the original data\n\nWe should never extrapolate!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#describing-the-fit",
    "href": "slides/slides-25-slr-interpretation.html#describing-the-fit",
    "title": "SLR coefficient estimates",
    "section": "Describing the fit",
    "text": "Describing the fit\n\nRecall sample correlation \\(R\\) describes the linear relationship between variables \\(x\\) and \\(y\\)\nWe typically use the coefficient of determination or \\(R^2\\) (R-squared) to describe strength of linear fit of a model\n\nDescribes amount of variation in \\(y\\) that is explained by predictor \\(x\\) in the least squares line\n\nIt turns out that \\(R^2\\) in SLR is exactly … \\(R\\) squared (i.e. the square of the sample correlation)\n\n\nWhat are the possible values of \\(R^2\\)? What are desirable values of \\(R^2\\)?"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-elmhurst-model-fit",
    "href": "slides/slides-25-slr-interpretation.html#example-elmhurst-model-fit",
    "title": "SLR coefficient estimates",
    "section": "Example: elmhurst model fit",
    "text": "Example: elmhurst model fit\n\n\n\n\nThe sample correlation between family income and aid is \\(R=\\) -0.499\nSo the coefficient of determination is \\(R^2 = (-0.499)^2 = 0.249\\)\n\nInterpretation: using a linear model, about 24.9% of the variability in gift aid received by the student is explained by family income\n\nI think this is actually a pretty good model!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#categorical-predictor-with-two-levels",
    "href": "slides/slides-25-slr-interpretation.html#categorical-predictor-with-two-levels",
    "title": "SLR coefficient estimates",
    "section": "Categorical predictor with two levels",
    "text": "Categorical predictor with two levels\n\n\nFor now, assume that \\(x\\) is categorical with two levels\n\nRunning example: the possum data from openintro which has data representing possums in Australia and New Guinea\n\nResponse variable: tail_l (tail length in cm)\nExplanatory variable: pop (either “Vic” for possums from Victoria or “other” for possums from New South Wales or Queensland)\n\nMaybe we would think to write our regression as\n\n\n\\[\\text{tail length} = \\beta_{0} + \\beta_{1} \\text{pop} + \\epsilon\\]\n\n\n\nWhy doesn’t this work?\n\n\nFunctions require a numerical input!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#indicator-variables",
    "href": "slides/slides-25-slr-interpretation.html#indicator-variables",
    "title": "SLR coefficient estimates",
    "section": "Indicator variables",
    "text": "Indicator variables\nWe need a mechanism to convert the categorical levels into numerical form!\n\n\n\nThis is achieved through an indicator variable which takes the value 1 for one specific level and the value 0 otherwise:\n\n\n\\[\n\\text{pop_other} = \\begin{cases}\n0 & \\text{ if  pop = Vic} \\\\\n1 & \\text{ if  pop = other}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n \n  \n    tail_l \n    pop \n    pop_other \n  \n \n\n  \n    38.0 \n    other \n    1 \n  \n  \n    34.0 \n    Vic \n    0 \n  \n  \n    36.0 \n    Vic \n    0 \n  \n  \n    36.5 \n    Vic \n    0 \n  \n  \n    41.5 \n    other \n    1 \n  \n\n\n\n\n\n\n\n\n\nThe level that corresponds to 0 is called the base level\n\nSo Vic is the base level"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#example-possum-model",
    "href": "slides/slides-25-slr-interpretation.html#example-possum-model",
    "title": "SLR coefficient estimates",
    "section": "Example: possum model",
    "text": "Example: possum model\nThis yields the now “legal” SLR model\n\\[\\text{tail length} = \\beta_{0} + \\beta_{1} \\text{pop_other} + \\epsilon\\]\n\nR will automatically convert categorical variables to indicators! So our estimates are as follows:\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    35.935 \n    0.253 \n    142.065 \n    0 \n  \n  \n    popother \n    1.927 \n    0.339 \n    5.690 \n    0 \n  \n\n\n\n\n\n\n\n\nWrite out the equation of our fitted model"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#intercept-for-categorical-x",
    "href": "slides/slides-25-slr-interpretation.html#intercept-for-categorical-x",
    "title": "SLR coefficient estimates",
    "section": "Intercept for categorical \\(x\\)",
    "text": "Intercept for categorical \\(x\\)\n\nOur fitted model is:\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927 \\times \\text{pop_other}\\]\n\n\n\nTry interpreting the intercept \\(b_{0}\\)\n\n\n\nWhat does \\(\\text{pop_other} = 0\\) mean? That the possum is from Victoria!\n\nSo when \\(x\\) is categorical, the interpretation of \\(b_{0}\\) is the estimated value of the response variable for the base level of \\(x\\)\n\nInterpretation: the expected tail length of possums from Victoria is 35.935 cm"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#slope-for-categorical-x",
    "href": "slides/slides-25-slr-interpretation.html#slope-for-categorical-x",
    "title": "SLR coefficient estimates",
    "section": "Slope for categorical \\(x\\)",
    "text": "Slope for categorical \\(x\\)\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times \\text{pop_other}\\]\n\nRemember, \\(b_{1}\\) is the expected change in \\(y\\) for a one unit increase in \\(x\\)\n\nWhat does it mean for \\(\\text{pop_other}\\) to increase by one unit here?\n\n\nChanging from to a pop value of “Vic” to “other”\n\n\nWhen \\(x\\) is categorical, the interpretation of \\(b_{1}\\) is the expected change in \\(y\\) when moving from the base level to the non-base level\n\n\nTry interpreting \\(b_{1}\\) in context!\n\n\nInterpretation: possums from “other” (i.e. New South Wales/Queensland) are expected to have tail lengths about 1.927 cm longer than possums from Victoria"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#slope-for-categorical-x-cont.",
    "href": "slides/slides-25-slr-interpretation.html#slope-for-categorical-x-cont.",
    "title": "SLR coefficient estimates",
    "section": "Slope for categorical \\(x\\) (cont.)",
    "text": "Slope for categorical \\(x\\) (cont.)\n\\[\\widehat{\\text{tail length}} = 35.935 + 1.927\\times \\text{pop_other}\\]\n\\[\n\\text{pop_other} = \\begin{cases}\n0 & \\text{ if  pop = Vic} \\\\\n1 & \\text{ if  pop = other}\n\\end{cases}\n\\]\n\nNote: interpretations for \\(b_{0}\\) and \\(b_{1}\\) for categorical \\(x\\) are the same as for numerical \\(x\\), but they have more specific/nuanced interpretations when placed in context"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#assessing-linear-fit",
    "href": "slides/slides-25-slr-interpretation.html#assessing-linear-fit",
    "title": "SLR coefficient estimates",
    "section": "Assessing linear fit",
    "text": "Assessing linear fit\n\nWhen categorical \\(x\\) only has two levels, Linearity is always satisfied (yay!)\nIndependence condition is the same before\nWe need to evaluate Nearly normal residuals and Equal variance for each level\n\nNote: the residual plot (right) is uncessary given histogram of residuals\n\n\n\n\n\n\n\n\n\n\n\nAre all four conditions for SLR met?"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html",
    "href": "slides/slides-26-slr-inference.html",
    "title": "Inference in SLR",
    "section": "",
    "text": "Last set of homework problems are released today!\nOffice hours changed this week:\n\nToday: 2-3pm only\nWednesday 4-5pm\nFriday: cancelled, moved to next week before midterm"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#recap",
    "href": "slides/slides-26-slr-inference.html#recap",
    "title": "Inference in SLR",
    "section": "Recap",
    "text": "Recap\n\nLearned how to interpret slope and intercept of fitted model\n\n\\(b_0\\) is estimate of \\(\\hat{y}\\) when \\(x=0\\)\n\\(b_{1}\\) is expected change in \\(\\hat{y}\\) for a one unit increase in \\(x\\)\n\nWhen explanatory \\(x\\) is categorical, we have a slightly more nuanced interpretation\nCoefficient of determination \\(R^2\\) assesses strength of linear model fit"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#variability-of-coefficient-estimates",
    "href": "slides/slides-26-slr-inference.html#variability-of-coefficient-estimates",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates\n\nRemember, a linear regression is fit using a sample of data\nDifferent samples from the same population will yield different point estimates of \\((b_{0}, b_{1})\\)\n\nI will generate 30 data points under the following model: \\(y = 1 + 0.5x+\\epsilon\\)\n\nHow? Randomly generate some \\(x\\) and \\(\\epsilon\\) values and then plug into model to get corresponding \\(y\\)\n\nFit SLR to these \\((x,y)\\) data, and obtain estimates \\((b_{0}, b_{1})\\)\nRepeat this 50 times"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#variability-of-coefficient-estimates-1",
    "href": "slides/slides-26-slr-inference.html#variability-of-coefficient-estimates-1",
    "title": "Inference in SLR",
    "section": "Variability of coefficient estimates",
    "text": "Variability of coefficient estimates"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#what-are-we-interested-in",
    "href": "slides/slides-26-slr-inference.html#what-are-we-interested-in",
    "title": "Inference in SLR",
    "section": "What are we interested in?",
    "text": "What are we interested in?\nRemember: we fit SLR to understand how \\(x\\) is (linearly) related to \\(y\\):\n\\[\ny = \\beta_{0} + \\beta_{1} x + \\epsilon\n\\]\n\n\nWhat would a value of \\(\\beta_{1} = 0\\) mean?\n\n\nIf \\(\\beta_{1} = 0\\), then the effect of \\(x\\) disappears and there is in fact no linear relationship between \\(x\\) and \\(y\\)\n\nWe don’t know \\(\\beta_{1}\\), so we can perform inference for it!\n\nCan conduct HTs and obtain CIs using our best guess \\(b_{1}\\)"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#running-example-evals-data",
    "href": "slides/slides-26-slr-inference.html#running-example-evals-data",
    "title": "Inference in SLR",
    "section": "Running example: evals data",
    "text": "Running example: evals data\nData on 463 courses at UT Austin were obtained to answer the question: “What factors explain differences in instructor teaching evaluation scores?”\n\nOne hypothesis is that attractiveness of a teacher influences their teaching evaluations\nWe will look at the variables:\n\nscore: course instructor’s average teaching score, where average is calculated from all students in that course. Scores ranged from 1-5, with 1 being lowest.\nbty_avg: course instructor’s average “beauty” score, where average is calculated from six student evaluations of “beauty”. Scores ranged from 1-10, with 1 being lowest.\n\n\nWrite out our linear regression model"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#teaching-evaluations-data",
    "href": "slides/slides-26-slr-inference.html#teaching-evaluations-data",
    "title": "Inference in SLR",
    "section": "Teaching evaluations data",
    "text": "Teaching evaluations data\n\n\nDoes this line really have a non-zero slope?"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#hypothesis-test-for-slope",
    "href": "slides/slides-26-slr-inference.html#hypothesis-test-for-slope",
    "title": "Inference in SLR",
    "section": "Hypothesis test for slope",
    "text": "Hypothesis test for slope\n\n\\(H_{0}: \\beta_{1} = 0\\): the true linear model has slope zero.\n\nIn context: there is no linear relationship between an instructor’s average beauty score and their average teaching evaluation score.\n\n\\(H_{A}: \\beta_{1} \\neq 0\\): the true linear model has a non-zero slope.\n\nIn context: there is a linear relationship between an average instructor’s beauty score and average teaching evaluation score.\n\nTo assess, we do what we usually do:\n\nCheck if methods are appropriate\nIf so: obtain an estimate, identify/estimate standard error of the estimate, find an appropriate test statistic, and calculate p-value\n\n\nThe output from lm() actually does all of #2 for us, but we will see how the test statistic and p-value are calculated!"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#teaching-evaluations-model-assessment",
    "href": "slides/slides-26-slr-inference.html#teaching-evaluations-model-assessment",
    "title": "Inference in SLR",
    "section": "Teaching evaluations: model assessment",
    "text": "Teaching evaluations: model assessment\nWe fit the model in R, and obtain the following plots.\n\nAre all conditions of LINE met?"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#looking-at-lm-output",
    "href": "slides/slides-26-slr-inference.html#looking-at-lm-output",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\nlibrary(broom)\neval_mod <- lm(score ~ bty_avg, data = evals)\neval_mod |>\n  tidy()\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880 \n    0.076 \n    50.961 \n    0e+00 \n  \n  \n    bty_avg \n    0.067 \n    0.016 \n    4.090 \n    5e-05 \n  \n\n\n\n\n\n\nAssuming the linear model is appropriate, interpret the coefficients!\n\n\nIntercept: an instructor with an average beauty score of 0 has an estimated evaluation score of 3.88\nSlope: for every one point increase in average beauty score an instructor receives, their evaluation score is estimated to increase by 0.067 points"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#looking-at-lm-output-1",
    "href": "slides/slides-26-slr-inference.html#looking-at-lm-output-1",
    "title": "Inference in SLR",
    "section": "Looking at lm() output",
    "text": "Looking at lm() output\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880 \n    0.076 \n    50.961 \n    0e+00 \n  \n  \n    bty_avg \n    0.067 \n    0.016 \n    4.090 \n    5e-05 \n  \n\n\n\n\n\n\n\n\nestimate: the observed point estimate (\\(b_{0}\\) or \\(b_{1}\\))\nstd.error: the estimated standard error of the estimate\n\n\n\nstatistic: the value of the test statistic\np.value: p-value associated with the two-sided alternative \\(H_{A}: \\beta_{1} \\neq 0\\)\n\n\n\n\nLet’s confirm the test statistic calculation:\n\n\n\\[\nt = \\frac{\\text{observed} - \\text{null}}{\\text{SE}_{0}} =\\frac{b_{1,obs} - \\beta_{1, 0}}{\\widehat{\\text{SE}}_{0}} = \\frac{0.066637 - 0}{0.0162912} = 4.0903823 \\sim t_{df}\n\\]\nwhere \\(df = n-2\\)"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#p-value-and-conclusion",
    "href": "slides/slides-26-slr-inference.html#p-value-and-conclusion",
    "title": "Inference in SLR",
    "section": "p-value and conclusion",
    "text": "p-value and conclusion\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880 \n    0.076 \n    50.961 \n    0e+00 \n  \n  \n    bty_avg \n    0.067 \n    0.016 \n    4.090 \n    5e-05 \n  \n\n\n\n\n\nLet’s confirm the p-value calculation:\n\\[\\text{p-value} = \\text{Pr}(T \\geq 4.09) + \\text{Pr}(T \\leq -4.09)\\] where \\(T \\sim t_{461}\\)\n\n\nWrite out the code you would use to calculate the p-value.\n\n\n\n2 * (1 - pt(4.09, df = 461)) = 0.00005082731\nAssuming the LINE conditions are met: since our p-value 0.00005082731 is extremely small, we would reject \\(H_{0}\\) at any reasonable significant level. Thus, the data provide convincing evidence that there is a linear relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#different-h_a",
    "href": "slides/slides-26-slr-inference.html#different-h_a",
    "title": "Inference in SLR",
    "section": "Different \\(H_{A}\\)",
    "text": "Different \\(H_{A}\\)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880 \n    0.076 \n    50.961 \n    0e+00 \n  \n  \n    bty_avg \n    0.067 \n    0.016 \n    4.090 \n    5e-05 \n  \n\n\n\n\n\n\n\n\nWrite code for your p-value if your alternative was \\(H_{A}: \\beta_{1} > 0\\). What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\geq 4.09)\\) = 1-pt(4.09, 461) = 0.00002541365\nThe data provide convincing evidence that there is a positive relationship between instructor’s beauty score and evaluation score.\n\n\n\nWrite code for your p-value if your alternative was \\(H_{A}: \\beta_{1} < 0\\). What would your conclusion be?\n\n\n\\(\\text{Pr}(T \\leq 4.09)\\) = pt(4.09, 461) = 0.9999745\nThe data do not provide convincing evidence that there is a negative relationship between instructor’s beauty score and evaluation score."
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#confidence-intervals",
    "href": "slides/slides-26-slr-inference.html#confidence-intervals",
    "title": "Inference in SLR",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    3.880 \n    0.076 \n    50.961 \n    0e+00 \n  \n  \n    bty_avg \n    0.067 \n    0.016 \n    4.090 \n    5e-05 \n  \n\n\n\n\n\nWe can also construct confidence intervals using the output from lm()! Remember:\n\\[\n\\text{CI} = \\text{point est.} \\pm \\text{critical value} \\times \\widehat{\\text{SE}}\n\\]\n\nCritical value also comes from \\(t_{n-2}\\) distribution\nSuppose we want a 95% confidence intervals for \\(\\beta_{1}\\):\n\n\nWhat code would you use to obtain critical value? Then set up your CI!\n\nqt(0.975, 461) = 1.97\n\n\n\n\\[\\text{95% CI}: 0.067 \\pm 1.97 \\times 0.016 = (0.035, 0.099)\\]"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#remarks",
    "href": "slides/slides-26-slr-inference.html#remarks",
    "title": "Inference in SLR",
    "section": "Remarks",
    "text": "Remarks\n\nNote: for \\(\\beta_{1}\\), the null hypothesis is always of the form \\(H_{0}: \\beta_{1} = 0\\)\nLINE conditions must be met for underlying mathematical and probability theory to hold here! If not met, interpret and perform inference with caution\nHere, the Independence and Normality conditions did not seem to be met\n\nTake STAT 412 or other course to learn how to incorporate dependencies between observations!\n\nSo what can we say?\n\nThe results suggested by our inference should be viewed as preliminary, and not conclusive\nFurther investigation is certainly warranted!\nChecking LINE can be very subjective, but that’s how real-world analysis will be!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#housekeeping",
    "href": "slides/slides-25-slr-interpretation.html#housekeeping",
    "title": "SLR coefficient estimates",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nWill discuss details of Midterm 2 next week!\nThis Problem Set 9 is our last problem set!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#fitting-elmhurst-model-by-hand",
    "href": "slides/slides-25-slr-interpretation.html#fitting-elmhurst-model-by-hand",
    "title": "SLR coefficient estimates",
    "section": "Fitting elmhurst model (by hand)",
    "text": "Fitting elmhurst model (by hand)\nLet’s obtain this coefficients by hand!\n\n\n\n\n \n  \n    variable \n    mean \n    s \n  \n \n\n  \n    family_income \n    101.78 \n    63.21 \n  \n  \n    gift_aid \n    19.94 \n    5.46 \n  \n\n\n\n\n\n\nR <- cor(elmhurst$family_income, elmhurst$gift_aid)\nR\n\n[1] -0.4985561\n\n\n\nWhat does this value of \\(R\\) tell us?\n\n\n\n\n\n\n\n\nSet-up the calculations:\n\n\\(b_{1} = \\frac{s_{y}}{s_{x}} R\\)\n\\(b_{0} = \\bar{y} -b_{1} \\bar{x}\\)\n\n\n\n\n\n\\(b_{1} = \\frac{5.461}{63.206} \\times -0.499 = -0.043\\)\n\\(b_{0} = 19.936 - -0.043 \\times 101.779 = 24.319\\)\nWrite out the fitted model!"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#intercept-in-elmhurst-model",
    "href": "slides/slides-25-slr-interpretation.html#intercept-in-elmhurst-model",
    "title": "SLR coefficient estimates",
    "section": "Intercept in elmhurst model",
    "text": "Intercept in elmhurst model\n\\[\n\\widehat{\\text{gift aid}} = 24.319 + -0.043 \\times \\text{income}\n\\]\n\nInterpretation of intercept: for a family with an income of $0, the expected gift aid would be $2.4319^{4}\nThe intercept’s interpretation only makes sense when a value of \\(x=0\\) is plausible!\n\nThis is typically not the case/relevant in many applications (though it is here!)"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#slope-in-elmhurst-model",
    "href": "slides/slides-25-slr-interpretation.html#slope-in-elmhurst-model",
    "title": "SLR coefficient estimates",
    "section": "Slope in elmhurst model",
    "text": "Slope in elmhurst model\n\\[\n\\widehat{\\text{gift aid}} = 24.319 + -0.043 \\times \\text{income}\n\\]\n\nInterpretation in context: for every $1000 increase in a family’s income, we expect that the gift aid the student receives will decrease by about $-43"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#running-slr-in-r",
    "href": "slides/slides-25-slr-interpretation.html#running-slr-in-r",
    "title": "SLR coefficient estimates",
    "section": "Running SLR in R",
    "text": "Running SLR in R\nWe run the model in R, and the output looks something like this:\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    24.319 \n    1.291 \n    18.831 \n    0 \n  \n  \n    family_income \n    -0.043 \n    0.011 \n    -3.985 \n    0 \n  \n\n\n\n\n\n\nThe estimates \\(b_{0}\\) and \\(b_{1}\\) are shown in the second column\n\nWe will use the other columns for HTs and CIs!\n\nWe can also easily add the fitted SLR line to a ggplot:\n\n\n\n\n\nggplot(elmhurst, aes(x = family_income, \n                     y = gift_aid)) +\n  geom_point() +\n  labs(x = \"Family income ($1000s)\", \n       y = \"Gift aid ($1000s)\", \n       caption = \"Least squares line\") +\n  geom_smooth(method = \"lm\", se = F)"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#describing-strength-the-fit",
    "href": "slides/slides-25-slr-interpretation.html#describing-strength-the-fit",
    "title": "SLR coefficient estimates",
    "section": "Describing strength the fit",
    "text": "Describing strength the fit\nIf we fit a model and determine LINE was met, we still need a way to describe how “good” the fit is!\n\nRecall sample correlation \\(R\\) describes the linear relationship between variables \\(x\\) and \\(y\\)\nWe typically use the coefficient of determination or \\(R^2\\) (R-squared) to describe strength of linear fit of a model\n\nDescribes amount of variation in \\(y\\) that is explained by predictor \\(x\\) in the least squares line\n\nIt turns out that \\(R^2\\) in SLR is exactly … \\(R\\) squared (i.e. the square of the sample correlation)\n\n\nWhat are the possible values of \\(R^2\\)? What are desirable values of \\(R^2\\)?"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#recap",
    "href": "slides/slides-25-slr-interpretation.html#recap",
    "title": "SLR coefficient estimates",
    "section": "Recap",
    "text": "Recap\n\nLinear regression: statistical method where the relationship between variable \\(x\\) and variable \\(y\\) is modeled as a line + error:\n\n\n\\[\ny = \\underbrace{\\beta_{0} + \\beta_{1} x}_{\\text{line}} + \\underbrace{\\epsilon}_{\\text{error}}\n\\]\n\n\n\\(\\beta_{0}\\) and \\(\\beta_{1}\\) are population parameters and their corresponding point estimates \\(b_{0}\\) and \\(b_{1}\\) are estimated from the data\nFitted model: \\(\\hat{y} = b_{0} + b_{1}x\\)\nResidual: \\(e_{i} = y_{i}-\\hat{y}_{i}\\)\nLINE conditions: Linearity, Independence, Normal residuals, Equal variance"
  },
  {
    "objectID": "slides/slides-25-slr-interpretation.html#remarks",
    "href": "slides/slides-25-slr-interpretation.html#remarks",
    "title": "SLR coefficient estimates",
    "section": "Remarks",
    "text": "Remarks\n\nWhen \\(x\\) is categorical, mathematical meaning for \\(b_{0}\\) and \\(b_{1}\\) are the same as for numerical \\(x\\), but they have more specific/nuanced interpretations when placed in context\nWhen \\(x\\) is categorical, SLR is a bit “overkill” (you’ll explore this in homework)\n\nAs we’ll see next week, the more interest things happen when we have more than one predictor in the model!"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#housekeeping",
    "href": "slides/slides-26-slr-inference.html#housekeeping",
    "title": "Inference in SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nMidterm 2 is one week from today (in class)\n\nContent through this week is fair game for midterm\nPractice problems to be released over the weekend"
  },
  {
    "objectID": "slides/slides-26-slr-inference.html#housekeeping-1",
    "href": "slides/slides-26-slr-inference.html#housekeeping-1",
    "title": "Inference in SLR",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nMidterm 2 is one week from today (in class)\n\nContent through this week is fair game for midterm\nPractice problems to be released over the weekend"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#housekeeping",
    "href": "slides/slides-27-mlr-intro.html#housekeeping",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nStudy for midterm!\nToday’s content will not be assessed on midterm, but might be useful for your final project and future coursework!"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data",
    "href": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Voice shimmer and jitter data",
    "text": "Voice shimmer and jitter data\nRecall the data from a previous problem set about voice jitter and shimmer among patients with and without Parkinson’s Disease (PD).\n\n\n\nThe variables in the dataset are as follows:\n\n\nclip: ID of the recording\njitter: a measure of variation in fundamental frequency\nshimmer: a measure of variation in amplitude\nhnr: a ratio of total components vs. noise in the voice recording\nstatus: PD vs. Healthy\navg.f.q: 1, 2, or 3, corresponding to average vocal fundamental frequency (1 = low, 2 = mid, 3 = high)"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#analysis-goal",
    "href": "slides/slides-27-mlr-intro.html#analysis-goal",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Analysis goal",
    "text": "Analysis goal\nWant to understand what might help explain the voice shimmer of a patient with low vocal fundamental frequency.\n\n\n\n\n\n\n\n\n\n\nWhat do you notice about how shimmer relates to hnr, jitter, and status?\n\nCan we somehow incorporate all the predictors into the same model for shimmer? Do you think we need to?"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#multiple-linear-regression-1",
    "href": "slides/slides-27-mlr-intro.html#multiple-linear-regression-1",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nWe have seen simple linear regression, where we had one explanatory variable\nExtend to include multiple explanatory variables\n\nSeems natural: usually several factors affect behavior of phenomena\n\nMultiple linear regression takes the form: \\[y = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\ldots + \\beta_{p} x_{p} + \\epsilon\\]\n\nNow there are \\(p\\) different explanatory variables \\(x_{1},\\ldots, x_{p}\\) per observation\nStill one response \\(y\\) and error \\(\\epsilon\\) per observation\n\nRepresents a holistic approach for modeling all of the variables simultaneously"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#pd-data-cont.",
    "href": "slides/slides-27-mlr-intro.html#pd-data-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "PD data (cont.)",
    "text": "PD data (cont.)\nLet’s start off by building a model that does not include status, as the EDA didn’t seem to show a strong relationship between status and shimmer.\n\nOur multiple linear regression model is:\n\\[\\text{shimmer} = \\beta_{0} + \\beta_{1} \\text{hnr} + \\beta_{2} \\text{jitter} + \\epsilon\\]\nJust as in the case of SLR, the estimates of \\(\\beta_{0}, \\beta_{1}, \\beta_{2}\\) parameters are chosen via the least squares criterion"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#multiple-regression-in-r",
    "href": "slides/slides-27-mlr-intro.html#multiple-regression-in-r",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Multiple regression in R",
    "text": "Multiple regression in R\nVery easy to code:\n\nshimmer_lm <- lm(shimmer ~ hnr + jitter, data = pd)\ntidy(shimmer_lm)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.732 \n    0.091 \n    8.022 \n    0.0e+00 \n  \n  \n    hnr \n    -0.025 \n    0.004 \n    -7.066 \n    0.0e+00 \n  \n  \n    jitter \n    13.467 \n    2.574 \n    5.232 \n    1.2e-06 \n  \n\n\n\n\n\n\nSimply identify the estimated coefficients from the output to obtain fitted model\n\nTry writing down the fitted model\n\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{shimmer}} &= 0.732  -0.025 \\text{hnr}+ 13.467 \\text{jitter}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-of-intercept",
    "href": "slides/slides-27-mlr-intro.html#interpretation-of-intercept",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation of intercept",
    "text": "Interpretation of intercept\n\nInterpretation of the estimated intercept \\(b_{0}\\) in MLR is very similar to SLR!\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{shimmer}} &= 0.732  -0.025 \\text{hnr} + 13.467 \\text{jitter}\n\\end{align*}\n\\]\n\n\n\nTry interpreting the intercept!\n\nWe simply plug in 0 for all the explanatory variables\n\nThe estimated voice shimmer of a patient with 0 hnr and 0 voice jitter is 0.732."
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-of-non-intercept",
    "href": "slides/slides-27-mlr-intro.html#interpretation-of-non-intercept",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation of non-intercept",
    "text": "Interpretation of non-intercept\n\nWhen we have more than one predictor variable, interpretation of the coefficients requires a bit of care\n\nMultiple moving parts\n\nInterpretation of a particular non-intercept coefficient \\(b_{k}\\) relies on “holding the other variables fixed/constant” (assuming the model is appropriate)\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{shimmer}} &= 0.732  -0.025 \\text{hnr} + 13.467 \\text{jitter}\n\\end{align*}\n\\]\n\n\nFor every one unit increase in a person’s HNR, their voice shimmer is expected/estimated to \\(\\color{orange}{\\text{decrease by } 0.025}\\), holding their voice jitter value constant\n\nInterpret the coefficient associated with jitter"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-on-non-intercept-cont.",
    "href": "slides/slides-27-mlr-intro.html#interpretation-on-non-intercept-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation on non-intercept (cont.)",
    "text": "Interpretation on non-intercept (cont.)\n\\[\n\\begin{align*}\n\\widehat{\\text{shimmer}} &= 0.732  -0.025 \\text{hnr} 13.467 \\text{jitter}\n\\end{align*}\n\\]\n\nFor every one unit increase in a patient’s voice jitter, their voice shimmer is expected to \\(\\color{orange}{\\text{increase by } 13.467}\\) units, holding their HNR value constant"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#more-isnt-always-better",
    "href": "slides/slides-27-mlr-intro.html#more-isnt-always-better",
    "title": "Introduction to Multiple Linear Regression",
    "section": "More isn’t always better",
    "text": "More isn’t always better\n\nYou might be tempted to throw in all available predictors into your model! Don’t fall into temptation!\nQuality over quantity\nFor SLR, we used the coefficient of determination \\(R^2\\) to assess how good the model was\n\n\\(R^2\\) is less helpful when there are many variables\nWhy? The \\(R^2\\) will never decrease (and will almost always increase) when we include an additional predictor"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#adjusted-r2",
    "href": "slides/slides-27-mlr-intro.html#adjusted-r2",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nFor multiple linear regression, we use the adjusted \\(R^2\\) to assess the quality of model fit\n\n“Adjusted” for the presence of additional predictors\nTake STAT 211 to learn the formula and intuition behind it!\n\nAdjusted \\(R^2\\) is always less than \\(R^2\\), and doesn’t have a nice interpretation\nWhen choosing between models, one method is to choose the one with highest adjusted \\(R^2\\)"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#adjusted-r2-cont.",
    "href": "slides/slides-27-mlr-intro.html#adjusted-r2-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Adjusted \\(R^2\\) (cont.)",
    "text": "Adjusted \\(R^2\\) (cont.)\n\n\n\nsummary(shimmer_lm)\n\n\nCall:\nlm(formula = shimmer ~ hnr + jitter, data = pd)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.182276 -0.047886 -0.007739  0.029861  0.236647 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.732203   0.091279   8.022 5.89e-12 ***\nhnr         -0.024795   0.003509  -7.066 4.54e-10 ***\njitter      13.466902   2.573728   5.232 1.23e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.07437 on 83 degrees of freedom\nMultiple R-squared:  0.807, Adjusted R-squared:  0.8024 \nF-statistic: 173.5 on 2 and 83 DF,  p-value: < 2.2e-16\n\n\n\n\nglance(shimmer_lm)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.807 \n    0.8024 \n    0.0744 \n    173.5385 \n    0 \n    2 \n    102.9875 \n    -197.975 \n    -188.1576 \n    0.4591 \n    83 \n    86"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#conditions-for-inference",
    "href": "slides/slides-27-mlr-intro.html#conditions-for-inference",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Conditions for inference",
    "text": "Conditions for inference\nWe still need LINE to hold\n\nLinearity: harder to assess now that multiple predictors are involved. Good idea to make several scatter plots\nIndependence: same as before\nNearly normal residuals: same as before\nEqual variance: residual plot has fitted values \\(\\hat{y}\\) on the x-axis"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#hypothesis-testing-in-mlr",
    "href": "slides/slides-27-mlr-intro.html#hypothesis-testing-in-mlr",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis testing in MLR",
    "text": "Hypothesis testing in MLR\n\nIn MLR, we are interested in the effect of each predictor variable on the response \\(y\\).\n\nNeed to account for presence of other predictors in the model\n\n\\(H_{0}: \\beta_{k} = 0\\), given other predictors in the model\n\\(H_{A}: \\beta_{k} \\neq 0\\), given other predictors in the model (or \\(>, <\\))\nWe can write down one null hypothesis for each coefficient in the model"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm",
    "href": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm()",
    "text": "Hypothesis tests from lm()\n\\[\\text{shimmer} = \\beta_{0} + \\beta_{1} \\text{hnr} + \\beta_{2} \\text{jitter} + \\epsilon\\]\nWe can test the following null hypotheses (no need to write down):\n\n\\(H_{0}: \\beta_{1} = 0\\), given jitter is included in the model\n\ni.e. HNR has no effect on shimmer once we account for jitter\n\n\\(H_{0}: \\beta_{2} = 0\\), given HNR is included in the model"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm-1",
    "href": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm-1",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm()",
    "text": "Hypothesis tests from lm()\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.73 \n    0.091 \n    8.022 \n    0.0e+00 \n  \n  \n    hnr \n    -0.02 \n    0.004 \n    -7.066 \n    0.0e+00 \n  \n  \n    jitter \n    13.47 \n    2.574 \n    5.232 \n    1.2e-06 \n  \n\n\n\n\n\n\nOutput from lm() provides:\n\nTest statistic, which follows \\(t_{n-p}\\) where \\(p =\\) total number of unknown parameters (i.e. \\(\\beta\\) terms)\np-values for testing two-sided \\(H_{A}\\) provided\n\n\n\n\nBased on the model fit, which variables seem to be important predictors of voice shimmer? Why?"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm-cont.",
    "href": "slides/slides-27-mlr-intro.html#hypothesis-tests-from-lm-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Hypothesis tests from lm() (cont.)",
    "text": "Hypothesis tests from lm() (cont.)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.732 \n    0.091 \n    8.022 \n    0.0e+00 \n  \n  \n    hnr \n    -0.025 \n    0.004 \n    -7.066 \n    0.0e+00 \n  \n  \n    jitter \n    13.467 \n    2.574 \n    5.232 \n    1.2e-06 \n  \n\n\n\n\n\n\nHNR does seem to be an important predictor for voice shimmer, even when including jitter in the model\n\nLow p-value suggests it would be extremely unlikely to see data that produce \\(b_{1} = -0.025\\) if the true relationship between shimmer and HNR was non-existent (i.e., if \\(\\beta_{1} = 0\\)) and the model also included jitter\n\nJitter does seem to be an important predictor, even when including HNR in the model"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#more-complex-model",
    "href": "slides/slides-27-mlr-intro.html#more-complex-model",
    "title": "Introduction to Multiple Linear Regression",
    "section": "More complex model",
    "text": "More complex model\nLet’s see a model that now includes the status of the patient as a predictor:\n\nshimmer_lm2 <- lm(shimmer ~ hnr + jitter + status, data = pd)\ntidy(shimmer_lm2)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.688 \n    0.103 \n    6.668 \n    0.0000000 \n  \n  \n    hnr \n    -0.024 \n    0.004 \n    -6.273 \n    0.0000000 \n  \n  \n    jitter \n    13.662 \n    2.585 \n    5.285 \n    0.0000010 \n  \n  \n    statusPD \n    0.020 \n    0.022 \n    0.915 \n    0.3628131 \n  \n\n\n\n\n\n\nRemember, status is categorical with two levels. lm() converted to indicator variable for us: statusPD = 1 when status = \"PD\"\n\n\n\nWrite out the fitted model."
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-with-categorical-variable",
    "href": "slides/slides-27-mlr-intro.html#interpretation-with-categorical-variable",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation with categorical variable",
    "text": "Interpretation with categorical variable\n\\[\n\\widehat{\\text{shimmer}} = 0.688 -0.024 \\text{hnr} + 13.662 \\text{jitter} + 0.02 \\text{statusPD}\n\\]\n\n\nTry interpreting the intercept here!\n\nWhat does it mean for the explanatory variables to be 0? It means hnr = 0, jitter = 0, and the patient does not have PD\n\nA “healthy” patient with HNR and jitter values of 0 is estimated to have a voice shimmer of 0.688"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-of-slope-coefficients",
    "href": "slides/slides-27-mlr-intro.html#interpretation-of-slope-coefficients",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation of slope coefficients",
    "text": "Interpretation of slope coefficients\n\\[\n\\widehat{shimmer} = 0.688  -0.024 \\text{hnr} + 13.662 \\text{jitter} + 0.02 \\text{statusPD}\n\\]\n\nTry interpreting the coefficients of hnr, jitter, and statusPD. Remember the special wording/acknowledgement now that we are in MLR world!\n\n\nCoefficient for hnr: for every one unit increase in HNR, we expect the patient’s shimmer to decrease by 0.024 units, holding the other variables (jitter and status) constant.\nCoefficient for jitter: for every one unit increase in jitter, we expect the patient’s shimmer to increase by 13.662 units, holding the other variables constant.\nCoefficient for statusPD: patients with PD are estimated to have a voice shimmer 0.02 units higher than patients without PD, holding the other variables constant"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#effect-of-status",
    "href": "slides/slides-27-mlr-intro.html#effect-of-status",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Effect of status",
    "text": "Effect of status\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.688 \n    0.103 \n    6.668 \n    0.0000000 \n  \n  \n    hnr \n    -0.024 \n    0.004 \n    -6.273 \n    0.0000000 \n  \n  \n    jitter \n    13.662 \n    2.585 \n    5.285 \n    0.0000010 \n  \n  \n    statusPD \n    0.020 \n    0.022 \n    0.915 \n    0.3628131 \n  \n\n\n\n\n\n\nBased off the model output, does it appear that status is an important predictor of a patient’s voice shimmer? Why or why not? What about the other two variables hnr and jitter?"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#comparing-models",
    "href": "slides/slides-27-mlr-intro.html#comparing-models",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Comparing models",
    "text": "Comparing models\nLet’s compare the two models:\n\n\n\ntidy(shimmer_lm) |>\n  select(term, estimate, p.value)\n\n\n\n\n\n \n  \n    term \n    estimate \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.732 \n    0e+00 \n  \n  \n    hnr \n    -0.025 \n    0e+00 \n  \n  \n    jitter \n    13.467 \n    1e-06 \n  \n\n\n\n\n\n\nglance(shimmer_lm)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.807 \n    0.8024 \n    0.0744 \n    173.5385 \n    0 \n    2 \n    102.9875 \n    -197.975 \n    -188.1576 \n    0.4591 \n    83 \n    86 \n  \n\n\n\n\n\n\n\ntidy(shimmer_lm2) |>\n  select(term, estimate, p.value)\n\n\n\n\n\n \n  \n    term \n    estimate \n    p.value \n  \n \n\n  \n    (Intercept) \n    0.688 \n    0.000000 \n  \n  \n    hnr \n    -0.024 \n    0.000000 \n  \n  \n    jitter \n    13.662 \n    0.000001 \n  \n  \n    statusPD \n    0.020 \n    0.362813 \n  \n\n\n\n\n\n\nglance(shimmer_lm2)\n\n\n\n\n\n \n  \n    r.squared \n    adj.r.squared \n    sigma \n    statistic \n    p.value \n    df \n    logLik \n    AIC \n    BIC \n    deviance \n    df.residual \n    nobs \n  \n \n\n  \n    0.809 \n    0.802 \n    0.0744 \n    115.7449 \n    0 \n    3 \n    103.4244 \n    -196.8488 \n    -184.5771 \n    0.4544 \n    82 \n    86 \n  \n\n\n\n\n\n\n\n\nWhat do you notice about the estimated coefficients, \\(R^2\\), and adjusted \\(R^2\\) across the two models?"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#remarks",
    "href": "slides/slides-27-mlr-intro.html#remarks",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Remarks",
    "text": "Remarks\n\nWe have only scratched the surface of MLR\nThings to consider (beyond our course):\n\nMulticollinearity (when the predictor variables are correlated with each other)\nModel selection\nMore than one categorical variable\nInteraction effects"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data-.incrementalfalse",
    "href": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data-.incrementalfalse",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Voice shimmer and jitter data {.incremental=“false”}",
    "text": "Voice shimmer and jitter data {.incremental=“false”}\nRecall the data from a previous problem set about voice jitter and shimmer among patients with and without Parkinson’s Disease (PD).\n\n\n\nThe variables in the dataset are as follows:\n\nclip: ID of the recording\njitter: a measure of variation in fundamental frequency\nshimmer: a measure of variation in amplitude\nhnr: a ratio of total components vs. noise in the voice recording\nstatus: PD vs. Healthy\navg.f.q: 1, 2, or 3, corresponding to average vocal fundamental frequency (1 = low, 2 = mid, 3 = high)"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data-.incrementalf",
    "href": "slides/slides-27-mlr-intro.html#voice-shimmer-and-jitter-data-.incrementalf",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Voice shimmer and jitter data {.incremental=F}",
    "text": "Voice shimmer and jitter data {.incremental=F}\nRecall the data from a previous problem set about voice jitter and shimmer among patients with and without Parkinson’s Disease (PD).\n\n\n\nThe variables in the dataset are as follows:\n\nclip: ID of the recording\njitter: a measure of variation in fundamental frequency\nshimmer: a measure of variation in amplitude\nhnr: a ratio of total components vs. noise in the voice recording\nstatus: PD vs. Healthy\navg.f.q: 1, 2, or 3, corresponding to average vocal fundamental frequency (1 = low, 2 = mid, 3 = high)"
  },
  {
    "objectID": "slides/handout-27-mlr-intro.html",
    "href": "slides/handout-27-mlr-intro.html",
    "title": "Multiple Linear Regression (MLR)",
    "section": "",
    "text": "Want to understand what might help explain the voice shimmer of a patient with low vocal fundamental frequency."
  },
  {
    "objectID": "slides/handout-27-mlr-intro.html#model-1",
    "href": "slides/handout-27-mlr-intro.html#model-1",
    "title": "Multiple Linear Regression (MLR)",
    "section": "Model 1",
    "text": "Model 1\nMultiple linear regression model: \n\nshimmer_lm <- lm(shimmer ~ hnr + jitter, data = pd) \n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.732\n0.091\n8.022\n0.0e+00\n\n\nhnr\n-0.025\n0.004\n-7.066\n0.0e+00\n\n\njitter\n13.467\n2.574\n5.232\n1.2e-06\n\n\n\n\n\nFitted model: \nInterpretation of:\n\nIntercept: \nRemaining coefficients: \n\nModel 1 fit\n\n\n\n\n\nr.squared\nadj.r.squared\n\n\n\n\n0.807\n0.8024\n\n\n\n\n\nConditions\n\n\n\n\n\n\n\n\n\n\n\n\nInference\n\nHypotheses: \nWhich variables seem to be associated with shimmer? Why?"
  },
  {
    "objectID": "slides/handout-27-mlr-intro.html#model-2",
    "href": "slides/handout-27-mlr-intro.html#model-2",
    "title": "Multiple Linear Regression (MLR)",
    "section": "Model 2",
    "text": "Model 2\nLet’s see a model that now includes the status of the patient as a predictor:\n\nshimmer_lm2 <- lm(shimmer ~ hnr + jitter + status, data = pd)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.688\n0.103\n6.668\n0.0000000\n\n\nhnr\n-0.024\n0.004\n-6.273\n0.0000000\n\n\njitter\n13.662\n2.585\n5.285\n0.0000010\n\n\nstatusPD\n0.020\n0.022\n0.915\n0.3628131\n\n\n\n\n\nFitted model: \nInterpretation of:\n\nIntercept: \nRemaining coefficients: \n\nModel 2 fit\n\n\n\n\n\nr.squared\nadj.r.squared\n\n\n\n\n0.807\n0.8024\n\n\n\n\n\nWhich model seems “better”, and why?"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html",
    "href": "slides/slides-27-mlr-intro.html",
    "title": "Introduction to Multiple Linear Regression",
    "section": "",
    "text": "Study for midterm!\nToday’s content will not be assessed on midterm, but might be useful for your final project and future coursework!"
  },
  {
    "objectID": "slides/slides-27-mlr-intro.html#interpretation-of-non-intercept-cont.",
    "href": "slides/slides-27-mlr-intro.html#interpretation-of-non-intercept-cont.",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpretation of non-intercept (cont.)",
    "text": "Interpretation of non-intercept (cont.)\n\\[\n\\begin{align*}\n\\widehat{\\text{shimmer}} &= 0.732  -0.025 \\text{hnr} + 13.467 \\text{jitter}\n\\end{align*}\n\\]\n\nFor every one unit increase in a patient’s voice jitter, their voice shimmer is expected to \\(\\color{orange}{\\text{increase by } 13.467}\\) units, holding their HNR value constant"
  },
  {
    "objectID": "slides/slides-28-project.html#housekeeping",
    "href": "slides/slides-28-project.html#housekeeping",
    "title": "Final project",
    "section": "Housekeeping",
    "text": "Housekeeping\n\n\n\n\nPlease sit with your final project group this week!\nOffice hours + additional 1:1 meetings available"
  },
  {
    "objectID": "slides/slides-28-project.html#final-report-requirements",
    "href": "slides/slides-28-project.html#final-report-requirements",
    "title": "Final project",
    "section": "Final report: Requirements",
    "text": "Final report: Requirements\nReview the Report components on the Project description page."
  },
  {
    "objectID": "slides/slides-28-project.html#qmd-template",
    "href": "slides/slides-28-project.html#qmd-template",
    "title": "Final project",
    "section": ".qmd template",
    "text": ".qmd template\nI have provided you with a .qmd template for the final project. Feel free to add to/modify the template as your group sees fit!\n\nPlease ensure your .qmd is in your STAT 201 folder\nThen, have a copy of your working dataset as a .csv file located in the same STAT 201 folder"
  },
  {
    "objectID": "slides/slides-28-project.html#data-file",
    "href": "slides/slides-28-project.html#data-file",
    "title": "Final project",
    "section": "Data file",
    "text": "Data file\n\nIn your group, everyone should have the same file name for the data.\nNow modify the second code chunk in the template to read in your data:\n\n\n\nNote: name the variable whatever you like (i.e. not need to use my_data, so long as your group is consistent.\n\n\nIf you prefer to use a .xlsx file, you will need to load the readxl package at the top of the document (may need to install first) and then modify the code to\n\n\n\nmy_data <- read_xlsx(\"data_file_name.xlsx\")"
  },
  {
    "objectID": "slides/slides-28-project.html#r-chunk-headers",
    "href": "slides/slides-28-project.html#r-chunk-headers",
    "title": "Final project",
    "section": "R chunk headers",
    "text": "R chunk headers\n\n\nIn .qmd documents, we can control the behavior of specific code chunks by changing the settings in the chunk header:\n\n\n\n\n\n\n\nFor example, setting the option eval = F in the code chunk header means “do not evaluate the code in this chunk”.\n\n\n\n\nCode:\n\n\n\n\nOutput:"
  },
  {
    "objectID": "slides/slides-28-project.html#hiding-code",
    "href": "slides/slides-28-project.html#hiding-code",
    "title": "Final project",
    "section": "Hiding code",
    "text": "Hiding code\nWe can hide code from the viewer but still have it execute using the echo setting.\n\n\nCode:\n\n\n\nOutput:\n\n\n\n\n\n\n\nCode:\n\n\n\n\nOutput:"
  },
  {
    "objectID": "slides/slides-28-project.html#working-methods",
    "href": "slides/slides-28-project.html#working-methods",
    "title": "Final project",
    "section": "Working methods",
    "text": "Working methods\n\nCollaborative working styles:\n\nPhysically work together on the same .qmd document\nWork on separate .qmd documents and then share code with each other (e.g. via a Googledoc) to compile one master .qmd\nA combination of the above two as the project comes together\n\nRecommendations:\n\nClear your environment before running new, shared code\nRender often"
  },
  {
    "objectID": "slides/slides-28-project.html#cleaning-your-data",
    "href": "slides/slides-28-project.html#cleaning-your-data",
    "title": "Final project",
    "section": "Cleaning your data",
    "text": "Cleaning your data\n\nYou might need to clean your data before working with it. This is probably most easily achieved within GoogleSheets or Excel rather than in R.\n\nE.g. a data entry is “6.4 hours” instead of 6.4, or there is inconsistent capitalization\n\nOnce/if your group has cleaned the data, you should replace the old data file in your STAT 201 folder with the cleaned version."
  },
  {
    "objectID": "slides/slides-28-project.html#due-dates",
    "href": "slides/slides-28-project.html#due-dates",
    "title": "Final project",
    "section": "Due dates",
    "text": "Due dates\n\nRough draft of report due Sunday, 5/11 at 11:59pm\n\nThis is low stakes in the sense that it will be graded on a good faith effort\nYour group will identify one-two sections of your report you would like feedback on!\n\nFinal presentations will take place on exam day Thursday, 5/15 from 9:00am-12:00pm\n\nSlides + preliminary results\n\nFinal reports due Sunday, 12/18 at 11:59pm (tentative)"
  },
  {
    "objectID": "project/stat201_final_project.html#introduction",
    "href": "project/stat201_final_project.html#introduction",
    "title": "STAT 201: Final Project Report Template",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "project/stat201_final_project.html#data-collection",
    "href": "project/stat201_final_project.html#data-collection",
    "title": "STAT 201: Final Project Report Template",
    "section": "Data Collection",
    "text": "Data Collection"
  },
  {
    "objectID": "project/stat201_final_project.html#methods",
    "href": "project/stat201_final_project.html#methods",
    "title": "STAT 201: Final Project Report Template",
    "section": "Methods",
    "text": "Methods"
  },
  {
    "objectID": "project/stat201_final_project.html#results",
    "href": "project/stat201_final_project.html#results",
    "title": "STAT 201: Final Project Report Template",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "project/stat201_final_project.html#discussion",
    "href": "project/stat201_final_project.html#discussion",
    "title": "STAT 201: Final Project Report Template",
    "section": "Discussion",
    "text": "Discussion"
  }
]